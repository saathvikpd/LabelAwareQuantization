{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4600c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4fc390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 subsets and saved to ./subsets.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def generate_subset(n_classes, dist_matrix_path=\"./cifar100_kl_div_matrix.npy\", class_names_path=\"./cifar100_class_names.npy\"):\n",
    "    assert n_classes > 1, \"Number of classes must be greater than 1.\"\n",
    "\n",
    "    # Load the KL divergence matrix and class names\n",
    "    kls_cf_matrix = np.load(dist_matrix_path)\n",
    "    class_names = np.load(class_names_path)\n",
    "\n",
    "    # Initialize a random starting class\n",
    "    rand_class_ind = np.random.randint(0, class_names.shape[0])\n",
    "    selected_classes = {rand_class_ind}\n",
    "\n",
    "    # Iteratively select classes to minimize variance in pairwise distances\n",
    "    for _ in range(n_classes - 1):\n",
    "        # Compute the pairwise distances for the current subset\n",
    "        subset_dists = []\n",
    "        for i in range(len(selected_classes)):\n",
    "            for j in range(i + 1, len(selected_classes)):\n",
    "                subset_dists.append(kls_cf_matrix[list(selected_classes)[i], list(selected_classes)[j]])\n",
    "\n",
    "        # Compute the average distance in the current subset\n",
    "        avg_dist = np.mean(subset_dists)\n",
    "\n",
    "        # Find the next class that minimizes the variance in pairwise distances\n",
    "        min_variance = float('inf')\n",
    "        best_class = -1\n",
    "\n",
    "        for candidate_class in range(class_names.shape[0]):\n",
    "            if candidate_class not in selected_classes:\n",
    "                # Compute the new pairwise distances if this candidate is added\n",
    "                new_dists = subset_dists.copy()\n",
    "                for selected_class in selected_classes:\n",
    "                    new_dists.append(kls_cf_matrix[selected_class, candidate_class])\n",
    "\n",
    "                # Compute the variance of the new distances\n",
    "                new_variance = np.var(new_dists)\n",
    "\n",
    "                # Update the best candidate if this one has lower variance\n",
    "                if new_variance < min_variance:\n",
    "                    min_variance = new_variance\n",
    "                    best_class = candidate_class\n",
    "\n",
    "        # Add the best candidate to the subset\n",
    "        selected_classes.add(best_class)\n",
    "\n",
    "    selected_classes = list(selected_classes)\n",
    "\n",
    "    # Compute distances for the subset\n",
    "    subset_dists = []\n",
    "    for i in range(len(selected_classes)):\n",
    "        for j in range(i + 1, len(selected_classes)):\n",
    "            subset_dists.append(kls_cf_matrix[selected_classes[i], selected_classes[j]])\n",
    "\n",
    "    return {\n",
    "        \"classes\": selected_classes,\n",
    "        \"max_dist\": max(subset_dists),\n",
    "        \"avg_dist\": np.mean(subset_dists),\n",
    "        \"variance_dist\": np.var(subset_dists),\n",
    "    }\n",
    "\n",
    "def generate_multiple_subsets(n_subsets, n_classes, dist_matrix_path, class_names_path):\n",
    "    results = []\n",
    "    for _ in range(n_subsets):\n",
    "        result = generate_subset(n_classes, dist_matrix_path, class_names_path)\n",
    "\n",
    "        # Convert numpy types to native Python types\n",
    "        result[\"classes\"] = [int(c) for c in result[\"classes\"]]\n",
    "        result[\"max_dist\"] = float(result[\"max_dist\"])\n",
    "        result[\"avg_dist\"] = float(result[\"avg_dist\"])\n",
    "        result[\"variance_dist\"] = float(result[\"variance_dist\"])\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if running in an interactive environment\n",
    "    if sys.argv[0].endswith(\"ipykernel_launcher.py\"):\n",
    "        # Default arguments for interactive use\n",
    "        n_subsets = 10\n",
    "        n_classes = 5\n",
    "        dist_matrix_path = \"./cifar100_kl_div_matrix.npy\"\n",
    "        class_names_path = \"./cifar100_class_names.npy\"\n",
    "        output_path = \"./subsets.json\"\n",
    "    else:\n",
    "        # Command-line arguments\n",
    "        parser = argparse.ArgumentParser(description=\"Generate multiple subsets of CIFAR-100 classes with equal distances.\")\n",
    "        parser.add_argument(\"--n_subsets\", type=int, required=True, help=\"Number of subsets to generate.\")\n",
    "        parser.add_argument(\"--n_classes\", type=int, required=True, help=\"Number of classes in each subset.\")\n",
    "        parser.add_argument(\"--dist_matrix_path\", type=str, default=\"./cifar100_kl_div_matrix.npy\", help=\"Path to KL divergence matrix.\")\n",
    "        parser.add_argument(\"--class_names_path\", type=str, default=\"./cifar100_class_names.npy\", help=\"Path to class names file.\")\n",
    "        parser.add_argument(\"--output_path\", type=str, required=True, help=\"Path to save the generated subsets.\")\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        n_subsets = args.n_subsets\n",
    "        n_classes = args.n_classes\n",
    "        dist_matrix_path = args.dist_matrix_path\n",
    "        class_names_path = args.class_names_path\n",
    "        output_path = args.output_path\n",
    "\n",
    "    # Generate subsets\n",
    "    subsets = generate_multiple_subsets(\n",
    "        n_subsets, n_classes, dist_matrix_path, class_names_path\n",
    "    )\n",
    "\n",
    "    # Save the subsets to a file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(subsets, f, indent=4)\n",
    "\n",
    "    print(f\"Generated {n_subsets} subsets and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e61207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
