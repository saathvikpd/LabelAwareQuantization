{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 668.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.64546966552734.\n",
      "The relative quantization error of layer 0 is 0.017783403396606445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 126.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 776.2818603515625.\n",
      "The relative quantization error of layer 1 is 0.044208671897649765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1151.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 240.56520080566406.\n",
      "The relative quantization error of layer 2 is 0.05393735691905022.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3375.081298828125.\n",
      "The relative quantization error of layer 3 is 0.09834781289100647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1355.83447265625.\n",
      "The relative quantization error of layer 4 is 0.046011582016944885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 67.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 545.7240600585938.\n",
      "The relative quantization error of layer 5 is 0.19376112520694733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1092.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 256.6248779296875.\n",
      "The relative quantization error of layer 6 is 0.23791871964931488.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 939.374755859375.\n",
      "The relative quantization error of layer 7 is 0.2184641808271408.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 833.4534301757812.\n",
      "The relative quantization error of layer 8 is 0.2623169422149658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 918.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 554.3295288085938.\n",
      "The relative quantization error of layer 9 is 0.2728867530822754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1435.7940673828125.\n",
      "The relative quantization error of layer 10 is 0.22668980062007904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:08<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1625.4991455078125.\n",
      "The relative quantization error of layer 11 is 0.31006309390068054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 515.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1149.89892578125.\n",
      "The relative quantization error of layer 12 is 0.29947182536125183.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1466.921142578125.\n",
      "The relative quantization error of layer 13 is 0.21396011114120483.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:30<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1912.191650390625.\n",
      "The relative quantization error of layer 14 is 0.29665929079055786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1935.9322509765625.\n",
      "The relative quantization error of layer 15 is 0.268711656332016.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2004.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 518.5234375.\n",
      "The relative quantization error of layer 16 is 0.2327100932598114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1256.160400390625.\n",
      "The relative quantization error of layer 17 is 0.4144757390022278.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 157.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1765.994140625.\n",
      "The relative quantization error of layer 18 is 0.316986083984375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1964.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 360.91546630859375.\n",
      "The relative quantization error of layer 19 is 0.26429855823516846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1229.5631103515625.\n",
      "The relative quantization error of layer 20 is 0.3111915588378906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1965.4537353515625.\n",
      "The relative quantization error of layer 21 is 0.3455166518688202.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2049.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 438.8128967285156.\n",
      "The relative quantization error of layer 22 is 0.29139500856399536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 42.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 940.1793212890625.\n",
      "The relative quantization error of layer 23 is 0.39435121417045593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:06<00:00, 73.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3226.4755859375.\n",
      "The relative quantization error of layer 24 is 0.3688076138496399.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 981.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 633.326416015625.\n",
      "The relative quantization error of layer 25 is 0.3348204791545868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 67.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1348.9918212890625.\n",
      "The relative quantization error of layer 26 is 0.3707347512245178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3386.48486328125.\n",
      "The relative quantization error of layer 27 is 0.36615321040153503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1338.5006103515625.\n",
      "The relative quantization error of layer 28 is 0.34996297955513.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3324.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.77899169921875.\n",
      "The relative quantization error of layer 29 is 0.183043971657753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 956.8047485351562.\n",
      "The relative quantization error of layer 30 is 0.4552737772464752.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1511.7650146484375.\n",
      "The relative quantization error of layer 31 is 0.3803092837333679.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3407.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.61090087890625.\n",
      "The relative quantization error of layer 32 is 0.22600175440311432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 879.4390869140625.\n",
      "The relative quantization error of layer 33 is 0.49237069487571716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 284.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1668.9735107421875.\n",
      "The relative quantization error of layer 34 is 0.43373793363571167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3302.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 242.9493865966797.\n",
      "The relative quantization error of layer 35 is 0.20867754518985748.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1012.0079956054688.\n",
      "The relative quantization error of layer 36 is 0.5289586186408997.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 234.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1756.049072265625.\n",
      "The relative quantization error of layer 37 is 0.44424358010292053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2611.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 209.20985412597656.\n",
      "The relative quantization error of layer 38 is 0.21559669077396393.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 90.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1400.2022705078125.\n",
      "The relative quantization error of layer 39 is 0.5282922387123108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 262.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1842.1240234375.\n",
      "The relative quantization error of layer 40 is 0.46005597710609436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3170.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 181.2685546875.\n",
      "The relative quantization error of layer 41 is 0.23492488265037537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1425.1866455078125.\n",
      "The relative quantization error of layer 42 is 0.5582507252693176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:10<00:00, 97.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2591.41162109375.\n",
      "The relative quantization error of layer 43 is 0.46860629320144653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:08<00:00, 529.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.31385803222656.\n",
      "The relative quantization error of layer 44 is 0.20379605889320374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 122.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 980.0164184570312.\n",
      "The relative quantization error of layer 45 is 0.45072317123413086.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:41<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2196.895263671875.\n",
      "The relative quantization error of layer 46 is 0.4708065986633301.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:20<00:00, 101.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 452.5502624511719.\n",
      "The relative quantization error of layer 47 is 0.4270804226398468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:10<00:00, 440.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 119.49333190917969.\n",
      "The relative quantization error of layer 48 is 0.12043233960866928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:09<00:00, 53.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 562.7575073242188.\n",
      "The relative quantization error of layer 49 is 0.6897441148757935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:18<00:00, 113.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 524.541748046875.\n",
      "The relative quantization error of layer 50 is 0.2965921461582184.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:17<00:00, 269.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 66.76044464111328.\n",
      "The relative quantization error of layer 51 is 0.14700211584568024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:08<00:00, 63.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 124.94536590576172.\n",
      "The relative quantization error of layer 52 is 0.8504214882850647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 6555.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 48.50029373168945.\n",
      "The relative quantization error of layer 53 is 0.2900856137275696.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:20:03.374934\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [05:15<00:00, 19.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.681.\n",
      "Top-5 accuracy of quantized resnet50 is 0.974.\n",
      "\n",
      "Time used for evaluation: 0:05:15.895206\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4521\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:01<00:00, 100.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 81.70989227294922.\n",
      "The relative quantization error of layer 0 is 0.01739463023841381.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 60.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 850.0037231445312.\n",
      "The relative quantization error of layer 1 is 0.047521572560071945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:03<00:00, 169.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 233.05426025390625.\n",
      "The relative quantization error of layer 2 is 0.050822097808122635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3758.468505859375.\n",
      "The relative quantization error of layer 3 is 0.11000832915306091.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1280.299072265625.\n",
      "The relative quantization error of layer 4 is 0.042450930923223495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:05<00:00, 47.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 591.506591796875.\n",
      "The relative quantization error of layer 5 is 0.19354981184005737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:02<00:00, 216.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 261.6175231933594.\n",
      "The relative quantization error of layer 6 is 0.2114490419626236.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1081.7672119140625.\n",
      "The relative quantization error of layer 7 is 0.21478986740112305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:05<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 869.8861083984375.\n",
      "The relative quantization error of layer 8 is 0.24371662735939026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 576.7366333007812.\n",
      "The relative quantization error of layer 9 is 0.25832170248031616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1575.6553955078125.\n",
      "The relative quantization error of layer 10 is 0.22003912925720215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:10<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1744.2557373046875.\n",
      "The relative quantization error of layer 11 is 0.2900499701499939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 500.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1177.174072265625.\n",
      "The relative quantization error of layer 12 is 0.290225625038147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1515.4134521484375.\n",
      "The relative quantization error of layer 13 is 0.21450833976268768.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:30<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1974.8702392578125.\n",
      "The relative quantization error of layer 14 is 0.27876991033554077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 155.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1925.7744140625.\n",
      "The relative quantization error of layer 15 is 0.2607696056365967.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2079.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 512.8494873046875.\n",
      "The relative quantization error of layer 16 is 0.23350338637828827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1182.802490234375.\n",
      "The relative quantization error of layer 17 is 0.3674866557121277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1830.7069091796875.\n",
      "The relative quantization error of layer 18 is 0.30247625708580017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1985.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 365.9837341308594.\n",
      "The relative quantization error of layer 19 is 0.2516019940376282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 44.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1287.7666015625.\n",
      "The relative quantization error of layer 20 is 0.31378793716430664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1959.6602783203125.\n",
      "The relative quantization error of layer 21 is 0.3176833391189575.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1968.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 441.26654052734375.\n",
      "The relative quantization error of layer 22 is 0.2730656564235687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1008.5574951171875.\n",
      "The relative quantization error of layer 23 is 0.37518319487571716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 66.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3296.333984375.\n",
      "The relative quantization error of layer 24 is 0.34955647587776184.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1009.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 589.8684692382812.\n",
      "The relative quantization error of layer 25 is 0.2920859158039093.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 109.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1343.102783203125.\n",
      "The relative quantization error of layer 26 is 0.36192837357521057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3384.9853515625.\n",
      "The relative quantization error of layer 27 is 0.3316437005996704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 282.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1354.2430419921875.\n",
      "The relative quantization error of layer 28 is 0.3236371576786041.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3161.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 274.98828125.\n",
      "The relative quantization error of layer 29 is 0.17934642732143402.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 101.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 970.999755859375.\n",
      "The relative quantization error of layer 30 is 0.4004310965538025.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1495.0411376953125.\n",
      "The relative quantization error of layer 31 is 0.3478686213493347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2811.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.6403503417969.\n",
      "The relative quantization error of layer 32 is 0.2189836949110031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 898.3057861328125.\n",
      "The relative quantization error of layer 33 is 0.4656110405921936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 231.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1688.2177734375.\n",
      "The relative quantization error of layer 34 is 0.3919447064399719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3247.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 246.03602600097656.\n",
      "The relative quantization error of layer 35 is 0.20038367807865143.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 107.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1057.5404052734375.\n",
      "The relative quantization error of layer 36 is 0.5028867125511169.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 268.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1768.1842041015625.\n",
      "The relative quantization error of layer 37 is 0.3731314539909363.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2778.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 203.1964874267578.\n",
      "The relative quantization error of layer 38 is 0.19879844784736633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 95.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1336.0025634765625.\n",
      "The relative quantization error of layer 39 is 0.5016278624534607.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 240.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1893.4315185546875.\n",
      "The relative quantization error of layer 40 is 0.4382513463497162.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2686.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 175.1667938232422.\n",
      "The relative quantization error of layer 41 is 0.20948384702205658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 93.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1470.2196044921875.\n",
      "The relative quantization error of layer 42 is 0.5333741903305054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:08<00:00, 127.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2523.68505859375.\n",
      "The relative quantization error of layer 43 is 0.4476703107357025.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1264.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 156.71987915039062.\n",
      "The relative quantization error of layer 44 is 0.1992192417383194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 201.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 919.54833984375.\n",
      "The relative quantization error of layer 45 is 0.4268774688243866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:34<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2254.703125.\n",
      "The relative quantization error of layer 46 is 0.4718843698501587.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 613.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 415.5697937011719.\n",
      "The relative quantization error of layer 47 is 0.3913230895996094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2946.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.17594146728516.\n",
      "The relative quantization error of layer 48 is 0.10368729382753372.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 225.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 547.1031494140625.\n",
      "The relative quantization error of layer 49 is 0.6788941025733948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 603.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 484.9843444824219.\n",
      "The relative quantization error of layer 50 is 0.27862870693206787.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2655.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 60.652191162109375.\n",
      "The relative quantization error of layer 51 is 0.10939576476812363.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 185.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 111.37257385253906.\n",
      "The relative quantization error of layer 52 is 0.7770408987998962.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7168.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 30.66959571838379.\n",
      "The relative quantization error of layer 53 is 0.18734614551067352.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:18:42.632644\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [03:58<00:00, 18.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.87625.\n",
      "Top-5 accuracy of quantized resnet50 is 0.98875.\n",
      "\n",
      "Time used for evaluation: 0:03:58.329569\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4586\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 631.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 76.45858001708984.\n",
      "The relative quantization error of layer 0 is 0.01823187619447708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 164.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 822.5619506835938.\n",
      "The relative quantization error of layer 1 is 0.04697589576244354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1247.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 214.77114868164062.\n",
      "The relative quantization error of layer 2 is 0.05100009962916374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3290.736083984375.\n",
      "The relative quantization error of layer 3 is 0.09778863191604614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1237.36376953125.\n",
      "The relative quantization error of layer 4 is 0.04290396347641945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 557.9832763671875.\n",
      "The relative quantization error of layer 5 is 0.1980220526456833.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 966.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 236.9168243408203.\n",
      "The relative quantization error of layer 6 is 0.22831526398658752.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 993.4666137695312.\n",
      "The relative quantization error of layer 7 is 0.22283267974853516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 72.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 805.6482543945312.\n",
      "The relative quantization error of layer 8 is 0.2576984763145447.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1290.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 532.520751953125.\n",
      "The relative quantization error of layer 9 is 0.26667287945747375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1649.9154052734375.\n",
      "The relative quantization error of layer 10 is 0.25876083970069885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1571.97265625.\n",
      "The relative quantization error of layer 11 is 0.31089791655540466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 506.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1125.156005859375.\n",
      "The relative quantization error of layer 12 is 0.2928887903690338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1435.0013427734375.\n",
      "The relative quantization error of layer 13 is 0.21023645997047424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:29<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1790.999267578125.\n",
      "The relative quantization error of layer 14 is 0.2939448654651642.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1835.226318359375.\n",
      "The relative quantization error of layer 15 is 0.2684214413166046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1998.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 485.6539611816406.\n",
      "The relative quantization error of layer 16 is 0.22850140929222107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1102.21142578125.\n",
      "The relative quantization error of layer 17 is 0.39555904269218445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1701.1092529296875.\n",
      "The relative quantization error of layer 18 is 0.30225005745887756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1975.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 353.8087463378906.\n",
      "The relative quantization error of layer 19 is 0.26709476113319397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1191.421630859375.\n",
      "The relative quantization error of layer 20 is 0.31015846133232117.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 129.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1860.40625.\n",
      "The relative quantization error of layer 21 is 0.3303070664405823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1580.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 419.1985778808594.\n",
      "The relative quantization error of layer 22 is 0.28514620661735535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 917.8932495117188.\n",
      "The relative quantization error of layer 23 is 0.3897039294242859.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 69.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3114.66357421875.\n",
      "The relative quantization error of layer 24 is 0.3589799404144287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1054.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 603.7662963867188.\n",
      "The relative quantization error of layer 25 is 0.3274354040622711.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 100.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1291.5753173828125.\n",
      "The relative quantization error of layer 26 is 0.36021360754966736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:30<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3127.03369140625.\n",
      "The relative quantization error of layer 27 is 0.35523271560668945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 248.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1257.649169921875.\n",
      "The relative quantization error of layer 28 is 0.33104339241981506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3205.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 241.2498321533203.\n",
      "The relative quantization error of layer 29 is 0.17431646585464478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 961.8990478515625.\n",
      "The relative quantization error of layer 30 is 0.4610963761806488.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1478.8114013671875.\n",
      "The relative quantization error of layer 31 is 0.3707979619503021.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3192.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 281.9369812011719.\n",
      "The relative quantization error of layer 32 is 0.2264605313539505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 838.677734375.\n",
      "The relative quantization error of layer 33 is 0.4840511679649353.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 289.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1585.1885986328125.\n",
      "The relative quantization error of layer 34 is 0.4315180480480194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3284.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 233.39450073242188.\n",
      "The relative quantization error of layer 35 is 0.21335852146148682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 974.76123046875.\n",
      "The relative quantization error of layer 36 is 0.5455650687217712.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 282.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1710.0220947265625.\n",
      "The relative quantization error of layer 37 is 0.436947762966156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3284.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 197.70965576171875.\n",
      "The relative quantization error of layer 38 is 0.220474973320961.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1327.31982421875.\n",
      "The relative quantization error of layer 39 is 0.5315601229667664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1752.759521484375.\n",
      "The relative quantization error of layer 40 is 0.4388231933116913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2773.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 173.11492919921875.\n",
      "The relative quantization error of layer 41 is 0.24520757794380188.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1357.29296875.\n",
      "The relative quantization error of layer 42 is 0.5466445088386536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 150.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2457.466552734375.\n",
      "The relative quantization error of layer 43 is 0.4508828818798065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1548.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.70001220703125.\n",
      "The relative quantization error of layer 44 is 0.212310329079628.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 922.8300170898438.\n",
      "The relative quantization error of layer 45 is 0.4227280020713806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2150.55126953125.\n",
      "The relative quantization error of layer 46 is 0.4670496881008148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 613.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 410.6810302734375.\n",
      "The relative quantization error of layer 47 is 0.38603121042251587.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2669.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.63517761230469.\n",
      "The relative quantization error of layer 48 is 0.10612235963344574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 558.8159790039062.\n",
      "The relative quantization error of layer 49 is 0.673798143863678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 611.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 471.0574645996094.\n",
      "The relative quantization error of layer 50 is 0.26578620076179504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2429.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 90.10118865966797.\n",
      "The relative quantization error of layer 51 is 0.1622009426355362.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 157.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 105.54539489746094.\n",
      "The relative quantization error of layer 52 is 0.7766669392585754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7953.21it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 34.525733947753906.\n",
      "The relative quantization error of layer 53 is 0.20446105301380157.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:38.000933\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:42<00:00, 17.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.734.\n",
      "Top-5 accuracy of quantized resnet50 is 0.984.\n",
      "\n",
      "Time used for evaluation: 0:04:42.309715\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4458\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 650.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 78.55730438232422.\n",
      "The relative quantization error of layer 0 is 0.017941806465387344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 805.5311279296875.\n",
      "The relative quantization error of layer 1 is 0.046015989035367966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1165.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 242.40093994140625.\n",
      "The relative quantization error of layer 2 is 0.05555694177746773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3413.998291015625.\n",
      "The relative quantization error of layer 3 is 0.10411219298839569.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1337.1729736328125.\n",
      "The relative quantization error of layer 4 is 0.045098885893821716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 61.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 579.6593017578125.\n",
      "The relative quantization error of layer 5 is 0.19947828352451324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 982.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 258.3544616699219.\n",
      "The relative quantization error of layer 6 is 0.23342199623584747.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1091.4722900390625.\n",
      "The relative quantization error of layer 7 is 0.2287670224905014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 891.4430541992188.\n",
      "The relative quantization error of layer 8 is 0.26608091592788696.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1121.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 545.7340087890625.\n",
      "The relative quantization error of layer 9 is 0.27293968200683594.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1665.6212158203125.\n",
      "The relative quantization error of layer 10 is 0.2437739074230194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1683.6239013671875.\n",
      "The relative quantization error of layer 11 is 0.30663907527923584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 548.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1177.0816650390625.\n",
      "The relative quantization error of layer 12 is 0.30595555901527405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1479.479736328125.\n",
      "The relative quantization error of layer 13 is 0.21466675400733948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2030.954345703125.\n",
      "The relative quantization error of layer 14 is 0.2936173379421234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2021.8050537109375.\n",
      "The relative quantization error of layer 15 is 0.27218592166900635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2085.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 505.45953369140625.\n",
      "The relative quantization error of layer 16 is 0.23601163923740387.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1135.775390625.\n",
      "The relative quantization error of layer 17 is 0.38604310154914856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1747.0611572265625.\n",
      "The relative quantization error of layer 18 is 0.29640763998031616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2004.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.4928283691406.\n",
      "The relative quantization error of layer 19 is 0.266834557056427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1195.6348876953125.\n",
      "The relative quantization error of layer 20 is 0.30065426230430603.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 157.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1941.503662109375.\n",
      "The relative quantization error of layer 21 is 0.3289804458618164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2075.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 421.58831787109375.\n",
      "The relative quantization error of layer 22 is 0.27195897698402405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 948.4638671875.\n",
      "The relative quantization error of layer 23 is 0.3827703595161438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:06<00:00, 73.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3259.361083984375.\n",
      "The relative quantization error of layer 24 is 0.3646901845932007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1063.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 600.2333374023438.\n",
      "The relative quantization error of layer 25 is 0.314809650182724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1329.4205322265625.\n",
      "The relative quantization error of layer 26 is 0.3637683093547821.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3387.4052734375.\n",
      "The relative quantization error of layer 27 is 0.3544275462627411.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1309.7574462890625.\n",
      "The relative quantization error of layer 28 is 0.3283469080924988.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2827.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.0272521972656.\n",
      "The relative quantization error of layer 29 is 0.1782642900943756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 94.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 958.3980712890625.\n",
      "The relative quantization error of layer 30 is 0.445456862449646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1526.543212890625.\n",
      "The relative quantization error of layer 31 is 0.3624774217605591.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3142.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 289.9393615722656.\n",
      "The relative quantization error of layer 32 is 0.21915599703788757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 877.7672729492188.\n",
      "The relative quantization error of layer 33 is 0.4787686765193939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 305.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1686.22509765625.\n",
      "The relative quantization error of layer 34 is 0.41419997811317444.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3411.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 241.32403564453125.\n",
      "The relative quantization error of layer 35 is 0.19855543971061707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 116.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1065.3153076171875.\n",
      "The relative quantization error of layer 36 is 0.5198407769203186.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1762.2960205078125.\n",
      "The relative quantization error of layer 37 is 0.4289274215698242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3271.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 217.78273010253906.\n",
      "The relative quantization error of layer 38 is 0.21931040287017822.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 98.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1349.6517333984375.\n",
      "The relative quantization error of layer 39 is 0.5079668164253235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 246.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1744.3238525390625.\n",
      "The relative quantization error of layer 40 is 0.4299943149089813.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3343.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.116455078125.\n",
      "The relative quantization error of layer 41 is 0.22312726080417633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1424.0240478515625.\n",
      "The relative quantization error of layer 42 is 0.5271744132041931.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:07<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2489.181396484375.\n",
      "The relative quantization error of layer 43 is 0.45149052143096924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1536.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 164.56610107421875.\n",
      "The relative quantization error of layer 44 is 0.20823782682418823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 892.7578735351562.\n",
      "The relative quantization error of layer 45 is 0.416467547416687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:33<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2232.896484375.\n",
      "The relative quantization error of layer 46 is 0.4735051989555359.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 622.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 410.6111145019531.\n",
      "The relative quantization error of layer 47 is 0.39084744453430176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2736.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 104.80562591552734.\n",
      "The relative quantization error of layer 48 is 0.10137654095888138.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 532.2374267578125.\n",
      "The relative quantization error of layer 49 is 0.6731271147727966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 625.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 445.7972106933594.\n",
      "The relative quantization error of layer 50 is 0.29107847809791565.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2734.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 67.6881332397461.\n",
      "The relative quantization error of layer 51 is 0.12543390691280365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 108.79949951171875.\n",
      "The relative quantization error of layer 52 is 0.7463139295578003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8876.74it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.32428550720215.\n",
      "The relative quantization error of layer 53 is 0.188373863697052.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:43.541462\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:44<00:00, 17.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.957.\n",
      "Top-5 accuracy of quantized resnet50 is 0.995.\n",
      "\n",
      "Time used for evaluation: 0:04:44.170225\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4522\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 621.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 72.06739044189453.\n",
      "The relative quantization error of layer 0 is 0.017908334732055664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 786.6515502929688.\n",
      "The relative quantization error of layer 1 is 0.044395942240953445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1143.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 234.692138671875.\n",
      "The relative quantization error of layer 2 is 0.053603123873472214.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3423.4150390625.\n",
      "The relative quantization error of layer 3 is 0.0998760238289833.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1345.4796142578125.\n",
      "The relative quantization error of layer 4 is 0.04635000601410866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 586.2440185546875.\n",
      "The relative quantization error of layer 5 is 0.19771748781204224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1118.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 258.4548034667969.\n",
      "The relative quantization error of layer 6 is 0.2181210219860077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1085.9595947265625.\n",
      "The relative quantization error of layer 7 is 0.2299121916294098.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 868.410888671875.\n",
      "The relative quantization error of layer 8 is 0.25457853078842163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1137.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 573.1781005859375.\n",
      "The relative quantization error of layer 9 is 0.2662183940410614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1553.56591796875.\n",
      "The relative quantization error of layer 10 is 0.23451943695545197.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1692.7763671875.\n",
      "The relative quantization error of layer 11 is 0.3095284402370453.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 521.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1201.448486328125.\n",
      "The relative quantization error of layer 12 is 0.3024396300315857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 40.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1475.5760498046875.\n",
      "The relative quantization error of layer 13 is 0.213963583111763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1925.9688720703125.\n",
      "The relative quantization error of layer 14 is 0.28942158818244934.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1907.08203125.\n",
      "The relative quantization error of layer 15 is 0.27241578698158264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2034.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 513.1503295898438.\n",
      "The relative quantization error of layer 16 is 0.2323310822248459.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 42.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1146.8570556640625.\n",
      "The relative quantization error of layer 17 is 0.3861149549484253.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 159.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1745.1275634765625.\n",
      "The relative quantization error of layer 18 is 0.2950231432914734.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2038.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.5077209472656.\n",
      "The relative quantization error of layer 19 is 0.2634688913822174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1228.3682861328125.\n",
      "The relative quantization error of layer 20 is 0.29617631435394287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 131.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1949.601806640625.\n",
      "The relative quantization error of layer 21 is 0.32465341687202454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2028.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 430.36041259765625.\n",
      "The relative quantization error of layer 22 is 0.273632675409317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 999.7289428710938.\n",
      "The relative quantization error of layer 23 is 0.32796940207481384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3253.4755859375.\n",
      "The relative quantization error of layer 24 is 0.36146169900894165.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1096.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 604.398193359375.\n",
      "The relative quantization error of layer 25 is 0.3056626617908478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1327.088134765625.\n",
      "The relative quantization error of layer 26 is 0.363272488117218.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3355.97509765625.\n",
      "The relative quantization error of layer 27 is 0.3504176437854767.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1383.7608642578125.\n",
      "The relative quantization error of layer 28 is 0.3374764025211334.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3299.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.0426940917969.\n",
      "The relative quantization error of layer 29 is 0.17786391079425812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 94.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 959.2871704101562.\n",
      "The relative quantization error of layer 30 is 0.4433731436729431.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1518.6585693359375.\n",
      "The relative quantization error of layer 31 is 0.3651748299598694.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3272.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 295.95166015625.\n",
      "The relative quantization error of layer 32 is 0.22205835580825806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 881.17724609375.\n",
      "The relative quantization error of layer 33 is 0.4767071604728699.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1689.5731201171875.\n",
      "The relative quantization error of layer 34 is 0.39493539929389954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3256.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.3253631591797.\n",
      "The relative quantization error of layer 35 is 0.20289850234985352.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1020.3131713867188.\n",
      "The relative quantization error of layer 36 is 0.5023385286331177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 296.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1735.40673828125.\n",
      "The relative quantization error of layer 37 is 0.4230521321296692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3302.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.94960021972656.\n",
      "The relative quantization error of layer 38 is 0.20819221436977386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1333.5889892578125.\n",
      "The relative quantization error of layer 39 is 0.5099363923072815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1828.4871826171875.\n",
      "The relative quantization error of layer 40 is 0.431429922580719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3376.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 174.12130737304688.\n",
      "The relative quantization error of layer 41 is 0.2148098349571228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1421.4556884765625.\n",
      "The relative quantization error of layer 42 is 0.5442228317260742.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 150.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2530.209716796875.\n",
      "The relative quantization error of layer 43 is 0.4512263536453247.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1416.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.76531982421875.\n",
      "The relative quantization error of layer 44 is 0.2076522558927536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 955.2408447265625.\n",
      "The relative quantization error of layer 45 is 0.4419361650943756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2212.4677734375.\n",
      "The relative quantization error of layer 46 is 0.4687601923942566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 607.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.2842102050781.\n",
      "The relative quantization error of layer 47 is 0.3921041786670685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2690.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.11483001708984.\n",
      "The relative quantization error of layer 48 is 0.11759152263402939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 568.2886962890625.\n",
      "The relative quantization error of layer 49 is 0.6941758394241333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 615.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 458.0707092285156.\n",
      "The relative quantization error of layer 50 is 0.32817772030830383.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2731.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 112.44623565673828.\n",
      "The relative quantization error of layer 51 is 0.20535573363304138.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 194.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 118.44444274902344.\n",
      "The relative quantization error of layer 52 is 0.7939467430114746.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7161.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 32.696502685546875.\n",
      "The relative quantization error of layer 53 is 0.1934611201286316.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:30.858404\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:18<00:00, 17.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.8444444444444444.\n",
      "Top-5 accuracy of quantized resnet50 is 0.9677777777777777.\n",
      "\n",
      "Time used for evaluation: 0:04:18.659705\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4533\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 609.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 80.4862289428711.\n",
      "The relative quantization error of layer 0 is 0.017877601087093353.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 829.23583984375.\n",
      "The relative quantization error of layer 1 is 0.04658883064985275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1155.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 236.4909210205078.\n",
      "The relative quantization error of layer 2 is 0.05122309923171997.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3479.227294921875.\n",
      "The relative quantization error of layer 3 is 0.1041768491268158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1302.9840087890625.\n",
      "The relative quantization error of layer 4 is 0.04474934935569763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 588.9149780273438.\n",
      "The relative quantization error of layer 5 is 0.20224529504776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1085.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 269.65625.\n",
      "The relative quantization error of layer 6 is 0.23326654732227325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 986.8971557617188.\n",
      "The relative quantization error of layer 7 is 0.22013361752033234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 880.6315307617188.\n",
      "The relative quantization error of layer 8 is 0.25807318091392517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1137.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 574.5507202148438.\n",
      "The relative quantization error of layer 9 is 0.26873332262039185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1611.6168212890625.\n",
      "The relative quantization error of layer 10 is 0.24241802096366882.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1671.3309326171875.\n",
      "The relative quantization error of layer 11 is 0.30489563941955566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 530.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1164.1929931640625.\n",
      "The relative quantization error of layer 12 is 0.2940260171890259.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1518.7579345703125.\n",
      "The relative quantization error of layer 13 is 0.21712571382522583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1931.591796875.\n",
      "The relative quantization error of layer 14 is 0.2934929430484772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 145.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1937.418212890625.\n",
      "The relative quantization error of layer 15 is 0.27512887120246887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2013.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 528.3603515625.\n",
      "The relative quantization error of layer 16 is 0.244644433259964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1215.98486328125.\n",
      "The relative quantization error of layer 17 is 0.4024144113063812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 157.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1772.7684326171875.\n",
      "The relative quantization error of layer 18 is 0.30301958322525024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2048.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 375.4214782714844.\n",
      "The relative quantization error of layer 19 is 0.2657819390296936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1218.268798828125.\n",
      "The relative quantization error of layer 20 is 0.3042581379413605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 114.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1974.6119384765625.\n",
      "The relative quantization error of layer 21 is 0.33340248465538025.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1995.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 448.22021484375.\n",
      "The relative quantization error of layer 22 is 0.27073609828948975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1010.7857666015625.\n",
      "The relative quantization error of layer 23 is 0.335233211517334.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 67.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3289.6142578125.\n",
      "The relative quantization error of layer 24 is 0.36475515365600586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:04<00:00, 561.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 616.8798217773438.\n",
      "The relative quantization error of layer 25 is 0.3191733956336975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 77.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1330.1556396484375.\n",
      "The relative quantization error of layer 26 is 0.3621789216995239.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:36<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3339.84326171875.\n",
      "The relative quantization error of layer 27 is 0.36553511023521423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 239.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1346.145751953125.\n",
      "The relative quantization error of layer 28 is 0.34107494354248047.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3232.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 267.1266174316406.\n",
      "The relative quantization error of layer 29 is 0.18320013582706451.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 984.211669921875.\n",
      "The relative quantization error of layer 30 is 0.4376566410064697.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1517.1832275390625.\n",
      "The relative quantization error of layer 31 is 0.3682645559310913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3322.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 298.9109802246094.\n",
      "The relative quantization error of layer 32 is 0.2231711745262146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 104.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 925.0520629882812.\n",
      "The relative quantization error of layer 33 is 0.488660991191864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 251.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1685.5133056640625.\n",
      "The relative quantization error of layer 34 is 0.4086384177207947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2698.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.8072967529297.\n",
      "The relative quantization error of layer 35 is 0.20854535698890686.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 98.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1057.296142578125.\n",
      "The relative quantization error of layer 36 is 0.5235733389854431.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 296.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1813.292724609375.\n",
      "The relative quantization error of layer 37 is 0.4300030767917633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3351.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 209.4046173095703.\n",
      "The relative quantization error of layer 38 is 0.2088991105556488.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1386.2042236328125.\n",
      "The relative quantization error of layer 39 is 0.5189045667648315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1888.312744140625.\n",
      "The relative quantization error of layer 40 is 0.44367116689682007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3293.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.72305297851562.\n",
      "The relative quantization error of layer 41 is 0.22034578025341034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1478.686279296875.\n",
      "The relative quantization error of layer 42 is 0.5530602931976318.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 149.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2576.25927734375.\n",
      "The relative quantization error of layer 43 is 0.4559628665447235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1542.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.04501342773438.\n",
      "The relative quantization error of layer 44 is 0.20576511323451996.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 193.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 957.9165649414062.\n",
      "The relative quantization error of layer 45 is 0.44165363907814026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2273.347900390625.\n",
      "The relative quantization error of layer 46 is 0.47622814774513245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 623.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 432.14459228515625.\n",
      "The relative quantization error of layer 47 is 0.4025346636772156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2706.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 118.49063110351562.\n",
      "The relative quantization error of layer 48 is 0.10733074694871902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 546.4694213867188.\n",
      "The relative quantization error of layer 49 is 0.6988699436187744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 627.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 492.6175231933594.\n",
      "The relative quantization error of layer 50 is 0.31453070044517517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2700.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 83.65044403076172.\n",
      "The relative quantization error of layer 51 is 0.14494813978672028.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 232.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 121.27889251708984.\n",
      "The relative quantization error of layer 52 is 0.8335400223731995.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7728.78it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 52.0993766784668.\n",
      "The relative quantization error of layer 53 is 0.30727657675743103.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:53.095594\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:18<00:00, 17.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.7577777777777778.\n",
      "Top-5 accuracy of quantized resnet50 is 0.9622222222222222.\n",
      "\n",
      "Time used for evaluation: 0:04:18.487850\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.45\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 634.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 81.04216766357422.\n",
      "The relative quantization error of layer 0 is 0.017878010869026184.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 838.8727416992188.\n",
      "The relative quantization error of layer 1 is 0.04727296531200409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1959.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 252.57247924804688.\n",
      "The relative quantization error of layer 2 is 0.05241599306464195.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3427.636474609375.\n",
      "The relative quantization error of layer 3 is 0.10737402737140656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1247.6856689453125.\n",
      "The relative quantization error of layer 4 is 0.0418543815612793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 68.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 563.1192626953125.\n",
      "The relative quantization error of layer 5 is 0.19256523251533508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 945.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 261.680419921875.\n",
      "The relative quantization error of layer 6 is 0.22117330133914948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1033.3350830078125.\n",
      "The relative quantization error of layer 7 is 0.21809442341327667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 60.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 889.5733032226562.\n",
      "The relative quantization error of layer 8 is 0.2509355843067169.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1172.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 555.2238159179688.\n",
      "The relative quantization error of layer 9 is 0.2627761960029602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1492.7845458984375.\n",
      "The relative quantization error of layer 10 is 0.22812341153621674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1662.2197265625.\n",
      "The relative quantization error of layer 11 is 0.29714637994766235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 517.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1161.09228515625.\n",
      "The relative quantization error of layer 12 is 0.2984074354171753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1488.6846923828125.\n",
      "The relative quantization error of layer 13 is 0.21302266418933868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1851.9635009765625.\n",
      "The relative quantization error of layer 14 is 0.28528884053230286.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 153.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1854.77001953125.\n",
      "The relative quantization error of layer 15 is 0.2659931778907776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2063.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 498.93170166015625.\n",
      "The relative quantization error of layer 16 is 0.23585833609104156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1105.992431640625.\n",
      "The relative quantization error of layer 17 is 0.3582785725593567.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 146.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1779.8175048828125.\n",
      "The relative quantization error of layer 18 is 0.3026648461818695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1976.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 363.0318603515625.\n",
      "The relative quantization error of layer 19 is 0.25606465339660645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1230.6590576171875.\n",
      "The relative quantization error of layer 20 is 0.29617297649383545.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1876.38671875.\n",
      "The relative quantization error of layer 21 is 0.31236737966537476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2054.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 435.1617431640625.\n",
      "The relative quantization error of layer 22 is 0.2644294500350952.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 982.9767456054688.\n",
      "The relative quantization error of layer 23 is 0.3296600878238678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:08<00:00, 61.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3251.991455078125.\n",
      "The relative quantization error of layer 24 is 0.3519369661808014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1055.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 599.8643188476562.\n",
      "The relative quantization error of layer 25 is 0.3037474751472473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1320.2633056640625.\n",
      "The relative quantization error of layer 26 is 0.35553842782974243.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3405.5830078125.\n",
      "The relative quantization error of layer 27 is 0.33853626251220703.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1309.6734619140625.\n",
      "The relative quantization error of layer 28 is 0.3203025162220001.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2621.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 258.6552429199219.\n",
      "The relative quantization error of layer 29 is 0.17248988151550293.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 980.51806640625.\n",
      "The relative quantization error of layer 30 is 0.43088915944099426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 302.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1474.7808837890625.\n",
      "The relative quantization error of layer 31 is 0.3453919291496277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3234.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 288.5091247558594.\n",
      "The relative quantization error of layer 32 is 0.21365147829055786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 869.4161376953125.\n",
      "The relative quantization error of layer 33 is 0.46164798736572266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1652.14404296875.\n",
      "The relative quantization error of layer 34 is 0.3837698698043823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3261.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.1459503173828.\n",
      "The relative quantization error of layer 35 is 0.19444386661052704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 98.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1031.3758544921875.\n",
      "The relative quantization error of layer 36 is 0.48686376214027405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 289.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1721.7119140625.\n",
      "The relative quantization error of layer 37 is 0.39840126037597656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3225.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 196.10147094726562.\n",
      "The relative quantization error of layer 38 is 0.19193169474601746.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 91.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1345.1573486328125.\n",
      "The relative quantization error of layer 39 is 0.4930965304374695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1834.1343994140625.\n",
      "The relative quantization error of layer 40 is 0.4194798767566681.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3280.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 170.40672302246094.\n",
      "The relative quantization error of layer 41 is 0.20365038514137268.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1403.248779296875.\n",
      "The relative quantization error of layer 42 is 0.5223652720451355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:07<00:00, 140.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2481.926025390625.\n",
      "The relative quantization error of layer 43 is 0.44308212399482727.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1539.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.47146606445312.\n",
      "The relative quantization error of layer 44 is 0.19282716512680054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 912.490234375.\n",
      "The relative quantization error of layer 45 is 0.4178600311279297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:33<00:00, 30.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2169.31103515625.\n",
      "The relative quantization error of layer 46 is 0.46400606632232666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 623.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 405.9227294921875.\n",
      "The relative quantization error of layer 47 is 0.4026484787464142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2694.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 114.39635467529297.\n",
      "The relative quantization error of layer 48 is 0.10480447113513947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 531.9862670898438.\n",
      "The relative quantization error of layer 49 is 0.6727069616317749.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 615.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 474.7659912109375.\n",
      "The relative quantization error of layer 50 is 0.3255908489227295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2729.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 78.10078430175781.\n",
      "The relative quantization error of layer 51 is 0.12851785123348236.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 232.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 110.83121490478516.\n",
      "The relative quantization error of layer 52 is 0.7969667315483093.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8477.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 35.757911682128906.\n",
      "The relative quantization error of layer 53 is 0.22149328887462616.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:32.972986\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:42<00:00, 17.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.753.\n",
      "Top-5 accuracy of quantized resnet50 is 0.958.\n",
      "\n",
      "Time used for evaluation: 0:04:42.830833\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4582\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 623.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.08088684082031.\n",
      "The relative quantization error of layer 0 is 0.01815336011350155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 860.9990844726562.\n",
      "The relative quantization error of layer 1 is 0.04877932369709015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1201.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 250.7579803466797.\n",
      "The relative quantization error of layer 2 is 0.054704662412405014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3269.2421875.\n",
      "The relative quantization error of layer 3 is 0.10116598010063171.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1514.1766357421875.\n",
      "The relative quantization error of layer 4 is 0.05241304263472557.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 62.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 604.0014038085938.\n",
      "The relative quantization error of layer 5 is 0.20421095192432404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1169.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 273.8750305175781.\n",
      "The relative quantization error of layer 6 is 0.23362497985363007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1058.6787109375.\n",
      "The relative quantization error of layer 7 is 0.22913561761379242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 895.5819091796875.\n",
      "The relative quantization error of layer 8 is 0.26440921425819397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1148.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 585.8885498046875.\n",
      "The relative quantization error of layer 9 is 0.27929064631462097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1472.253662109375.\n",
      "The relative quantization error of layer 10 is 0.2302308827638626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1722.90625.\n",
      "The relative quantization error of layer 11 is 0.3106001019477844.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 516.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1188.4268798828125.\n",
      "The relative quantization error of layer 12 is 0.30410587787628174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1529.5208740234375.\n",
      "The relative quantization error of layer 13 is 0.21997405588626862.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1994.50048828125.\n",
      "The relative quantization error of layer 14 is 0.29300594329833984.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2051.380859375.\n",
      "The relative quantization error of layer 15 is 0.26791074872016907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2065.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 506.7023010253906.\n",
      "The relative quantization error of layer 16 is 0.23466657102108002.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1095.312255859375.\n",
      "The relative quantization error of layer 17 is 0.3762688934803009.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1826.0823974609375.\n",
      "The relative quantization error of layer 18 is 0.30684706568717957.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1867.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 371.5076904296875.\n",
      "The relative quantization error of layer 19 is 0.2573123872280121.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1232.6092529296875.\n",
      "The relative quantization error of layer 20 is 0.3062853217124939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1979.4549560546875.\n",
      "The relative quantization error of layer 21 is 0.33004921674728394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2018.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 429.46337890625.\n",
      "The relative quantization error of layer 22 is 0.2730157673358917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 45.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1073.1695556640625.\n",
      "The relative quantization error of layer 23 is 0.4061906039714813.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:06<00:00, 73.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3240.04345703125.\n",
      "The relative quantization error of layer 24 is 0.36547818779945374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 837.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 619.3576049804688.\n",
      "The relative quantization error of layer 25 is 0.3238833546638489.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1329.526611328125.\n",
      "The relative quantization error of layer 26 is 0.3642909824848175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3322.723388671875.\n",
      "The relative quantization error of layer 27 is 0.3578914701938629.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 304.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1299.1248779296875.\n",
      "The relative quantization error of layer 28 is 0.32290059328079224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1912.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 252.4745330810547.\n",
      "The relative quantization error of layer 29 is 0.17426638305187225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 94.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 989.1278076171875.\n",
      "The relative quantization error of layer 30 is 0.4506099224090576.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 285.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1519.28125.\n",
      "The relative quantization error of layer 31 is 0.3564767837524414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3310.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 303.3511657714844.\n",
      "The relative quantization error of layer 32 is 0.22353485226631165.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 838.5944213867188.\n",
      "The relative quantization error of layer 33 is 0.4587939381599426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 302.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1646.668212890625.\n",
      "The relative quantization error of layer 34 is 0.40552276372909546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3300.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.83876037597656.\n",
      "The relative quantization error of layer 35 is 0.1986578404903412.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 107.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1081.524169921875.\n",
      "The relative quantization error of layer 36 is 0.5184803605079651.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1750.6485595703125.\n",
      "The relative quantization error of layer 37 is 0.4266289472579956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3297.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 206.09915161132812.\n",
      "The relative quantization error of layer 38 is 0.21122512221336365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1376.0098876953125.\n",
      "The relative quantization error of layer 39 is 0.5114254951477051.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1836.0283203125.\n",
      "The relative quantization error of layer 40 is 0.43741947412490845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3237.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.48123168945312.\n",
      "The relative quantization error of layer 41 is 0.22134679555892944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 86.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1462.2486572265625.\n",
      "The relative quantization error of layer 42 is 0.5410662889480591.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 147.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2483.09765625.\n",
      "The relative quantization error of layer 43 is 0.44569462537765503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1530.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.5284423828125.\n",
      "The relative quantization error of layer 44 is 0.20191535353660583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 228.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 933.0274047851562.\n",
      "The relative quantization error of layer 45 is 0.43189767003059387.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:31<00:00, 32.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2199.673095703125.\n",
      "The relative quantization error of layer 46 is 0.4665668308734894.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 615.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 431.3343811035156.\n",
      "The relative quantization error of layer 47 is 0.3975939452648163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2758.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 118.23359680175781.\n",
      "The relative quantization error of layer 48 is 0.11725226789712906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 217.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 501.0726013183594.\n",
      "The relative quantization error of layer 49 is 0.6421054601669312.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 620.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 471.1295471191406.\n",
      "The relative quantization error of layer 50 is 0.2692621350288391.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2738.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 93.68390655517578.\n",
      "The relative quantization error of layer 51 is 0.15259145200252533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 196.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.9018325805664.\n",
      "The relative quantization error of layer 52 is 0.8009023070335388.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8555.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 33.21625518798828.\n",
      "The relative quantization error of layer 53 is 0.20543648302555084.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:34.174952\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:41<00:00, 17.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.936.\n",
      "Top-5 accuracy of quantized resnet50 is 0.992.\n",
      "\n",
      "Time used for evaluation: 0:04:41.085458\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4486\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 628.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 77.6112289428711.\n",
      "The relative quantization error of layer 0 is 0.017681604251265526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 795.6928100585938.\n",
      "The relative quantization error of layer 1 is 0.0450274832546711.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1171.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 229.29644775390625.\n",
      "The relative quantization error of layer 2 is 0.05431356653571129.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3378.89794921875.\n",
      "The relative quantization error of layer 3 is 0.09801594913005829.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1286.055908203125.\n",
      "The relative quantization error of layer 4 is 0.04509046673774719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 581.3546142578125.\n",
      "The relative quantization error of layer 5 is 0.20098254084587097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1118.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 270.4610900878906.\n",
      "The relative quantization error of layer 6 is 0.23361952602863312.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 995.1119384765625.\n",
      "The relative quantization error of layer 7 is 0.22046524286270142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 884.5479125976562.\n",
      "The relative quantization error of layer 8 is 0.2638418674468994.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1191.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 580.8980712890625.\n",
      "The relative quantization error of layer 9 is 0.26952481269836426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1505.3076171875.\n",
      "The relative quantization error of layer 10 is 0.2305281013250351.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1650.0198974609375.\n",
      "The relative quantization error of layer 11 is 0.3100712299346924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 510.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1189.7086181640625.\n",
      "The relative quantization error of layer 12 is 0.30255088210105896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1484.136962890625.\n",
      "The relative quantization error of layer 13 is 0.2130889743566513.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:30<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1900.7008056640625.\n",
      "The relative quantization error of layer 14 is 0.2945472002029419.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 114.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2013.4228515625.\n",
      "The relative quantization error of layer 15 is 0.2750204801559448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1865.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 530.821044921875.\n",
      "The relative quantization error of layer 16 is 0.24442975223064423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1133.3599853515625.\n",
      "The relative quantization error of layer 17 is 0.37581971287727356.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 153.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1777.852783203125.\n",
      "The relative quantization error of layer 18 is 0.30529356002807617.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1504.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 364.9065246582031.\n",
      "The relative quantization error of layer 19 is 0.26360365748405457.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1218.6973876953125.\n",
      "The relative quantization error of layer 20 is 0.3063708543777466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 159.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1933.75048828125.\n",
      "The relative quantization error of layer 21 is 0.3303793966770172.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2001.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 440.6297912597656.\n",
      "The relative quantization error of layer 22 is 0.2796899974346161.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 48.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 997.4503173828125.\n",
      "The relative quantization error of layer 23 is 0.3477560877799988.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3205.94775390625.\n",
      "The relative quantization error of layer 24 is 0.36056625843048096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1031.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 615.9356079101562.\n",
      "The relative quantization error of layer 25 is 0.3190463185310364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1304.9229736328125.\n",
      "The relative quantization error of layer 26 is 0.3571736216545105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:29<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3311.974609375.\n",
      "The relative quantization error of layer 27 is 0.3601158559322357.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 293.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1355.2796630859375.\n",
      "The relative quantization error of layer 28 is 0.3353728950023651.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3214.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 249.01144409179688.\n",
      "The relative quantization error of layer 29 is 0.1739635467529297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 109.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1053.898193359375.\n",
      "The relative quantization error of layer 30 is 0.4818764626979828.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1541.75244140625.\n",
      "The relative quantization error of layer 31 is 0.3656732439994812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3269.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 299.3529357910156.\n",
      "The relative quantization error of layer 32 is 0.22271329164505005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 859.1729736328125.\n",
      "The relative quantization error of layer 33 is 0.469001442193985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 303.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1695.9195556640625.\n",
      "The relative quantization error of layer 34 is 0.4169944226741791.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3258.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 238.5487823486328.\n",
      "The relative quantization error of layer 35 is 0.20054855942726135.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 106.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1104.27978515625.\n",
      "The relative quantization error of layer 36 is 0.5203343629837036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1794.6705322265625.\n",
      "The relative quantization error of layer 37 is 0.4318048059940338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3244.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.84002685546875.\n",
      "The relative quantization error of layer 38 is 0.20773518085479736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1407.8173828125.\n",
      "The relative quantization error of layer 39 is 0.5214051604270935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1930.3665771484375.\n",
      "The relative quantization error of layer 40 is 0.4492895305156708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3363.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.33370971679688.\n",
      "The relative quantization error of layer 41 is 0.22312062978744507.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1486.881591796875.\n",
      "The relative quantization error of layer 42 is 0.5554049611091614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 153.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2613.22265625.\n",
      "The relative quantization error of layer 43 is 0.46775200963020325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1523.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 167.97955322265625.\n",
      "The relative quantization error of layer 44 is 0.20515775680541992.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 970.4356689453125.\n",
      "The relative quantization error of layer 45 is 0.43928784132003784.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2249.078125.\n",
      "The relative quantization error of layer 46 is 0.4775989055633545.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 620.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 446.3297119140625.\n",
      "The relative quantization error of layer 47 is 0.38457930088043213.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2653.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 131.62240600585938.\n",
      "The relative quantization error of layer 48 is 0.11942066997289658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 193.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 579.743896484375.\n",
      "The relative quantization error of layer 49 is 0.7013811469078064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 621.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 519.3849487304688.\n",
      "The relative quantization error of layer 50 is 0.28296959400177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2682.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 65.58450317382812.\n",
      "The relative quantization error of layer 51 is 0.12904873490333557.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 122.86917114257812.\n",
      "The relative quantization error of layer 52 is 0.8493674993515015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7890.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.29290771484375.\n",
      "The relative quantization error of layer 53 is 0.26082152128219604.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:32.574674\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [04:00<00:00, 18.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.75875.\n",
      "Top-5 accuracy of quantized resnet50 is 0.9325.\n",
      "\n",
      "Time used for evaluation: 0:04:00.317177\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4497\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 585.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 84.87102508544922.\n",
      "The relative quantization error of layer 0 is 0.01813593879342079.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 166.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 824.1890258789062.\n",
      "The relative quantization error of layer 1 is 0.04691583290696144.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1570.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 253.94729614257812.\n",
      "The relative quantization error of layer 2 is 0.05697000399231911.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3504.63525390625.\n",
      "The relative quantization error of layer 3 is 0.10243507474660873.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1487.6204833984375.\n",
      "The relative quantization error of layer 4 is 0.050874628126621246.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 594.5858154296875.\n",
      "The relative quantization error of layer 5 is 0.2018018662929535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1155.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 256.30670166015625.\n",
      "The relative quantization error of layer 6 is 0.22176377475261688.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1037.34765625.\n",
      "The relative quantization error of layer 7 is 0.22391685843467712.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 62.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 908.6163330078125.\n",
      "The relative quantization error of layer 8 is 0.2666087746620178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1008.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 594.9276733398438.\n",
      "The relative quantization error of layer 9 is 0.28553032875061035.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1556.262451171875.\n",
      "The relative quantization error of layer 10 is 0.23695500195026398.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1695.025390625.\n",
      "The relative quantization error of layer 11 is 0.31372517347335815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 544.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1211.26171875.\n",
      "The relative quantization error of layer 12 is 0.3102719783782959.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1521.3377685546875.\n",
      "The relative quantization error of layer 13 is 0.2197616994380951.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2034.7364501953125.\n",
      "The relative quantization error of layer 14 is 0.29792535305023193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 130.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2070.07080078125.\n",
      "The relative quantization error of layer 15 is 0.27142274379730225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1734.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 551.6180419921875.\n",
      "The relative quantization error of layer 16 is 0.24588067829608917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1226.87451171875.\n",
      "The relative quantization error of layer 17 is 0.40584269165992737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1830.7093505859375.\n",
      "The relative quantization error of layer 18 is 0.3122207522392273.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2047.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 376.93035888671875.\n",
      "The relative quantization error of layer 19 is 0.264670193195343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1259.808837890625.\n",
      "The relative quantization error of layer 20 is 0.3134971261024475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1965.3148193359375.\n",
      "The relative quantization error of layer 21 is 0.338421106338501.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2054.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 446.2237854003906.\n",
      "The relative quantization error of layer 22 is 0.2897064983844757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 967.1962890625.\n",
      "The relative quantization error of layer 23 is 0.39623793959617615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3451.718505859375.\n",
      "The relative quantization error of layer 24 is 0.38122907280921936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1052.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 648.4649658203125.\n",
      "The relative quantization error of layer 25 is 0.3357169032096863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1377.367919921875.\n",
      "The relative quantization error of layer 26 is 0.3785753548145294.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3411.197021484375.\n",
      "The relative quantization error of layer 27 is 0.36335375905036926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 303.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1373.7347412109375.\n",
      "The relative quantization error of layer 28 is 0.33345431089401245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3253.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.7144775390625.\n",
      "The relative quantization error of layer 29 is 0.1842314749956131.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 92.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1019.5464477539062.\n",
      "The relative quantization error of layer 30 is 0.4546063244342804.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 296.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1556.3905029296875.\n",
      "The relative quantization error of layer 31 is 0.3681837022304535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3284.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.1285400390625.\n",
      "The relative quantization error of layer 32 is 0.22418925166130066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 875.5137329101562.\n",
      "The relative quantization error of layer 33 is 0.47684651613235474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 288.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1707.19482421875.\n",
      "The relative quantization error of layer 34 is 0.4245312511920929.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3323.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.50668334960938.\n",
      "The relative quantization error of layer 35 is 0.20333053171634674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1059.4110107421875.\n",
      "The relative quantization error of layer 36 is 0.5226368308067322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 289.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1773.36083984375.\n",
      "The relative quantization error of layer 37 is 0.4305562973022461.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3328.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 214.51748657226562.\n",
      "The relative quantization error of layer 38 is 0.2091338038444519.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 109.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1408.4998779296875.\n",
      "The relative quantization error of layer 39 is 0.5163760781288147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 240.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1847.7498779296875.\n",
      "The relative quantization error of layer 40 is 0.44205281138420105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3363.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.8973846435547.\n",
      "The relative quantization error of layer 41 is 0.22686739265918732.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1478.1336669921875.\n",
      "The relative quantization error of layer 42 is 0.5524274110794067.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:07<00:00, 134.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2534.8740234375.\n",
      "The relative quantization error of layer 43 is 0.45962804555892944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1551.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 166.25062561035156.\n",
      "The relative quantization error of layer 44 is 0.21137192845344543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 226.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 942.613525390625.\n",
      "The relative quantization error of layer 45 is 0.43073469400405884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:31<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2238.58642578125.\n",
      "The relative quantization error of layer 46 is 0.4709756672382355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 608.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 445.7004089355469.\n",
      "The relative quantization error of layer 47 is 0.39381143450737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2706.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 107.6017074584961.\n",
      "The relative quantization error of layer 48 is 0.10570606589317322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 114.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 546.5221557617188.\n",
      "The relative quantization error of layer 49 is 0.6846526861190796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 621.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 479.019287109375.\n",
      "The relative quantization error of layer 50 is 0.3538861870765686.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2730.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 48.825679779052734.\n",
      "The relative quantization error of layer 51 is 0.11109182238578796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 115.48381042480469.\n",
      "The relative quantization error of layer 52 is 0.8232512474060059.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8337.90it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 38.03871536254883.\n",
      "The relative quantization error of layer 53 is 0.23378124833106995.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:42.511178\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:48<00:00, 18.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.876.\n",
      "Top-5 accuracy of quantized resnet50 is 0.958.\n",
      "\n",
      "Time used for evaluation: 0:04:48.993900\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4507\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 672.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.64193725585938.\n",
      "The relative quantization error of layer 0 is 0.01847168244421482.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 161.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 788.0772705078125.\n",
      "The relative quantization error of layer 1 is 0.0446050763130188.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1823.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 232.39430236816406.\n",
      "The relative quantization error of layer 2 is 0.05783667787909508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3613.490234375.\n",
      "The relative quantization error of layer 3 is 0.1026335135102272.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1281.0640869140625.\n",
      "The relative quantization error of layer 4 is 0.04427172616124153.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 54.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 533.7682495117188.\n",
      "The relative quantization error of layer 5 is 0.19197331368923187.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 887.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 254.01763916015625.\n",
      "The relative quantization error of layer 6 is 0.23327136039733887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1085.4317626953125.\n",
      "The relative quantization error of layer 7 is 0.23807868361473083.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 62.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 836.3896484375.\n",
      "The relative quantization error of layer 8 is 0.2553166151046753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 916.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 529.57421875.\n",
      "The relative quantization error of layer 9 is 0.2626226544380188.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1555.1090087890625.\n",
      "The relative quantization error of layer 10 is 0.23359771072864532.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:08<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1682.1409912109375.\n",
      "The relative quantization error of layer 11 is 0.31115585565567017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 407.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1149.5279541015625.\n",
      "The relative quantization error of layer 12 is 0.3024483919143677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1427.329833984375.\n",
      "The relative quantization error of layer 13 is 0.2089729756116867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1831.9119873046875.\n",
      "The relative quantization error of layer 14 is 0.29345181584358215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 159.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1893.131103515625.\n",
      "The relative quantization error of layer 15 is 0.26778778433799744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1608.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 479.7449951171875.\n",
      "The relative quantization error of layer 16 is 0.2256755381822586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1115.221435546875.\n",
      "The relative quantization error of layer 17 is 0.38520076870918274.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 123.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1732.470947265625.\n",
      "The relative quantization error of layer 18 is 0.3063848912715912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1642.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 364.5085144042969.\n",
      "The relative quantization error of layer 19 is 0.2652009129524231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1186.9173583984375.\n",
      "The relative quantization error of layer 20 is 0.3006211519241333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 122.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1893.1221923828125.\n",
      "The relative quantization error of layer 21 is 0.32989802956581116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1598.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 437.1526794433594.\n",
      "The relative quantization error of layer 22 is 0.2827378809452057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 926.8607177734375.\n",
      "The relative quantization error of layer 23 is 0.3902089297771454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:08<00:00, 59.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3208.802978515625.\n",
      "The relative quantization error of layer 24 is 0.35882100462913513.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1058.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 600.3479614257812.\n",
      "The relative quantization error of layer 25 is 0.3228796124458313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1343.1182861328125.\n",
      "The relative quantization error of layer 26 is 0.36704781651496887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3279.937744140625.\n",
      "The relative quantization error of layer 27 is 0.3530655801296234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 293.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1324.587158203125.\n",
      "The relative quantization error of layer 28 is 0.34500572085380554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2693.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 261.761962890625.\n",
      "The relative quantization error of layer 29 is 0.18287131190299988.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 105.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 979.7992553710938.\n",
      "The relative quantization error of layer 30 is 0.46270912885665894.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 275.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1484.8507080078125.\n",
      "The relative quantization error of layer 31 is 0.36800041794776917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3339.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 289.5317687988281.\n",
      "The relative quantization error of layer 32 is 0.2233281433582306.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 101.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 865.8959350585938.\n",
      "The relative quantization error of layer 33 is 0.4779524505138397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1659.6336669921875.\n",
      "The relative quantization error of layer 34 is 0.4110109508037567.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2978.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.73658752441406.\n",
      "The relative quantization error of layer 35 is 0.2044147253036499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1031.297607421875.\n",
      "The relative quantization error of layer 36 is 0.5191032886505127.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 303.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1786.76025390625.\n",
      "The relative quantization error of layer 37 is 0.4287009537220001.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3279.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 212.89195251464844.\n",
      "The relative quantization error of layer 38 is 0.21526126563549042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1370.8914794921875.\n",
      "The relative quantization error of layer 39 is 0.5170117616653442.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1854.60546875.\n",
      "The relative quantization error of layer 40 is 0.45735445618629456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3377.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.653564453125.\n",
      "The relative quantization error of layer 41 is 0.22356639802455902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 96.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1493.3597412109375.\n",
      "The relative quantization error of layer 42 is 0.5583693981170654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:08<00:00, 127.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2603.0380859375.\n",
      "The relative quantization error of layer 43 is 0.46840327978134155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1546.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.71713256835938.\n",
      "The relative quantization error of layer 44 is 0.20513787865638733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 225.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 971.1642456054688.\n",
      "The relative quantization error of layer 45 is 0.4563838541507721.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2269.56005859375.\n",
      "The relative quantization error of layer 46 is 0.4773205816745758.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 596.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 467.3255310058594.\n",
      "The relative quantization error of layer 47 is 0.4320797920227051.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2699.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 109.50394439697266.\n",
      "The relative quantization error of layer 48 is 0.13746322691440582.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 569.6467895507812.\n",
      "The relative quantization error of layer 49 is 0.7103138566017151.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 608.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 505.7739562988281.\n",
      "The relative quantization error of layer 50 is 0.3123168647289276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2701.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 72.27043151855469.\n",
      "The relative quantization error of layer 51 is 0.125698521733284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 167.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 135.3768768310547.\n",
      "The relative quantization error of layer 52 is 0.854874312877655.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8924.17it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 54.941253662109375.\n",
      "The relative quantization error of layer 53 is 0.31550440192222595.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:49.586326\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:39<00:00, 17.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.52.\n",
      "Top-5 accuracy of quantized resnet50 is 0.906.\n",
      "\n",
      "Time used for evaluation: 0:04:39.671576\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.445\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 606.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 86.79178619384766.\n",
      "The relative quantization error of layer 0 is 0.01902310736477375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 69.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 951.3181762695312.\n",
      "The relative quantization error of layer 1 is 0.05337147414684296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 928.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 257.9752502441406.\n",
      "The relative quantization error of layer 2 is 0.0558597557246685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3438.235595703125.\n",
      "The relative quantization error of layer 3 is 0.10280784219503403.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1458.404296875.\n",
      "The relative quantization error of layer 4 is 0.048301443457603455.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 62.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 626.1879272460938.\n",
      "The relative quantization error of layer 5 is 0.20652635395526886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 795.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 258.3316955566406.\n",
      "The relative quantization error of layer 6 is 0.21805058419704437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1068.1729736328125.\n",
      "The relative quantization error of layer 7 is 0.2336415946483612.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 935.3134765625.\n",
      "The relative quantization error of layer 8 is 0.25779271125793457.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1015.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 610.1842651367188.\n",
      "The relative quantization error of layer 9 is 0.2690626382827759.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1618.9503173828125.\n",
      "The relative quantization error of layer 10 is 0.23678767681121826.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1787.0087890625.\n",
      "The relative quantization error of layer 11 is 0.3046899735927582.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 529.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1244.92138671875.\n",
      "The relative quantization error of layer 12 is 0.3104494512081146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1542.2935791015625.\n",
      "The relative quantization error of layer 13 is 0.21829965710639954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2096.09423828125.\n",
      "The relative quantization error of layer 14 is 0.3009655177593231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2109.326904296875.\n",
      "The relative quantization error of layer 15 is 0.2713312804698944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2114.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 534.5404663085938.\n",
      "The relative quantization error of layer 16 is 0.24396464228630066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 38.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1194.8572998046875.\n",
      "The relative quantization error of layer 17 is 0.3929687738418579.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 133.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1833.992919921875.\n",
      "The relative quantization error of layer 18 is 0.2988494634628296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1666.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 379.298583984375.\n",
      "The relative quantization error of layer 19 is 0.2629152834415436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1222.5235595703125.\n",
      "The relative quantization error of layer 20 is 0.30299291014671326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 148.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1962.6241455078125.\n",
      "The relative quantization error of layer 21 is 0.3229730427265167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1999.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 457.9356994628906.\n",
      "The relative quantization error of layer 22 is 0.2762298285961151.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 997.077392578125.\n",
      "The relative quantization error of layer 23 is 0.3615085184574127.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3353.50537109375.\n",
      "The relative quantization error of layer 24 is 0.36462658643722534.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1074.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 612.5576171875.\n",
      "The relative quantization error of layer 25 is 0.31531742215156555.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 109.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1381.305419921875.\n",
      "The relative quantization error of layer 26 is 0.3733022212982178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3521.304443359375.\n",
      "The relative quantization error of layer 27 is 0.35439151525497437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1359.5963134765625.\n",
      "The relative quantization error of layer 28 is 0.3326774835586548.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2502.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.78973388671875.\n",
      "The relative quantization error of layer 29 is 0.18020804226398468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 998.56689453125.\n",
      "The relative quantization error of layer 30 is 0.41961929202079773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 281.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1512.998291015625.\n",
      "The relative quantization error of layer 31 is 0.35321035981178284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3218.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 289.2701721191406.\n",
      "The relative quantization error of layer 32 is 0.21213337779045105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 97.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 903.1541137695312.\n",
      "The relative quantization error of layer 33 is 0.47164541482925415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 236.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1673.206787109375.\n",
      "The relative quantization error of layer 34 is 0.4026261568069458.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3366.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.4293975830078.\n",
      "The relative quantization error of layer 35 is 0.1964266151189804.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 107.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1045.0001220703125.\n",
      "The relative quantization error of layer 36 is 0.5098432302474976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1732.046142578125.\n",
      "The relative quantization error of layer 37 is 0.4164294898509979.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3334.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 207.7436065673828.\n",
      "The relative quantization error of layer 38 is 0.20312321186065674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1311.3294677734375.\n",
      "The relative quantization error of layer 39 is 0.4954310655593872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 291.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1851.93505859375.\n",
      "The relative quantization error of layer 40 is 0.4246874451637268.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3117.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.8118438720703.\n",
      "The relative quantization error of layer 41 is 0.21778243780136108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1385.5045166015625.\n",
      "The relative quantization error of layer 42 is 0.5093169808387756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 152.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2473.947265625.\n",
      "The relative quantization error of layer 43 is 0.4411711096763611.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1543.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.3213653564453.\n",
      "The relative quantization error of layer 44 is 0.19867828488349915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 225.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 885.5145263671875.\n",
      "The relative quantization error of layer 45 is 0.4107222259044647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2161.128173828125.\n",
      "The relative quantization error of layer 46 is 0.4613967835903168.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 590.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 391.3081970214844.\n",
      "The relative quantization error of layer 47 is 0.3876880705356598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2933.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.41350555419922.\n",
      "The relative quantization error of layer 48 is 0.11401968449354172.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 228.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 508.36102294921875.\n",
      "The relative quantization error of layer 49 is 0.6567677855491638.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 629.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 465.4237976074219.\n",
      "The relative quantization error of layer 50 is 0.39056748151779175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2745.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 62.70943832397461.\n",
      "The relative quantization error of layer 51 is 0.09959672391414642.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 108.70973205566406.\n",
      "The relative quantization error of layer 52 is 0.78778076171875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7717.03it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 26.348501205444336.\n",
      "The relative quantization error of layer 53 is 0.15756304562091827.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:44.087312\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:43<00:00, 17.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.932.\n",
      "Top-5 accuracy of quantized resnet50 is 0.989.\n",
      "\n",
      "Time used for evaluation: 0:04:43.935736\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4553\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 510.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 76.7719955444336.\n",
      "The relative quantization error of layer 0 is 0.018256794661283493.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 77.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 842.1950073242188.\n",
      "The relative quantization error of layer 1 is 0.04770825430750847.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1184.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 258.5923767089844.\n",
      "The relative quantization error of layer 2 is 0.057827528566122055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3533.540771484375.\n",
      "The relative quantization error of layer 3 is 0.1016649454832077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1364.9534912109375.\n",
      "The relative quantization error of layer 4 is 0.0469650961458683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 565.8901977539062.\n",
      "The relative quantization error of layer 5 is 0.19961632788181305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1031.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 259.8719787597656.\n",
      "The relative quantization error of layer 6 is 0.22608929872512817.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 999.1017456054688.\n",
      "The relative quantization error of layer 7 is 0.22601565718650818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 905.6027221679688.\n",
      "The relative quantization error of layer 8 is 0.2605672776699066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1104.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 564.414794921875.\n",
      "The relative quantization error of layer 9 is 0.2687878906726837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1553.2314453125.\n",
      "The relative quantization error of layer 10 is 0.23639652132987976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1699.10693359375.\n",
      "The relative quantization error of layer 11 is 0.30516350269317627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 525.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1205.79052734375.\n",
      "The relative quantization error of layer 12 is 0.30261629819869995.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1500.33056640625.\n",
      "The relative quantization error of layer 13 is 0.21507862210273743.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1988.1644287109375.\n",
      "The relative quantization error of layer 14 is 0.301436185836792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2005.8953857421875.\n",
      "The relative quantization error of layer 15 is 0.27208298444747925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2049.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 518.9035034179688.\n",
      "The relative quantization error of layer 16 is 0.23765648901462555.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1270.7030029296875.\n",
      "The relative quantization error of layer 17 is 0.40807807445526123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 128.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1779.3455810546875.\n",
      "The relative quantization error of layer 18 is 0.3111964762210846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2009.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 371.3633728027344.\n",
      "The relative quantization error of layer 19 is 0.2658175230026245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 44.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1196.214599609375.\n",
      "The relative quantization error of layer 20 is 0.30225059390068054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 140.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1976.781982421875.\n",
      "The relative quantization error of layer 21 is 0.3368748426437378.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2072.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 448.17742919921875.\n",
      "The relative quantization error of layer 22 is 0.28164008259773254.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1044.186767578125.\n",
      "The relative quantization error of layer 23 is 0.38825660943984985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3325.421875.\n",
      "The relative quantization error of layer 24 is 0.37270426750183105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1079.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 622.20849609375.\n",
      "The relative quantization error of layer 25 is 0.3167361915111542.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1386.6995849609375.\n",
      "The relative quantization error of layer 26 is 0.3731487989425659.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:30<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3438.608642578125.\n",
      "The relative quantization error of layer 27 is 0.3593378961086273.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1370.972900390625.\n",
      "The relative quantization error of layer 28 is 0.35028189420700073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3325.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.0557861328125.\n",
      "The relative quantization error of layer 29 is 0.179896742105484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 991.5275268554688.\n",
      "The relative quantization error of layer 30 is 0.4583539366722107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1560.9459228515625.\n",
      "The relative quantization error of layer 31 is 0.37458857893943787.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3310.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.0102233886719.\n",
      "The relative quantization error of layer 32 is 0.2221858948469162.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 899.8251953125.\n",
      "The relative quantization error of layer 33 is 0.48647233843803406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 291.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1714.25244140625.\n",
      "The relative quantization error of layer 34 is 0.4123566150665283.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3305.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 249.3302459716797.\n",
      "The relative quantization error of layer 35 is 0.20406700670719147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1075.5059814453125.\n",
      "The relative quantization error of layer 36 is 0.5250831246376038.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 236.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1801.1912841796875.\n",
      "The relative quantization error of layer 37 is 0.434398889541626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3166.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 211.6764678955078.\n",
      "The relative quantization error of layer 38 is 0.21204432845115662.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1392.791259765625.\n",
      "The relative quantization error of layer 39 is 0.5159156918525696.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 291.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1908.88330078125.\n",
      "The relative quantization error of layer 40 is 0.454253613948822.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3313.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 191.2786407470703.\n",
      "The relative quantization error of layer 41 is 0.2259979248046875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 104.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1519.876953125.\n",
      "The relative quantization error of layer 42 is 0.5504892468452454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 150.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2615.82470703125.\n",
      "The relative quantization error of layer 43 is 0.47079968452453613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1540.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.7683868408203.\n",
      "The relative quantization error of layer 44 is 0.19807729125022888.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 971.2008056640625.\n",
      "The relative quantization error of layer 45 is 0.44971194863319397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:31<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2267.176025390625.\n",
      "The relative quantization error of layer 46 is 0.47527793049812317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 619.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 441.8551025390625.\n",
      "The relative quantization error of layer 47 is 0.4111306965351105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2685.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 104.5100326538086.\n",
      "The relative quantization error of layer 48 is 0.11481400579214096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 231.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 540.8963623046875.\n",
      "The relative quantization error of layer 49 is 0.6904905438423157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 571.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 479.0099792480469.\n",
      "The relative quantization error of layer 50 is 0.28681010007858276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2695.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 86.06829833984375.\n",
      "The relative quantization error of layer 51 is 0.20169159770011902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 119.39791107177734.\n",
      "The relative quantization error of layer 52 is 0.8225749135017395.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7342.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 42.3726806640625.\n",
      "The relative quantization error of layer 53 is 0.2556644678115845.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:34.349202\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:21<00:00, 17.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.8422222222222222.\n",
      "Top-5 accuracy of quantized resnet50 is 0.9844444444444445.\n",
      "\n",
      "Time used for evaluation: 0:04:21.751877\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4522\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 599.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 75.37034606933594.\n",
      "The relative quantization error of layer 0 is 0.018148252740502357.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 810.82080078125.\n",
      "The relative quantization error of layer 1 is 0.0455511249601841.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1212.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 249.74404907226562.\n",
      "The relative quantization error of layer 2 is 0.05578034371137619.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3494.625.\n",
      "The relative quantization error of layer 3 is 0.10605490207672119.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1403.73388671875.\n",
      "The relative quantization error of layer 4 is 0.04665690287947655.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 589.0565795898438.\n",
      "The relative quantization error of layer 5 is 0.20141494274139404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1178.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 274.4111633300781.\n",
      "The relative quantization error of layer 6 is 0.22403152287006378.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1166.4415283203125.\n",
      "The relative quantization error of layer 7 is 0.24003779888153076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 887.0850830078125.\n",
      "The relative quantization error of layer 8 is 0.2557099163532257.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1097.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 602.0917358398438.\n",
      "The relative quantization error of layer 9 is 0.2841607928276062.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1530.794677734375.\n",
      "The relative quantization error of layer 10 is 0.23897506296634674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1669.5687255859375.\n",
      "The relative quantization error of layer 11 is 0.3076881170272827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 520.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1186.8253173828125.\n",
      "The relative quantization error of layer 12 is 0.30017557740211487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1503.529296875.\n",
      "The relative quantization error of layer 13 is 0.21551844477653503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1959.6231689453125.\n",
      "The relative quantization error of layer 14 is 0.29130440950393677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1988.010986328125.\n",
      "The relative quantization error of layer 15 is 0.27065789699554443.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2037.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 524.2162475585938.\n",
      "The relative quantization error of layer 16 is 0.2410593330860138.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 45.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1155.4591064453125.\n",
      "The relative quantization error of layer 17 is 0.3852352499961853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1802.0540771484375.\n",
      "The relative quantization error of layer 18 is 0.30339789390563965.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2010.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 370.81121826171875.\n",
      "The relative quantization error of layer 19 is 0.25116172432899475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1218.972412109375.\n",
      "The relative quantization error of layer 20 is 0.29853612184524536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 128.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2006.508056640625.\n",
      "The relative quantization error of layer 21 is 0.33323076367378235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1999.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 438.3454284667969.\n",
      "The relative quantization error of layer 22 is 0.27025875449180603.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1020.009765625.\n",
      "The relative quantization error of layer 23 is 0.35633623600006104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 69.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3321.780029296875.\n",
      "The relative quantization error of layer 24 is 0.3651712238788605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1045.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 643.5646362304688.\n",
      "The relative quantization error of layer 25 is 0.32181650400161743.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1367.01171875.\n",
      "The relative quantization error of layer 26 is 0.3665742874145508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3424.47900390625.\n",
      "The relative quantization error of layer 27 is 0.3501332700252533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 221.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1319.8316650390625.\n",
      "The relative quantization error of layer 28 is 0.322803795337677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3257.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 259.8384704589844.\n",
      "The relative quantization error of layer 29 is 0.17438489198684692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 962.1546630859375.\n",
      "The relative quantization error of layer 30 is 0.4179877042770386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1517.67333984375.\n",
      "The relative quantization error of layer 31 is 0.3541436791419983.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3289.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 287.9290771484375.\n",
      "The relative quantization error of layer 32 is 0.21464870870113373.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 886.18701171875.\n",
      "The relative quantization error of layer 33 is 0.46692419052124023.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 304.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1674.9267578125.\n",
      "The relative quantization error of layer 34 is 0.3995263874530792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3209.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.6732940673828.\n",
      "The relative quantization error of layer 35 is 0.19956868886947632.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1047.2265625.\n",
      "The relative quantization error of layer 36 is 0.4871068596839905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 305.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1765.4095458984375.\n",
      "The relative quantization error of layer 37 is 0.3959977924823761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3249.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 207.1767578125.\n",
      "The relative quantization error of layer 38 is 0.20119303464889526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1357.167236328125.\n",
      "The relative quantization error of layer 39 is 0.5005164742469788.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 304.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1826.5538330078125.\n",
      "The relative quantization error of layer 40 is 0.42850908637046814.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3123.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.283203125.\n",
      "The relative quantization error of layer 41 is 0.21872210502624512.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1416.706298828125.\n",
      "The relative quantization error of layer 42 is 0.526258647441864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:07<00:00, 143.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2539.357177734375.\n",
      "The relative quantization error of layer 43 is 0.4594604969024658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1546.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 161.11204528808594.\n",
      "The relative quantization error of layer 44 is 0.19996191561222076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 225.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 913.1174926757812.\n",
      "The relative quantization error of layer 45 is 0.41335803270339966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2193.6318359375.\n",
      "The relative quantization error of layer 46 is 0.4639985263347626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 621.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 402.2662658691406.\n",
      "The relative quantization error of layer 47 is 0.38608017563819885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2669.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 99.83912658691406.\n",
      "The relative quantization error of layer 48 is 0.11621382087469101.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 232.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 521.6677856445312.\n",
      "The relative quantization error of layer 49 is 0.654330849647522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 626.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 424.9084777832031.\n",
      "The relative quantization error of layer 50 is 0.2877054214477539.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2709.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 96.27379608154297.\n",
      "The relative quantization error of layer 51 is 0.1764865666627884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 226.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 112.03619384765625.\n",
      "The relative quantization error of layer 52 is 0.7907559871673584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8384.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 36.139888763427734.\n",
      "The relative quantization error of layer 53 is 0.2144782841205597.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:28.342214\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:44<00:00, 17.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.866.\n",
      "Top-5 accuracy of quantized resnet50 is 0.988.\n",
      "\n",
      "Time used for evaluation: 0:04:44.507425\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4527\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 394.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 69.29164123535156.\n",
      "The relative quantization error of layer 0 is 0.017602000385522842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 76.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 729.50439453125.\n",
      "The relative quantization error of layer 1 is 0.0413394570350647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1206.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 228.60427856445312.\n",
      "The relative quantization error of layer 2 is 0.05390947312116623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3579.96337890625.\n",
      "The relative quantization error of layer 3 is 0.10113678872585297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1257.793212890625.\n",
      "The relative quantization error of layer 4 is 0.0431249737739563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 553.0664672851562.\n",
      "The relative quantization error of layer 5 is 0.194830983877182.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1203.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 249.96731567382812.\n",
      "The relative quantization error of layer 6 is 0.23097315430641174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 955.6708984375.\n",
      "The relative quantization error of layer 7 is 0.21746894717216492.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 844.964111328125.\n",
      "The relative quantization error of layer 8 is 0.25657472014427185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1131.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 542.0736083984375.\n",
      "The relative quantization error of layer 9 is 0.27252671122550964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1554.6181640625.\n",
      "The relative quantization error of layer 10 is 0.246606707572937.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1581.9730224609375.\n",
      "The relative quantization error of layer 11 is 0.30561450123786926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 495.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1141.1846923828125.\n",
      "The relative quantization error of layer 12 is 0.30150917172431946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1466.40478515625.\n",
      "The relative quantization error of layer 13 is 0.21455450356006622.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1845.0955810546875.\n",
      "The relative quantization error of layer 14 is 0.2951809763908386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1911.993896484375.\n",
      "The relative quantization error of layer 15 is 0.2764534056186676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1925.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 505.5785827636719.\n",
      "The relative quantization error of layer 16 is 0.24005253612995148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1142.550048828125.\n",
      "The relative quantization error of layer 17 is 0.39431148767471313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 121.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1702.25439453125.\n",
      "The relative quantization error of layer 18 is 0.3094239830970764.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1977.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 364.3059387207031.\n",
      "The relative quantization error of layer 19 is 0.2679615914821625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1191.2518310546875.\n",
      "The relative quantization error of layer 20 is 0.301580011844635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 154.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1897.645263671875.\n",
      "The relative quantization error of layer 21 is 0.3402305245399475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1888.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 423.0541076660156.\n",
      "The relative quantization error of layer 22 is 0.2832155227661133.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 42.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1071.0404052734375.\n",
      "The relative quantization error of layer 23 is 0.40888911485671997.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3275.564697265625.\n",
      "The relative quantization error of layer 24 is 0.3684750199317932.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1004.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 608.0879516601562.\n",
      "The relative quantization error of layer 25 is 0.3194082975387573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1356.095947265625.\n",
      "The relative quantization error of layer 26 is 0.3707275092601776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3282.323486328125.\n",
      "The relative quantization error of layer 27 is 0.3641180396080017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1336.861572265625.\n",
      "The relative quantization error of layer 28 is 0.3528003394603729.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3223.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 256.88616943359375.\n",
      "The relative quantization error of layer 29 is 0.18172530829906464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 964.8228759765625.\n",
      "The relative quantization error of layer 30 is 0.4615279734134674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 298.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1501.0174560546875.\n",
      "The relative quantization error of layer 31 is 0.37451234459877014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3326.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.0381774902344.\n",
      "The relative quantization error of layer 32 is 0.2284734547138214.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 908.3805541992188.\n",
      "The relative quantization error of layer 33 is 0.49826762080192566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1693.7666015625.\n",
      "The relative quantization error of layer 34 is 0.43171194195747375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3292.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.62704467773438.\n",
      "The relative quantization error of layer 35 is 0.20591126382350922.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 87.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1085.4644775390625.\n",
      "The relative quantization error of layer 36 is 0.5285409092903137.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 286.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1783.1129150390625.\n",
      "The relative quantization error of layer 37 is 0.44678542017936707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3297.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 203.1107177734375.\n",
      "The relative quantization error of layer 38 is 0.20688635110855103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1392.6146240234375.\n",
      "The relative quantization error of layer 39 is 0.5212892889976501.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1919.634521484375.\n",
      "The relative quantization error of layer 40 is 0.45405352115631104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3121.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.5342559814453.\n",
      "The relative quantization error of layer 41 is 0.22414545714855194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1513.776123046875.\n",
      "The relative quantization error of layer 42 is 0.556100606918335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 156.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2630.634765625.\n",
      "The relative quantization error of layer 43 is 0.4774473309516907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1539.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.87867736816406.\n",
      "The relative quantization error of layer 44 is 0.20225130021572113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 190.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 983.5101928710938.\n",
      "The relative quantization error of layer 45 is 0.46385103464126587.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:33<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2254.0703125.\n",
      "The relative quantization error of layer 46 is 0.48075416684150696.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 617.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 444.1507568359375.\n",
      "The relative quantization error of layer 47 is 0.4261282682418823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2653.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.77659606933594.\n",
      "The relative quantization error of layer 48 is 0.11733714491128922.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 559.1333618164062.\n",
      "The relative quantization error of layer 49 is 0.7031128406524658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 611.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 494.46331787109375.\n",
      "The relative quantization error of layer 50 is 0.3304305076599121.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2690.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 83.49138641357422.\n",
      "The relative quantization error of layer 51 is 0.18567654490470886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 228.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 133.1664581298828.\n",
      "The relative quantization error of layer 52 is 0.8544366955757141.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8329.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 51.87723159790039.\n",
      "The relative quantization error of layer 53 is 0.2997380197048187.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:39.668960\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:43<00:00, 17.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.556.\n",
      "Top-5 accuracy of quantized resnet50 is 0.91.\n",
      "\n",
      "Time used for evaluation: 0:04:43.387427\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4477\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 393.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 84.92091369628906.\n",
      "The relative quantization error of layer 0 is 0.018600936979055405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 68.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 910.2996215820312.\n",
      "The relative quantization error of layer 1 is 0.05079256743192673.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 933.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 250.07139587402344.\n",
      "The relative quantization error of layer 2 is 0.055880289524793625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3557.6982421875.\n",
      "The relative quantization error of layer 3 is 0.10155531018972397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1419.1871337890625.\n",
      "The relative quantization error of layer 4 is 0.048578619956970215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 606.9380493164062.\n",
      "The relative quantization error of layer 5 is 0.20353807508945465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1142.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 265.4178771972656.\n",
      "The relative quantization error of layer 6 is 0.23692098259925842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1034.0693359375.\n",
      "The relative quantization error of layer 7 is 0.2240978479385376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 912.4173583984375.\n",
      "The relative quantization error of layer 8 is 0.2684369385242462.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 832.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 583.3654174804688.\n",
      "The relative quantization error of layer 9 is 0.27375930547714233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1618.0745849609375.\n",
      "The relative quantization error of layer 10 is 0.2278267741203308.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1702.8795166015625.\n",
      "The relative quantization error of layer 11 is 0.3091460168361664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 492.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1214.1141357421875.\n",
      "The relative quantization error of layer 12 is 0.3016338348388672.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1540.7587890625.\n",
      "The relative quantization error of layer 13 is 0.22197364270687103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2031.537353515625.\n",
      "The relative quantization error of layer 14 is 0.2945560812950134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 146.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2010.3653564453125.\n",
      "The relative quantization error of layer 15 is 0.2636207044124603.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2068.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 551.395263671875.\n",
      "The relative quantization error of layer 16 is 0.24354024231433868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1239.4122314453125.\n",
      "The relative quantization error of layer 17 is 0.39346593618392944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 148.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1824.5008544921875.\n",
      "The relative quantization error of layer 18 is 0.30665355920791626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2005.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 372.724609375.\n",
      "The relative quantization error of layer 19 is 0.26088643074035645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1257.409912109375.\n",
      "The relative quantization error of layer 20 is 0.31042230129241943.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2022.402587890625.\n",
      "The relative quantization error of layer 21 is 0.3309933841228485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1999.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 448.75421142578125.\n",
      "The relative quantization error of layer 22 is 0.2786717116832733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1004.46630859375.\n",
      "The relative quantization error of layer 23 is 0.370974063873291.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:08<00:00, 60.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3408.293212890625.\n",
      "The relative quantization error of layer 24 is 0.3697589039802551.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1031.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 631.3655395507812.\n",
      "The relative quantization error of layer 25 is 0.32863354682922363.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1356.643798828125.\n",
      "The relative quantization error of layer 26 is 0.3699791431427002.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3526.03759765625.\n",
      "The relative quantization error of layer 27 is 0.35786110162734985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1329.8328857421875.\n",
      "The relative quantization error of layer 28 is 0.3371361196041107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3302.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.0072937011719.\n",
      "The relative quantization error of layer 29 is 0.18274563550949097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1025.3470458984375.\n",
      "The relative quantization error of layer 30 is 0.45771265029907227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1564.211181640625.\n",
      "The relative quantization error of layer 31 is 0.37296900153160095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3289.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 300.8091735839844.\n",
      "The relative quantization error of layer 32 is 0.22533626854419708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 883.5665283203125.\n",
      "The relative quantization error of layer 33 is 0.47326940298080444.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1686.2115478515625.\n",
      "The relative quantization error of layer 34 is 0.39149942994117737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3391.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 250.1402130126953.\n",
      "The relative quantization error of layer 35 is 0.20729191601276398.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1022.0507202148438.\n",
      "The relative quantization error of layer 36 is 0.5165676474571228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 246.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1781.1630859375.\n",
      "The relative quantization error of layer 37 is 0.42460551857948303.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3396.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 211.29254150390625.\n",
      "The relative quantization error of layer 38 is 0.20875142514705658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1350.536865234375.\n",
      "The relative quantization error of layer 39 is 0.5059906244277954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 167.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1871.130126953125.\n",
      "The relative quantization error of layer 40 is 0.42541947960853577.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1742.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 186.30003356933594.\n",
      "The relative quantization error of layer 41 is 0.22584910690784454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1398.878662109375.\n",
      "The relative quantization error of layer 42 is 0.5251028537750244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:10<00:00, 99.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2545.761474609375.\n",
      "The relative quantization error of layer 43 is 0.456582248210907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1193.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 149.9547882080078.\n",
      "The relative quantization error of layer 44 is 0.1942681223154068.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 918.8423461914062.\n",
      "The relative quantization error of layer 45 is 0.43143993616104126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:33<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2188.939208984375.\n",
      "The relative quantization error of layer 46 is 0.4717807471752167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 619.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 400.45440673828125.\n",
      "The relative quantization error of layer 47 is 0.405831903219223.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2723.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.97296142578125.\n",
      "The relative quantization error of layer 48 is 0.0880088359117508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 523.955322265625.\n",
      "The relative quantization error of layer 49 is 0.6574284434318542.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 626.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 517.71533203125.\n",
      "The relative quantization error of layer 50 is 0.26343321800231934.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2704.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 100.82210540771484.\n",
      "The relative quantization error of layer 51 is 0.14651837944984436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 231.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 107.30517578125.\n",
      "The relative quantization error of layer 52 is 0.7783093452453613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8366.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.344383239746094.\n",
      "The relative quantization error of layer 53 is 0.1880931407213211.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:58.145158\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:44<00:00, 17.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.944.\n",
      "Top-5 accuracy of quantized resnet50 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:04:44.396653\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4532\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 632.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 77.00394439697266.\n",
      "The relative quantization error of layer 0 is 0.017932992428541183.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 159.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 839.0157470703125.\n",
      "The relative quantization error of layer 1 is 0.047501787543296814.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1012.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 245.4951171875.\n",
      "The relative quantization error of layer 2 is 0.05606419965624809.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3551.338623046875.\n",
      "The relative quantization error of layer 3 is 0.0983395129442215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1293.8492431640625.\n",
      "The relative quantization error of layer 4 is 0.04519612342119217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 571.3353881835938.\n",
      "The relative quantization error of layer 5 is 0.1993127316236496.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1217.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 257.43878173828125.\n",
      "The relative quantization error of layer 6 is 0.23324550688266754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1010.6222534179688.\n",
      "The relative quantization error of layer 7 is 0.2250715047121048.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 880.0641479492188.\n",
      "The relative quantization error of layer 8 is 0.2670334279537201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 872.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 560.5342407226562.\n",
      "The relative quantization error of layer 9 is 0.27184757590293884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1518.00927734375.\n",
      "The relative quantization error of layer 10 is 0.23454183340072632.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:08<00:00, 30.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1636.6207275390625.\n",
      "The relative quantization error of layer 11 is 0.30605313181877136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 528.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1151.42333984375.\n",
      "The relative quantization error of layer 12 is 0.2982812523841858.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1473.5892333984375.\n",
      "The relative quantization error of layer 13 is 0.21379989385604858.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1887.596923828125.\n",
      "The relative quantization error of layer 14 is 0.2945047616958618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2085.7412109375.\n",
      "The relative quantization error of layer 15 is 0.27813613414764404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1998.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 507.6640625.\n",
      "The relative quantization error of layer 16 is 0.2335897833108902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1140.573486328125.\n",
      "The relative quantization error of layer 17 is 0.38961538672447205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1718.52099609375.\n",
      "The relative quantization error of layer 18 is 0.30662310123443604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2040.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 361.37213134765625.\n",
      "The relative quantization error of layer 19 is 0.2653104364871979.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1158.7349853515625.\n",
      "The relative quantization error of layer 20 is 0.3006274998188019.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 156.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1935.8995361328125.\n",
      "The relative quantization error of layer 21 is 0.33634912967681885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2048.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 421.9712219238281.\n",
      "The relative quantization error of layer 22 is 0.2810002565383911.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1013.8576049804688.\n",
      "The relative quantization error of layer 23 is 0.38445550203323364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 70.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3296.330810546875.\n",
      "The relative quantization error of layer 24 is 0.37195298075675964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 991.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 623.0291137695312.\n",
      "The relative quantization error of layer 25 is 0.3274637460708618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1347.105712890625.\n",
      "The relative quantization error of layer 26 is 0.3668864369392395.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3329.45947265625.\n",
      "The relative quantization error of layer 27 is 0.36492517590522766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 289.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1320.6663818359375.\n",
      "The relative quantization error of layer 28 is 0.34445494413375854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3230.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 253.59371948242188.\n",
      "The relative quantization error of layer 29 is 0.17921796441078186.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 107.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1031.9864501953125.\n",
      "The relative quantization error of layer 30 is 0.46844008564949036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1558.1571044921875.\n",
      "The relative quantization error of layer 31 is 0.3779887557029724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3272.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 297.7763671875.\n",
      "The relative quantization error of layer 32 is 0.22848060727119446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 894.0319213867188.\n",
      "The relative quantization error of layer 33 is 0.49412745237350464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 289.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1700.7791748046875.\n",
      "The relative quantization error of layer 34 is 0.42542824149131775.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3283.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.5008087158203.\n",
      "The relative quantization error of layer 35 is 0.2079160362482071.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 84.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1030.412841796875.\n",
      "The relative quantization error of layer 36 is 0.5217610597610474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:08<00:00, 127.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1780.1197509765625.\n",
      "The relative quantization error of layer 37 is 0.43919339776039124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1046.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 214.9705047607422.\n",
      "The relative quantization error of layer 38 is 0.2185717225074768.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 82.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1383.0689697265625.\n",
      "The relative quantization error of layer 39 is 0.5216742157936096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:12<00:00, 81.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1901.09326171875.\n",
      "The relative quantization error of layer 40 is 0.4543672502040863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1452.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 184.57325744628906.\n",
      "The relative quantization error of layer 41 is 0.23370908200740814.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 85.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1486.0079345703125.\n",
      "The relative quantization error of layer 42 is 0.5547121167182922.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:09<00:00, 107.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2608.126220703125.\n",
      "The relative quantization error of layer 43 is 0.4735719859600067.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:08<00:00, 537.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 173.57444763183594.\n",
      "The relative quantization error of layer 44 is 0.21427378058433533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 126.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 984.7298583984375.\n",
      "The relative quantization error of layer 45 is 0.45194923877716064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:40<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2287.47607421875.\n",
      "The relative quantization error of layer 46 is 0.4804249107837677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:19<00:00, 107.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 458.9846496582031.\n",
      "The relative quantization error of layer 47 is 0.4138466715812683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:07<00:00, 578.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 123.911865234375.\n",
      "The relative quantization error of layer 48 is 0.131944477558136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:06<00:00, 77.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 556.620849609375.\n",
      "The relative quantization error of layer 49 is 0.7123172283172607.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:08<00:00, 236.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 544.5306396484375.\n",
      "The relative quantization error of layer 50 is 0.25332754850387573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:04<00:00, 961.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 97.31473541259766.\n",
      "The relative quantization error of layer 51 is 0.157501682639122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:05<00:00, 86.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 122.1148681640625.\n",
      "The relative quantization error of layer 52 is 0.8269721865653992.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 6530.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 50.280364990234375.\n",
      "The relative quantization error of layer 53 is 0.2900913953781128.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:19:34.965933\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:41<00:00, 18.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.8677777777777778.\n",
      "Top-5 accuracy of quantized resnet50 is 0.9888888888888889.\n",
      "\n",
      "Time used for evaluation: 0:04:41.822169\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4473\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 624.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.09091186523438.\n",
      "The relative quantization error of layer 0 is 0.01775999180972576.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 849.3851318359375.\n",
      "The relative quantization error of layer 1 is 0.04769909009337425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1964.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 239.53089904785156.\n",
      "The relative quantization error of layer 2 is 0.05397773161530495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3636.421875.\n",
      "The relative quantization error of layer 3 is 0.10389135777950287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1395.2291259765625.\n",
      "The relative quantization error of layer 4 is 0.047096725553274155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 60.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 562.5392456054688.\n",
      "The relative quantization error of layer 5 is 0.19429431855678558.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 937.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 277.0576477050781.\n",
      "The relative quantization error of layer 6 is 0.23259307444095612.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1125.2132568359375.\n",
      "The relative quantization error of layer 7 is 0.22867043316364288.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 66.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 892.96630859375.\n",
      "The relative quantization error of layer 8 is 0.2626506984233856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1058.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 574.1468505859375.\n",
      "The relative quantization error of layer 9 is 0.27614426612854004.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1652.3902587890625.\n",
      "The relative quantization error of layer 10 is 0.24034163355827332.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1713.5169677734375.\n",
      "The relative quantization error of layer 11 is 0.303669273853302.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 497.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1204.926025390625.\n",
      "The relative quantization error of layer 12 is 0.29576829075813293.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1540.88623046875.\n",
      "The relative quantization error of layer 13 is 0.21818788349628448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1894.62353515625.\n",
      "The relative quantization error of layer 14 is 0.2904755175113678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2070.8466796875.\n",
      "The relative quantization error of layer 15 is 0.276223748922348.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1872.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 542.4942626953125.\n",
      "The relative quantization error of layer 16 is 0.24785804748535156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1209.2918701171875.\n",
      "The relative quantization error of layer 17 is 0.3996778726577759.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 153.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1777.8575439453125.\n",
      "The relative quantization error of layer 18 is 0.30032649636268616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1558.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 365.2711486816406.\n",
      "The relative quantization error of layer 19 is 0.2616574168205261.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1266.6888427734375.\n",
      "The relative quantization error of layer 20 is 0.3085392713546753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1992.200927734375.\n",
      "The relative quantization error of layer 21 is 0.32671183347702026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1287.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 445.4419250488281.\n",
      "The relative quantization error of layer 22 is 0.263419508934021.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1033.994384765625.\n",
      "The relative quantization error of layer 23 is 0.32399365305900574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3385.373779296875.\n",
      "The relative quantization error of layer 24 is 0.3695719242095947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1027.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 616.9096069335938.\n",
      "The relative quantization error of layer 25 is 0.3161713182926178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1350.424560546875.\n",
      "The relative quantization error of layer 26 is 0.3636794984340668.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3428.4833984375.\n",
      "The relative quantization error of layer 27 is 0.34877124428749084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.51it/s]\n",
      " 15%|█▌        | 351/2304 [00:00<00:00, 3499.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1383.012939453125.\n",
      "The relative quantization error of layer 28 is 0.3440436124801636.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3308.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 259.45947265625.\n",
      "The relative quantization error of layer 29 is 0.17447149753570557.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 974.4658203125.\n",
      "The relative quantization error of layer 30 is 0.4154207110404968.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.35it/s]\n",
      " 15%|█▍        | 343/2304 [00:00<00:00, 3422.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1528.201171875.\n",
      "The relative quantization error of layer 31 is 0.36708056926727295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3308.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 299.7994689941406.\n",
      "The relative quantization error of layer 32 is 0.2291959971189499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 100.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 900.498779296875.\n",
      "The relative quantization error of layer 33 is 0.4851643443107605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 303.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1687.170166015625.\n",
      "The relative quantization error of layer 34 is 0.3944142460823059.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3302.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 241.631591796875.\n",
      "The relative quantization error of layer 35 is 0.20569108426570892.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1036.32177734375.\n",
      "The relative quantization error of layer 36 is 0.5119791030883789.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1790.5494384765625.\n",
      "The relative quantization error of layer 37 is 0.4283056855201721.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2736.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.31993103027344.\n",
      "The relative quantization error of layer 38 is 0.2056652307510376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 92.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1394.239013671875.\n",
      "The relative quantization error of layer 39 is 0.5227258801460266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1875.604248046875.\n",
      "The relative quantization error of layer 40 is 0.43823572993278503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3305.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.20159912109375.\n",
      "The relative quantization error of layer 41 is 0.21620607376098633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 115.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1444.5570068359375.\n",
      "The relative quantization error of layer 42 is 0.5422229766845703.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 150.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2585.7666015625.\n",
      "The relative quantization error of layer 43 is 0.46299612522125244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1548.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.22711181640625.\n",
      "The relative quantization error of layer 44 is 0.20049868524074554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 191.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 961.26904296875.\n",
      "The relative quantization error of layer 45 is 0.43838241696357727.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2238.960693359375.\n",
      "The relative quantization error of layer 46 is 0.4709851145744324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 591.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 454.0386047363281.\n",
      "The relative quantization error of layer 47 is 0.40519511699676514.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2688.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.92285919189453.\n",
      "The relative quantization error of layer 48 is 0.10349699854850769.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 543.9711303710938.\n",
      "The relative quantization error of layer 49 is 0.6817748546600342.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 603.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 486.1423645019531.\n",
      "The relative quantization error of layer 50 is 0.2781708836555481.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2690.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 77.2095947265625.\n",
      "The relative quantization error of layer 51 is 0.15140312910079956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 233.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 130.79286193847656.\n",
      "The relative quantization error of layer 52 is 0.8565225601196289.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8395.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 46.66645431518555.\n",
      "The relative quantization error of layer 53 is 0.28263789415359497.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:35.299892\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:41<00:00, 17.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.712.\n",
      "Top-5 accuracy of quantized resnet50 is 0.952.\n",
      "\n",
      "Time used for evaluation: 0:04:41.537791\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4535\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 622.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 71.58513641357422.\n",
      "The relative quantization error of layer 0 is 0.017526987940073013.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 164.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 753.5476684570312.\n",
      "The relative quantization error of layer 1 is 0.04266781732439995.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1143.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 230.0458526611328.\n",
      "The relative quantization error of layer 2 is 0.054418954998254776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3582.900390625.\n",
      "The relative quantization error of layer 3 is 0.09903595596551895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1162.944091796875.\n",
      "The relative quantization error of layer 4 is 0.03990199789404869.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 553.2701416015625.\n",
      "The relative quantization error of layer 5 is 0.19487126171588898.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1176.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 228.7905731201172.\n",
      "The relative quantization error of layer 6 is 0.21409817039966583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 902.3150024414062.\n",
      "The relative quantization error of layer 7 is 0.2084118127822876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 807.8629760742188.\n",
      "The relative quantization error of layer 8 is 0.2526985704898834.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1237.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 526.500732421875.\n",
      "The relative quantization error of layer 9 is 0.2626165449619293.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1500.595703125.\n",
      "The relative quantization error of layer 10 is 0.23082603514194489.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1540.8472900390625.\n",
      "The relative quantization error of layer 11 is 0.30251169204711914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 512.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1091.2764892578125.\n",
      "The relative quantization error of layer 12 is 0.2899293303489685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 42.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1447.5804443359375.\n",
      "The relative quantization error of layer 13 is 0.21139781177043915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1784.096435546875.\n",
      "The relative quantization error of layer 14 is 0.287868469953537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1913.435791015625.\n",
      "The relative quantization error of layer 15 is 0.2760104238986969.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 495.3267822265625.\n",
      "The relative quantization error of layer 16 is 0.23568324744701385.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1149.10693359375.\n",
      "The relative quantization error of layer 17 is 0.39669743180274963.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1705.69677734375.\n",
      "The relative quantization error of layer 18 is 0.31072697043418884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2025.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 355.8960876464844.\n",
      "The relative quantization error of layer 19 is 0.263635516166687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1198.43310546875.\n",
      "The relative quantization error of layer 20 is 0.3020772635936737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 128.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1889.0155029296875.\n",
      "The relative quantization error of layer 21 is 0.3402687907218933.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2046.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 418.677001953125.\n",
      "The relative quantization error of layer 22 is 0.2797325849533081.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 48.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 949.2933959960938.\n",
      "The relative quantization error of layer 23 is 0.3977782428264618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3259.343994140625.\n",
      "The relative quantization error of layer 24 is 0.3711603581905365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1065.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 625.4447631835938.\n",
      "The relative quantization error of layer 25 is 0.32257264852523804.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1324.4471435546875.\n",
      "The relative quantization error of layer 26 is 0.36053788661956787.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3306.77880859375.\n",
      "The relative quantization error of layer 27 is 0.36338841915130615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 305.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1339.7276611328125.\n",
      "The relative quantization error of layer 28 is 0.35119935870170593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2908.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 256.2504577636719.\n",
      "The relative quantization error of layer 29 is 0.17944352328777313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 116.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 999.3295288085938.\n",
      "The relative quantization error of layer 30 is 0.459764689207077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1555.252197265625.\n",
      "The relative quantization error of layer 31 is 0.3815849721431732.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3307.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.3013916015625.\n",
      "The relative quantization error of layer 32 is 0.2206534743309021.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 117.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 903.1223754882812.\n",
      "The relative quantization error of layer 33 is 0.49444571137428284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 243.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1705.334716796875.\n",
      "The relative quantization error of layer 34 is 0.4225030541419983.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3382.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 239.8165740966797.\n",
      "The relative quantization error of layer 35 is 0.19816765189170837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1066.2869873046875.\n",
      "The relative quantization error of layer 36 is 0.5275419354438782.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 294.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1819.19091796875.\n",
      "The relative quantization error of layer 37 is 0.44712838530540466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3360.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 211.96176147460938.\n",
      "The relative quantization error of layer 38 is 0.21192306280136108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1373.6878662109375.\n",
      "The relative quantization error of layer 39 is 0.5123444199562073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 293.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1936.1552734375.\n",
      "The relative quantization error of layer 40 is 0.4586152732372284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3325.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 179.28097534179688.\n",
      "The relative quantization error of layer 41 is 0.2208939790725708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1508.074462890625.\n",
      "The relative quantization error of layer 42 is 0.5548049807548523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 152.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2603.759033203125.\n",
      "The relative quantization error of layer 43 is 0.4743369519710541.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1540.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 156.38546752929688.\n",
      "The relative quantization error of layer 44 is 0.20039613544940948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 220.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 985.7859497070312.\n",
      "The relative quantization error of layer 45 is 0.45544466376304626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2292.585205078125.\n",
      "The relative quantization error of layer 46 is 0.4844721555709839.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 610.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 463.7642822265625.\n",
      "The relative quantization error of layer 47 is 0.4271930158138275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2713.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 123.92115020751953.\n",
      "The relative quantization error of layer 48 is 0.12370340526103973.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 556.1546020507812.\n",
      "The relative quantization error of layer 49 is 0.7019863724708557.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 622.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 500.8628845214844.\n",
      "The relative quantization error of layer 50 is 0.37071478366851807.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2738.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 78.37094116210938.\n",
      "The relative quantization error of layer 51 is 0.16377705335617065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 198.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 125.56895446777344.\n",
      "The relative quantization error of layer 52 is 0.8283141255378723.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8706.20it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 50.13181686401367.\n",
      "The relative quantization error of layer 53 is 0.29374805092811584.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:27.580306\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:44<00:00, 17.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.566.\n",
      "Top-5 accuracy of quantized resnet50 is 0.909.\n",
      "\n",
      "Time used for evaluation: 0:04:44.780029\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4512\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 621.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 82.26408386230469.\n",
      "The relative quantization error of layer 0 is 0.01848195493221283.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 77.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 912.5191650390625.\n",
      "The relative quantization error of layer 1 is 0.05142136663198471.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1148.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 253.37196350097656.\n",
      "The relative quantization error of layer 2 is 0.05563150346279144.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3316.61865234375.\n",
      "The relative quantization error of layer 3 is 0.10090208053588867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1512.324951171875.\n",
      "The relative quantization error of layer 4 is 0.051529355347156525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 605.3088989257812.\n",
      "The relative quantization error of layer 5 is 0.20544715225696564.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1125.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 275.3521423339844.\n",
      "The relative quantization error of layer 6 is 0.2420693039894104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1103.005859375.\n",
      "The relative quantization error of layer 7 is 0.23934058845043182.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 72.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 911.3048095703125.\n",
      "The relative quantization error of layer 8 is 0.26838839054107666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1075.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 596.9483642578125.\n",
      "The relative quantization error of layer 9 is 0.2834082841873169.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1575.0262451171875.\n",
      "The relative quantization error of layer 10 is 0.23675432801246643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1735.103515625.\n",
      "The relative quantization error of layer 11 is 0.31006214022636414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 523.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1207.7529296875.\n",
      "The relative quantization error of layer 12 is 0.30779123306274414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1553.8685302734375.\n",
      "The relative quantization error of layer 13 is 0.22268298268318176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2112.465576171875.\n",
      "The relative quantization error of layer 14 is 0.2946980595588684.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 148.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2066.927978515625.\n",
      "The relative quantization error of layer 15 is 0.2749321758747101.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1989.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 530.0868530273438.\n",
      "The relative quantization error of layer 16 is 0.2404780387878418.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1206.78564453125.\n",
      "The relative quantization error of layer 17 is 0.39188912510871887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 142.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1828.7613525390625.\n",
      "The relative quantization error of layer 18 is 0.3077314794063568.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1813.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 369.5491027832031.\n",
      "The relative quantization error of layer 19 is 0.2601667046546936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1217.7332763671875.\n",
      "The relative quantization error of layer 20 is 0.3017500340938568.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2022.1983642578125.\n",
      "The relative quantization error of layer 21 is 0.33785223960876465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1973.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 442.93988037109375.\n",
      "The relative quantization error of layer 22 is 0.27513590455055237.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 963.4227905273438.\n",
      "The relative quantization error of layer 23 is 0.38160932064056396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3325.09375.\n",
      "The relative quantization error of layer 24 is 0.36853140592575073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 938.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 623.9232177734375.\n",
      "The relative quantization error of layer 25 is 0.32397693395614624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1339.945068359375.\n",
      "The relative quantization error of layer 26 is 0.36996060609817505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3468.337890625.\n",
      "The relative quantization error of layer 27 is 0.35330748558044434.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1344.4691162109375.\n",
      "The relative quantization error of layer 28 is 0.33109351992607117.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3302.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 261.95550537109375.\n",
      "The relative quantization error of layer 29 is 0.18054702877998352.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 956.3783569335938.\n",
      "The relative quantization error of layer 30 is 0.4392375648021698.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 310.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1542.5428466796875.\n",
      "The relative quantization error of layer 31 is 0.3670651316642761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3267.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 297.5924377441406.\n",
      "The relative quantization error of layer 32 is 0.21903856098651886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 918.1495361328125.\n",
      "The relative quantization error of layer 33 is 0.4840923547744751.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 300.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1664.3902587890625.\n",
      "The relative quantization error of layer 34 is 0.4139508903026581.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3254.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.5343475341797.\n",
      "The relative quantization error of layer 35 is 0.2021312415599823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 99.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1062.680908203125.\n",
      "The relative quantization error of layer 36 is 0.5109212398529053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 301.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1767.3597412109375.\n",
      "The relative quantization error of layer 37 is 0.42298999428749084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3366.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 218.2825927734375.\n",
      "The relative quantization error of layer 38 is 0.21730434894561768.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1387.88916015625.\n",
      "The relative quantization error of layer 39 is 0.5087666511535645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 290.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1821.2255859375.\n",
      "The relative quantization error of layer 40 is 0.429330438375473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3318.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 184.45803833007812.\n",
      "The relative quantization error of layer 41 is 0.21932892501354218.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 107.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1445.3221435546875.\n",
      "The relative quantization error of layer 42 is 0.5489568710327148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 151.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2465.47509765625.\n",
      "The relative quantization error of layer 43 is 0.4455355405807495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1546.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 166.43836975097656.\n",
      "The relative quantization error of layer 44 is 0.20673489570617676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 224.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 927.8241577148438.\n",
      "The relative quantization error of layer 45 is 0.41835564374923706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:33<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2149.673828125.\n",
      "The relative quantization error of layer 46 is 0.4627295136451721.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 613.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 412.5455322265625.\n",
      "The relative quantization error of layer 47 is 0.41448426246643066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2676.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 112.21393585205078.\n",
      "The relative quantization error of layer 48 is 0.12500597536563873.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 230.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 528.496826171875.\n",
      "The relative quantization error of layer 49 is 0.6591005325317383.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 626.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 477.26593017578125.\n",
      "The relative quantization error of layer 50 is 0.28352758288383484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2724.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 119.5755386352539.\n",
      "The relative quantization error of layer 51 is 0.2056042104959488.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 115.55596160888672.\n",
      "The relative quantization error of layer 52 is 0.7898293137550354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 7883.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.407140731811523.\n",
      "The relative quantization error of layer 53 is 0.18015022575855255.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:30.038428\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:43<00:00, 17.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.93.\n",
      "Top-5 accuracy of quantized resnet50 is 0.983.\n",
      "\n",
      "Time used for evaluation: 0:04:43.231390\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4534\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 350.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 76.37206268310547.\n",
      "The relative quantization error of layer 0 is 0.01800161972641945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 75.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 946.8336791992188.\n",
      "The relative quantization error of layer 1 is 0.05323905870318413.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1058.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 247.17056274414062.\n",
      "The relative quantization error of layer 2 is 0.05713644623756409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3537.513916015625.\n",
      "The relative quantization error of layer 3 is 0.10010088980197906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1408.6539306640625.\n",
      "The relative quantization error of layer 4 is 0.04868036508560181.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 68.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 581.1993408203125.\n",
      "The relative quantization error of layer 5 is 0.2010357677936554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1155.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 270.939453125.\n",
      "The relative quantization error of layer 6 is 0.2344055473804474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1029.703857421875.\n",
      "The relative quantization error of layer 7 is 0.22751864790916443.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 860.6802978515625.\n",
      "The relative quantization error of layer 8 is 0.2611450254917145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1132.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 585.0855712890625.\n",
      "The relative quantization error of layer 9 is 0.2874312102794647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1563.9737548828125.\n",
      "The relative quantization error of layer 10 is 0.24000757932662964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1682.2591552734375.\n",
      "The relative quantization error of layer 11 is 0.3159104287624359.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 516.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1192.7261962890625.\n",
      "The relative quantization error of layer 12 is 0.3016739785671234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1537.2630615234375.\n",
      "The relative quantization error of layer 13 is 0.22138354182243347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:27<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2023.84033203125.\n",
      "The relative quantization error of layer 14 is 0.3004913926124573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 156.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2063.697021484375.\n",
      "The relative quantization error of layer 15 is 0.2759522497653961.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2081.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 543.5457763671875.\n",
      "The relative quantization error of layer 16 is 0.24311034381389618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1249.7158203125.\n",
      "The relative quantization error of layer 17 is 0.4063214361667633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1817.053955078125.\n",
      "The relative quantization error of layer 18 is 0.31700751185417175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1916.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 375.2830505371094.\n",
      "The relative quantization error of layer 19 is 0.27331796288490295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1271.1387939453125.\n",
      "The relative quantization error of layer 20 is 0.3155481219291687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 151.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2000.6063232421875.\n",
      "The relative quantization error of layer 21 is 0.3486306071281433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2022.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 426.1191711425781.\n",
      "The relative quantization error of layer 22 is 0.2787975072860718.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 991.6234741210938.\n",
      "The relative quantization error of layer 23 is 0.40038737654685974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 71.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3520.555419921875.\n",
      "The relative quantization error of layer 24 is 0.388640433549881.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 810.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 626.951171875.\n",
      "The relative quantization error of layer 25 is 0.3250172734260559.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 102.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1379.6650390625.\n",
      "The relative quantization error of layer 26 is 0.3794446587562561.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3463.07763671875.\n",
      "The relative quantization error of layer 27 is 0.37129396200180054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 271.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1367.9456787109375.\n",
      "The relative quantization error of layer 28 is 0.35327303409576416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2810.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.24212646484375.\n",
      "The relative quantization error of layer 29 is 0.18225522339344025.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 98.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 989.7644653320312.\n",
      "The relative quantization error of layer 30 is 0.4518119990825653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 243.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1544.4844970703125.\n",
      "The relative quantization error of layer 31 is 0.37769222259521484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2337.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 298.6039123535156.\n",
      "The relative quantization error of layer 32 is 0.2280488908290863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 874.3130493164062.\n",
      "The relative quantization error of layer 33 is 0.4809192717075348.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 236.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1673.4835205078125.\n",
      "The relative quantization error of layer 34 is 0.41995927691459656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3293.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.9981689453125.\n",
      "The relative quantization error of layer 35 is 0.2060193121433258.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1069.5069580078125.\n",
      "The relative quantization error of layer 36 is 0.5379599332809448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:05<00:00, 201.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1797.5372314453125.\n",
      "The relative quantization error of layer 37 is 0.44193586707115173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3295.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 207.34536743164062.\n",
      "The relative quantization error of layer 38 is 0.21034759283065796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 114.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1412.8182373046875.\n",
      "The relative quantization error of layer 39 is 0.5242809653282166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 237.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1902.695068359375.\n",
      "The relative quantization error of layer 40 is 0.45420435070991516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2445.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 191.79759216308594.\n",
      "The relative quantization error of layer 41 is 0.2346443235874176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1470.600830078125.\n",
      "The relative quantization error of layer 42 is 0.5547797679901123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 149.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2668.817626953125.\n",
      "The relative quantization error of layer 43 is 0.4748552739620209.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1544.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 169.9649200439453.\n",
      "The relative quantization error of layer 44 is 0.21091431379318237.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 228.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 981.91748046875.\n",
      "The relative quantization error of layer 45 is 0.446438729763031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:31<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2275.379150390625.\n",
      "The relative quantization error of layer 46 is 0.4777030050754547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 607.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 453.9031677246094.\n",
      "The relative quantization error of layer 47 is 0.40424367785453796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2712.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 125.64439392089844.\n",
      "The relative quantization error of layer 48 is 0.13930602371692657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 559.3713989257812.\n",
      "The relative quantization error of layer 49 is 0.6964532136917114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 600.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 522.8226928710938.\n",
      "The relative quantization error of layer 50 is 0.32453081011772156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2859.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 92.87886810302734.\n",
      "The relative quantization error of layer 51 is 0.1769603043794632.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 113.996337890625.\n",
      "The relative quantization error of layer 52 is 0.8259173035621643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8599.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.462772369384766.\n",
      "The relative quantization error of layer 53 is 0.2657056152820587.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:47.885120\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:45<00:00, 17.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.869.\n",
      "Top-5 accuracy of quantized resnet50 is 0.988.\n",
      "\n",
      "Time used for evaluation: 0:04:45.224747\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4503\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 606.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 70.51956939697266.\n",
      "The relative quantization error of layer 0 is 0.018474066630005836.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 163.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 855.737548828125.\n",
      "The relative quantization error of layer 1 is 0.048741888254880905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1937.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 245.85545349121094.\n",
      "The relative quantization error of layer 2 is 0.05703385919332504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3491.4677734375.\n",
      "The relative quantization error of layer 3 is 0.10177075117826462.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1372.15185546875.\n",
      "The relative quantization error of layer 4 is 0.047480110079050064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 556.0940551757812.\n",
      "The relative quantization error of layer 5 is 0.19560791552066803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 926.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 267.2742919921875.\n",
      "The relative quantization error of layer 6 is 0.2486599236726761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1012.5257568359375.\n",
      "The relative quantization error of layer 7 is 0.22799985110759735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 876.9752197265625.\n",
      "The relative quantization error of layer 8 is 0.26663967967033386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 563.4881591796875.\n",
      "The relative quantization error of layer 9 is 0.2746000587940216.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1473.658935546875.\n",
      "The relative quantization error of layer 10 is 0.23064036667346954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1626.321044921875.\n",
      "The relative quantization error of layer 11 is 0.30972883105278015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 517.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1156.3865966796875.\n",
      "The relative quantization error of layer 12 is 0.294218510389328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1512.2349853515625.\n",
      "The relative quantization error of layer 13 is 0.2183808982372284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1957.320068359375.\n",
      "The relative quantization error of layer 14 is 0.29968827962875366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2039.9356689453125.\n",
      "The relative quantization error of layer 15 is 0.27119162678718567.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2009.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 516.0846557617188.\n",
      "The relative quantization error of layer 16 is 0.23761914670467377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1243.011962890625.\n",
      "The relative quantization error of layer 17 is 0.4137955904006958.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 156.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1827.9365234375.\n",
      "The relative quantization error of layer 18 is 0.31896838545799255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2044.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 376.80230712890625.\n",
      "The relative quantization error of layer 19 is 0.26751384139060974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1214.26513671875.\n",
      "The relative quantization error of layer 20 is 0.30570924282073975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 149.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1975.9095458984375.\n",
      "The relative quantization error of layer 21 is 0.3422848880290985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2027.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 428.19580078125.\n",
      "The relative quantization error of layer 22 is 0.2738424837589264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1050.280517578125.\n",
      "The relative quantization error of layer 23 is 0.3901602029800415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 71.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3326.97021484375.\n",
      "The relative quantization error of layer 24 is 0.3686615824699402.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1085.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 627.8720092773438.\n",
      "The relative quantization error of layer 25 is 0.32092368602752686.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 92.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1347.6688232421875.\n",
      "The relative quantization error of layer 26 is 0.36775004863739014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:32<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3363.28662109375.\n",
      "The relative quantization error of layer 27 is 0.3607351779937744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1361.2840576171875.\n",
      "The relative quantization error of layer 28 is 0.3402490019798279.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3236.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.306884765625.\n",
      "The relative quantization error of layer 29 is 0.18355147540569305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1030.6669921875.\n",
      "The relative quantization error of layer 30 is 0.4467928111553192.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1530.65673828125.\n",
      "The relative quantization error of layer 31 is 0.37347719073295593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3282.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 300.9764709472656.\n",
      "The relative quantization error of layer 32 is 0.2279220074415207.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 892.80419921875.\n",
      "The relative quantization error of layer 33 is 0.4902005195617676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 295.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1758.0694580078125.\n",
      "The relative quantization error of layer 34 is 0.41691648960113525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3269.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.92262268066406.\n",
      "The relative quantization error of layer 35 is 0.21055883169174194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1060.092529296875.\n",
      "The relative quantization error of layer 36 is 0.5380582809448242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 219.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1838.09375.\n",
      "The relative quantization error of layer 37 is 0.44582197070121765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2748.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 206.137939453125.\n",
      "The relative quantization error of layer 38 is 0.21156847476959229.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 105.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1411.35400390625.\n",
      "The relative quantization error of layer 39 is 0.5333833694458008.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1902.6715087890625.\n",
      "The relative quantization error of layer 40 is 0.44375020265579224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3514.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 192.24952697753906.\n",
      "The relative quantization error of layer 41 is 0.2367732673883438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1441.6064453125.\n",
      "The relative quantization error of layer 42 is 0.5557463765144348.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 147.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2609.33251953125.\n",
      "The relative quantization error of layer 43 is 0.4710772931575775.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1533.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 167.20620727539062.\n",
      "The relative quantization error of layer 44 is 0.2115904837846756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 226.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 957.9407348632812.\n",
      "The relative quantization error of layer 45 is 0.43896540999412537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:31<00:00, 32.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2249.407470703125.\n",
      "The relative quantization error of layer 46 is 0.4836711287498474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 581.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 453.37066650390625.\n",
      "The relative quantization error of layer 47 is 0.42855891585350037.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2899.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 111.97702026367188.\n",
      "The relative quantization error of layer 48 is 0.10766835510730743.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 231.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 565.9757690429688.\n",
      "The relative quantization error of layer 49 is 0.6822047233581543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 514.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 454.1347351074219.\n",
      "The relative quantization error of layer 50 is 0.27547264099121094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2699.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 124.02233123779297.\n",
      "The relative quantization error of layer 51 is 0.1750284731388092.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 229.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 118.39173889160156.\n",
      "The relative quantization error of layer 52 is 0.8172175884246826.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8256.40it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 41.53630447387695.\n",
      "The relative quantization error of layer 53 is 0.25952181220054626.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:38.966051\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:43<00:00, 17.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.793.\n",
      "Top-5 accuracy of quantized resnet50 is 0.981.\n",
      "\n",
      "Time used for evaluation: 0:04:43.753529\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.446\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 607.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.79631805419922.\n",
      "The relative quantization error of layer 0 is 0.01802506111562252.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 165.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 862.5772705078125.\n",
      "The relative quantization error of layer 1 is 0.04812267795205116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1167.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 231.4818878173828.\n",
      "The relative quantization error of layer 2 is 0.052970945835113525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3632.23681640625.\n",
      "The relative quantization error of layer 3 is 0.10359054058790207.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1277.431640625.\n",
      "The relative quantization error of layer 4 is 0.043199557811021805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 73.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 568.521484375.\n",
      "The relative quantization error of layer 5 is 0.19805629551410675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1252.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 257.1098937988281.\n",
      "The relative quantization error of layer 6 is 0.2262105792760849.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1077.7286376953125.\n",
      "The relative quantization error of layer 7 is 0.23358756303787231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 881.6768188476562.\n",
      "The relative quantization error of layer 8 is 0.2564944922924042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1149.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 556.9952392578125.\n",
      "The relative quantization error of layer 9 is 0.266128808259964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1560.6588134765625.\n",
      "The relative quantization error of layer 10 is 0.23429010808467865.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 33.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1664.4312744140625.\n",
      "The relative quantization error of layer 11 is 0.3022923171520233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 514.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1220.7523193359375.\n",
      "The relative quantization error of layer 12 is 0.29775431752204895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1553.5498046875.\n",
      "The relative quantization error of layer 13 is 0.21910257637500763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1889.6378173828125.\n",
      "The relative quantization error of layer 14 is 0.29030418395996094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:04<00:00, 118.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1975.5235595703125.\n",
      "The relative quantization error of layer 15 is 0.2721136212348938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2047.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 505.4769287109375.\n",
      "The relative quantization error of layer 16 is 0.2369166761636734.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1264.0986328125.\n",
      "The relative quantization error of layer 17 is 0.41517406702041626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 155.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1778.723876953125.\n",
      "The relative quantization error of layer 18 is 0.2995975911617279.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2099.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 363.9788513183594.\n",
      "The relative quantization error of layer 19 is 0.253172904253006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1252.7623291015625.\n",
      "The relative quantization error of layer 20 is 0.30496659874916077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 159.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1966.64501953125.\n",
      "The relative quantization error of layer 21 is 0.3314700126647949.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2004.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 438.14495849609375.\n",
      "The relative quantization error of layer 22 is 0.27833306789398193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 46.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1093.69921875.\n",
      "The relative quantization error of layer 23 is 0.4080129563808441.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3395.527587890625.\n",
      "The relative quantization error of layer 24 is 0.3690411150455475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1017.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 618.0781860351562.\n",
      "The relative quantization error of layer 25 is 0.3163452744483948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 108.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1397.14501953125.\n",
      "The relative quantization error of layer 26 is 0.3708568513393402.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:29<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3432.066650390625.\n",
      "The relative quantization error of layer 27 is 0.35532012581825256.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1366.204833984375.\n",
      "The relative quantization error of layer 28 is 0.342831015586853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3350.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 256.95526123046875.\n",
      "The relative quantization error of layer 29 is 0.17574596405029297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1005.9243774414062.\n",
      "The relative quantization error of layer 30 is 0.44843125343322754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 296.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1546.106689453125.\n",
      "The relative quantization error of layer 31 is 0.3686980605125427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3308.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.5306396484375.\n",
      "The relative quantization error of layer 32 is 0.22096043825149536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 892.0020141601562.\n",
      "The relative quantization error of layer 33 is 0.48030969500541687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 292.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1712.5419921875.\n",
      "The relative quantization error of layer 34 is 0.4180406630039215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3319.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 241.77760314941406.\n",
      "The relative quantization error of layer 35 is 0.2009209245443344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1015.3128051757812.\n",
      "The relative quantization error of layer 36 is 0.5159803628921509.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 299.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1797.897216796875.\n",
      "The relative quantization error of layer 37 is 0.4267067611217499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3313.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 200.7200164794922.\n",
      "The relative quantization error of layer 38 is 0.20553098618984222.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 113.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1349.3790283203125.\n",
      "The relative quantization error of layer 39 is 0.5140124559402466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 271.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1835.81494140625.\n",
      "The relative quantization error of layer 40 is 0.4299265146255493.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3376.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.5244598388672.\n",
      "The relative quantization error of layer 41 is 0.22281509637832642.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 110.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1441.8525390625.\n",
      "The relative quantization error of layer 42 is 0.5340363383293152.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 152.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2543.779541015625.\n",
      "The relative quantization error of layer 43 is 0.45569756627082825.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1311.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 165.84693908691406.\n",
      "The relative quantization error of layer 44 is 0.20154842734336853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 225.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 937.2711791992188.\n",
      "The relative quantization error of layer 45 is 0.4235522150993347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2212.67041015625.\n",
      "The relative quantization error of layer 46 is 0.469913512468338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 599.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 425.2368469238281.\n",
      "The relative quantization error of layer 47 is 0.3728927969932556.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2823.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.28329467773438.\n",
      "The relative quantization error of layer 48 is 0.09758298844099045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 196.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 539.617431640625.\n",
      "The relative quantization error of layer 49 is 0.6649901866912842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 624.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 519.9345092773438.\n",
      "The relative quantization error of layer 50 is 0.30602264404296875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2714.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 62.07569885253906.\n",
      "The relative quantization error of layer 51 is 0.13427411019802094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 233.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 124.3642807006836.\n",
      "The relative quantization error of layer 52 is 0.8233004808425903.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 6438.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 40.41521072387695.\n",
      "The relative quantization error of layer 53 is 0.2256574034690857.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:29.719715\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:41<00:00, 17.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.754.\n",
      "Top-5 accuracy of quantized resnet50 is 0.972.\n",
      "\n",
      "Time used for evaluation: 0:04:41.304364\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4542\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 645.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.90959167480469.\n",
      "The relative quantization error of layer 0 is 0.019259655848145485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 164.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 847.6021728515625.\n",
      "The relative quantization error of layer 1 is 0.048298779875040054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1172.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 235.81703186035156.\n",
      "The relative quantization error of layer 2 is 0.05311627313494682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3328.61328125.\n",
      "The relative quantization error of layer 3 is 0.10427181422710419.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1447.8548583984375.\n",
      "The relative quantization error of layer 4 is 0.04939024895429611.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 616.0802001953125.\n",
      "The relative quantization error of layer 5 is 0.2052582949399948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 884.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 272.28875732421875.\n",
      "The relative quantization error of layer 6 is 0.23430636525154114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1057.46337890625.\n",
      "The relative quantization error of layer 7 is 0.2295939326286316.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 56.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 850.2611083984375.\n",
      "The relative quantization error of layer 8 is 0.26097115874290466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1225.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 596.8565673828125.\n",
      "The relative quantization error of layer 9 is 0.2832832932472229.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1585.2847900390625.\n",
      "The relative quantization error of layer 10 is 0.24121634662151337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1698.635986328125.\n",
      "The relative quantization error of layer 11 is 0.3093184232711792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:02<00:00, 508.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1174.9515380859375.\n",
      "The relative quantization error of layer 12 is 0.30951452255249023.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 41.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1498.442138671875.\n",
      "The relative quantization error of layer 13 is 0.21664030849933624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2025.983154296875.\n",
      "The relative quantization error of layer 14 is 0.2960410714149475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 152.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2136.02490234375.\n",
      "The relative quantization error of layer 15 is 0.26756706833839417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2041.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 527.5017700195312.\n",
      "The relative quantization error of layer 16 is 0.24366126954555511.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 48.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1217.536865234375.\n",
      "The relative quantization error of layer 17 is 0.397887647151947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1798.0113525390625.\n",
      "The relative quantization error of layer 18 is 0.3056126534938812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2066.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 379.5105285644531.\n",
      "The relative quantization error of layer 19 is 0.2645063102245331.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1209.151123046875.\n",
      "The relative quantization error of layer 20 is 0.3002474904060364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 150.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1966.7335205078125.\n",
      "The relative quantization error of layer 21 is 0.325320839881897.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1811.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 449.421630859375.\n",
      "The relative quantization error of layer 22 is 0.27807989716529846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:02<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1046.24267578125.\n",
      "The relative quantization error of layer 23 is 0.39968106150627136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:07<00:00, 72.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3355.93115234375.\n",
      "The relative quantization error of layer 24 is 0.3706209659576416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:02<00:00, 1081.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 621.4179077148438.\n",
      "The relative quantization error of layer 25 is 0.3227756917476654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 100.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1336.4271240234375.\n",
      "The relative quantization error of layer 26 is 0.3685128092765808.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:31<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3409.57763671875.\n",
      "The relative quantization error of layer 27 is 0.35511064529418945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 248.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1346.677490234375.\n",
      "The relative quantization error of layer 28 is 0.33581408858299255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3290.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.20489501953125.\n",
      "The relative quantization error of layer 29 is 0.18206919729709625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 94.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 944.2510375976562.\n",
      "The relative quantization error of layer 30 is 0.4400562047958374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 297.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1518.0438232421875.\n",
      "The relative quantization error of layer 31 is 0.3579534888267517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3318.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 295.6761474609375.\n",
      "The relative quantization error of layer 32 is 0.21715454757213593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 852.7330322265625.\n",
      "The relative quantization error of layer 33 is 0.46309641003608704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 259.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1677.8167724609375.\n",
      "The relative quantization error of layer 34 is 0.38516849279403687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3306.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 241.82174682617188.\n",
      "The relative quantization error of layer 35 is 0.1957426220178604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 96.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1047.26708984375.\n",
      "The relative quantization error of layer 36 is 0.5141669511795044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 278.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1712.2928466796875.\n",
      "The relative quantization error of layer 37 is 0.40952953696250916.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3332.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.97096252441406.\n",
      "The relative quantization error of layer 38 is 0.2025710791349411.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 116.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1328.517822265625.\n",
      "The relative quantization error of layer 39 is 0.5045471787452698.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 268.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1819.9041748046875.\n",
      "The relative quantization error of layer 40 is 0.42343875765800476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2680.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 181.63197326660156.\n",
      "The relative quantization error of layer 41 is 0.2189587950706482.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 112.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1421.666259765625.\n",
      "The relative quantization error of layer 42 is 0.5262741446495056.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:06<00:00, 148.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2483.94287109375.\n",
      "The relative quantization error of layer 43 is 0.4517636299133301.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:03<00:00, 1529.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 163.4862518310547.\n",
      "The relative quantization error of layer 44 is 0.20306514203548431.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 220.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 906.583251953125.\n",
      "The relative quantization error of layer 45 is 0.4323425889015198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2136.69287109375.\n",
      "The relative quantization error of layer 46 is 0.45765548944473267.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 624.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 402.1537780761719.\n",
      "The relative quantization error of layer 47 is 0.38518503308296204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2743.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 106.37165832519531.\n",
      "The relative quantization error of layer 48 is 0.0929693728685379.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 526.903076171875.\n",
      "The relative quantization error of layer 49 is 0.6642101407051086.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 528.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 446.0697937011719.\n",
      "The relative quantization error of layer 50 is 0.2516433298587799.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2738.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 55.01335525512695.\n",
      "The relative quantization error of layer 51 is 0.10050762444734573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:02<00:00, 227.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.36074829101562.\n",
      "The relative quantization error of layer 52 is 0.7872646450996399.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 8556.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 32.97359085083008.\n",
      "The relative quantization error of layer 53 is 0.20818355679512024.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:17:43.703472\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:45<00:00, 10.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.962.\n",
      "Top-5 accuracy of quantized resnet50 is 0.992.\n",
      "\n",
      "Time used for evaluation: 0:02:45.007039\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4544\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 930.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 72.45728302001953.\n",
      "The relative quantization error of layer 0 is 0.017681878060102463.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 191.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 877.7852783203125.\n",
      "The relative quantization error of layer 1 is 0.0492984764277935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2922.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 245.00022888183594.\n",
      "The relative quantization error of layer 2 is 0.05624012276530266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3815.63818359375.\n",
      "The relative quantization error of layer 3 is 0.10800464451313019.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1241.6302490234375.\n",
      "The relative quantization error of layer 4 is 0.0426819808781147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 166.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 588.8751831054688.\n",
      "The relative quantization error of layer 5 is 0.19796541333198547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2923.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 257.7674865722656.\n",
      "The relative quantization error of layer 6 is 0.2239137887954712.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1018.4771728515625.\n",
      "The relative quantization error of layer 7 is 0.2237773835659027.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 172.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 879.0068969726562.\n",
      "The relative quantization error of layer 8 is 0.2573532164096832.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2882.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 561.7774047851562.\n",
      "The relative quantization error of layer 9 is 0.2687363922595978.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1540.3651123046875.\n",
      "The relative quantization error of layer 10 is 0.23537443578243256.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1628.1148681640625.\n",
      "The relative quantization error of layer 11 is 0.30386045575141907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1615.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1200.020263671875.\n",
      "The relative quantization error of layer 12 is 0.3030666410923004.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1449.7406005859375.\n",
      "The relative quantization error of layer 13 is 0.21021346747875214.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:12<00:00, 20.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1978.8712158203125.\n",
      "The relative quantization error of layer 14 is 0.2872580885887146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 289.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1926.5521240234375.\n",
      "The relative quantization error of layer 15 is 0.2682378590106964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4570.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 492.7556457519531.\n",
      "The relative quantization error of layer 16 is 0.23217333853244781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 142.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1143.7161865234375.\n",
      "The relative quantization error of layer 17 is 0.38362041115760803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 287.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1738.97509765625.\n",
      "The relative quantization error of layer 18 is 0.3011743724346161.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:01<00:00, 835.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.2938232421875.\n",
      "The relative quantization error of layer 19 is 0.26170989871025085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 116.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1250.118408203125.\n",
      "The relative quantization error of layer 20 is 0.30370017886161804.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 271.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2005.4599609375.\n",
      "The relative quantization error of layer 21 is 0.3374710977077484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2991.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 437.3800964355469.\n",
      "The relative quantization error of layer 22 is 0.27798017859458923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 128.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 958.84765625.\n",
      "The relative quantization error of layer 23 is 0.36629799008369446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 130.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3364.44873046875.\n",
      "The relative quantization error of layer 24 is 0.3675830066204071.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1852.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 626.1454467773438.\n",
      "The relative quantization error of layer 25 is 0.3219109773635864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 247.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1334.979248046875.\n",
      "The relative quantization error of layer 26 is 0.363195538520813.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 30.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3343.53369140625.\n",
      "The relative quantization error of layer 27 is 0.35744988918304443.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 491.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1346.3736572265625.\n",
      "The relative quantization error of layer 28 is 0.33986878395080566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4883.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.7159423828125.\n",
      "The relative quantization error of layer 29 is 0.1790139377117157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 248.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 973.6760864257812.\n",
      "The relative quantization error of layer 30 is 0.4509891867637634.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 499.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1528.217041015625.\n",
      "The relative quantization error of layer 31 is 0.36921149492263794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4825.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.2774658203125.\n",
      "The relative quantization error of layer 32 is 0.2246353030204773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 232.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 907.7200317382812.\n",
      "The relative quantization error of layer 33 is 0.48800128698349.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 457.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1709.46142578125.\n",
      "The relative quantization error of layer 34 is 0.42590969800949097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 5483.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.89956665039062.\n",
      "The relative quantization error of layer 35 is 0.203327015042305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 300.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1043.528564453125.\n",
      "The relative quantization error of layer 36 is 0.5268030166625977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 502.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1786.8175048828125.\n",
      "The relative quantization error of layer 37 is 0.44004905223846436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 5438.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 218.1576385498047.\n",
      "The relative quantization error of layer 38 is 0.21253663301467896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 208.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1361.785400390625.\n",
      "The relative quantization error of layer 39 is 0.5170286297798157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 461.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1899.7913818359375.\n",
      "The relative quantization error of layer 40 is 0.4478314518928528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3894.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.75662231445312.\n",
      "The relative quantization error of layer 41 is 0.2241227924823761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 245.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1462.6024169921875.\n",
      "The relative quantization error of layer 42 is 0.5445414781570435.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 270.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2561.514404296875.\n",
      "The relative quantization error of layer 43 is 0.4659762382507324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2596.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 163.21597290039062.\n",
      "The relative quantization error of layer 44 is 0.20007041096687317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 473.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 958.9597778320312.\n",
      "The relative quantization error of layer 45 is 0.43944111466407776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:17<00:00, 60.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2278.21630859375.\n",
      "The relative quantization error of layer 46 is 0.47948673367500305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1058.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 446.85498046875.\n",
      "The relative quantization error of layer 47 is 0.4022049307823181.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:00<00:00, 5003.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 110.7938003540039.\n",
      "The relative quantization error of layer 48 is 0.10197556763887405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 483.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 577.075927734375.\n",
      "The relative quantization error of layer 49 is 0.7016158699989319.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1052.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 541.6461181640625.\n",
      "The relative quantization error of layer 50 is 0.3050363063812256.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:00<00:00, 5235.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 84.03359985351562.\n",
      "The relative quantization error of layer 51 is 0.21719253063201904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 463.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 124.35791778564453.\n",
      "The relative quantization error of layer 52 is 0.8249949216842651.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 18568.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 47.018917083740234.\n",
      "The relative quantization error of layer 53 is 0.28155121207237244.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:08:27.181537\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:38<00:00,  9.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.79.\n",
      "Top-5 accuracy of quantized resnet50 is 0.972.\n",
      "\n",
      "Time used for evaluation: 0:02:38.020430\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4479\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 893.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 79.15117645263672.\n",
      "The relative quantization error of layer 0 is 0.018373148515820503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 191.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 857.5234985351562.\n",
      "The relative quantization error of layer 1 is 0.04823622852563858.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2938.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 235.1512908935547.\n",
      "The relative quantization error of layer 2 is 0.055331576615571976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 51.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3649.890869140625.\n",
      "The relative quantization error of layer 3 is 0.10219788551330566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1394.24658203125.\n",
      "The relative quantization error of layer 4 is 0.04690663516521454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 170.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 588.4358520507812.\n",
      "The relative quantization error of layer 5 is 0.20392657816410065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2892.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 247.90626525878906.\n",
      "The relative quantization error of layer 6 is 0.22613602876663208.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1067.5284423828125.\n",
      "The relative quantization error of layer 7 is 0.23711387813091278.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 172.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 868.8416137695312.\n",
      "The relative quantization error of layer 8 is 0.26072365045547485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2917.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 595.0885009765625.\n",
      "The relative quantization error of layer 9 is 0.2793706953525543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1519.22607421875.\n",
      "The relative quantization error of layer 10 is 0.23833172023296356.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 84.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1711.8975830078125.\n",
      "The relative quantization error of layer 11 is 0.3092581629753113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1645.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1200.931884765625.\n",
      "The relative quantization error of layer 12 is 0.30223822593688965.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 144.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1512.16162109375.\n",
      "The relative quantization error of layer 13 is 0.21791204810142517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:12<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1959.4593505859375.\n",
      "The relative quantization error of layer 14 is 0.2953178584575653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 287.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1954.3961181640625.\n",
      "The relative quantization error of layer 15 is 0.2708575129508972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4623.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 540.2913818359375.\n",
      "The relative quantization error of layer 16 is 0.24801261723041534.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 143.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1199.6177978515625.\n",
      "The relative quantization error of layer 17 is 0.401732474565506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 290.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1819.9608154296875.\n",
      "The relative quantization error of layer 18 is 0.3097619116306305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4549.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 375.6504211425781.\n",
      "The relative quantization error of layer 19 is 0.2671612501144409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 144.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1248.366943359375.\n",
      "The relative quantization error of layer 20 is 0.30944836139678955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 287.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1996.6903076171875.\n",
      "The relative quantization error of layer 21 is 0.3400452136993408.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4591.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 440.0914306640625.\n",
      "The relative quantization error of layer 22 is 0.2868240177631378.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 145.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 972.371826171875.\n",
      "The relative quantization error of layer 23 is 0.3936954438686371.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 143.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3294.05078125.\n",
      "The relative quantization error of layer 24 is 0.3683876395225525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2391.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 629.9322509765625.\n",
      "The relative quantization error of layer 25 is 0.3246058225631714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 326.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1371.7589111328125.\n",
      "The relative quantization error of layer 26 is 0.3691238760948181.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:15<00:00, 32.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3404.797607421875.\n",
      "The relative quantization error of layer 27 is 0.36531326174736023.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 528.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1399.098388671875.\n",
      "The relative quantization error of layer 28 is 0.34473222494125366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6488.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 258.53961181640625.\n",
      "The relative quantization error of layer 29 is 0.17693154513835907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 326.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 997.68505859375.\n",
      "The relative quantization error of layer 30 is 0.46293333172798157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 529.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1542.5322265625.\n",
      "The relative quantization error of layer 31 is 0.3754851818084717.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6624.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.6470642089844.\n",
      "The relative quantization error of layer 32 is 0.22059190273284912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 322.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 905.8677368164062.\n",
      "The relative quantization error of layer 33 is 0.4898991584777832.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 529.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1700.614501953125.\n",
      "The relative quantization error of layer 34 is 0.43350735306739807.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6481.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 257.06243896484375.\n",
      "The relative quantization error of layer 35 is 0.210163876414299.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 321.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1086.1685791015625.\n",
      "The relative quantization error of layer 36 is 0.5183676481246948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 520.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1824.183349609375.\n",
      "The relative quantization error of layer 37 is 0.43761396408081055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6686.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 212.24234008789062.\n",
      "The relative quantization error of layer 38 is 0.2044328898191452.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 328.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1421.786865234375.\n",
      "The relative quantization error of layer 39 is 0.5193512439727783.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 505.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1929.551025390625.\n",
      "The relative quantization error of layer 40 is 0.46170157194137573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6666.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 185.61074829101562.\n",
      "The relative quantization error of layer 41 is 0.22807498276233673.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 316.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1513.91162109375.\n",
      "The relative quantization error of layer 42 is 0.5533977746963501.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 275.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2654.3115234375.\n",
      "The relative quantization error of layer 43 is 0.46912622451782227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2843.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 170.15283203125.\n",
      "The relative quantization error of layer 44 is 0.20726604759693146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 468.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 993.341064453125.\n",
      "The relative quantization error of layer 45 is 0.4572455585002899.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:16<00:00, 62.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2302.89599609375.\n",
      "The relative quantization error of layer 46 is 0.48387765884399414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1095.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 448.1174621582031.\n",
      "The relative quantization error of layer 47 is 0.4178987741470337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:00<00:00, 5157.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 119.43745422363281.\n",
      "The relative quantization error of layer 48 is 0.12584324181079865.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 477.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 588.6698608398438.\n",
      "The relative quantization error of layer 49 is 0.7023515701293945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1094.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 479.9708251953125.\n",
      "The relative quantization error of layer 50 is 0.2708462178707123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:00<00:00, 5217.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 88.5832290649414.\n",
      "The relative quantization error of layer 51 is 0.13386394083499908.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 469.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 125.99573516845703.\n",
      "The relative quantization error of layer 52 is 0.8541163206100464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 16290.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 44.26674270629883.\n",
      "The relative quantization error of layer 53 is 0.2621883749961853.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:08:25.968680\n",
      "\n",
      "\n",
      "Using the original model accuracy from pytorch.\n",
      "\n",
      "Top-1 accuracy of resnet50 is 0.8262.\n",
      "Top-5 accuracy of resnet50 is 0.9673.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:39<00:00,  9.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.802.\n",
      "Top-5 accuracy of quantized resnet50 is 0.958.\n",
      "\n",
      "Time used for evaluation: 0:02:39.221696\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4515\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cpu with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 935.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 77.67154693603516.\n",
      "The relative quantization error of layer 0 is 0.01774583011865616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 185.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 912.5106201171875.\n",
      "The relative quantization error of layer 1 is 0.05145081877708435.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2954.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 252.33016967773438.\n",
      "The relative quantization error of layer 2 is 0.05717446282505989.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3502.15380859375.\n",
      "The relative quantization error of layer 3 is 0.10266301035881042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 53.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1320.9669189453125.\n",
      "The relative quantization error of layer 4 is 0.04455553740262985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 173.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 600.4560546875.\n",
      "The relative quantization error of layer 5 is 0.20229335129261017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2789.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 255.5810546875.\n",
      "The relative quantization error of layer 6 is 0.22175385057926178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1078.336669921875.\n",
      "The relative quantization error of layer 7 is 0.23239973187446594.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 164.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 877.9752807617188.\n",
      "The relative quantization error of layer 8 is 0.25622430443763733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2899.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 582.1869506835938.\n",
      "The relative quantization error of layer 9 is 0.26984071731567383.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 51.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1650.007080078125.\n",
      "The relative quantization error of layer 10 is 0.24793045222759247.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 84.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1689.05517578125.\n",
      "The relative quantization error of layer 11 is 0.3119775056838989.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1817.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1209.81640625.\n",
      "The relative quantization error of layer 12 is 0.30329176783561707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 143.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1514.584228515625.\n",
      "The relative quantization error of layer 13 is 0.21775005757808685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:12<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1935.9068603515625.\n",
      "The relative quantization error of layer 14 is 0.2905641794204712.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 289.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1927.2335205078125.\n",
      "The relative quantization error of layer 15 is 0.2703569829463959.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4613.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 536.6159057617188.\n",
      "The relative quantization error of layer 16 is 0.24363908171653748.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 144.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1231.9271240234375.\n",
      "The relative quantization error of layer 17 is 0.3968893587589264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 289.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1768.9158935546875.\n",
      "The relative quantization error of layer 18 is 0.29908671975135803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4361.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 375.63116455078125.\n",
      "The relative quantization error of layer 19 is 0.2595720887184143.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 134.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1256.666015625.\n",
      "The relative quantization error of layer 20 is 0.30423542857170105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 285.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1996.2410888671875.\n",
      "The relative quantization error of layer 21 is 0.3271072506904602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4612.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 444.5044250488281.\n",
      "The relative quantization error of layer 22 is 0.2751658260822296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 140.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1043.47119140625.\n",
      "The relative quantization error of layer 23 is 0.3637228310108185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:03<00:00, 139.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3351.38916015625.\n",
      "The relative quantization error of layer 24 is 0.37387722730636597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2432.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 620.8164672851562.\n",
      "The relative quantization error of layer 25 is 0.3134533166885376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 328.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1377.9022216796875.\n",
      "The relative quantization error of layer 26 is 0.3676791191101074.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:15<00:00, 32.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3446.19970703125.\n",
      "The relative quantization error of layer 27 is 0.3572743237018585.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 530.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1362.2259521484375.\n",
      "The relative quantization error of layer 28 is 0.33007901906967163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 6585.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 269.0093994140625.\n",
      "The relative quantization error of layer 29 is 0.1775691658258438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 322.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1021.2022094726562.\n",
      "The relative quantization error of layer 30 is 0.43698209524154663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 465.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1541.1817626953125.\n",
      "The relative quantization error of layer 31 is 0.35944435000419617.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/saathvikdirisala/Documents/DSC180B/Quantized_Neural_Nets/src/main.py\", line 232, in <module>\n",
      "    main(b, mlp_s, cnn_s, bs, mlp_per, cnn_per, l)\n",
      "  File \"/Users/saathvikdirisala/Documents/DSC180B/Quantized_Neural_Nets/src/main.py\", line 143, in main\n",
      "    quantized_model = quantizer.quantize_network()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/saathvikdirisala/Documents/DSC180B/Quantized_Neural_Nets/src/quantize_neural_net.py\", line 141, in quantize_network\n",
      "    analog_layer_input, quantized_layer_input = self._populate_linear_layer_input(layer_idx)\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/saathvikdirisala/Documents/DSC180B/Quantized_Neural_Nets/src/quantize_neural_net.py\", line 261, in _populate_linear_layer_input\n",
      "    self.analog_network(raw_input_data.to(self.device))\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/timm/models/resnet.py\", line 636, in forward\n",
      "    x = self.forward_features(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/timm/models/resnet.py\", line 625, in forward_features\n",
      "    x = self.layer3(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/timm/models/resnet.py\", line 213, in forward\n",
      "    x = self.conv2(x)\n",
      "        ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['None', 'None', 'True', 'False'] * 10\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'resnet50' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Original Sparsity</th>\n",
       "      <th>Quantized Sparsity</th>\n",
       "      <th>Retain_rate</th>\n",
       "      <th>Fusion</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(47), np.int64(64), np....</td>\n",
       "      <td>['lizard', 'maple_tree', 'possum', 'ray', 'ray...</td>\n",
       "      <td>44.511445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.637726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(59), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['pine_tree', 'train', 'rocket', 'table', 'mot...</td>\n",
       "      <td>50.340385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.589799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(19), np.int64(20), np....</td>\n",
       "      <td>['lamp', 'cattle', 'chair', 'apple', 'cattle',...</td>\n",
       "      <td>82.345975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.351426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(76), np.int64(48), np.int64(41), np....</td>\n",
       "      <td>['skyscraper', 'motorcycle', 'lawn_mower', 'ta...</td>\n",
       "      <td>23.021616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.481517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(29), np.int64(9), np.int64(65), np.i...</td>\n",
       "      <td>['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.606611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(72), np.int64(69), np.int64(48), np....</td>\n",
       "      <td>['seal', 'rocket', 'motorcycle', 'snake', 'can...</td>\n",
       "      <td>30.303197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.778188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(36), np.int64(65), np.int64(26), np....</td>\n",
       "      <td>['hamster', 'rabbit', 'crab', 'bear', 'motorcy...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.427204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.867778</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(66), np.int64(75), np.int64(60), np....</td>\n",
       "      <td>['raccoon', 'skunk', 'plain', 'orange', 'lion'...</td>\n",
       "      <td>142.446653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.135427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                  0.8262   \n",
       "1    resnet50  CIFAR100                       64                  0.8262   \n",
       "2    resnet50  CIFAR100                       64                  0.8262   \n",
       "3    resnet50  CIFAR100                       64                  0.8262   \n",
       "4    resnet50  CIFAR100                       64                  0.8262   \n",
       "5    resnet50  CIFAR100                       64                  0.8262   \n",
       "6    resnet50  CIFAR100                       64                  0.8262   \n",
       "7    resnet50  CIFAR100                       64                  0.8262   \n",
       "8    resnet50  CIFAR100                       64                  0.8262   \n",
       "9    resnet50  CIFAR100                       64                  0.8262   \n",
       "10   resnet50  CIFAR100                       64                  0.8262   \n",
       "11   resnet50  CIFAR100                       64                  0.8262   \n",
       "12   resnet50  CIFAR100                       64                  0.8262   \n",
       "13   resnet50  CIFAR100                       64                  0.8262   \n",
       "14   resnet50  CIFAR100                       64                  0.8262   \n",
       "15   resnet50  CIFAR100                       64                  0.8262   \n",
       "16   resnet50  CIFAR100                       64                  0.8262   \n",
       "17   resnet50  CIFAR100                       64                  0.8262   \n",
       "18   resnet50  CIFAR100                       64                  0.8262   \n",
       "19   resnet50  CIFAR100                       64                  0.8262   \n",
       "20   resnet50  CIFAR100                       64                  0.8262   \n",
       "21   resnet50  CIFAR100                       64                  0.8262   \n",
       "22   resnet50  CIFAR100                       64                  0.8262   \n",
       "23   resnet50  CIFAR100                       64                  0.8262   \n",
       "24   resnet50  CIFAR100                       64                  0.8262   \n",
       "25   resnet50  CIFAR100                       64                  0.8262   \n",
       "26   resnet50  CIFAR100                       64                  0.8262   \n",
       "27   resnet50  CIFAR100                       64                  0.8262   \n",
       "28   resnet50  CIFAR100                       64                  0.8262   \n",
       "29   resnet50  CIFAR100                       64                  0.8262   \n",
       "30   resnet50  CIFAR100                       64                  0.8262   \n",
       "31   resnet50  CIFAR100                       64                  0.8262   \n",
       "32   resnet50  CIFAR100                       64                  0.8262   \n",
       "33   resnet50  CIFAR100                       64                  0.8262   \n",
       "34   resnet50  CIFAR100                       64                  0.8262   \n",
       "35   resnet50  CIFAR100                       64                  0.8262   \n",
       "36   resnet50  CIFAR100                       64                  0.8262   \n",
       "37   resnet50  CIFAR100                       64                  0.8262   \n",
       "38   resnet50  CIFAR100                       64                  0.8262   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                  0.603000                  0.9673                 0.917000   \n",
       "1                  0.848889                  0.9673                 0.970000   \n",
       "2                  0.843000                  0.9673                 0.989000   \n",
       "3                  0.615000                  0.9673                 0.911000   \n",
       "4                  0.944000                  0.9673                 0.995000   \n",
       "5                  0.830000                  0.9673                 0.974000   \n",
       "6                  0.737000                  0.9673                 0.955000   \n",
       "7                  0.776667                  0.9673                 0.983333   \n",
       "8                  0.693000                  0.9673                 0.975000   \n",
       "9                  0.946000                  0.9673                 0.995000   \n",
       "10                 0.808000                  0.9673                 0.974000   \n",
       "11                 0.884000                  0.9673                 0.988000   \n",
       "12                 0.794000                  0.9673                 0.963000   \n",
       "13                 0.681000                  0.9673                 0.974000   \n",
       "14                 0.876250                  0.9673                 0.988750   \n",
       "15                 0.734000                  0.9673                 0.984000   \n",
       "16                 0.957000                  0.9673                 0.995000   \n",
       "17                 0.844444                  0.9673                 0.967778   \n",
       "18                 0.757778                  0.9673                 0.962222   \n",
       "19                 0.753000                  0.9673                 0.958000   \n",
       "20                 0.936000                  0.9673                 0.992000   \n",
       "21                 0.758750                  0.9673                 0.932500   \n",
       "22                 0.876000                  0.9673                 0.958000   \n",
       "23                 0.520000                  0.9673                 0.906000   \n",
       "24                 0.932000                  0.9673                 0.989000   \n",
       "25                 0.842222                  0.9673                 0.984444   \n",
       "26                 0.866000                  0.9673                 0.988000   \n",
       "27                 0.556000                  0.9673                 0.910000   \n",
       "28                 0.944000                  0.9673                 0.993000   \n",
       "29                 0.867778                  0.9673                 0.988889   \n",
       "30                 0.712000                  0.9673                 0.952000   \n",
       "31                 0.566000                  0.9673                 0.909000   \n",
       "32                 0.930000                  0.9673                 0.983000   \n",
       "33                 0.869000                  0.9673                 0.988000   \n",
       "34                 0.793000                  0.9673                 0.981000   \n",
       "35                 0.754000                  0.9673                 0.972000   \n",
       "36                 0.962000                  0.9673                 0.992000   \n",
       "37                 0.790000                  0.9673                 0.972000   \n",
       "38                 0.802000                  0.9673                 0.958000   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Original Sparsity  \\\n",
       "0      4                 1.16                 1.16  ...                0.0   \n",
       "1      4                 1.16                 1.16  ...                0.0   \n",
       "2      4                 1.16                 1.16  ...                0.0   \n",
       "3      4                 1.16                 1.16  ...                0.0   \n",
       "4      4                 1.16                 1.16  ...                0.0   \n",
       "5      4                 1.16                 1.16  ...                0.0   \n",
       "6      4                 1.16                 1.16  ...                0.0   \n",
       "7      4                 1.16                 1.16  ...                0.0   \n",
       "8      4                 1.16                 1.16  ...                0.0   \n",
       "9      4                 1.16                 1.16  ...                0.0   \n",
       "10     4                 1.16                 1.16  ...                0.0   \n",
       "11     4                 1.16                 1.16  ...                0.0   \n",
       "12     4                 1.16                 1.16  ...                0.0   \n",
       "13     4                 1.16                 1.16  ...                0.0   \n",
       "14     4                 1.16                 1.16  ...                0.0   \n",
       "15     4                 1.16                 1.16  ...                0.0   \n",
       "16     4                 1.16                 1.16  ...                0.0   \n",
       "17     4                 1.16                 1.16  ...                0.0   \n",
       "18     4                 1.16                 1.16  ...                0.0   \n",
       "19     4                 1.16                 1.16  ...                0.0   \n",
       "20     4                 1.16                 1.16  ...                0.0   \n",
       "21     4                 1.16                 1.16  ...                0.0   \n",
       "22     4                 1.16                 1.16  ...                0.0   \n",
       "23     4                 1.16                 1.16  ...                0.0   \n",
       "24     4                 1.16                 1.16  ...                0.0   \n",
       "25     4                 1.16                 1.16  ...                0.0   \n",
       "26     4                 1.16                 1.16  ...                0.0   \n",
       "27     4                 1.16                 1.16  ...                0.0   \n",
       "28     4                 1.16                 1.16  ...                0.0   \n",
       "29     4                 1.16                 1.16  ...                0.0   \n",
       "30     4                 1.16                 1.16  ...                0.0   \n",
       "31     4                 1.16                 1.16  ...                0.0   \n",
       "32     4                 1.16                 1.16  ...                0.0   \n",
       "33     4                 1.16                 1.16  ...                0.0   \n",
       "34     4                 1.16                 1.16  ...                0.0   \n",
       "35     4                 1.16                 1.16  ...                0.0   \n",
       "36     4                 1.16                 1.16  ...                0.0   \n",
       "37     4                 1.16                 1.16  ...                0.0   \n",
       "38     4                 1.16                 1.16  ...                0.0   \n",
       "\n",
       "    Quantized Sparsity  Retain_rate  Fusion  Seed  \\\n",
       "0               0.4454         0.25   False     0   \n",
       "1               0.4474         0.25   False     0   \n",
       "2               0.4504         0.25   False     0   \n",
       "3               0.4483         0.25   False     0   \n",
       "4               0.4543         0.25   False     0   \n",
       "5               0.4480         0.25   False     0   \n",
       "6               0.4464         0.25   False     0   \n",
       "7               0.4539         0.25   False     0   \n",
       "8               0.4510         0.25   False     0   \n",
       "9               0.4540         0.25   False     0   \n",
       "10              0.4535         0.25   False     0   \n",
       "11              0.4516         0.25   False     0   \n",
       "12              0.4575         0.25   False     0   \n",
       "13              0.4521         0.25   False     0   \n",
       "14              0.4586         0.25   False     0   \n",
       "15              0.4458         0.25   False     0   \n",
       "16              0.4522         0.25   False     0   \n",
       "17              0.4533         0.25   False     0   \n",
       "18              0.4500         0.25   False     0   \n",
       "19              0.4582         0.25   False     0   \n",
       "20              0.4486         0.25   False     0   \n",
       "21              0.4497         0.25   False     0   \n",
       "22              0.4507         0.25   False     0   \n",
       "23              0.4450         0.25   False     0   \n",
       "24              0.4553         0.25   False     0   \n",
       "25              0.4522         0.25   False     0   \n",
       "26              0.4527         0.25   False     0   \n",
       "27              0.4477         0.25   False     0   \n",
       "28              0.4532         0.25   False     0   \n",
       "29              0.4473         0.25   False     0   \n",
       "30              0.4535         0.25   False     0   \n",
       "31              0.4512         0.25   False     0   \n",
       "32              0.4534         0.25   False     0   \n",
       "33              0.4503         0.25   False     0   \n",
       "34              0.4460         0.25   False     0   \n",
       "35              0.4542         0.25   False     0   \n",
       "36              0.4544         0.25   False     0   \n",
       "37              0.4479         0.25   False     0   \n",
       "38              0.4515         0.25   False     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "1   [np.int64(44), np.int64(47), np.int64(64), np....   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "7   [np.int64(59), np.int64(90), np.int64(69), np....   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "14  [np.int64(40), np.int64(19), np.int64(20), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "17  [np.int64(76), np.int64(48), np.int64(41), np....   \n",
       "18  [np.int64(29), np.int64(9), np.int64(65), np.i...   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "21  [np.int64(72), np.int64(69), np.int64(48), np....   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "25  [np.int64(36), np.int64(65), np.int64(26), np....   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "29  [np.int64(66), np.int64(75), np.int64(60), np....   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "1   ['lizard', 'maple_tree', 'possum', 'ray', 'ray...   44.511445  0.000000   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "7   ['pine_tree', 'train', 'rocket', 'table', 'mot...   50.340385  0.000000   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "14  ['lamp', 'cattle', 'chair', 'apple', 'cattle',...   82.345975  0.000000   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "17  ['skyscraper', 'motorcycle', 'lawn_mower', 'ta...   23.021616  0.000000   \n",
       "18  ['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...   29.710575  0.000000   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "21  ['seal', 'rocket', 'motorcycle', 'snake', 'can...   30.303197  0.000000   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "25  ['hamster', 'rabbit', 'crab', 'bear', 'motorcy...   58.464503  0.000000   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "29  ['raccoon', 'skunk', 'plain', 'orange', 'lion'...  142.446653  0.000000   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "\n",
       "       Avg_KL  \n",
       "0    0.369210  \n",
       "1   12.637726  \n",
       "2   66.416617  \n",
       "3    0.578157  \n",
       "4   69.558004  \n",
       "5   14.820982  \n",
       "6    8.848314  \n",
       "7    8.589799  \n",
       "8    1.950773  \n",
       "9   66.299283  \n",
       "10  14.212071  \n",
       "11  21.038719  \n",
       "12   2.107963  \n",
       "13   7.046100  \n",
       "14  17.351426  \n",
       "15   2.298235  \n",
       "16  66.114634  \n",
       "17   7.481517  \n",
       "18   6.606611  \n",
       "19   1.931516  \n",
       "20  66.564161  \n",
       "21   7.778188  \n",
       "22  18.962063  \n",
       "23   0.949666  \n",
       "24  73.389381  \n",
       "25  12.427204  \n",
       "26  25.333189  \n",
       "27   0.994000  \n",
       "28  67.623141  \n",
       "29  17.135427  \n",
       "30   9.783706  \n",
       "31   0.669352  \n",
       "32  66.601175  \n",
       "33  17.543812  \n",
       "34  22.350282  \n",
       "35   1.885359  \n",
       "36  68.423650  \n",
       "37  17.354552  \n",
       "38  11.636914  \n",
       "\n",
       "[39 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11911c390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsXElEQVR4nO3df3RU9Z3/8ddMIBkQMhAwmQEjpNRf2ZQgYNKU+t09NRSqJyvdHg+7lS8s3aVf06RLzZ6tsEVS7KnxrLuU/mDBslA9TV1Z3apla2NpLHRdU1OJnppGUDAFDiYEiExiMAnO3O8f2YyMmUlmkkk+M3Ofj3PmHOfOnZnPzZjMi8+P98dhWZYlAAAAQ5ymGwAAAOyNMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAqEmmGxCNQCCgd955R9OnT5fD4TDdHAAAEAXLstTd3a05c+bI6Yzc/5EUYeSdd95Rbm6u6WYAAIBROH36tK655pqIjydFGJk+fbqkgYvJzMw03BoAABCNrq4u5ebmBr/HI0mKMDI4NJOZmUkYAQAgyYw0xYIJrAAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjkqLoGQAAqcwfsNTY2qmO7l5lT3epKC9LaU777MVGGAEAwKC65jZtO9CiNl9v8JjX7VJ1Wb5WFngNtmziMEwDAIAhdc1tKq9tCgkiktTu61V5bZPqmtsMtWxiEUYAADDAH7C07UCLrDCPDR7bdqBF/kC4M1ILYQQAgDjwByw1nLigZ187o4YTF0YMEY2tnUN6RK5kSWrz9aqxtTPOLU08zBkBAGCMRjPvo6M7chAZzXnJjJ4RAADGYLTzPrKnu6J6/WjPS2aEEQAARmks8z6K8rLkdbsUaQGvQwO9K0V5WXFqbeIijAAAMEpjmfeR5nSouixfkoYEksH71WX5tqg3QhgBAGCUxjrvY2WBV7vWLJbHHToU43G7tGvNYtvUGWECKwAAoxSPeR8rC7xanu+hAisAAIjd4LyPdl9v2HkjDg30cow07yPN6VDJglnj0sZkwDANAACjxLyP+CCMAAAwBpHmfWRdla6dX7TPvI+xYJgGAIAxWlngVSBgacuzzersuSxJutDTr2/9vEVOp0ICSaw79NphR1/CCAAAY1TX3KaKx18dMm9ksPDZ4MqYWCu12mVHX4ZpAAAYg2gLnz33+9gqtdppR1/CCAAAYxBt4bMtzzZHXanVbjv6EkYAABiDaAufdfb0R3zso5Va7bajL2EEAIAxiOdGdoPBxm47+hJGAAAYg5E2vJOkmVMnR/Vag8HGbjv6EkYAABiD4QqfDQpYlmZMnRz1Dr1229GXMAIAwBgNFj5zR+gB6Xr/A128dFmWoqvUarfKroQRAADiYHm+R65JaWEfGwwhM6ZOVk5mdDv0TsSOvv6ApYYTF/Tsa2fUcOKCsdU5FD0DACAOGls71d41/AqYi5cu6yd/s1hOpyOqiqrjuaNvIhVUI4wAABAH0a5sOd/TpzsXzY36dcdjR9/BgmojVYydKAzTAAAQB8myAiYRC6oRRgAAiIOivCzNGGEJ74ypk42vgEnEgmqEEQAAJkgirH1JxIJqhBEAAOKgsbVTFy9dHvacdy9dNl7CPRGHkwgjAADEQSL2OISTiAXVCCMAAMRBIvY4hJOIBdUIIwAAxEEi9jhEMhEF1WJBnREAAOJgsMehvLZJDilk6WwilnAfz4JqsXJYlmWm9msMurq65Ha75fP5lJmZabo5AABElEiVTU2L9vubnhEAAOIokXockgVhBACAOBuPEu6pjAmsAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjBpVGNm5c6fmz58vl8ul4uJiNTY2Rjz38uXLeuCBB7RgwQK5XC4VFhaqrq5u1A0GAACpJeYwsn//flVVVam6ulpNTU0qLCzUihUr1NHREfb8LVu26JFHHtH3v/99tbS06J577tHnP/95vfrqq2NuPAAASH4Oy7KsWJ5QXFysW265RT/4wQ8kSYFAQLm5ufrqV7+qTZs2DTl/zpw5+sY3vqGKiorgsS984QuaMmWKamtro3rPrq4uud1u+Xw+ZWZmxtJcAABgSLTf3zH1jPT39+vIkSMqLS398AWcTpWWlqqhoSHsc/r6+uRyuUKOTZkyRS+++GIsbw0AAFJUTGHk/Pnz8vv9ysnJCTmek5Oj9vb2sM9ZsWKFtm/frrfeekuBQEAHDx7UT3/6U7W1tUV8n76+PnV1dYXcAABAahr31TTf/e53dd111+nGG29Uenq6KisrtX79ejmdkd+6pqZGbrc7eMvNzR3vZgIAAENiCiOzZ89WWlqazp49G3L87Nmz8ng8YZ9z9dVX65lnnlFPT49Onjypo0ePatq0afrYxz4W8X02b94sn88XvJ0+fTqWZgIAgCQSUxhJT0/XkiVLVF9fHzwWCARUX1+vkpKSYZ/rcrk0d+5cffDBB/rP//xP3XnnnRHPzcjIUGZmZsgNAACkpkmxPqGqqkrr1q3T0qVLVVRUpB07dqinp0fr16+XJK1du1Zz585VTU2NJOnll1/WmTNntGjRIp05c0bf/OY3FQgE9PWvfz2+VwIAAJJSzGFk9erVOnfunLZu3ar29nYtWrRIdXV1wUmtp06dCpkP0tvbqy1btujtt9/WtGnTdPvtt+vHP/6xZsyYEbeLAAAAySvmOiMmUGcEAIDkMy51RgAAAOIt5mEaIBX4A5YaWzvV0d2r7OkuFeVlKc3pMN0sALAlwghsp665TdsOtKjN1xs85nW7VF2Wr5UFXoMtAwB7YpgGtlLX3Kby2qaQICJJ7b5eldc2qa45cmVgAMD4IIzANvwBS9sOtCjcjO3BY9sOtMgfSPg53QCQUggjsI3G1s4hPSJXsiS1+XrV2No5cY0CABBGYB8d3ZGDyGjOAwDEBxNYkbCiXfES7XnZ011RvW+05wEA4oMwgoQU7YqXWFbGFOVlyet2qd3XG3beiEOSxz0QZgAAE4dhGiScaFe8xLoyJs3pUHVZvqSB4HGlwfvVZfnUGwGACUYYQUKJdsVL/weBUa2MWVng1a41i+Vxhw7FeNwu7VqzmDojAGAAwzRIKNGuePlxwx+jXhlTsmBWyGMrC7xanu+hAisAJAjCCBJKtCtZTnZeGtPrpTkdQ0IKAMAMhmmQUKJdyTIva2pcXw8AYA49I0goRXlZmjF1si5eujzsedmZrqRYGcOGfAAwMsIIEsrBlvYRg4gkPfjcG7r/jptU8firckghgSRRVsawIR8ARIdhGiSMwZU00Wjz9WrmVRkJuzKGDfkAIHr0jCBhjLSS5qM6unt156K5CbcyZqTlyQ4NLDtenu9hyAYARBhBAol1T5jByamJtjImlg35EqndAGAKwzRIGLGsfPEmwOTUSNiQDwBiQxhBwhjcO2akgQuHzE9OHQ4b8gFAbAgjSBjD7R0zaObUycYnp45kpFDlUGL37ADARCOMIKFE2jtmxpTJurf0Or2yZXlCBxGJDfkAIFYOy7LCTfpPKF1dXXK73fL5fMrMzDTdHEyAVCgWRp0RAHYX7fc3YQQYR6kQqgBgtKL9/mZpLzCOEm3ZMQAkIuaMAAAAo+gZQVQYbgAAjBfCCEbEREwAwHhimAbDYsM3AMB4I4wgopE2fJMGNnzzBxJ+QRYAIIERRpKEP2Cp4cQFPfvaGTWcuDAhASCWDd8AABgt5owkAVNzNtjwDQBix4T/2BFGEtzgnI2P9oMMztkYz31a2PANAGLDhP/RYZgmgZmes1GUl6UZUydHfJwN3wDgQ0z4Hz3CSAIzPWfjYEu7Ll66POz7s+EbAJj/x2OyI4wkMJNzNgZ/sYYzc+pkLc/3xP29ASDZmP7HY7IjjCQwk3M2RvrFkqR3L13mFwsAxIT/sSKMJLCivCx53S5FGgQZzzkb/GIBQPSY8D82hJEEluZ0qLosX5KGBJLB++M1Z4NfLACInsl/PKYCwkiCW1ng1a41i+Vxh37pe9yucV3Wyy8WAETP5D8eU4HDsqyEn9rb1dUlt9stn8+nzMxM080xwkQRncFlapJCZogPvut4hiEASEbUGQkV7fc3YQTDGusvFpUIAdgNf/c+RBhB3Iz2F4t/IQCAvRFGYFSkMvYM8QCAfUT7/c0EVsQdlQgBALEgjCDuqEQIAIgFYQRxR8E0AEAsCCOIOwqmAQBiQRhB3FEwDQAQC8II4o5KhACAWBBGMC5MlbEHACSfSaYbgNS1ssCr5fkeKhECAIZFGMG4SnM6VLJglulmAAASGMM0AADAKMIIAAAwijACAACMIowAAACjCCMAAMAoVtMgrvwBi6W8AICYEEYQN3XNbdp2oCVkx16v26XqsnyKnAEAImKYBnFR19ym8tqmkCAiSe2+XpXXNqmuuc1QywAAiY4wgjHzByxtO9AiK8xjg8e2HWiRPxDuDACA3RFGEMIfsNRw4oKefe2MGk5ciCpANLZ2DukRuZIlqc3Xq8bWzji2FACQKpgzgqDRzvno6I4cREZzHgDAXkbVM7Jz507Nnz9fLpdLxcXFamxsHPb8HTt26IYbbtCUKVOUm5ure++9V729fDElkrHM+cie7or42GjOAwDYS8xhZP/+/aqqqlJ1dbWamppUWFioFStWqKOjI+z5jz/+uDZt2qTq6mq98cYb2rt3r/bv369//Md/HHPjER9jnfNRlJclr9ulSAt4HRroYSnKy4pDawEAqSbmMLJ9+3Zt2LBB69evV35+vnbv3q2pU6dq3759Yc9/6aWXtGzZMn3xi1/U/Pnz9dnPflZ/9Vd/NWJvCibOWOd8pDkdqi7Ll6QhgWTwfnVZPvVGAABhxRRG+vv7deTIEZWWln74Ak6nSktL1dDQEPY5n/rUp3TkyJFg+Hj77bf13HPP6fbbbx9DsxFP8ZjzsbLAq11rFsvjDh2K8bhd2rVmMXVGAAARxTSB9fz58/L7/crJyQk5npOTo6NHj4Z9zhe/+EWdP39en/70p2VZlj744APdc889ww7T9PX1qa+vL3i/q6srlmbGXapXFY3XnI+VBV4tz/ek9M8KABB/476a5tChQ3rwwQf1r//6ryouLtbx48e1ceNGfetb39L9998f9jk1NTXatm3beDctKnaoKjo456Pd1xt23ohDAz0c0cz5SHM6VLJgVtzbONFSPYACQCJxWJYVdSWq/v5+TZ06VU899ZRWrVoVPL5u3TpdvHhRzz777JDn3HrrrfrkJz+phx9+OHistrZWX/7yl/Xee+/J6Rw6UhSuZyQ3N1c+n0+ZmZnRNnfMBleYfPQHNPiVlErDD4PXKinkelPxWkdihwAKABOhq6tLbrd7xO/vmOaMpKena8mSJaqvrw8eCwQCqq+vV0lJSdjnXLp0aUjgSEtLkyRFykEZGRnKzMwMuU00u1UVTcQ5H6MpwDZWlLUHgIkX8zBNVVWV1q1bp6VLl6qoqEg7duxQT0+P1q9fL0lau3at5s6dq5qaGklSWVmZtm/frptvvjk4THP//ferrKwsGEoSUSwrTFJhWEJKrDkfJnonRgqgDg0E0OX5HoZsACCOYg4jq1ev1rlz57R161a1t7dr0aJFqqurC05qPXXqVEhPyJYtW+RwOLRlyxadOXNGV199tcrKyvTtb387flcxDuxaVTQR5nxEGh4b7J0Yr54aOwZQAEgEo5rAWllZqcrKyrCPHTp0KPQNJk1SdXW1qqurR/NWxlBV1AyTvRN2DaAAYBob5UVAVVEzTG66RwAFADMIIxFQVdQMk70TBFAAMIMwMoxEXGGS6kz2ThBAAcCMcS96luwSaYWJHcSzANtoDAbQj67k8VBnBADGTUxFz0yJtmgKUkMiFGCjAisAjF2039+EESQkqqACQPKL9vubYZoUkIr/imd4DADsgzCS5FK5ByERCrABAMYfq2mSGPuoAABSAWEkSdltIz8AQOoijCQpk5VKAQCIJ8JIkmIfFQBAqiCMJCn2UQEApArCSJJiHxUAQKogjCQp9lEBAKQKwkgSYyM/AEAqoOhZkqNSKQAg2RFGUgCVSgEAyYxhGgAAYBRhBAAAGMUwTZJJxR16AQD2RhhJQJECRyrv0AsAsC/CSIKJFDj+vNCrH/6mdcjGeIM79LKUFwCQrJgzkkDqmttUXts0ZAO8Nl+vHgkTRCR26AUAJD96RkbQ/0FAP274o052XtK8rKn6vyXzlT4p/hnOH7C07UBL2MAxkit36GWJLwAg2RBGhlHzXIv2/Herruxw+PZzb2jDrXnafHt+XN+rsbVzSI9IrNihFwCQjAgjEdQ816JHftM65HjAUvB4PANJPIIEO/QCAJIRc0bC6P8goD3/PTSIXGnPf7eq/4NA3N5zLEGCHXoBAMmMMBLGjxv+qJHmggasgfPipSgvS163a8gOvB/FDr0AgFRDGAnjZOeluJ4XjTSnQ9VlA8M+4QKHQ9L/+z957NALAEg5zBkJY17W1LieF62VBV7tWrN4SJ0RzxWFzb6+8iYqsAIAUorDsqyEL07R1dUlt9stn8+nzMzMcX+//g8CuvH+Xww7VON0SEe/9blxW+ZL4AAAJLtov7/pGQkjfZJTG27NC7uaZtCGW/PGJYhIA0M21AsBANgFYSSCwWW7H60z4nRoXOqMAABgVwzTjGCiKrACAJBqGKaJk/RJTv3NrR8z3QwAAFIW/8QHAABG0TOSQliFAwBIRoSRFFHX3DakPon3ivokAAAkKoZpouQPWGo4cUHPvnZGDScuyD9SvfgJVNfcpvLapiG7/rb7elVe26S65jZDLQMAYGT0jEQhkXsd/AFL2w60KFw0sjRQRn7bgRYtz/cwZAMASEj0jIwg0XsdGls7h7TtSpakNl+vGls7J65RAADEgDAyjJF6HaSBXgeTQzYd3ZGDyGjOAwBgohFGhpEMvQ7Z010jnxTDeQAATDTCyDCSodehKC9LXrdLkWaDODQwv6UoL2simwUAQNQII8NIhl6HNKdD1WUD++R8NJAM3q8uy2fyKgAgYRFGhpEsvQ4rC7zatWaxPO7QUORxu7RrzWLjK34AABgOS3uHMdjrUF7bJIcUMpE10XodVhZ4tTzfQwVWAEDSYdfeKCRynREAABIVu/bGEb0OAACMH8JIlNKcDpUsmGW6GQAApBwmsAIAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAo1hNk+L8AYslyQCAhEYYSWEUawMAJAOGaVJUXXObymubQoKIJLX7elVe26S65jZDLQMAIBRhJAX5A5a2HWhRuDr/g8e2HWiRP5DwOwEAAGyAMJKCGls7h/SIXMmS1ObrVWNr58Q1CgCACAgjKaijO3IQGc15AACMJ8JICsqe7orreQAAjCfCSAoqysuS1+1SpAW8Dg2sqinKy5rIZgEAEBZhJAWlOR2qLsuXpCGBZPB+dVk+9UYAAAlhVGFk586dmj9/vlwul4qLi9XY2Bjx3D/7sz+Tw+EYcrvjjjtG3WiMbGWBV7vWLJbHHToU43G7tGvNYuqMAAASRsxFz/bv36+qqirt3r1bxcXF2rFjh1asWKFjx44pOzt7yPk//elP1d/fH7x/4cIFFRYW6q677hpbyzGilQVeLc/3UIEVAJDQHJZlxVRsori4WLfccot+8IMfSJICgYByc3P11a9+VZs2bRrx+Tt27NDWrVvV1tamq666Kqr37Orqktvtls/nU2ZmZizNBQAAhkT7/R3TME1/f7+OHDmi0tLSD1/A6VRpaakaGhqieo29e/fqL//yL6MOIgAAILXFNExz/vx5+f1+5eTkhBzPycnR0aNHR3x+Y2OjmpubtXfv3mHP6+vrU19fX/B+V1dXLM0EAABJZEJX0+zdu1ef+MQnVFRUNOx5NTU1crvdwVtubu4EtXAof8BSw4kLeva1M2o4cYES6gAAxFlMPSOzZ89WWlqazp49G3L87Nmz8ng8wz63p6dHTzzxhB544IER32fz5s2qqqoK3u/q6jISSNj1FgCA8RdTz0h6erqWLFmi+vr64LFAIKD6+nqVlJQM+9wnn3xSfX19WrNmzYjvk5GRoczMzJDbRGPXWwAAJkbMwzRVVVXas2ePHnvsMb3xxhsqLy9XT0+P1q9fL0lau3atNm/ePOR5e/fu1apVqzRr1qyxt3qcsestAAATJ+Y6I6tXr9a5c+e0detWtbe3a9GiRaqrqwtOaj116pScztCMc+zYMb344ov65S9/GZ9Wj7NYdr0tWZD44QoAgEQWcxiRpMrKSlVWVoZ97NChQ0OO3XDDDYqxnIlR7HoLAMDEYW+aMNj1FgCAiUMYCYNdbwEAmDiEkTDY9RYAgIlDGIkgEXa9peAaAMAORjWB1S5M7npLwTUAgF3EvGuvCXbbtXew4NpHP5jBCDRRPTMAAIzFuOzai/FHwTUAgN0QRhJMLAXXAABIBYSRBEPBNQCA3RBGEgwF1wAAdkMYSTAUXAMA2A1hJMFQcA0AYDeEkQSUCAXXAACYKBQ9S1AmC64BADCRCCMJLM3pUMmCWaabAQDAuGKYBgAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARk0y3QDT/AFLja2d6ujuVfZ0l4ryspTmdJhuFgAAtmHrMFLX3KZtB1rU5usNHvO6Xaouy9fKAq/BlgEAYB+2Haapa25TeW1TSBCRpHZfr8prm1TX3GaoZQAA2Istw4g/YGnbgRZZYR4bPLbtQIv8gXBnAACAeLJlGGls7RzSI3IlS1Kbr1eNrZ0T1ygAAGzKlmGkoztyEBnNeQAAYPRsGUayp7vieh4AABg9W4aRorwsed0uRVrA69DAqpqivKyJbBYAALZkyzCS5nSouixfkoYEksH71WX51BsBAGAC2DKMSNLyfI++Vnq93FMmhxz3uF3atWYxdUYAAJggtix6Fq7Y2Ywpk7V+2XxVfuY6ekQAAJhAtusZiVTszPf+Ze341Vs62NJuqGUAANjTqMLIzp07NX/+fLlcLhUXF6uxsXHY8y9evKiKigp5vV5lZGTo+uuv13PPPTeqBo8Fxc4AAEg8MYeR/fv3q6qqStXV1WpqalJhYaFWrFihjo6OsOf39/dr+fLl+uMf/6innnpKx44d0549ezR37twxNz5WFDsDACDxxDxnZPv27dqwYYPWr18vSdq9e7d+/vOfa9++fdq0adOQ8/ft26fOzk699NJLmjx5YLLo/Pnzx9bqUaLYGQAAiSemnpH+/n4dOXJEpaWlH76A06nS0lI1NDSEfc7PfvYzlZSUqKKiQjk5OSooKNCDDz4ov98/tpaPAsXOAABIPDH1jJw/f15+v185OTkhx3NycnT06NGwz3n77bf1wgsv6O6779Zzzz2n48eP6ytf+YouX76s6urqsM/p6+tTX19f8H5XV1cszYxosNhZu6837LwRhwaW9lLsDACAiTPuq2kCgYCys7P1wx/+UEuWLNHq1av1jW98Q7t37474nJqaGrnd7uAtNzc3Lm2h2BkAAIknpjAye/ZspaWl6ezZsyHHz549K4/HE/Y5Xq9X119/vdLS0oLHbrrpJrW3t6u/vz/sczZv3iyfzxe8nT59OpZmDmtlgVe71iyWxx06FEOxMwAAzIhpmCY9PV1LlixRfX29Vq1aJWmg56O+vl6VlZVhn7Ns2TI9/vjjCgQCcjoHss+bb74pr9er9PT0sM/JyMhQRkZGLE2LycoCr5bne9TY2qmO7l5lTx8YmqFHBACAiRfzME1VVZX27Nmjxx57TG+88YbKy8vV09MTXF2zdu1abd68OXh+eXm5Ojs7tXHjRr355pv6+c9/rgcffFAVFRXxu4pRSHM6VLJglu5cNFclC2YRRAAAMCTmpb2rV6/WuXPntHXrVrW3t2vRokWqq6sLTmo9depUsAdEknJzc/X888/r3nvv1cKFCzV37lxt3LhR9913X/yuAgAAJC2HZVkJX260q6tLbrdbPp9PmZmZppsDAACiEO33t+32pgEAAImFMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMmmW6Aaf6ApcbWTnV09yp7uktFeVlKczpMNwsAANuwdRipa27TtgMtavP1Bo953S5Vl+VrZYHXYMsAALAP2w7T1DW3qby2KSSISFK7r1fltU2qa24z1DIAAOzFlmHEH7C07UCLrDCPDR7bdqBF/kC4MwAAQDzZMow0tnYO6RG5kiWpzderxtbOiWsUAAA2Zcsw0tEdOYiM5jwAADB6tgwj2dNdcT0PAACMni3DSFFelrxul4ZbwOt1DyzzBQAA48uWYSTN6VB1Wb4kRQwk71/262BL+8Q1CgAAm7JlGJGklQVe7VqzWO6pk8M+7rt0mSW+AABMANuGEUlanu+Ra1L4HwFLfAEAmBi2DiONrZ1q7+qL+DhLfAEAGH+2DiMs8QUAwDxbhxGW+AIAYJ6tw8hIS3wdYokvAADjzdZhZLglvoP3q8vyleYcriIJAAAYC1uHEenDJb4ed+hQjMft0q41i7WywGuoZQAA2MMk0w1IBCsLvFqe71Fja6c6unuVPX1gaIYeEQAAxh9h5H+lOR0qWTDLdDMAALAd2w/TAAAAswgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwapLpBiQKf8BSY2unOrp7lT3dpaK8LKU5HaabBQBAyiOMSKprbtO2Ay1q8/UGj3ndLlWX5WtlgddgywAASH22H6apa25TeW1TSBCRpHZfr8prm1TX3GaoZQAA2IOtw4g/YGnbgRZZYR4bPLbtQIv8gXBnAACAeLB1GGls7RzSI3IlS1Kbr1eNrZ0T1ygAAGzG1mGkoztyEBnNeQAAIHa2DiPZ011xPQ8AAMTO1mGkKC9LXrdLkRbwOjSwqqYoL2simwUAgK3YOoykOR2qLsuXpCGBZPB+dVk+9UYAABhHtg4jkrSywKtdaxbL4w4divG4Xdq1ZjF1RgAAGGcUPdNAIFme76ECKwAABhBG/lea06GSBbNMNwMAANux/TANAAAwizACAACMIowAAACjCCMAAMAowggAADBqVGFk586dmj9/vlwul4qLi9XY2Bjx3EcffVQOhyPk5nJRXh0AAAyIOYzs379fVVVVqq6uVlNTkwoLC7VixQp1dHREfE5mZqba2tqCt5MnT46p0QAAIHXEHEa2b9+uDRs2aP369crPz9fu3bs1depU7du3L+JzHA6HPB5P8JaTkzOmRgMAgNQRUxjp7+/XkSNHVFpa+uELOJ0qLS1VQ0NDxOe99957mjdvnnJzc3XnnXfqD3/4w7Dv09fXp66urpAbAABITTFVYD1//rz8fv+Qno2cnBwdPXo07HNuuOEG7du3TwsXLpTP59M///M/61Of+pT+8Ic/6Jprrgn7nJqaGm3btm3IcUIJAADJY/B727Ks4U+0YnDmzBlLkvXSSy+FHP+Hf/gHq6ioKKrX6O/vtxYsWGBt2bIl4jm9vb2Wz+cL3lpaWixJ3Lhx48aNG7ckvJ0+fXrYbBBTz8js2bOVlpams2fPhhw/e/asPB5PVK8xefJk3XzzzTp+/HjEczIyMpSRkRG8P23aNJ0+fVrTp0+XwzH2zeu6urqUm5ur06dPKzMzc8yvlyzseN12vGaJ6+a6U58dr1lKvuu2LEvd3d2aM2fOsOfFFEbS09O1ZMkS1dfXa9WqVZKkQCCg+vp6VVZWRvUafr9fr7/+um6//fao39fpdEYc0hmLzMzMpPgw482O123Ha5a4brux43Xb8Zql5Lput9s94jkx79pbVVWldevWaenSpSoqKtKOHTvU09Oj9evXS5LWrl2ruXPnqqamRpL0wAMP6JOf/KQ+/vGP6+LFi3r44Yd18uRJ/e3f/m2sbw0AAFJQzGFk9erVOnfunLZu3ar29nYtWrRIdXV1wUmtp06dktP54SKdd999Vxs2bFB7e7tmzpypJUuW6KWXXlJ+fn78rgIAACStmMOIJFVWVkYcljl06FDI/e985zv6zne+M5q3GTcZGRmqrq4OmZdiB3a8bjtes8R1c92pz47XLKXudTssa6T1NgAAAOOHjfIAAIBRhBEAAGAUYQQAABhFGAEAAEbZLozs3LlT8+fPl8vlUnFxsRobG003Ka5+85vfqKysTHPmzJHD4dAzzzwT8rhlWdq6dau8Xq+mTJmi0tJSvfXWW2YaG0c1NTW65ZZbNH36dGVnZ2vVqlU6duxYyDm9vb2qqKjQrFmzNG3aNH3hC18YUk042ezatUsLFy4MFkAqKSnRL37xi+DjqXjNH/XQQw/J4XDoa1/7WvBYKl73N7/5TTkcjpDbjTfeGHw8Fa950JkzZ7RmzRrNmjVLU6ZM0Sc+8Qm98sorwcdT8e/a/Pnzh3zeDodDFRUVklLv87ZVGNm/f7+qqqpUXV2tpqYmFRYWasWKFero6DDdtLjp6elRYWGhdu7cGfbxf/qnf9L3vvc97d69Wy+//LKuuuoqrVixQr29vRPc0vg6fPiwKioq9Nvf/lYHDx7U5cuX9dnPflY9PT3Bc+69914dOHBATz75pA4fPqx33nlHf/EXf2Gw1WN3zTXX6KGHHtKRI0f0yiuv6DOf+UzIztipeM1X+t3vfqdHHnlECxcuDDmeqtf9J3/yJ2prawveXnzxxeBjqXrN7777rpYtW6bJkyfrF7/4hVpaWvQv//IvmjlzZvCcVPy79rvf/S7ksz548KAk6a677pKUgp93VLvbpYiioiKroqIieN/v91tz5syxampqDLZq/Eiynn766eD9QCBgeTwe6+GHHw4eu3jxopWRkWH9+7//u4EWjp+Ojg5LknX48GHLsgauc/LkydaTTz4ZPOeNN96wJFkNDQ2mmjkuZs6caf3bv/1byl9zd3e3dd1111kHDx60/vRP/9TauHGjZVmp+1lXV1dbhYWFYR9L1Wu2LMu67777rE9/+tMRH7fL37WNGzdaCxYssAKBQEp+3rbpGenv79eRI0dUWloaPOZ0OlVaWqqGhgaDLZs4ra2tam9vD/kZuN1uFRcXp9zPwOfzSZKysrIkSUeOHNHly5dDrv3GG2/UtddemzLX7vf79cQTT6inp0clJSUpf80VFRW64447Qq5PSu3P+q233tKcOXP0sY99THfffbdOnTolKbWv+Wc/+5mWLl2qu+66S9nZ2br55pu1Z8+e4ON2+LvW39+v2tpafelLX5LD4UjJz9s2YeT8+fPy+/3BsvWDcnJy1N7ebqhVE2vwOlP9ZxAIBPS1r31Ny5YtU0FBgaSBa09PT9eMGTNCzk2Fa3/99dc1bdo0ZWRk6J577tHTTz+t/Pz8lL7mJ554Qk1NTcE9sK6UqtddXFysRx99VHV1ddq1a5daW1t16623qru7O2WvWZLefvtt7dq1S9ddd52ef/55lZeX6+/+7u/02GOPSbLH37VnnnlGFy9e1F//9V9LSs3/x0dVDh5IZBUVFWpubg4ZT09lN9xwg1577TX5fD499dRTWrdunQ4fPmy6WePm9OnT2rhxow4ePCiXy2W6ORPmc5/7XPC/Fy5cqOLiYs2bN0//8R//oSlTphhs2fgKBAJaunSpHnzwQUnSzTffrObmZu3evVvr1q0z3LqJsXfvXn3uc5/TnDlzTDdl3NimZ2T27NlKS0sbMtv47Nmz8ng8hlo1sQavM5V/BpWVlfqv//ov/frXv9Y111wTPO7xeNTf36+LFy+GnJ8K156enq6Pf/zjWrJkiWpqalRYWKjvfve7KXvNR44cUUdHhxYvXqxJkyZp0qRJOnz4sL73ve9p0qRJysnJScnr/qgZM2bo+uuv1/Hjx1P2s5Ykr9c7ZGPVm266KThElep/106ePKlf/epXITvdp+LnbZswkp6eriVLlqi+vj54LBAIqL6+XiUlJQZbNnHy8vLk8XhCfgZdXV16+eWXk/5nYFmWKisr9fTTT+uFF15QXl5eyONLlizR5MmTQ6792LFjOnXqVNJf+0cFAgH19fWl7DXfdtttev311/Xaa68Fb0uXLtXdd98d/O9UvO6Peu+993TixAl5vd6U/awladmyZUOW6b/55puaN2+epNT+uyZJP/rRj5Sdna077rgjeCwlP2/TM2gn0hNPPGFlZGRYjz76qNXS0mJ9+ctftmbMmGG1t7ebblrcdHd3W6+++qr16quvWpKs7du3W6+++qp18uRJy7Is66GHHrJmzJhhPfvss9bvf/97684777Ty8vKs999/33DLx6a8vNxyu93WoUOHrLa2tuDt0qVLwXPuuece69prr7VeeOEF65VXXrFKSkqskpISg60eu02bNlmHDx+2Wltbrd///vfWpk2bLIfDYf3yl7+0LCs1rzmcK1fTWFZqXvff//3fW4cOHbJaW1ut//mf/7FKS0ut2bNnWx0dHZZlpeY1W5ZlNTY2WpMmTbK+/e1vW2+99Zb1k5/8xJo6dapVW1sbPCdV/675/X7r2muvte67774hj6Xa522rMGJZlvX973/fuvbaa6309HSrqKjI+u1vf2u6SXH161//2pI05LZu3TrLsgaWwd1///1WTk6OlZGRYd12223WsWPHzDY6DsJdsyTrRz/6UfCc999/3/rKV75izZw505o6dar1+c9/3mprazPX6Dj40pe+ZM2bN89KT0+3rr76auu2224LBhHLSs1rDuejYSQVr3v16tWW1+u10tPTrblz51qrV6+2jh8/Hnw8Fa950IEDB6yCggIrIyPDuvHGG60f/vCHIY+n6t+1559/3pIU9lpS7fN2WJZlGemSAQAAkI3mjAAAgMREGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGDU/wcA1gvsuADT9wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4c90c8-1575-4523-8136-cdee52d38d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/dsc180/lib/python3.11/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/dsc180/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/7dl6wg8j4039_df2sf3y5k_w0000gn/T/ipykernel_72534/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/7dl6wg8j4039_df2sf3y5k_w0000gn/T/ipykernel_72534/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized ResNet50 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\"])\n",
    "# plt.savefig(\"./imgs/resnet50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Original Sparsity</th>\n",
       "      <th>Quantized Sparsity</th>\n",
       "      <th>Retain_rate</th>\n",
       "      <th>Fusion</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(47), np.int64(64), np....</td>\n",
       "      <td>['lizard', 'maple_tree', 'possum', 'ray', 'ray...</td>\n",
       "      <td>44.511445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.637726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(59), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['pine_tree', 'train', 'rocket', 'table', 'mot...</td>\n",
       "      <td>50.340385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.589799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(19), np.int64(20), np....</td>\n",
       "      <td>['lamp', 'cattle', 'chair', 'apple', 'cattle',...</td>\n",
       "      <td>82.345975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.351426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(76), np.int64(48), np.int64(41), np....</td>\n",
       "      <td>['skyscraper', 'motorcycle', 'lawn_mower', 'ta...</td>\n",
       "      <td>23.021616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.481517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(29), np.int64(9), np.int64(65), np.i...</td>\n",
       "      <td>['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.606611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(72), np.int64(69), np.int64(48), np....</td>\n",
       "      <td>['seal', 'rocket', 'motorcycle', 'snake', 'can...</td>\n",
       "      <td>30.303197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.778188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(36), np.int64(65), np.int64(26), np....</td>\n",
       "      <td>['hamster', 'rabbit', 'crab', 'bear', 'motorcy...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.427204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.867778</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(66), np.int64(75), np.int64(60), np....</td>\n",
       "      <td>['raccoon', 'skunk', 'plain', 'orange', 'lion'...</td>\n",
       "      <td>142.446653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.135427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                  0.8262   \n",
       "1    resnet50  CIFAR100                       64                  0.8262   \n",
       "2    resnet50  CIFAR100                       64                  0.8262   \n",
       "3    resnet50  CIFAR100                       64                  0.8262   \n",
       "4    resnet50  CIFAR100                       64                  0.8262   \n",
       "5    resnet50  CIFAR100                       64                  0.8262   \n",
       "6    resnet50  CIFAR100                       64                  0.8262   \n",
       "7    resnet50  CIFAR100                       64                  0.8262   \n",
       "8    resnet50  CIFAR100                       64                  0.8262   \n",
       "9    resnet50  CIFAR100                       64                  0.8262   \n",
       "10   resnet50  CIFAR100                       64                  0.8262   \n",
       "11   resnet50  CIFAR100                       64                  0.8262   \n",
       "12   resnet50  CIFAR100                       64                  0.8262   \n",
       "13   resnet50  CIFAR100                       64                  0.8262   \n",
       "14   resnet50  CIFAR100                       64                  0.8262   \n",
       "15   resnet50  CIFAR100                       64                  0.8262   \n",
       "16   resnet50  CIFAR100                       64                  0.8262   \n",
       "17   resnet50  CIFAR100                       64                  0.8262   \n",
       "18   resnet50  CIFAR100                       64                  0.8262   \n",
       "19   resnet50  CIFAR100                       64                  0.8262   \n",
       "20   resnet50  CIFAR100                       64                  0.8262   \n",
       "21   resnet50  CIFAR100                       64                  0.8262   \n",
       "22   resnet50  CIFAR100                       64                  0.8262   \n",
       "23   resnet50  CIFAR100                       64                  0.8262   \n",
       "24   resnet50  CIFAR100                       64                  0.8262   \n",
       "25   resnet50  CIFAR100                       64                  0.8262   \n",
       "26   resnet50  CIFAR100                       64                  0.8262   \n",
       "27   resnet50  CIFAR100                       64                  0.8262   \n",
       "28   resnet50  CIFAR100                       64                  0.8262   \n",
       "29   resnet50  CIFAR100                       64                  0.8262   \n",
       "30   resnet50  CIFAR100                       64                  0.8262   \n",
       "31   resnet50  CIFAR100                       64                  0.8262   \n",
       "32   resnet50  CIFAR100                       64                  0.8262   \n",
       "33   resnet50  CIFAR100                       64                  0.8262   \n",
       "34   resnet50  CIFAR100                       64                  0.8262   \n",
       "35   resnet50  CIFAR100                       64                  0.8262   \n",
       "36   resnet50  CIFAR100                       64                  0.8262   \n",
       "37   resnet50  CIFAR100                       64                  0.8262   \n",
       "38   resnet50  CIFAR100                       64                  0.8262   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                  0.603000                  0.9673                 0.917000   \n",
       "1                  0.848889                  0.9673                 0.970000   \n",
       "2                  0.843000                  0.9673                 0.989000   \n",
       "3                  0.615000                  0.9673                 0.911000   \n",
       "4                  0.944000                  0.9673                 0.995000   \n",
       "5                  0.830000                  0.9673                 0.974000   \n",
       "6                  0.737000                  0.9673                 0.955000   \n",
       "7                  0.776667                  0.9673                 0.983333   \n",
       "8                  0.693000                  0.9673                 0.975000   \n",
       "9                  0.946000                  0.9673                 0.995000   \n",
       "10                 0.808000                  0.9673                 0.974000   \n",
       "11                 0.884000                  0.9673                 0.988000   \n",
       "12                 0.794000                  0.9673                 0.963000   \n",
       "13                 0.681000                  0.9673                 0.974000   \n",
       "14                 0.876250                  0.9673                 0.988750   \n",
       "15                 0.734000                  0.9673                 0.984000   \n",
       "16                 0.957000                  0.9673                 0.995000   \n",
       "17                 0.844444                  0.9673                 0.967778   \n",
       "18                 0.757778                  0.9673                 0.962222   \n",
       "19                 0.753000                  0.9673                 0.958000   \n",
       "20                 0.936000                  0.9673                 0.992000   \n",
       "21                 0.758750                  0.9673                 0.932500   \n",
       "22                 0.876000                  0.9673                 0.958000   \n",
       "23                 0.520000                  0.9673                 0.906000   \n",
       "24                 0.932000                  0.9673                 0.989000   \n",
       "25                 0.842222                  0.9673                 0.984444   \n",
       "26                 0.866000                  0.9673                 0.988000   \n",
       "27                 0.556000                  0.9673                 0.910000   \n",
       "28                 0.944000                  0.9673                 0.993000   \n",
       "29                 0.867778                  0.9673                 0.988889   \n",
       "30                 0.712000                  0.9673                 0.952000   \n",
       "31                 0.566000                  0.9673                 0.909000   \n",
       "32                 0.930000                  0.9673                 0.983000   \n",
       "33                 0.869000                  0.9673                 0.988000   \n",
       "34                 0.793000                  0.9673                 0.981000   \n",
       "35                 0.754000                  0.9673                 0.972000   \n",
       "36                 0.962000                  0.9673                 0.992000   \n",
       "37                 0.790000                  0.9673                 0.972000   \n",
       "38                 0.802000                  0.9673                 0.958000   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Original Sparsity  \\\n",
       "0      4                 1.16                 1.16  ...                0.0   \n",
       "1      4                 1.16                 1.16  ...                0.0   \n",
       "2      4                 1.16                 1.16  ...                0.0   \n",
       "3      4                 1.16                 1.16  ...                0.0   \n",
       "4      4                 1.16                 1.16  ...                0.0   \n",
       "5      4                 1.16                 1.16  ...                0.0   \n",
       "6      4                 1.16                 1.16  ...                0.0   \n",
       "7      4                 1.16                 1.16  ...                0.0   \n",
       "8      4                 1.16                 1.16  ...                0.0   \n",
       "9      4                 1.16                 1.16  ...                0.0   \n",
       "10     4                 1.16                 1.16  ...                0.0   \n",
       "11     4                 1.16                 1.16  ...                0.0   \n",
       "12     4                 1.16                 1.16  ...                0.0   \n",
       "13     4                 1.16                 1.16  ...                0.0   \n",
       "14     4                 1.16                 1.16  ...                0.0   \n",
       "15     4                 1.16                 1.16  ...                0.0   \n",
       "16     4                 1.16                 1.16  ...                0.0   \n",
       "17     4                 1.16                 1.16  ...                0.0   \n",
       "18     4                 1.16                 1.16  ...                0.0   \n",
       "19     4                 1.16                 1.16  ...                0.0   \n",
       "20     4                 1.16                 1.16  ...                0.0   \n",
       "21     4                 1.16                 1.16  ...                0.0   \n",
       "22     4                 1.16                 1.16  ...                0.0   \n",
       "23     4                 1.16                 1.16  ...                0.0   \n",
       "24     4                 1.16                 1.16  ...                0.0   \n",
       "25     4                 1.16                 1.16  ...                0.0   \n",
       "26     4                 1.16                 1.16  ...                0.0   \n",
       "27     4                 1.16                 1.16  ...                0.0   \n",
       "28     4                 1.16                 1.16  ...                0.0   \n",
       "29     4                 1.16                 1.16  ...                0.0   \n",
       "30     4                 1.16                 1.16  ...                0.0   \n",
       "31     4                 1.16                 1.16  ...                0.0   \n",
       "32     4                 1.16                 1.16  ...                0.0   \n",
       "33     4                 1.16                 1.16  ...                0.0   \n",
       "34     4                 1.16                 1.16  ...                0.0   \n",
       "35     4                 1.16                 1.16  ...                0.0   \n",
       "36     4                 1.16                 1.16  ...                0.0   \n",
       "37     4                 1.16                 1.16  ...                0.0   \n",
       "38     4                 1.16                 1.16  ...                0.0   \n",
       "\n",
       "    Quantized Sparsity  Retain_rate  Fusion  Seed  \\\n",
       "0               0.4454         0.25   False     0   \n",
       "1               0.4474         0.25   False     0   \n",
       "2               0.4504         0.25   False     0   \n",
       "3               0.4483         0.25   False     0   \n",
       "4               0.4543         0.25   False     0   \n",
       "5               0.4480         0.25   False     0   \n",
       "6               0.4464         0.25   False     0   \n",
       "7               0.4539         0.25   False     0   \n",
       "8               0.4510         0.25   False     0   \n",
       "9               0.4540         0.25   False     0   \n",
       "10              0.4535         0.25   False     0   \n",
       "11              0.4516         0.25   False     0   \n",
       "12              0.4575         0.25   False     0   \n",
       "13              0.4521         0.25   False     0   \n",
       "14              0.4586         0.25   False     0   \n",
       "15              0.4458         0.25   False     0   \n",
       "16              0.4522         0.25   False     0   \n",
       "17              0.4533         0.25   False     0   \n",
       "18              0.4500         0.25   False     0   \n",
       "19              0.4582         0.25   False     0   \n",
       "20              0.4486         0.25   False     0   \n",
       "21              0.4497         0.25   False     0   \n",
       "22              0.4507         0.25   False     0   \n",
       "23              0.4450         0.25   False     0   \n",
       "24              0.4553         0.25   False     0   \n",
       "25              0.4522         0.25   False     0   \n",
       "26              0.4527         0.25   False     0   \n",
       "27              0.4477         0.25   False     0   \n",
       "28              0.4532         0.25   False     0   \n",
       "29              0.4473         0.25   False     0   \n",
       "30              0.4535         0.25   False     0   \n",
       "31              0.4512         0.25   False     0   \n",
       "32              0.4534         0.25   False     0   \n",
       "33              0.4503         0.25   False     0   \n",
       "34              0.4460         0.25   False     0   \n",
       "35              0.4542         0.25   False     0   \n",
       "36              0.4544         0.25   False     0   \n",
       "37              0.4479         0.25   False     0   \n",
       "38              0.4515         0.25   False     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "1   [np.int64(44), np.int64(47), np.int64(64), np....   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "7   [np.int64(59), np.int64(90), np.int64(69), np....   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "14  [np.int64(40), np.int64(19), np.int64(20), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "17  [np.int64(76), np.int64(48), np.int64(41), np....   \n",
       "18  [np.int64(29), np.int64(9), np.int64(65), np.i...   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "21  [np.int64(72), np.int64(69), np.int64(48), np....   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "25  [np.int64(36), np.int64(65), np.int64(26), np....   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "29  [np.int64(66), np.int64(75), np.int64(60), np....   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "1   ['lizard', 'maple_tree', 'possum', 'ray', 'ray...   44.511445  0.000000   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "7   ['pine_tree', 'train', 'rocket', 'table', 'mot...   50.340385  0.000000   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "14  ['lamp', 'cattle', 'chair', 'apple', 'cattle',...   82.345975  0.000000   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "17  ['skyscraper', 'motorcycle', 'lawn_mower', 'ta...   23.021616  0.000000   \n",
       "18  ['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...   29.710575  0.000000   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "21  ['seal', 'rocket', 'motorcycle', 'snake', 'can...   30.303197  0.000000   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "25  ['hamster', 'rabbit', 'crab', 'bear', 'motorcy...   58.464503  0.000000   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "29  ['raccoon', 'skunk', 'plain', 'orange', 'lion'...  142.446653  0.000000   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "\n",
       "       Avg_KL  \n",
       "0    0.369210  \n",
       "1   12.637726  \n",
       "2   66.416617  \n",
       "3    0.578157  \n",
       "4   69.558004  \n",
       "5   14.820982  \n",
       "6    8.848314  \n",
       "7    8.589799  \n",
       "8    1.950773  \n",
       "9   66.299283  \n",
       "10  14.212071  \n",
       "11  21.038719  \n",
       "12   2.107963  \n",
       "13   7.046100  \n",
       "14  17.351426  \n",
       "15   2.298235  \n",
       "16  66.114634  \n",
       "17   7.481517  \n",
       "18   6.606611  \n",
       "19   1.931516  \n",
       "20  66.564161  \n",
       "21   7.778188  \n",
       "22  18.962063  \n",
       "23   0.949666  \n",
       "24  73.389381  \n",
       "25  12.427204  \n",
       "26  25.333189  \n",
       "27   0.994000  \n",
       "28  67.623141  \n",
       "29  17.135427  \n",
       "30   9.783706  \n",
       "31   0.669352  \n",
       "32  66.601175  \n",
       "33  17.543812  \n",
       "34  22.350282  \n",
       "35   1.885359  \n",
       "36  68.423650  \n",
       "37  17.354552  \n",
       "38  11.636914  \n",
       "\n",
       "[39 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [43:06<00:00, 16.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "model.to(device)  \n",
    "model.eval() \n",
    "\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1)\n",
    "# original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "maxk = max(topk)\n",
    "topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "correct_mat = []\n",
    "for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test.to(device))\n",
    "    topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "    target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "    correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# break    \n",
    "# acc_items += [original_topk_accuracy]\n",
    "\n",
    "# df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "646f3cfa-3cbc-4db4-8430-2e70853e0228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False]]),\n",
       " tensor([[False, False,  True, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False]]),\n",
       " tensor([[ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False]]),\n",
       " tensor([[ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False]]),\n",
       " tensor([[ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False,  True, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [ True, False, False, False, False]])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_mat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:19<00:00,  8.17it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (157,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (x_test, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader)):\n\u001b[1;32m      3\u001b[0m     classes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [target]\n\u001b[0;32m----> 4\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (157,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "    classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.815, 0.949]),\n",
       " array([0.82888889, 0.96777778]),\n",
       " array([0.863, 0.983]),\n",
       " array([0.799, 0.951]),\n",
       " array([0.887, 0.988]),\n",
       " array([0.797, 0.973]),\n",
       " array([0.83 , 0.968]),\n",
       " array([0.79444444, 0.96666667]),\n",
       " array([0.767, 0.961]),\n",
       " array([0.867, 0.986]),\n",
       " array([0.834, 0.968]),\n",
       " array([0.84 , 0.974]),\n",
       " array([0.821, 0.968]),\n",
       " array([0.775, 0.964]),\n",
       " array([0.85  , 0.9675]),\n",
       " array([0.808, 0.986]),\n",
       " array([0.877, 0.988]),\n",
       " array([0.86444444, 0.97333333]),\n",
       " array([0.81555556, 0.96444444]),\n",
       " array([0.823, 0.963]),\n",
       " array([0.871, 0.988]),\n",
       " array([0.81125, 0.95375]),\n",
       " array([0.845, 0.972]),\n",
       " array([0.746, 0.939]),\n",
       " array([0.873, 0.986]),\n",
       " array([0.84222222, 0.97888889]),\n",
       " array([0.848, 0.973]),\n",
       " array([0.771, 0.95 ]),\n",
       " array([0.872, 0.988]),\n",
       " array([0.86111111, 0.97111111]),\n",
       " array([0.826, 0.952]),\n",
       " array([0.781, 0.946]),\n",
       " array([0.861, 0.985]),\n",
       " array([0.806, 0.965]),\n",
       " array([0.848, 0.974]),\n",
       " array([0.884, 0.981]),\n",
       " array([0.879, 0.987]),\n",
       " array([0.831, 0.952]),\n",
       " array([0.779, 0.968])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "    topk_count = []\n",
    "    filtered = correct_mat[np.isin(classes, subset)]\n",
    "    for i, k in enumerate(topk):\n",
    "        topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "    return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "857795db-e94f-4078-bdb2-5d74b09ffb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.815     , 0.949     ],\n",
       "       [0.82888889, 0.96777778],\n",
       "       [0.863     , 0.983     ],\n",
       "       [0.799     , 0.951     ],\n",
       "       [0.887     , 0.988     ],\n",
       "       [0.797     , 0.973     ],\n",
       "       [0.83      , 0.968     ],\n",
       "       [0.79444444, 0.96666667],\n",
       "       [0.767     , 0.961     ],\n",
       "       [0.867     , 0.986     ],\n",
       "       [0.834     , 0.968     ],\n",
       "       [0.84      , 0.974     ],\n",
       "       [0.821     , 0.968     ],\n",
       "       [0.775     , 0.964     ],\n",
       "       [0.85      , 0.9675    ],\n",
       "       [0.808     , 0.986     ],\n",
       "       [0.877     , 0.988     ],\n",
       "       [0.86444444, 0.97333333],\n",
       "       [0.81555556, 0.96444444],\n",
       "       [0.823     , 0.963     ],\n",
       "       [0.871     , 0.988     ],\n",
       "       [0.81125   , 0.95375   ],\n",
       "       [0.845     , 0.972     ],\n",
       "       [0.746     , 0.939     ],\n",
       "       [0.873     , 0.986     ],\n",
       "       [0.84222222, 0.97888889],\n",
       "       [0.848     , 0.973     ],\n",
       "       [0.771     , 0.95      ],\n",
       "       [0.872     , 0.988     ],\n",
       "       [0.86111111, 0.97111111],\n",
       "       [0.826     , 0.952     ],\n",
       "       [0.781     , 0.946     ],\n",
       "       [0.861     , 0.985     ],\n",
       "       [0.806     , 0.965     ],\n",
       "       [0.848     , 0.974     ],\n",
       "       [0.884     , 0.981     ],\n",
       "       [0.879     , 0.987     ],\n",
       "       [0.831     , 0.952     ],\n",
       "       [0.779     , 0.968     ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
