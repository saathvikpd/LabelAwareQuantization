{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f376d630-cea9-4230-9c3f-5299c7c71ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 819.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 78.60328674316406.\n",
      "The relative quantization error of layer 0 is 0.01801394112408161.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 792.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 798.91650390625.\n",
      "The relative quantization error of layer 1 is 0.04563897103071213.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2452.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 243.92697143554688.\n",
      "The relative quantization error of layer 2 is 0.056220248341560364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3428.0498046875.\n",
      "The relative quantization error of layer 3 is 0.10449382662773132.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 206.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1344.4697265625.\n",
      "The relative quantization error of layer 4 is 0.045345891267061234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 491.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 580.2412719726562.\n",
      "The relative quantization error of layer 5 is 0.19968923926353455.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2309.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 261.4765930175781.\n",
      "The relative quantization error of layer 6 is 0.23481950163841248.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1104.542724609375.\n",
      "The relative quantization error of layer 7 is 0.23239722847938538.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 491.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 893.5902099609375.\n",
      "The relative quantization error of layer 8 is 0.2667343020439148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2545.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 550.0385131835938.\n",
      "The relative quantization error of layer 9 is 0.2762410342693329.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1603.29736328125.\n",
      "The relative quantization error of layer 10 is 0.23434165120124817.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 280.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1662.936767578125.\n",
      "The relative quantization error of layer 11 is 0.3049107491970062.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2568.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1165.5595703125.\n",
      "The relative quantization error of layer 12 is 0.3049519956111908.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 645.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1474.7783203125.\n",
      "The relative quantization error of layer 13 is 0.21377186477184296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2037.2901611328125.\n",
      "The relative quantization error of layer 14 is 0.29399436712265015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2028.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1997.7686767578125.\n",
      "The relative quantization error of layer 15 is 0.2705525755882263.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2582.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 496.8290710449219.\n",
      "The relative quantization error of layer 16 is 0.2307748794555664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 668.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1156.279541015625.\n",
      "The relative quantization error of layer 17 is 0.3914157450199127.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1953.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1754.8455810546875.\n",
      "The relative quantization error of layer 18 is 0.2977437973022461.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2465.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.4869689941406.\n",
      "The relative quantization error of layer 19 is 0.26470357179641724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 833.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1200.9613037109375.\n",
      "The relative quantization error of layer 20 is 0.301238477230072.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2052.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1933.2034912109375.\n",
      "The relative quantization error of layer 21 is 0.3282482624053955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2628.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 421.2938232421875.\n",
      "The relative quantization error of layer 22 is 0.2717444896697998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 929.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 972.8091430664062.\n",
      "The relative quantization error of layer 23 is 0.3890569508075714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1465.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3248.953125.\n",
      "The relative quantization error of layer 24 is 0.3642328977584839.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2635.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 604.1432495117188.\n",
      "The relative quantization error of layer 25 is 0.3161460757255554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1513.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1321.205810546875.\n",
      "The relative quantization error of layer 26 is 0.3635188639163971.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 511.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3413.43408203125.\n",
      "The relative quantization error of layer 27 is 0.3601175546646118.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2592.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1303.28857421875.\n",
      "The relative quantization error of layer 28 is 0.3283965587615967.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2594.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 253.6796112060547.\n",
      "The relative quantization error of layer 29 is 0.17411909997463226.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1479.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 947.061279296875.\n",
      "The relative quantization error of layer 30 is 0.43974488973617554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2508.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1518.8935546875.\n",
      "The relative quantization error of layer 31 is 0.36055323481559753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2622.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 287.26348876953125.\n",
      "The relative quantization error of layer 32 is 0.21948713064193726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1504.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 880.278564453125.\n",
      "The relative quantization error of layer 33 is 0.4797913432121277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2576.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1677.7725830078125.\n",
      "The relative quantization error of layer 34 is 0.4110827147960663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2613.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 246.34242248535156.\n",
      "The relative quantization error of layer 35 is 0.19920656085014343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1479.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1028.03955078125.\n",
      "The relative quantization error of layer 36 is 0.5005041360855103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2577.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1741.0982666015625.\n",
      "The relative quantization error of layer 37 is 0.4279484152793884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2613.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 214.5257568359375.\n",
      "The relative quantization error of layer 38 is 0.2097948044538498.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1513.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1340.2607421875.\n",
      "The relative quantization error of layer 39 is 0.5082924365997314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2631.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1772.06689453125.\n",
      "The relative quantization error of layer 40 is 0.4319979250431061.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2659.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 179.4534912109375.\n",
      "The relative quantization error of layer 41 is 0.2249629944562912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1481.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1422.542724609375.\n",
      "The relative quantization error of layer 42 is 0.527755856513977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2127.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2476.380859375.\n",
      "The relative quantization error of layer 43 is 0.454189658164978.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2638.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 166.73899841308594.\n",
      "The relative quantization error of layer 44 is 0.2086024433374405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2044.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 909.2929077148438.\n",
      "The relative quantization error of layer 45 is 0.41918593645095825.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 902.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2226.62939453125.\n",
      "The relative quantization error of layer 46 is 0.4674471914768219.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2575.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 401.8501281738281.\n",
      "The relative quantization error of layer 47 is 0.4068136513233185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2569.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 101.78260040283203.\n",
      "The relative quantization error of layer 48 is 0.10281042754650116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1763.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 544.8045043945312.\n",
      "The relative quantization error of layer 49 is 0.6997693777084351.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2630.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 515.3909912109375.\n",
      "The relative quantization error of layer 50 is 0.25942543148994446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2662.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 91.90060424804688.\n",
      "The relative quantization error of layer 51 is 0.142515629529953.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2132.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 111.3040771484375.\n",
      "The relative quantization error of layer 52 is 0.792534589767456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2657.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 43.32610321044922.\n",
      "The relative quantization error of layer 53 is 0.27831900119781494.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.725392\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.79it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.877.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.988.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.921.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.989.\n",
      "\n",
      "Time used for evaluation: 0:00:04.683185\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4512\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 785.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 82.07852935791016.\n",
      "The relative quantization error of layer 0 is 0.01848059892654419.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 822.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 868.5502319335938.\n",
      "The relative quantization error of layer 1 is 0.04873768240213394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2278.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 244.8697052001953.\n",
      "The relative quantization error of layer 2 is 0.05464449152350426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 203.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3480.76220703125.\n",
      "The relative quantization error of layer 3 is 0.10331514477729797.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1392.3267822265625.\n",
      "The relative quantization error of layer 4 is 0.04830322042107582.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 496.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 593.4545288085938.\n",
      "The relative quantization error of layer 5 is 0.20272332429885864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2193.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 272.70703125.\n",
      "The relative quantization error of layer 6 is 0.23551121354103088.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 245.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1050.460693359375.\n",
      "The relative quantization error of layer 7 is 0.22700421512126923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 492.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 919.6317138671875.\n",
      "The relative quantization error of layer 8 is 0.26998481154441833.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2301.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 563.4885864257812.\n",
      "The relative quantization error of layer 9 is 0.2795320153236389.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 216.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1546.955078125.\n",
      "The relative quantization error of layer 10 is 0.23336538672447205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 283.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1735.9647216796875.\n",
      "The relative quantization error of layer 11 is 0.3125261068344116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2501.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1163.987548828125.\n",
      "The relative quantization error of layer 12 is 0.3040322959423065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 889.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1575.34375.\n",
      "The relative quantization error of layer 13 is 0.22559504210948944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2024.265380859375.\n",
      "The relative quantization error of layer 14 is 0.29931992292404175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2003.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1968.542236328125.\n",
      "The relative quantization error of layer 15 is 0.27691391110420227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2458.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 509.6309814453125.\n",
      "The relative quantization error of layer 16 is 0.23875343799591064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 698.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1105.378173828125.\n",
      "The relative quantization error of layer 17 is 0.3782574236392975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1986.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1775.1536865234375.\n",
      "The relative quantization error of layer 18 is 0.3070201575756073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2486.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.34796142578125.\n",
      "The relative quantization error of layer 19 is 0.2637605369091034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 892.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1254.2889404296875.\n",
      "The relative quantization error of layer 20 is 0.3106819987297058.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2008.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2012.631591796875.\n",
      "The relative quantization error of layer 21 is 0.33542531728744507.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2301.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 443.78350830078125.\n",
      "The relative quantization error of layer 22 is 0.2790970802307129.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 920.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1015.8672485351562.\n",
      "The relative quantization error of layer 23 is 0.38657957315444946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1441.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3325.545166015625.\n",
      "The relative quantization error of layer 24 is 0.3705824613571167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2429.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 606.2796630859375.\n",
      "The relative quantization error of layer 25 is 0.32538169622421265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1489.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1368.8740234375.\n",
      "The relative quantization error of layer 26 is 0.37540575861930847.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 526.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3415.97509765625.\n",
      "The relative quantization error of layer 27 is 0.35798442363739014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2239.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1299.977294921875.\n",
      "The relative quantization error of layer 28 is 0.33291444182395935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2473.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 272.149658203125.\n",
      "The relative quantization error of layer 29 is 0.1886146068572998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1489.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1003.0474243164062.\n",
      "The relative quantization error of layer 30 is 0.4532891809940338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2466.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1516.39404296875.\n",
      "The relative quantization error of layer 31 is 0.366438090801239.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2457.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.57476806640625.\n",
      "The relative quantization error of layer 32 is 0.2192842811346054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1413.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 889.4950561523438.\n",
      "The relative quantization error of layer 33 is 0.4769879877567291.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2387.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1692.930908203125.\n",
      "The relative quantization error of layer 34 is 0.40014588832855225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2477.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.9451446533203.\n",
      "The relative quantization error of layer 35 is 0.2029343843460083.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1481.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1061.0272216796875.\n",
      "The relative quantization error of layer 36 is 0.5205318331718445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2444.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1729.41650390625.\n",
      "The relative quantization error of layer 37 is 0.4133041501045227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2467.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.48825073242188.\n",
      "The relative quantization error of layer 38 is 0.21250952780246735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1474.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1316.007568359375.\n",
      "The relative quantization error of layer 39 is 0.5095374584197998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2453.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1811.140380859375.\n",
      "The relative quantization error of layer 40 is 0.4336789846420288.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2486.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.30555725097656.\n",
      "The relative quantization error of layer 41 is 0.2213011533021927.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1474.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1413.9632568359375.\n",
      "The relative quantization error of layer 42 is 0.5319193005561829.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2070.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2467.365966796875.\n",
      "The relative quantization error of layer 43 is 0.4546872079372406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2469.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.82666015625.\n",
      "The relative quantization error of layer 44 is 0.20414182543754578.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1732.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 911.0509033203125.\n",
      "The relative quantization error of layer 45 is 0.4188508987426758.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 936.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2147.39599609375.\n",
      "The relative quantization error of layer 46 is 0.46057069301605225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2471.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 418.1368408203125.\n",
      "The relative quantization error of layer 47 is 0.37985795736312866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2515.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 98.63148498535156.\n",
      "The relative quantization error of layer 48 is 0.09450535476207733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2014.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 534.06103515625.\n",
      "The relative quantization error of layer 49 is 0.6599753499031067.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2473.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 456.50799560546875.\n",
      "The relative quantization error of layer 50 is 0.2505219280719757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2536.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 52.21720886230469.\n",
      "The relative quantization error of layer 51 is 0.08884144574403763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2047.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.70069122314453.\n",
      "The relative quantization error of layer 52 is 0.7921640872955322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2502.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 37.942108154296875.\n",
      "The relative quantization error of layer 53 is 0.23352664709091187.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.138578\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.80it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.855.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.984.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.951.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.995.\n",
      "\n",
      "Time used for evaluation: 0:00:04.303764\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4549\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 787.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.99716186523438.\n",
      "The relative quantization error of layer 0 is 0.019012289121747017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 784.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 936.192626953125.\n",
      "The relative quantization error of layer 1 is 0.05257284641265869.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2219.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 257.1488952636719.\n",
      "The relative quantization error of layer 2 is 0.057543110102415085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 245.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3385.27197265625.\n",
      "The relative quantization error of layer 3 is 0.1008651852607727.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1460.085205078125.\n",
      "The relative quantization error of layer 4 is 0.049442049115896225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 475.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 623.7521362304688.\n",
      "The relative quantization error of layer 5 is 0.20915813744068146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2251.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 275.1811828613281.\n",
      "The relative quantization error of layer 6 is 0.24218375980854034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1065.6920166015625.\n",
      "The relative quantization error of layer 7 is 0.2352016568183899.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 499.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 927.2147216796875.\n",
      "The relative quantization error of layer 8 is 0.2653990387916565.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2268.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 580.3699951171875.\n",
      "The relative quantization error of layer 9 is 0.28088313341140747.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 237.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1750.170654296875.\n",
      "The relative quantization error of layer 10 is 0.2580987513065338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 280.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1702.0667724609375.\n",
      "The relative quantization error of layer 11 is 0.3036992847919464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2435.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1228.3828125.\n",
      "The relative quantization error of layer 12 is 0.3087892234325409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 698.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1570.280517578125.\n",
      "The relative quantization error of layer 13 is 0.2244504690170288.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1995.7086181640625.\n",
      "The relative quantization error of layer 14 is 0.29574719071388245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2013.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2044.1343994140625.\n",
      "The relative quantization error of layer 15 is 0.2738245129585266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2550.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 513.5228271484375.\n",
      "The relative quantization error of layer 16 is 0.2369655817747116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 826.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1161.7823486328125.\n",
      "The relative quantization error of layer 17 is 0.3852122724056244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1913.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1802.68701171875.\n",
      "The relative quantization error of layer 18 is 0.30717042088508606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2538.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 367.436767578125.\n",
      "The relative quantization error of layer 19 is 0.2575954794883728.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 926.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1198.2745361328125.\n",
      "The relative quantization error of layer 20 is 0.3044814169406891.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2021.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1928.865478515625.\n",
      "The relative quantization error of layer 21 is 0.32082003355026245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2221.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 435.9116516113281.\n",
      "The relative quantization error of layer 22 is 0.2760060131549835.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 923.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 955.5152587890625.\n",
      "The relative quantization error of layer 23 is 0.3463822603225708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1448.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3262.8037109375.\n",
      "The relative quantization error of layer 24 is 0.3635730743408203.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2490.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 614.5410766601562.\n",
      "The relative quantization error of layer 25 is 0.32158634066581726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1495.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1350.479736328125.\n",
      "The relative quantization error of layer 26 is 0.3675036132335663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 526.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3302.369384765625.\n",
      "The relative quantization error of layer 27 is 0.35148733854293823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2248.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1343.5042724609375.\n",
      "The relative quantization error of layer 28 is 0.33639565110206604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2519.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.627197265625.\n",
      "The relative quantization error of layer 29 is 0.17724433541297913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1420.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 975.0399169921875.\n",
      "The relative quantization error of layer 30 is 0.41044121980667114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2450.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1480.32568359375.\n",
      "The relative quantization error of layer 31 is 0.35174039006233215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2514.27it/s]\n",
      "100%|██████████| 256/256 [00:00<00:00, 1372.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.5020446777344.\n",
      "The relative quantization error of layer 32 is 0.21698330342769623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n",
      "The quantization error of layer 33 is 890.351806640625.\n",
      "The relative quantization error of layer 33 is 0.477064847946167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2516.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1626.3912353515625.\n",
      "The relative quantization error of layer 34 is 0.39059576392173767.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2539.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 241.13461303710938.\n",
      "The relative quantization error of layer 35 is 0.20082199573516846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1505.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1020.25732421875.\n",
      "The relative quantization error of layer 36 is 0.5089839696884155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2486.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1748.0877685546875.\n",
      "The relative quantization error of layer 37 is 0.41895464062690735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2561.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.47674560546875.\n",
      "The relative quantization error of layer 38 is 0.21036864817142487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1198.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1353.887939453125.\n",
      "The relative quantization error of layer 39 is 0.5017455220222473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2524.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1846.642822265625.\n",
      "The relative quantization error of layer 40 is 0.4344850182533264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2517.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 179.166748046875.\n",
      "The relative quantization error of layer 41 is 0.22133982181549072.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1463.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1454.939208984375.\n",
      "The relative quantization error of layer 42 is 0.5400277972221375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2082.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2435.736328125.\n",
      "The relative quantization error of layer 43 is 0.4432676136493683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2501.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.17779541015625.\n",
      "The relative quantization error of layer 44 is 0.1984144002199173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2051.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 880.1253662109375.\n",
      "The relative quantization error of layer 45 is 0.40827512741088867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 927.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2160.8642578125.\n",
      "The relative quantization error of layer 46 is 0.4617655277252197.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2496.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 411.0384826660156.\n",
      "The relative quantization error of layer 47 is 0.40383878350257874.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2533.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 97.87985229492188.\n",
      "The relative quantization error of layer 48 is 0.10922756046056747.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2065.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 516.9335327148438.\n",
      "The relative quantization error of layer 49 is 0.6584457755088806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2373.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 423.1690368652344.\n",
      "The relative quantization error of layer 50 is 0.22922161221504211.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2554.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 65.02177429199219.\n",
      "The relative quantization error of layer 51 is 0.10548395663499832.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2113.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 104.1026382446289.\n",
      "The relative quantization error of layer 52 is 0.7536569237709045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2537.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 23.22694206237793.\n",
      "The relative quantization error of layer 53 is 0.14235715568065643.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.601598\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.77it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.88.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.963.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.996.\n",
      "\n",
      "Time used for evaluation: 0:00:04.301644\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4563\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 811.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 80.79678344726562.\n",
      "The relative quantization error of layer 0 is 0.01851601153612137.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 789.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 896.2164306640625.\n",
      "The relative quantization error of layer 1 is 0.05052796006202698.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2216.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 248.02198791503906.\n",
      "The relative quantization error of layer 2 is 0.05559670180082321.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3381.048095703125.\n",
      "The relative quantization error of layer 3 is 0.0984647125005722.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1549.2130126953125.\n",
      "The relative quantization error of layer 4 is 0.05268504098057747.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 492.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 617.00439453125.\n",
      "The relative quantization error of layer 5 is 0.2077702432870865.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2336.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 271.5842590332031.\n",
      "The relative quantization error of layer 6 is 0.24295692145824432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 231.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1048.554931640625.\n",
      "The relative quantization error of layer 7 is 0.23007212579250336.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 889.130615234375.\n",
      "The relative quantization error of layer 8 is 0.26189640164375305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2558.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 554.7296752929688.\n",
      "The relative quantization error of layer 9 is 0.2745650112628937.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1633.1175537109375.\n",
      "The relative quantization error of layer 10 is 0.2430744767189026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 269.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1681.83349609375.\n",
      "The relative quantization error of layer 11 is 0.3125317096710205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2597.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1172.811767578125.\n",
      "The relative quantization error of layer 12 is 0.3009558618068695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 812.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1523.0301513671875.\n",
      "The relative quantization error of layer 13 is 0.21957358717918396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2060.63671875.\n",
      "The relative quantization error of layer 14 is 0.2968674302101135.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2076.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2012.343017578125.\n",
      "The relative quantization error of layer 15 is 0.26879361271858215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2603.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 519.599609375.\n",
      "The relative quantization error of layer 16 is 0.23537369072437286.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 772.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1151.414306640625.\n",
      "The relative quantization error of layer 17 is 0.3806048333644867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2012.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1789.959716796875.\n",
      "The relative quantization error of layer 18 is 0.29631325602531433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2468.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 370.49609375.\n",
      "The relative quantization error of layer 19 is 0.2584778070449829.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 929.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1205.1605224609375.\n",
      "The relative quantization error of layer 20 is 0.30413708090782166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2044.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1956.560546875.\n",
      "The relative quantization error of layer 21 is 0.3266468644142151.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2619.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 424.4765930175781.\n",
      "The relative quantization error of layer 22 is 0.2631237804889679.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 933.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 950.8019409179688.\n",
      "The relative quantization error of layer 23 is 0.3744008541107178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1453.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3290.147216796875.\n",
      "The relative quantization error of layer 24 is 0.365579754114151.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2593.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 617.9888305664062.\n",
      "The relative quantization error of layer 25 is 0.31971803307533264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1500.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1336.282470703125.\n",
      "The relative quantization error of layer 26 is 0.3681429922580719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 524.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3366.60107421875.\n",
      "The relative quantization error of layer 27 is 0.3562573194503784.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2572.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1308.3299560546875.\n",
      "The relative quantization error of layer 28 is 0.32733774185180664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2563.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 258.3851013183594.\n",
      "The relative quantization error of layer 29 is 0.17894867062568665.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1488.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 975.8762817382812.\n",
      "The relative quantization error of layer 30 is 0.41369614005088806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2403.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1471.5128173828125.\n",
      "The relative quantization error of layer 31 is 0.345272034406662.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2622.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 298.98077392578125.\n",
      "The relative quantization error of layer 32 is 0.2228376567363739.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1507.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 858.8087158203125.\n",
      "The relative quantization error of layer 33 is 0.46934953331947327.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2609.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1644.48193359375.\n",
      "The relative quantization error of layer 34 is 0.3974613547325134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2616.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.2613525390625.\n",
      "The relative quantization error of layer 35 is 0.20427605509757996.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1520.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1020.1917724609375.\n",
      "The relative quantization error of layer 36 is 0.5073104500770569.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2456.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1717.605712890625.\n",
      "The relative quantization error of layer 37 is 0.41157928109169006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2615.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.52505493164062.\n",
      "The relative quantization error of layer 38 is 0.2079230397939682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1510.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1333.050048828125.\n",
      "The relative quantization error of layer 39 is 0.5028805732727051.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2611.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1784.3848876953125.\n",
      "The relative quantization error of layer 40 is 0.42716163396835327.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2620.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 173.23721313476562.\n",
      "The relative quantization error of layer 41 is 0.21756583452224731.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1507.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1407.6566162109375.\n",
      "The relative quantization error of layer 42 is 0.5326536297798157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2103.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2424.978759765625.\n",
      "The relative quantization error of layer 43 is 0.44112539291381836.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2593.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 156.97821044921875.\n",
      "The relative quantization error of layer 44 is 0.19905196130275726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2087.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 872.8106689453125.\n",
      "The relative quantization error of layer 45 is 0.40706995129585266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 956.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2162.853271484375.\n",
      "The relative quantization error of layer 46 is 0.4633384943008423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2624.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 405.38873291015625.\n",
      "The relative quantization error of layer 47 is 0.4086441099643707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 528/4608 [00:00<00:01, 2637.45it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['False'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'efficientnet_b1' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969179e-0865-48e8-a11d-cc1e1f526b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_options = ['True'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'efficientnet_b1' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df = df[df[\"Classes Repeated\"] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bc03e-1a1c-43ae-bc01-15060dca5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from data_loaders import data_loader\n",
    "# from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 64\n",
    "\n",
    "# topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "\n",
    "#     model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "#     model.to(device)  \n",
    "#     train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset = subset)\n",
    "\n",
    "# # ===========\n",
    "# #  CODE HERE\n",
    "# # ===========\n",
    "\n",
    "#     model.eval() \n",
    "#     original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "#     # maxk = max(topk)\n",
    "#     # topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "#     # correct_mat = []\n",
    "#     # for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     #     with torch.no_grad():\n",
    "#     #         y_pred = model(x_test.to(device))\n",
    "#     #     topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "#     #     target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "#     #     correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# # break    \n",
    "# # acc_items += [original_topk_accuracy]\n",
    "\n",
    "# # df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# # df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# # df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# # print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n",
    "\n",
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 5  # Set the number of fine-tuning epochs\n",
    "learning_rate = 1e-4  # Fine-tuning learning rate\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = [stage.item() if hasattr(stage, \"item\") else stage for stage in subset_stage]\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "    model.to(device)  \n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset=subset)\n",
    "\n",
    "    # Define optimizer & loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate after fine-tuning\n",
    "    model.eval()\n",
    "    original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "    print(f\"Top-1 and Top-5 Accuracy after fine-tuning: {original_topk_accuracy}\")\n",
    "\n",
    "    acc_items += [original_topk_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e564bcc8-8a12-4965-9e9c-79909c3b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the printed output as input for raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63c97c08-e8f2-4e8a-ba26-12b49693d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1726c059-fe07-4ee0-9236-bb67aba13d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# extracted = re.findall(r\"\\[[01]{1}.[0-9 ]{3} [01]{1}.[0-9 ]{3}\\]\", raw_text)\n",
    "extracted = re.findall(r\"Top-1 and Top-5 Accuracy after fine-tuning:\\s*(\\[[^\\]]+\\])\", raw_text)\n",
    "# data = list(map(lambda x: [float(x[1:6]), float(x[7:12])], extracted))\n",
    "data = [list(map(float, s.strip(\"[]\").split())) for s in extracted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "370887c8-4003-449d-93ff-700942aa2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[0.981 0.999]',\n",
       "  '[0.98  0.998]',\n",
       "  '[0.981 1.   ]',\n",
       "  '[0.979 0.999]',\n",
       "  '[0.983 0.997]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.8   0.984]',\n",
       "  '[0.896 0.99 ]',\n",
       "  '[0.9   0.992]',\n",
       "  '[0.84  0.992]',\n",
       "  '[0.915 0.994]',\n",
       "  '[0.889 0.987]',\n",
       "  '[0.901 0.992]'],\n",
       " 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1879a6f-3f42-4c8f-bef8-b7a537282650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Trained Top1 Accuracy\", \"Trained Top5 Accuracy\"]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d20aacbe-ec3d-4a21-a92d-82bb75e69a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes = []\n",
    "# for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "#     topk_count = []\n",
    "#     filtered = correct_mat[np.isin(classes, subset)]\n",
    "#     for i, k in enumerate(topk):\n",
    "#         topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "#     return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "    \n",
    "#     acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "# acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import dist_matrix\n",
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "\n",
    "# G = nx.from_numpy_array(dist_matrix)\n",
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa2b9e10-57f2-462e-8f96-5df897ffd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import community \n",
    "# partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae727e7e-c5e5-4627-bb52-ca17fdbd41c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dfe0db6-01b1-4965-a589-ce94866dd132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import class_names\n",
    "\n",
    "# grps = {}\n",
    "\n",
    "# for k,v in partition.items():\n",
    "#     if v not in grps:\n",
    "#         grps[v] = []\n",
    "#     grps[v] += [class_names[k].item()]\n",
    "\n",
    "# grps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e2b417d-386d-4233-80bd-e097adec7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100_subset_generation import dist_matrix, class_names\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "KL_data_all = []\n",
    "# new_col = []\n",
    "median = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    # print(list(map(lambda x: class_names[x].item(), subset))))\n",
    "\n",
    "    # new_col += [len(subset) != len(set(subset))]\n",
    "    \n",
    "    KL_data = []\n",
    "    for j in combinations(set(subset), 2):\n",
    "        KL_data += [dist_matrix[j[0], j[1]].item()]\n",
    "\n",
    "    KL_data_all += [KL_data]\n",
    "\n",
    "    median += [np.median(KL_data).item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a011a4a-a284-4b40-b242-a757a73bfc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>46.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.522912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.417347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.793771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.378134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0   66.980437  \n",
       "1   49.097501  \n",
       "2   60.747142  \n",
       "3   60.747142  \n",
       "4   46.604676  \n",
       "5   49.097501  \n",
       "6   60.747142  \n",
       "7    1.522912  \n",
       "8    1.549429  \n",
       "9    1.417347  \n",
       "10   1.666552  \n",
       "11   1.549429  \n",
       "12   0.793771  \n",
       "13   0.378134  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Median_KL\"] = median\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dd02952-818a-4588-bfaa-bbfce9e4d30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "pd.DataFrame(KL_data_all, index = df[\"Quantized Top1 Accuracy\"]).T.boxplot(vert = False, positions = df[\"Quantized Top1 Accuracy\"] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0724d809-8a16-40f1-aad0-cd9252c5c0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[\"Classes Repeated\"] = new_col\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e9939a-6dcb-4678-8a83-9ad2ba3012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3593c-43f4-4388-9121-057b93a9b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626567-9b3d-40c0-981e-484ed7d33fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3058420-34ee-470e-a70b-492d24039904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7102e16-7f17-4da8-b66c-ff7d8260d341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>55.650079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0      vgg16  CIFAR100                       64                   0.887   \n",
       "1      vgg16  CIFAR100                       64                   0.861   \n",
       "2      vgg16  CIFAR100                       64                   0.884   \n",
       "3      vgg16  CIFAR100                       64                   0.879   \n",
       "4      vgg16  CIFAR100                       64                   0.872   \n",
       "\n",
       "   Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                    0.935                   0.989                    0.991   \n",
       "1                    0.902                   0.987                    0.989   \n",
       "2                    0.960                   0.991                    0.996   \n",
       "3                    0.953                   0.987                    0.994   \n",
       "4                    0.952                   0.986                    0.994   \n",
       "\n",
       "   Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0     4                 1.16                 1.16  ...     0   \n",
       "1     4                 1.16                 1.16  ...     0   \n",
       "2     4                 1.16                 1.16  ...     0   \n",
       "3     4                 1.16                 1.16  ...     0   \n",
       "4     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                               Subset_Inds  \\\n",
       "0  [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1  [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2  [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3  [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4   [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "\n",
       "                                      Subset_Classes      Max_KL    Min_KL  \\\n",
       "0  ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4  ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "\n",
       "      Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0  68.940139             False                  0.982                  0.999   \n",
       "1  69.604010             False                  0.955                  0.999   \n",
       "2  73.300755             False                  0.975                  1.000   \n",
       "3  68.423650             False                  0.988                  1.000   \n",
       "4  68.367547             False                  0.983                  1.000   \n",
       "\n",
       "   Median_KL  \n",
       "0  66.980437  \n",
       "1  66.877609  \n",
       "2  66.980437  \n",
       "3  50.328013  \n",
       "4  55.650079  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "621a9e36-75ad-4db7-9d8e-305ecfec26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.2246467991473532e-16, 6.123233995736766e-17, 1.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "cmap = colormaps['rainbow']\n",
    "cmap(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f06af688250>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    plt.plot(df.iloc[i][[\"Min_KL\", \"Max_KL\"]], [df.iloc[i][\"Quantized Top1 Accuracy\"]] * 2, color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Min_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Max_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "072a7807-ef35-47de-807e-713dcf873518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(100):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized EfficientNet On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e647349-11a1-48f2-bb7f-80b685680da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(80):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fc909a7-7edb-48b6-a0ad-876549adac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(80):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b67a379b-ea0d-41f1-8e05-11ab681a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(80):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57a59db2-c5d9-448d-bd08-831468fc95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Median KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized EfficientNet On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973c463-7a01-4b31-81d8-98ff135a4621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
