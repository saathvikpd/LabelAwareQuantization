{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f376d630-cea9-4230-9c3f-5299c7c71ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 647.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 86.91419982910156.\n",
      "The relative quantization error of layer 0 is 0.018671410158276558.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 575.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 942.5114135742188.\n",
      "The relative quantization error of layer 1 is 0.052830975502729416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1821.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 246.29869079589844.\n",
      "The relative quantization error of layer 2 is 0.05529818683862686.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 251.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3519.596923828125.\n",
      "The relative quantization error of layer 3 is 0.10132728517055511.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1536.9398193359375.\n",
      "The relative quantization error of layer 4 is 0.051909949630498886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 453.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 620.3403930664062.\n",
      "The relative quantization error of layer 5 is 0.20371486246585846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1751.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 271.087158203125.\n",
      "The relative quantization error of layer 6 is 0.22232294082641602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 233.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1105.66552734375.\n",
      "The relative quantization error of layer 7 is 0.22828055918216705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 468.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 903.4515991210938.\n",
      "The relative quantization error of layer 8 is 0.26006069779396057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1999.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 588.2514038085938.\n",
      "The relative quantization error of layer 9 is 0.27466487884521484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 236.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1653.1593017578125.\n",
      "The relative quantization error of layer 10 is 0.23023389279842377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1738.46044921875.\n",
      "The relative quantization error of layer 11 is 0.30476391315460205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1985.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1198.88037109375.\n",
      "The relative quantization error of layer 12 is 0.2986406087875366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1530.853515625.\n",
      "The relative quantization error of layer 13 is 0.22014661133289337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2046.1915283203125.\n",
      "The relative quantization error of layer 14 is 0.2921665906906128.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1539.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2045.0550537109375.\n",
      "The relative quantization error of layer 15 is 0.26607081294059753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1976.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 533.4207763671875.\n",
      "The relative quantization error of layer 16 is 0.24154725670814514.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 844.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1213.21240234375.\n",
      "The relative quantization error of layer 17 is 0.3881314992904663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1738.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1792.8070068359375.\n",
      "The relative quantization error of layer 18 is 0.29998111724853516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1974.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 369.6341552734375.\n",
      "The relative quantization error of layer 19 is 0.25670671463012695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 845.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1241.499755859375.\n",
      "The relative quantization error of layer 20 is 0.3043767809867859.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1727.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1957.5482177734375.\n",
      "The relative quantization error of layer 21 is 0.3192407488822937.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1974.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 458.63671875.\n",
      "The relative quantization error of layer 22 is 0.2745196223258972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 841.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1039.9857177734375.\n",
      "The relative quantization error of layer 23 is 0.38210225105285645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1281.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3349.955322265625.\n",
      "The relative quantization error of layer 24 is 0.3614110052585602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1946.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 628.2282104492188.\n",
      "The relative quantization error of layer 25 is 0.3221478760242462.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1366.872802734375.\n",
      "The relative quantization error of layer 26 is 0.37206560373306274.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 506.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3438.84033203125.\n",
      "The relative quantization error of layer 27 is 0.35501137375831604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1942.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1340.6287841796875.\n",
      "The relative quantization error of layer 28 is 0.33304762840270996.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1951.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.3382568359375.\n",
      "The relative quantization error of layer 29 is 0.17947304248809814.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1319.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 996.007080078125.\n",
      "The relative quantization error of layer 30 is 0.4293910264968872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1937.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1505.0203857421875.\n",
      "The relative quantization error of layer 31 is 0.3582915663719177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1960.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 289.72430419921875.\n",
      "The relative quantization error of layer 32 is 0.21231770515441895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1313.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 869.3864135742188.\n",
      "The relative quantization error of layer 33 is 0.4710392653942108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1933.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1665.4417724609375.\n",
      "The relative quantization error of layer 34 is 0.4105967879295349.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1973.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 246.19369506835938.\n",
      "The relative quantization error of layer 35 is 0.20190253853797913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1322.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1020.9266357421875.\n",
      "The relative quantization error of layer 36 is 0.505439817905426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1942.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1718.6234130859375.\n",
      "The relative quantization error of layer 37 is 0.39695560932159424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1978.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 206.81629943847656.\n",
      "The relative quantization error of layer 38 is 0.20817872881889343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1314.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1333.26171875.\n",
      "The relative quantization error of layer 39 is 0.501234233379364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1955.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1814.0069580078125.\n",
      "The relative quantization error of layer 40 is 0.4253368675708771.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1960.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.61683654785156.\n",
      "The relative quantization error of layer 41 is 0.2182348519563675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1302.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1366.9542236328125.\n",
      "The relative quantization error of layer 42 is 0.5211108922958374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1769.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2473.3515625.\n",
      "The relative quantization error of layer 43 is 0.43867969512939453.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1967.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.5902557373047.\n",
      "The relative quantization error of layer 44 is 0.2031192183494568.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1704.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 913.5071411132812.\n",
      "The relative quantization error of layer 45 is 0.42220520973205566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 867.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2151.3896484375.\n",
      "The relative quantization error of layer 46 is 0.45780736207962036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1945.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 394.10552978515625.\n",
      "The relative quantization error of layer 47 is 0.3984088599681854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1986.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 94.32920837402344.\n",
      "The relative quantization error of layer 48 is 0.09794047474861145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1752.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 516.514404296875.\n",
      "The relative quantization error of layer 49 is 0.647638738155365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1953.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 418.2751770019531.\n",
      "The relative quantization error of layer 50 is 0.24619422852993011.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1970.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 78.9695816040039.\n",
      "The relative quantization error of layer 51 is 0.13780918717384338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1782.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 112.42508697509766.\n",
      "The relative quantization error of layer 52 is 0.7933148145675659.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2006.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.293668746948242.\n",
      "The relative quantization error of layer 53 is 0.17913824319839478.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.425784\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.75it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.887.\n",
      "Top-5 accuracy of vgg16 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.935.\n",
      "Top-5 accuracy of quantized vgg16 is 0.991.\n",
      "\n",
      "Time used for evaluation: 0:00:04.101216\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4544\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 658.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 89.37291717529297.\n",
      "The relative quantization error of layer 0 is 0.019322343170642853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 676.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 889.4987182617188.\n",
      "The relative quantization error of layer 1 is 0.049748118966817856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1881.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 249.7788848876953.\n",
      "The relative quantization error of layer 2 is 0.054945215582847595.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 230.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3466.1064453125.\n",
      "The relative quantization error of layer 3 is 0.1033816710114479.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1469.180419921875.\n",
      "The relative quantization error of layer 4 is 0.04899902269244194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 460.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 606.5226440429688.\n",
      "The relative quantization error of layer 5 is 0.20314350724220276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1838.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 286.342041015625.\n",
      "The relative quantization error of layer 6 is 0.23921792209148407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1095.8194580078125.\n",
      "The relative quantization error of layer 7 is 0.22438932955265045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 470.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 952.2750244140625.\n",
      "The relative quantization error of layer 8 is 0.2725343704223633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2031.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 596.4483032226562.\n",
      "The relative quantization error of layer 9 is 0.2860269546508789.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 248.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1601.66552734375.\n",
      "The relative quantization error of layer 10 is 0.2274477779865265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1699.1558837890625.\n",
      "The relative quantization error of layer 11 is 0.30288124084472656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2045.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1199.5460205078125.\n",
      "The relative quantization error of layer 12 is 0.29228445887565613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 762.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1530.8408203125.\n",
      "The relative quantization error of layer 13 is 0.2183115929365158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2112.08056640625.\n",
      "The relative quantization error of layer 14 is 0.2990170419216156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1677.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2150.136474609375.\n",
      "The relative quantization error of layer 15 is 0.27026695013046265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2054.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 545.66455078125.\n",
      "The relative quantization error of layer 16 is 0.24495959281921387.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 804.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1188.3062744140625.\n",
      "The relative quantization error of layer 17 is 0.38152381777763367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1762.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1788.5611572265625.\n",
      "The relative quantization error of layer 18 is 0.29164326190948486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2018.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 380.8675842285156.\n",
      "The relative quantization error of layer 19 is 0.25680243968963623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 849.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1335.403076171875.\n",
      "The relative quantization error of layer 20 is 0.3224031329154968.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1764.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2008.2301025390625.\n",
      "The relative quantization error of layer 21 is 0.330385684967041.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2040.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 468.1438903808594.\n",
      "The relative quantization error of layer 22 is 0.2807074785232544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 848.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1018.0431518554688.\n",
      "The relative quantization error of layer 23 is 0.34474870562553406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1299.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3338.640380859375.\n",
      "The relative quantization error of layer 24 is 0.3673573434352875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2051.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 637.3052368164062.\n",
      "The relative quantization error of layer 25 is 0.32140111923217773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1326.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1366.708740234375.\n",
      "The relative quantization error of layer 26 is 0.3703731894493103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 508.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3422.27880859375.\n",
      "The relative quantization error of layer 27 is 0.3558642864227295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2023.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1370.33056640625.\n",
      "The relative quantization error of layer 28 is 0.33402690291404724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2038.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.5234375.\n",
      "The relative quantization error of layer 29 is 0.17371517419815063.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1335.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 961.3477783203125.\n",
      "The relative quantization error of layer 30 is 0.4166528284549713.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2030.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1551.5963134765625.\n",
      "The relative quantization error of layer 31 is 0.35929572582244873.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2052.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.7152404785156.\n",
      "The relative quantization error of layer 32 is 0.21954673528671265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1328.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 866.5774536132812.\n",
      "The relative quantization error of layer 33 is 0.46943286061286926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2023.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1698.86474609375.\n",
      "The relative quantization error of layer 34 is 0.41476890444755554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2055.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.4579315185547.\n",
      "The relative quantization error of layer 35 is 0.20568303763866425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1341.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1039.4178466796875.\n",
      "The relative quantization error of layer 36 is 0.5214319229125977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2040.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1761.1221923828125.\n",
      "The relative quantization error of layer 37 is 0.403719037771225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2037.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.0161590576172.\n",
      "The relative quantization error of layer 38 is 0.21206755936145782.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1318.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1362.924560546875.\n",
      "The relative quantization error of layer 39 is 0.504457414150238.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2056.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1827.1900634765625.\n",
      "The relative quantization error of layer 40 is 0.43001994490623474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2050.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.80015563964844.\n",
      "The relative quantization error of layer 41 is 0.21865057945251465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1162.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1424.430908203125.\n",
      "The relative quantization error of layer 42 is 0.5423433780670166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1811.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2484.4462890625.\n",
      "The relative quantization error of layer 43 is 0.44268572330474854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2035.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.8542938232422.\n",
      "The relative quantization error of layer 44 is 0.20378731191158295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1748.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 926.4378051757812.\n",
      "The relative quantization error of layer 45 is 0.42842161655426025.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 861.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2178.857421875.\n",
      "The relative quantization error of layer 46 is 0.461349755525589.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2043.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 404.82586669921875.\n",
      "The relative quantization error of layer 47 is 0.3877008259296417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2065.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.8635482788086.\n",
      "The relative quantization error of layer 48 is 0.09530707448720932.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1783.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 540.412109375.\n",
      "The relative quantization error of layer 49 is 0.6738975644111633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2043.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 465.0981140136719.\n",
      "The relative quantization error of layer 50 is 0.2718142569065094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2077.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 68.88935852050781.\n",
      "The relative quantization error of layer 51 is 0.10998127609491348.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1820.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 114.04342651367188.\n",
      "The relative quantization error of layer 52 is 0.7995764017105103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2076.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 28.081544876098633.\n",
      "The relative quantization error of layer 53 is 0.17564751207828522.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:59.468506\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.77it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.861.\n",
      "Top-5 accuracy of vgg16 is 0.987.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.902.\n",
      "Top-5 accuracy of quantized vgg16 is 0.989.\n",
      "\n",
      "Time used for evaluation: 0:00:04.197846\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4535\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 628.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 88.7612533569336.\n",
      "The relative quantization error of layer 0 is 0.018525240942835808.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 600.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 857.0553588867188.\n",
      "The relative quantization error of layer 1 is 0.04829750955104828.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1861.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 243.88720703125.\n",
      "The relative quantization error of layer 2 is 0.05328213423490524.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3628.99853515625.\n",
      "The relative quantization error of layer 3 is 0.10780768096446991.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1502.7449951171875.\n",
      "The relative quantization error of layer 4 is 0.05200399085879326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 609.1554565429688.\n",
      "The relative quantization error of layer 5 is 0.20286020636558533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1738.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 279.3013916015625.\n",
      "The relative quantization error of layer 6 is 0.23453286290168762.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 243.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1088.3232421875.\n",
      "The relative quantization error of layer 7 is 0.2290622889995575.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 470.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 897.6824340820312.\n",
      "The relative quantization error of layer 8 is 0.2591214179992676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1958.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 563.234375.\n",
      "The relative quantization error of layer 9 is 0.26731330156326294.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 231.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1624.994873046875.\n",
      "The relative quantization error of layer 10 is 0.23640984296798706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1702.098876953125.\n",
      "The relative quantization error of layer 11 is 0.3081016540527344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1985.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1186.7259521484375.\n",
      "The relative quantization error of layer 12 is 0.3016454875469208.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 797.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1532.4713134765625.\n",
      "The relative quantization error of layer 13 is 0.21885214745998383.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2095.297119140625.\n",
      "The relative quantization error of layer 14 is 0.2984406352043152.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1735.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2074.75732421875.\n",
      "The relative quantization error of layer 15 is 0.26873549818992615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1982.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 507.3116149902344.\n",
      "The relative quantization error of layer 16 is 0.2327188402414322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1154.7725830078125.\n",
      "The relative quantization error of layer 17 is 0.38309207558631897.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1724.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1853.87646484375.\n",
      "The relative quantization error of layer 18 is 0.31004798412323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1987.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 371.90557861328125.\n",
      "The relative quantization error of layer 19 is 0.2581915557384491.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1258.9591064453125.\n",
      "The relative quantization error of layer 20 is 0.31110578775405884.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1742.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2062.74609375.\n",
      "The relative quantization error of layer 21 is 0.33502793312072754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1971.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 426.32330322265625.\n",
      "The relative quantization error of layer 22 is 0.2691212594509125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 840.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1109.50244140625.\n",
      "The relative quantization error of layer 23 is 0.38882583379745483.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1283.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3459.907470703125.\n",
      "The relative quantization error of layer 24 is 0.37651053071022034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1959.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 631.3500366210938.\n",
      "The relative quantization error of layer 25 is 0.3145955204963684.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1309.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1320.6558837890625.\n",
      "The relative quantization error of layer 26 is 0.3640238046646118.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 505.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3541.148193359375.\n",
      "The relative quantization error of layer 27 is 0.34888651967048645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1914.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1338.36962890625.\n",
      "The relative quantization error of layer 28 is 0.3269602060317993.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1948.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 269.2679748535156.\n",
      "The relative quantization error of layer 29 is 0.18217769265174866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1312.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1003.2155151367188.\n",
      "The relative quantization error of layer 30 is 0.4327917695045471.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1971.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1512.4976806640625.\n",
      "The relative quantization error of layer 31 is 0.3541305661201477.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1943.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 290.2174987792969.\n",
      "The relative quantization error of layer 32 is 0.21759437024593353.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1309.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 885.6708984375.\n",
      "The relative quantization error of layer 33 is 0.470138281583786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1929.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1658.498779296875.\n",
      "The relative quantization error of layer 34 is 0.4164850413799286.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1960.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 234.3221893310547.\n",
      "The relative quantization error of layer 35 is 0.2043427675962448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1033.66015625.\n",
      "The relative quantization error of layer 36 is 0.5067852735519409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1951.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1731.9801025390625.\n",
      "The relative quantization error of layer 37 is 0.4069516062736511.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1957.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.5245361328125.\n",
      "The relative quantization error of layer 38 is 0.2081810086965561.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1298.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1320.5946044921875.\n",
      "The relative quantization error of layer 39 is 0.5059638023376465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1952.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1816.14013671875.\n",
      "The relative quantization error of layer 40 is 0.4274802803993225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1974.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.3048553466797.\n",
      "The relative quantization error of layer 41 is 0.22527751326560974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1299.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1407.9736328125.\n",
      "The relative quantization error of layer 42 is 0.5247769355773926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1769.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2463.238525390625.\n",
      "The relative quantization error of layer 43 is 0.4431365728378296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1957.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.3644256591797.\n",
      "The relative quantization error of layer 44 is 0.2068822830915451.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1739.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 881.0156860351562.\n",
      "The relative quantization error of layer 45 is 0.4027518332004547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 866.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2173.79736328125.\n",
      "The relative quantization error of layer 46 is 0.45614093542099.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1947.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 395.4071960449219.\n",
      "The relative quantization error of layer 47 is 0.37317177653312683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1969.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 105.20418548583984.\n",
      "The relative quantization error of layer 48 is 0.1048496663570404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1743.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 529.6853637695312.\n",
      "The relative quantization error of layer 49 is 0.6587938070297241.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1934.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 478.5613708496094.\n",
      "The relative quantization error of layer 50 is 0.2720809876918793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1976.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 71.50035095214844.\n",
      "The relative quantization error of layer 51 is 0.15688711404800415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1791.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 105.29026794433594.\n",
      "The relative quantization error of layer 52 is 0.7647289633750916.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1964.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 25.472715377807617.\n",
      "The relative quantization error of layer 53 is 0.15928730368614197.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.197350\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.90it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.884.\n",
      "Top-5 accuracy of vgg16 is 0.991.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.96.\n",
      "Top-5 accuracy of quantized vgg16 is 0.996.\n",
      "\n",
      "Time used for evaluation: 0:00:03.998961\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4569\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 646.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 88.42169952392578.\n",
      "The relative quantization error of layer 0 is 0.01928042247891426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 602.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 849.2393798828125.\n",
      "The relative quantization error of layer 1 is 0.0483768992125988.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1847.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 237.31216430664062.\n",
      "The relative quantization error of layer 2 is 0.053252510726451874.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 237.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3341.226806640625.\n",
      "The relative quantization error of layer 3 is 0.10452856123447418.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1434.1920166015625.\n",
      "The relative quantization error of layer 4 is 0.048890888690948486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 453.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 614.456298828125.\n",
      "The relative quantization error of layer 5 is 0.20553290843963623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2019.21it/s]\n",
      " 25%|██▌       | 16/64 [00:00<00:00, 158.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 266.2724914550781.\n",
      "The relative quantization error of layer 6 is 0.22989417612552643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 196.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1030.91748046875.\n",
      "The relative quantization error of layer 7 is 0.223677858710289.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 470.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 846.7193603515625.\n",
      "The relative quantization error of layer 8 is 0.2608628273010254.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1928.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 583.917236328125.\n",
      "The relative quantization error of layer 9 is 0.28069013357162476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 234.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1667.53955078125.\n",
      "The relative quantization error of layer 10 is 0.25300681591033936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1697.5548095703125.\n",
      "The relative quantization error of layer 11 is 0.3093715310096741.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2008.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1199.55615234375.\n",
      "The relative quantization error of layer 12 is 0.31259381771087646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 842.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1510.674560546875.\n",
      "The relative quantization error of layer 13 is 0.21842557191848755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2036.8250732421875.\n",
      "The relative quantization error of layer 14 is 0.29784610867500305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1760.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2151.57177734375.\n",
      "The relative quantization error of layer 15 is 0.26830849051475525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2009.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 535.52392578125.\n",
      "The relative quantization error of layer 16 is 0.24523217976093292.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 785.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1257.0892333984375.\n",
      "The relative quantization error of layer 17 is 0.41268619894981384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1733.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1822.1766357421875.\n",
      "The relative quantization error of layer 18 is 0.3085388243198395.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1997.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 381.15728759765625.\n",
      "The relative quantization error of layer 19 is 0.26479995250701904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1200.3193359375.\n",
      "The relative quantization error of layer 20 is 0.2973751127719879.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1757.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1963.4786376953125.\n",
      "The relative quantization error of layer 21 is 0.3241874873638153.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2010.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 444.7479553222656.\n",
      "The relative quantization error of layer 22 is 0.2770046889781952.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 845.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1010.2808227539062.\n",
      "The relative quantization error of layer 23 is 0.384867787361145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1292.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3360.399169921875.\n",
      "The relative quantization error of layer 24 is 0.3725404441356659.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2004.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 613.3572998046875.\n",
      "The relative quantization error of layer 25 is 0.31986743211746216.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1320.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1351.791748046875.\n",
      "The relative quantization error of layer 26 is 0.37239494919776917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 508.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3426.764892578125.\n",
      "The relative quantization error of layer 27 is 0.35857918858528137.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1967.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1364.026123046875.\n",
      "The relative quantization error of layer 28 is 0.33925285935401917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2008.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.853271484375.\n",
      "The relative quantization error of layer 29 is 0.18285830318927765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1331.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 965.9886474609375.\n",
      "The relative quantization error of layer 30 is 0.44650018215179443.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1995.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1539.860107421875.\n",
      "The relative quantization error of layer 31 is 0.3620118200778961.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2019.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 297.9493408203125.\n",
      "The relative quantization error of layer 32 is 0.21919842064380646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1331.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 860.8523559570312.\n",
      "The relative quantization error of layer 33 is 0.4676499664783478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1992.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1696.56591796875.\n",
      "The relative quantization error of layer 34 is 0.3910518288612366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2028.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.0788116455078.\n",
      "The relative quantization error of layer 35 is 0.20325139164924622.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1336.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1060.7108154296875.\n",
      "The relative quantization error of layer 36 is 0.5174257755279541.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1985.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1732.2796630859375.\n",
      "The relative quantization error of layer 37 is 0.41830894351005554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2004.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.78109741210938.\n",
      "The relative quantization error of layer 38 is 0.20742104947566986.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1323.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1360.6138916015625.\n",
      "The relative quantization error of layer 39 is 0.5119627118110657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1984.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1837.2740478515625.\n",
      "The relative quantization error of layer 40 is 0.42920157313346863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2018.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 184.88665771484375.\n",
      "The relative quantization error of layer 41 is 0.2250489890575409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1315.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1414.822021484375.\n",
      "The relative quantization error of layer 42 is 0.5294628143310547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1790.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2486.717529296875.\n",
      "The relative quantization error of layer 43 is 0.4532385766506195.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1997.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 163.77572631835938.\n",
      "The relative quantization error of layer 44 is 0.20197078585624695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1776.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 910.78564453125.\n",
      "The relative quantization error of layer 45 is 0.4214673638343811.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 865.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2148.471435546875.\n",
      "The relative quantization error of layer 46 is 0.4626809060573578.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2012.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 407.70098876953125.\n",
      "The relative quantization error of layer 47 is 0.39219456911087036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2020.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 100.36445617675781.\n",
      "The relative quantization error of layer 48 is 0.10188871622085571.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1769.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 527.015380859375.\n",
      "The relative quantization error of layer 49 is 0.6679224967956543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2009.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 435.6247253417969.\n",
      "The relative quantization error of layer 50 is 0.2824901044368744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2031.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 56.502540588378906.\n",
      "The relative quantization error of layer 51 is 0.14205381274223328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1803.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.77813720703125.\n",
      "The relative quantization error of layer 52 is 0.7747651934623718.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1999.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 32.55192565917969.\n",
      "The relative quantization error of layer 53 is 0.2055213451385498.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.244040\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.05it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.879.\n",
      "Top-5 accuracy of vgg16 is 0.987.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.953.\n",
      "Top-5 accuracy of quantized vgg16 is 0.994.\n",
      "\n",
      "Time used for evaluation: 0:00:04.192079\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.454\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 617.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.61016845703125.\n",
      "The relative quantization error of layer 0 is 0.019294049590826035.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 674.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 867.593505859375.\n",
      "The relative quantization error of layer 1 is 0.048739802092313766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2047.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 257.15997314453125.\n",
      "The relative quantization error of layer 2 is 0.058910418301820755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 246.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3361.840087890625.\n",
      "The relative quantization error of layer 3 is 0.09954290837049484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1594.9576416015625.\n",
      "The relative quantization error of layer 4 is 0.05468146502971649.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 464.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 581.490478515625.\n",
      "The relative quantization error of layer 5 is 0.19991642236709595.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2061.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 274.7066955566406.\n",
      "The relative quantization error of layer 6 is 0.23192700743675232.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 206.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1143.8360595703125.\n",
      "The relative quantization error of layer 7 is 0.24445073306560516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 459.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 889.3245849609375.\n",
      "The relative quantization error of layer 8 is 0.2603957951068878.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1957.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 613.5164794921875.\n",
      "The relative quantization error of layer 9 is 0.2903258204460144.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1603.236083984375.\n",
      "The relative quantization error of layer 10 is 0.23681582510471344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 262.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1776.55615234375.\n",
      "The relative quantization error of layer 11 is 0.3100956082344055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2026.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1206.6837158203125.\n",
      "The relative quantization error of layer 12 is 0.30798348784446716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 804.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1545.6103515625.\n",
      "The relative quantization error of layer 13 is 0.22137947380542755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2082.270263671875.\n",
      "The relative quantization error of layer 14 is 0.3000209629535675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1774.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2082.575927734375.\n",
      "The relative quantization error of layer 15 is 0.2724628448486328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2030.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 543.1726684570312.\n",
      "The relative quantization error of layer 16 is 0.2479858696460724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 823.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1140.2120361328125.\n",
      "The relative quantization error of layer 17 is 0.3775951862335205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1775.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1824.564208984375.\n",
      "The relative quantization error of layer 18 is 0.3099755346775055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2048.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 362.652587890625.\n",
      "The relative quantization error of layer 19 is 0.2580885887145996.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 845.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1257.5772705078125.\n",
      "The relative quantization error of layer 20 is 0.30905696749687195.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1770.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1979.5882568359375.\n",
      "The relative quantization error of layer 21 is 0.3304515779018402.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2023.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 437.9473571777344.\n",
      "The relative quantization error of layer 22 is 0.2756504714488983.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 744.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1001.5169677734375.\n",
      "The relative quantization error of layer 23 is 0.37154287099838257.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1290.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3244.542236328125.\n",
      "The relative quantization error of layer 24 is 0.3612079322338104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2050.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 623.7828979492188.\n",
      "The relative quantization error of layer 25 is 0.3156861960887909.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1337.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1357.0006103515625.\n",
      "The relative quantization error of layer 26 is 0.36840683221817017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 509.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3417.532470703125.\n",
      "The relative quantization error of layer 27 is 0.3586822748184204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2001.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1343.8311767578125.\n",
      "The relative quantization error of layer 28 is 0.3274913430213928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2032.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.1664123535156.\n",
      "The relative quantization error of layer 29 is 0.18064475059509277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1332.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1006.4522705078125.\n",
      "The relative quantization error of layer 30 is 0.42264023423194885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1997.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1552.589599609375.\n",
      "The relative quantization error of layer 31 is 0.36415693163871765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2035.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.273681640625.\n",
      "The relative quantization error of layer 32 is 0.2148858904838562.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1330.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 865.077392578125.\n",
      "The relative quantization error of layer 33 is 0.46182337403297424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1999.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1644.380615234375.\n",
      "The relative quantization error of layer 34 is 0.3917858302593231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2018.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.99269104003906.\n",
      "The relative quantization error of layer 35 is 0.19906653463840485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1331.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1055.156982421875.\n",
      "The relative quantization error of layer 36 is 0.5107903480529785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1989.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1774.7203369140625.\n",
      "The relative quantization error of layer 37 is 0.4209378659725189.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2016.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.5374755859375.\n",
      "The relative quantization error of layer 38 is 0.20965991914272308.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1354.2003173828125.\n",
      "The relative quantization error of layer 39 is 0.5023149847984314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2003.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1846.803466796875.\n",
      "The relative quantization error of layer 40 is 0.43031802773475647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2024.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.11016845703125.\n",
      "The relative quantization error of layer 41 is 0.2233559936285019.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1390.4608154296875.\n",
      "The relative quantization error of layer 42 is 0.5125033855438232.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1803.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2491.5263671875.\n",
      "The relative quantization error of layer 43 is 0.45352163910865784.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2013.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.3290557861328.\n",
      "The relative quantization error of layer 44 is 0.1977381855249405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1785.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 898.9244384765625.\n",
      "The relative quantization error of layer 45 is 0.4267159104347229.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 874.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2145.9814453125.\n",
      "The relative quantization error of layer 46 is 0.4628174602985382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2047.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 391.876708984375.\n",
      "The relative quantization error of layer 47 is 0.377119779586792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2058.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 94.35272979736328.\n",
      "The relative quantization error of layer 48 is 0.09439709037542343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1785.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 520.85595703125.\n",
      "The relative quantization error of layer 49 is 0.6625937819480896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2042.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 467.8585205078125.\n",
      "The relative quantization error of layer 50 is 0.3703061640262604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2066.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 61.467811584472656.\n",
      "The relative quantization error of layer 51 is 0.11586641520261765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1818.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 107.66515350341797.\n",
      "The relative quantization error of layer 52 is 0.786264181137085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2075.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 33.605064392089844.\n",
      "The relative quantization error of layer 53 is 0.19957317411899567.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:59.299039\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.92it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.872.\n",
      "Top-5 accuracy of vgg16 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.952.\n",
      "Top-5 accuracy of quantized vgg16 is 0.994.\n",
      "\n",
      "Time used for evaluation: 0:00:03.891989\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4554\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 644.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 89.54010009765625.\n",
      "The relative quantization error of layer 0 is 0.01960359886288643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 684.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 867.3124389648438.\n",
      "The relative quantization error of layer 1 is 0.04887334257364273.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1990.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 271.0954895019531.\n",
      "The relative quantization error of layer 2 is 0.062090665102005005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 251.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3351.599365234375.\n",
      "The relative quantization error of layer 3 is 0.10001032799482346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1497.86669921875.\n",
      "The relative quantization error of layer 4 is 0.05106060951948166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 460.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 612.4157104492188.\n",
      "The relative quantization error of layer 5 is 0.20981080830097198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2082.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 263.9105224609375.\n",
      "The relative quantization error of layer 6 is 0.2303566038608551.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 222.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1032.6507568359375.\n",
      "The relative quantization error of layer 7 is 0.23067763447761536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 448.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 861.1111450195312.\n",
      "The relative quantization error of layer 8 is 0.2642546594142914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2074.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 583.5884399414062.\n",
      "The relative quantization error of layer 9 is 0.2778954803943634.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1685.47021484375.\n",
      "The relative quantization error of layer 10 is 0.2480621039867401.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 263.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1669.35986328125.\n",
      "The relative quantization error of layer 11 is 0.3108723759651184.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2101.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1211.586181640625.\n",
      "The relative quantization error of layer 12 is 0.30877673625946045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 854.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1509.1402587890625.\n",
      "The relative quantization error of layer 13 is 0.2188452035188675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2020.4942626953125.\n",
      "The relative quantization error of layer 14 is 0.2941778302192688.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1782.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2098.89208984375.\n",
      "The relative quantization error of layer 15 is 0.26999813318252563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2093.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 546.7174072265625.\n",
      "The relative quantization error of layer 16 is 0.24142274260520935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 685.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1262.083740234375.\n",
      "The relative quantization error of layer 17 is 0.40515756607055664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1791.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1834.9473876953125.\n",
      "The relative quantization error of layer 18 is 0.308379590511322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2125.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 381.4869079589844.\n",
      "The relative quantization error of layer 19 is 0.26666679978370667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 855.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1224.4775390625.\n",
      "The relative quantization error of layer 20 is 0.3074077367782593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1809.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2046.5472412109375.\n",
      "The relative quantization error of layer 21 is 0.33904752135276794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2088.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 440.6825256347656.\n",
      "The relative quantization error of layer 22 is 0.2782924175262451.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 856.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 989.6392211914062.\n",
      "The relative quantization error of layer 23 is 0.3829721212387085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1317.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3352.026611328125.\n",
      "The relative quantization error of layer 24 is 0.3703434467315674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2075.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 648.2236328125.\n",
      "The relative quantization error of layer 25 is 0.3299782872200012.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1360.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1328.337890625.\n",
      "The relative quantization error of layer 26 is 0.36778944730758667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 514.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3423.3388671875.\n",
      "The relative quantization error of layer 27 is 0.36168503761291504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2058.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1353.6932373046875.\n",
      "The relative quantization error of layer 28 is 0.3358922302722931.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2040.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.8031921386719.\n",
      "The relative quantization error of layer 29 is 0.1809682697057724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1359.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 952.3780517578125.\n",
      "The relative quantization error of layer 30 is 0.4363959729671478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2084.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1499.8372802734375.\n",
      "The relative quantization error of layer 31 is 0.3616448640823364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2116.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 299.5273132324219.\n",
      "The relative quantization error of layer 32 is 0.2226012498140335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1362.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 860.2048950195312.\n",
      "The relative quantization error of layer 33 is 0.4672962725162506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1970.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1667.9412841796875.\n",
      "The relative quantization error of layer 34 is 0.40607330203056335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2123.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.82359313964844.\n",
      "The relative quantization error of layer 35 is 0.20666171610355377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1360.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1062.8731689453125.\n",
      "The relative quantization error of layer 36 is 0.5058021545410156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2090.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1766.8013916015625.\n",
      "The relative quantization error of layer 37 is 0.41655024886131287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2122.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.68487548828125.\n",
      "The relative quantization error of layer 38 is 0.2088305801153183.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1357.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1320.824462890625.\n",
      "The relative quantization error of layer 39 is 0.5060670971870422.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2104.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1809.478759765625.\n",
      "The relative quantization error of layer 40 is 0.41727837920188904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2106.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 181.1380157470703.\n",
      "The relative quantization error of layer 41 is 0.22457733750343323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1361.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1431.704345703125.\n",
      "The relative quantization error of layer 42 is 0.5415711998939514.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1860.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2459.6650390625.\n",
      "The relative quantization error of layer 43 is 0.4526940584182739.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2069.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.6256103515625.\n",
      "The relative quantization error of layer 44 is 0.20363536477088928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1836.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 908.4357299804688.\n",
      "The relative quantization error of layer 45 is 0.41794392466545105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 885.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2181.482177734375.\n",
      "The relative quantization error of layer 46 is 0.46683305501937866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2099.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 407.6167297363281.\n",
      "The relative quantization error of layer 47 is 0.38531801104545593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2132.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.6048812866211.\n",
      "The relative quantization error of layer 48 is 0.09736797958612442.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1820.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 532.4658203125.\n",
      "The relative quantization error of layer 49 is 0.6715086102485657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2099.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 436.4768371582031.\n",
      "The relative quantization error of layer 50 is 0.25598427653312683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2142.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 77.54704284667969.\n",
      "The relative quantization error of layer 51 is 0.15338464081287384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1851.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 113.10881042480469.\n",
      "The relative quantization error of layer 52 is 0.8017836213111877.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2120.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 26.082199096679688.\n",
      "The relative quantization error of layer 53 is 0.15825790166854858.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:58.955438\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.98it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.879.\n",
      "Top-5 accuracy of vgg16 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.948.\n",
      "Top-5 accuracy of quantized vgg16 is 0.988.\n",
      "\n",
      "Time used for evaluation: 0:00:04.097492\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4516\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 654.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 92.20298767089844.\n",
      "The relative quantization error of layer 0 is 0.019399426877498627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 627.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 887.666015625.\n",
      "The relative quantization error of layer 1 is 0.05011849105358124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1824.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 243.43701171875.\n",
      "The relative quantization error of layer 2 is 0.05264168605208397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 251.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3585.053466796875.\n",
      "The relative quantization error of layer 3 is 0.10536826401948929.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1451.6873779296875.\n",
      "The relative quantization error of layer 4 is 0.049439456313848495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 457.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 608.0125122070312.\n",
      "The relative quantization error of layer 5 is 0.2004682570695877.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1979.10it/s]\n",
      " 66%|██████▌   | 42/64 [00:00<00:00, 215.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 265.8986511230469.\n",
      "The relative quantization error of layer 6 is 0.2277555763721466.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 220.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1057.634521484375.\n",
      "The relative quantization error of layer 7 is 0.22714513540267944.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 466.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 912.092041015625.\n",
      "The relative quantization error of layer 8 is 0.2573148012161255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1904.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 569.2140502929688.\n",
      "The relative quantization error of layer 9 is 0.27376189827919006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 238.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1497.590576171875.\n",
      "The relative quantization error of layer 10 is 0.2315656691789627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1721.361572265625.\n",
      "The relative quantization error of layer 11 is 0.3061494827270508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2015.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1184.944091796875.\n",
      "The relative quantization error of layer 12 is 0.29633060097694397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 840.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1569.837158203125.\n",
      "The relative quantization error of layer 13 is 0.2230590134859085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2037.5994873046875.\n",
      "The relative quantization error of layer 14 is 0.29372069239616394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1709.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2032.572265625.\n",
      "The relative quantization error of layer 15 is 0.266017884016037.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1983.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 535.3914794921875.\n",
      "The relative quantization error of layer 16 is 0.23827049136161804.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 842.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1263.0089111328125.\n",
      "The relative quantization error of layer 17 is 0.4062518775463104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1765.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1812.2890625.\n",
      "The relative quantization error of layer 18 is 0.302153080701828.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1982.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 375.72100830078125.\n",
      "The relative quantization error of layer 19 is 0.2625611424446106.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 728.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1269.0474853515625.\n",
      "The relative quantization error of layer 20 is 0.30576902627944946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1740.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1925.340576171875.\n",
      "The relative quantization error of layer 21 is 0.3170364797115326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2005.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 451.66119384765625.\n",
      "The relative quantization error of layer 22 is 0.28276553750038147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 844.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1047.7734375.\n",
      "The relative quantization error of layer 23 is 0.36343908309936523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1294.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3293.0478515625.\n",
      "The relative quantization error of layer 24 is 0.3614451587200165.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2014.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 638.10009765625.\n",
      "The relative quantization error of layer 25 is 0.3287743628025055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1323.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1391.5113525390625.\n",
      "The relative quantization error of layer 26 is 0.37538525462150574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 508.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3432.11474609375.\n",
      "The relative quantization error of layer 27 is 0.36618512868881226.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1992.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1366.6904296875.\n",
      "The relative quantization error of layer 28 is 0.3340439796447754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2012.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.6820983886719.\n",
      "The relative quantization error of layer 29 is 0.18205541372299194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1316.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 992.3269653320312.\n",
      "The relative quantization error of layer 30 is 0.43863239884376526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1982.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1527.8544921875.\n",
      "The relative quantization error of layer 31 is 0.36532458662986755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2003.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 302.9097595214844.\n",
      "The relative quantization error of layer 32 is 0.22708067297935486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1318.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 895.6144409179688.\n",
      "The relative quantization error of layer 33 is 0.48018527030944824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1985.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1686.3450927734375.\n",
      "The relative quantization error of layer 34 is 0.39552125334739685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2046.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 250.2554931640625.\n",
      "The relative quantization error of layer 35 is 0.20615971088409424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1331.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1048.3475341796875.\n",
      "The relative quantization error of layer 36 is 0.5121288299560547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1984.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1801.559814453125.\n",
      "The relative quantization error of layer 37 is 0.428447961807251.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2017.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 211.47409057617188.\n",
      "The relative quantization error of layer 38 is 0.21153801679611206.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1327.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1366.7742919921875.\n",
      "The relative quantization error of layer 39 is 0.5084609985351562.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1995.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1881.998291015625.\n",
      "The relative quantization error of layer 40 is 0.44172319769859314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1990.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 184.36392211914062.\n",
      "The relative quantization error of layer 41 is 0.22416700422763824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1327.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1445.90185546875.\n",
      "The relative quantization error of layer 42 is 0.5330579876899719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1803.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2527.812255859375.\n",
      "The relative quantization error of layer 43 is 0.45119452476501465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1998.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 150.42218017578125.\n",
      "The relative quantization error of layer 44 is 0.19306494295597076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1769.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 937.4224853515625.\n",
      "The relative quantization error of layer 45 is 0.4324827790260315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 868.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2209.983154296875.\n",
      "The relative quantization error of layer 46 is 0.4653780460357666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1966.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 412.13287353515625.\n",
      "The relative quantization error of layer 47 is 0.3971404433250427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2028.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.92204284667969.\n",
      "The relative quantization error of layer 48 is 0.1000799611210823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1766.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 519.9902954101562.\n",
      "The relative quantization error of layer 49 is 0.6665525436401367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2008.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 494.9749450683594.\n",
      "The relative quantization error of layer 50 is 0.24140134453773499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2039.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 76.453369140625.\n",
      "The relative quantization error of layer 51 is 0.15557554364204407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1813.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 114.6833267211914.\n",
      "The relative quantization error of layer 52 is 0.8100928068161011.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2023.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 34.325496673583984.\n",
      "The relative quantization error of layer 53 is 0.20781952142715454.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:59.786070\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.87it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.873.\n",
      "Top-5 accuracy of vgg16 is 0.983.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.945.\n",
      "Top-5 accuracy of quantized vgg16 is 0.992.\n",
      "\n",
      "Time used for evaluation: 0:00:03.988587\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.455\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['False'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'vgg16' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9969179e-0865-48e8-a11d-cc1e1f526b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 627.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 77.90684509277344.\n",
      "The relative quantization error of layer 0 is 0.01787581294775009.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 766.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 784.6292724609375.\n",
      "The relative quantization error of layer 1 is 0.04429594799876213.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1980.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 248.9803924560547.\n",
      "The relative quantization error of layer 2 is 0.0603678859770298.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3594.26708984375.\n",
      "The relative quantization error of layer 3 is 0.10643544048070908.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 248.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1309.9251708984375.\n",
      "The relative quantization error of layer 4 is 0.04435741901397705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 601.6043701171875.\n",
      "The relative quantization error of layer 5 is 0.20509937405586243.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1907.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 259.1159362792969.\n",
      "The relative quantization error of layer 6 is 0.22808580100536346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 216.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 996.2561645507812.\n",
      "The relative quantization error of layer 7 is 0.22160698473453522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 457.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 889.9071044921875.\n",
      "The relative quantization error of layer 8 is 0.2541274428367615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1794.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 552.8585205078125.\n",
      "The relative quantization error of layer 9 is 0.26797786355018616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1512.9442138671875.\n",
      "The relative quantization error of layer 10 is 0.23121023178100586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1620.9312744140625.\n",
      "The relative quantization error of layer 11 is 0.30767062306404114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1952.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1195.605224609375.\n",
      "The relative quantization error of layer 12 is 0.2951594293117523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 814.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1472.75439453125.\n",
      "The relative quantization error of layer 13 is 0.2128991335630417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2056.404052734375.\n",
      "The relative quantization error of layer 14 is 0.29733729362487793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1735.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2025.7822265625.\n",
      "The relative quantization error of layer 15 is 0.2743983268737793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1980.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 523.3638916015625.\n",
      "The relative quantization error of layer 16 is 0.23623476922512054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1173.131591796875.\n",
      "The relative quantization error of layer 17 is 0.3867272436618805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1701.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1740.7938232421875.\n",
      "The relative quantization error of layer 18 is 0.30539414286613464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1974.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 365.09423828125.\n",
      "The relative quantization error of layer 19 is 0.2633943259716034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 836.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1234.202880859375.\n",
      "The relative quantization error of layer 20 is 0.3027251362800598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1718.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1953.397705078125.\n",
      "The relative quantization error of layer 21 is 0.3422847092151642.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1967.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 436.2076416015625.\n",
      "The relative quantization error of layer 22 is 0.28482887148857117.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1085.8096923828125.\n",
      "The relative quantization error of layer 23 is 0.3635622560977936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1278.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3312.041259765625.\n",
      "The relative quantization error of layer 24 is 0.3703199326992035.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1950.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 616.6768798828125.\n",
      "The relative quantization error of layer 25 is 0.3235657215118408.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1301.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1366.165771484375.\n",
      "The relative quantization error of layer 26 is 0.3677883744239807.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 506.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3428.179931640625.\n",
      "The relative quantization error of layer 27 is 0.36100131273269653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1930.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1354.941162109375.\n",
      "The relative quantization error of layer 28 is 0.33568912744522095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1960.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.65948486328125.\n",
      "The relative quantization error of layer 29 is 0.17916040122509003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1309.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 974.3473510742188.\n",
      "The relative quantization error of layer 30 is 0.4239705502986908.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1944.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1516.68505859375.\n",
      "The relative quantization error of layer 31 is 0.36934027075767517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1967.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 300.6404113769531.\n",
      "The relative quantization error of layer 32 is 0.22840310633182526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1316.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 887.3245849609375.\n",
      "The relative quantization error of layer 33 is 0.48167258501052856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1943.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1731.8392333984375.\n",
      "The relative quantization error of layer 34 is 0.4110144376754761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1973.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.91744995117188.\n",
      "The relative quantization error of layer 35 is 0.20869427919387817.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1167.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1044.512939453125.\n",
      "The relative quantization error of layer 36 is 0.5178549885749817.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1957.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1785.826416015625.\n",
      "The relative quantization error of layer 37 is 0.43016746640205383.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1966.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.64089965820312.\n",
      "The relative quantization error of layer 38 is 0.20776452124118805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1314.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1384.4927978515625.\n",
      "The relative quantization error of layer 39 is 0.5187137722969055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1944.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1899.9014892578125.\n",
      "The relative quantization error of layer 40 is 0.4583628475666046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1959.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 172.78211975097656.\n",
      "The relative quantization error of layer 41 is 0.2190418690443039.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1314.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1467.767822265625.\n",
      "The relative quantization error of layer 42 is 0.5546430349349976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1764.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2633.88623046875.\n",
      "The relative quantization error of layer 43 is 0.4677344560623169.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1968.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.72702026367188.\n",
      "The relative quantization error of layer 44 is 0.20118412375450134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1744.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 971.9547729492188.\n",
      "The relative quantization error of layer 45 is 0.44226914644241333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 863.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2265.657470703125.\n",
      "The relative quantization error of layer 46 is 0.4777231216430664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1964.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 447.4263916015625.\n",
      "The relative quantization error of layer 47 is 0.4153430163860321.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1958.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.94734954833984.\n",
      "The relative quantization error of layer 48 is 0.11586941033601761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1741.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 570.0822143554688.\n",
      "The relative quantization error of layer 49 is 0.7061227560043335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1961.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 453.2322692871094.\n",
      "The relative quantization error of layer 50 is 0.3690376579761505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1965.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 106.50924682617188.\n",
      "The relative quantization error of layer 51 is 0.17485536634922028.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1778.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 132.96148681640625.\n",
      "The relative quantization error of layer 52 is 0.8590793013572693.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1975.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.26709747314453.\n",
      "The relative quantization error of layer 53 is 0.2746294140815735.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.828189\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.04it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.815.\n",
      "Top-5 accuracy of vgg16 is 0.949.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.607.\n",
      "Top-5 accuracy of quantized vgg16 is 0.904.\n",
      "\n",
      "Time used for evaluation: 0:00:03.896262\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4433\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 647.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 63.0817756652832.\n",
      "The relative quantization error of layer 0 is 0.01802997849881649.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 765.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 753.8070678710938.\n",
      "The relative quantization error of layer 1 is 0.043042682111263275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1847.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 228.3680419921875.\n",
      "The relative quantization error of layer 2 is 0.05658067390322685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 242.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3423.78515625.\n",
      "The relative quantization error of layer 3 is 0.09453735500574112.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1204.3365478515625.\n",
      "The relative quantization error of layer 4 is 0.04091173782944679.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 467.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 558.5283203125.\n",
      "The relative quantization error of layer 5 is 0.19623540341854095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1829.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 241.20394897460938.\n",
      "The relative quantization error of layer 6 is 0.22739851474761963.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 886.9579467773438.\n",
      "The relative quantization error of layer 7 is 0.20799486339092255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 464.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 857.7286987304688.\n",
      "The relative quantization error of layer 8 is 0.25651323795318604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1970.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 541.048583984375.\n",
      "The relative quantization error of layer 9 is 0.27115848660469055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 219.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1552.8990478515625.\n",
      "The relative quantization error of layer 10 is 0.24739864468574524.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1624.90478515625.\n",
      "The relative quantization error of layer 11 is 0.30692389607429504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1934.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1160.0245361328125.\n",
      "The relative quantization error of layer 12 is 0.3007645905017853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 791.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1467.58349609375.\n",
      "The relative quantization error of layer 13 is 0.21273715794086456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1871.8094482421875.\n",
      "The relative quantization error of layer 14 is 0.2923904359340668.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1710.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1931.3206787109375.\n",
      "The relative quantization error of layer 15 is 0.275482714176178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1909.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 466.1758728027344.\n",
      "The relative quantization error of layer 16 is 0.22219005227088928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 833.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1163.9583740234375.\n",
      "The relative quantization error of layer 17 is 0.4031009078025818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1720.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1688.3077392578125.\n",
      "The relative quantization error of layer 18 is 0.3085422217845917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1947.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 363.32110595703125.\n",
      "The relative quantization error of layer 19 is 0.269643098115921.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1207.1126708984375.\n",
      "The relative quantization error of layer 20 is 0.304317444562912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1714.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1922.6297607421875.\n",
      "The relative quantization error of layer 21 is 0.34477922320365906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1919.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 411.748779296875.\n",
      "The relative quantization error of layer 22 is 0.2809712588787079.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 832.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 942.5259399414062.\n",
      "The relative quantization error of layer 23 is 0.3973224461078644.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1268.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3255.9619140625.\n",
      "The relative quantization error of layer 24 is 0.37024083733558655.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1928.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 612.7290649414062.\n",
      "The relative quantization error of layer 25 is 0.3232104480266571.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1295.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1370.617919921875.\n",
      "The relative quantization error of layer 26 is 0.36665380001068115.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 505.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3257.234619140625.\n",
      "The relative quantization error of layer 27 is 0.36837995052337646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1920.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1338.0838623046875.\n",
      "The relative quantization error of layer 28 is 0.3471367657184601.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1907.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.83477783203125.\n",
      "The relative quantization error of layer 29 is 0.18193289637565613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1307.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 948.0198364257812.\n",
      "The relative quantization error of layer 30 is 0.45964983105659485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1891.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1572.591552734375.\n",
      "The relative quantization error of layer 31 is 0.3863542377948761.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1927.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.3843994140625.\n",
      "The relative quantization error of layer 32 is 0.22485734522342682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1290.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 905.713623046875.\n",
      "The relative quantization error of layer 33 is 0.5020338296890259.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1901.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1732.081298828125.\n",
      "The relative quantization error of layer 34 is 0.437134325504303.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1924.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 257.42510986328125.\n",
      "The relative quantization error of layer 35 is 0.21196874976158142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1289.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1040.98828125.\n",
      "The relative quantization error of layer 36 is 0.5190343856811523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1887.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1802.5272216796875.\n",
      "The relative quantization error of layer 37 is 0.453578919172287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1935.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 216.75640869140625.\n",
      "The relative quantization error of layer 38 is 0.2105773389339447.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1419.8516845703125.\n",
      "The relative quantization error of layer 39 is 0.5174874663352966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1899.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1885.8543701171875.\n",
      "The relative quantization error of layer 40 is 0.46019554138183594.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1917.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 191.47122192382812.\n",
      "The relative quantization error of layer 41 is 0.22192531824111938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1293.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1480.05517578125.\n",
      "The relative quantization error of layer 42 is 0.544107973575592.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1753.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2620.092529296875.\n",
      "The relative quantization error of layer 43 is 0.472148597240448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1927.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 168.6507568359375.\n",
      "The relative quantization error of layer 44 is 0.20803630352020264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1562.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 991.7337646484375.\n",
      "The relative quantization error of layer 45 is 0.454556405544281.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 856.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2249.8984375.\n",
      "The relative quantization error of layer 46 is 0.47686776518821716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1925.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 451.9313659667969.\n",
      "The relative quantization error of layer 47 is 0.42111852765083313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1910.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 116.07452392578125.\n",
      "The relative quantization error of layer 48 is 0.11035368591547012.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1705.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 562.9407348632812.\n",
      "The relative quantization error of layer 49 is 0.6905831694602966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1901.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 495.2698974609375.\n",
      "The relative quantization error of layer 50 is 0.4099469482898712.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1939.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 97.61416625976562.\n",
      "The relative quantization error of layer 51 is 0.22961917519569397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1404.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 135.51922607421875.\n",
      "The relative quantization error of layer 52 is 0.8649452328681946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1411.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 46.27341079711914.\n",
      "The relative quantization error of layer 53 is 0.2774997353553772.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:02.175376\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.808.\n",
      "Top-5 accuracy of vgg16 is 0.958.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.661.\n",
      "Top-5 accuracy of quantized vgg16 is 0.945.\n",
      "\n",
      "Time used for evaluation: 0:00:04.106604\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4497\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 653.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 73.2369155883789.\n",
      "The relative quantization error of layer 0 is 0.01865849271416664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 769.11it/s]\n",
      " 69%|██████▊   | 395/576 [00:00<00:00, 1984.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 846.0547485351562.\n",
      "The relative quantization error of layer 1 is 0.04758116975426674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1993.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 229.8721466064453.\n",
      "The relative quantization error of layer 2 is 0.05398908257484436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3516.000732421875.\n",
      "The relative quantization error of layer 3 is 0.09793737530708313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1450.34375.\n",
      "The relative quantization error of layer 4 is 0.04945041611790657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 471.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 558.0444946289062.\n",
      "The relative quantization error of layer 5 is 0.19522805511951447.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1950.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 245.4854736328125.\n",
      "The relative quantization error of layer 6 is 0.22353459894657135.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1013.771728515625.\n",
      "The relative quantization error of layer 7 is 0.2300274521112442.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 468.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 838.2871704101562.\n",
      "The relative quantization error of layer 8 is 0.2646559178829193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1991.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 546.277587890625.\n",
      "The relative quantization error of layer 9 is 0.2753312289714813.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 243.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1609.1502685546875.\n",
      "The relative quantization error of layer 10 is 0.25133439898490906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 260.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1652.8927001953125.\n",
      "The relative quantization error of layer 11 is 0.3169277608394623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2027.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1146.977294921875.\n",
      "The relative quantization error of layer 12 is 0.302860826253891.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 744.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1473.236572265625.\n",
      "The relative quantization error of layer 13 is 0.2157411426305771.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1866.3521728515625.\n",
      "The relative quantization error of layer 14 is 0.28728872537612915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1725.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1877.1717529296875.\n",
      "The relative quantization error of layer 15 is 0.26927319169044495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2017.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 486.77264404296875.\n",
      "The relative quantization error of layer 16 is 0.22945235669612885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1099.2901611328125.\n",
      "The relative quantization error of layer 17 is 0.387721985578537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1755.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1724.4119873046875.\n",
      "The relative quantization error of layer 18 is 0.3039551377296448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1955.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 351.0350646972656.\n",
      "The relative quantization error of layer 19 is 0.2565824091434479.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 839.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1176.87158203125.\n",
      "The relative quantization error of layer 20 is 0.3004240393638611.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1751.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1873.8590087890625.\n",
      "The relative quantization error of layer 21 is 0.3281615674495697.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2029.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 409.5154113769531.\n",
      "The relative quantization error of layer 22 is 0.2775651514530182.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 842.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 939.6495361328125.\n",
      "The relative quantization error of layer 23 is 0.39291515946388245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1294.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3187.2333984375.\n",
      "The relative quantization error of layer 24 is 0.3634791970252991.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2013.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 608.5906372070312.\n",
      "The relative quantization error of layer 25 is 0.32869753241539.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1325.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1311.082763671875.\n",
      "The relative quantization error of layer 26 is 0.3657260537147522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 502.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3219.437255859375.\n",
      "The relative quantization error of layer 27 is 0.35927173495292664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1971.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1287.5194091796875.\n",
      "The relative quantization error of layer 28 is 0.3364787995815277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1998.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 248.46038818359375.\n",
      "The relative quantization error of layer 29 is 0.18053896725177765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1327.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 941.6688842773438.\n",
      "The relative quantization error of layer 30 is 0.45185917615890503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1951.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1438.016357421875.\n",
      "The relative quantization error of layer 31 is 0.36448732018470764.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2016.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 284.4527893066406.\n",
      "The relative quantization error of layer 32 is 0.22965894639492035.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1317.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 863.0093383789062.\n",
      "The relative quantization error of layer 33 is 0.4818136990070343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1999.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1636.9705810546875.\n",
      "The relative quantization error of layer 34 is 0.42725658416748047.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2040.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.21249389648438.\n",
      "The relative quantization error of layer 35 is 0.21037961542606354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1331.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1001.465576171875.\n",
      "The relative quantization error of layer 36 is 0.525160551071167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1988.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1748.35546875.\n",
      "The relative quantization error of layer 37 is 0.44396886229515076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2011.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 204.715576171875.\n",
      "The relative quantization error of layer 38 is 0.21493107080459595.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1299.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1337.1553955078125.\n",
      "The relative quantization error of layer 39 is 0.5174323916435242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1999.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1845.6466064453125.\n",
      "The relative quantization error of layer 40 is 0.448269784450531.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1994.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.6555633544922.\n",
      "The relative quantization error of layer 41 is 0.2291780412197113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1431.908447265625.\n",
      "The relative quantization error of layer 42 is 0.552794337272644.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1705.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2539.763916015625.\n",
      "The relative quantization error of layer 43 is 0.46487146615982056.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1988.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.9617919921875.\n",
      "The relative quantization error of layer 44 is 0.20398849248886108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1764.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 960.671875.\n",
      "The relative quantization error of layer 45 is 0.4550272226333618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 871.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2218.2685546875.\n",
      "The relative quantization error of layer 46 is 0.4697711169719696.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2019.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 456.17327880859375.\n",
      "The relative quantization error of layer 47 is 0.41316255927085876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2024.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 106.6520767211914.\n",
      "The relative quantization error of layer 48 is 0.1113283783197403.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1767.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 561.0995483398438.\n",
      "The relative quantization error of layer 49 is 0.701876699924469.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2015.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 474.2021484375.\n",
      "The relative quantization error of layer 50 is 0.2611479163169861.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2033.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 77.46300506591797.\n",
      "The relative quantization error of layer 51 is 0.14322496950626373.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1666.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 133.30072021484375.\n",
      "The relative quantization error of layer 52 is 0.8510524034500122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2023.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.11066436767578.\n",
      "The relative quantization error of layer 53 is 0.27034255862236023.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.031583\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.751.\n",
      "Top-5 accuracy of vgg16 is 0.949.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.519.\n",
      "Top-5 accuracy of quantized vgg16 is 0.935.\n",
      "\n",
      "Time used for evaluation: 0:00:04.196332\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4454\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 640.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 64.67581939697266.\n",
      "The relative quantization error of layer 0 is 0.017370741814374924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 520.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 719.7955932617188.\n",
      "The relative quantization error of layer 1 is 0.04107236862182617.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1838.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 225.73065185546875.\n",
      "The relative quantization error of layer 2 is 0.054565440863370895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 243.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3416.857177734375.\n",
      "The relative quantization error of layer 3 is 0.0969146266579628.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.49it/s]\n",
      " 34%|███▍      | 87/256 [00:00<00:00, 438.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1160.4052734375.\n",
      "The relative quantization error of layer 4 is 0.04021918773651123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 456.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 530.8765258789062.\n",
      "The relative quantization error of layer 5 is 0.19140811264514923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1800.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 234.7142791748047.\n",
      "The relative quantization error of layer 6 is 0.22060048580169678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 927.7468872070312.\n",
      "The relative quantization error of layer 7 is 0.21720652282238007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 794.068115234375.\n",
      "The relative quantization error of layer 8 is 0.2517525255680084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1998.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 527.2279663085938.\n",
      "The relative quantization error of layer 9 is 0.26251181960105896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 238.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1467.2579345703125.\n",
      "The relative quantization error of layer 10 is 0.2319810837507248.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1572.6484375.\n",
      "The relative quantization error of layer 11 is 0.3055149018764496.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1983.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1110.7801513671875.\n",
      "The relative quantization error of layer 12 is 0.29429808259010315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 840.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1402.673828125.\n",
      "The relative quantization error of layer 13 is 0.20611505210399628.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 70.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1768.6998291015625.\n",
      "The relative quantization error of layer 14 is 0.2863197922706604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1740.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1897.0181884765625.\n",
      "The relative quantization error of layer 15 is 0.2747066020965576.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1983.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 489.824951171875.\n",
      "The relative quantization error of layer 16 is 0.23286500573158264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 835.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1084.28564453125.\n",
      "The relative quantization error of layer 17 is 0.37827515602111816.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1732.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1686.28271484375.\n",
      "The relative quantization error of layer 18 is 0.3082960247993469.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1997.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 352.901611328125.\n",
      "The relative quantization error of layer 19 is 0.2613777816295624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 836.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1162.20556640625.\n",
      "The relative quantization error of layer 20 is 0.2950219511985779.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1736.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1903.44921875.\n",
      "The relative quantization error of layer 21 is 0.3410021960735321.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1993.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 423.1571960449219.\n",
      "The relative quantization error of layer 22 is 0.28253474831581116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 840.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 986.863525390625.\n",
      "The relative quantization error of layer 23 is 0.37894725799560547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1284.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3246.894775390625.\n",
      "The relative quantization error of layer 24 is 0.36696046590805054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1977.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 613.7791137695312.\n",
      "The relative quantization error of layer 25 is 0.32450762391090393.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1316.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1326.4189453125.\n",
      "The relative quantization error of layer 26 is 0.35963478684425354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 507.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3168.730712890625.\n",
      "The relative quantization error of layer 27 is 0.3578212857246399.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1961.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1332.3798828125.\n",
      "The relative quantization error of layer 28 is 0.34727275371551514.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1971.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 258.1767883300781.\n",
      "The relative quantization error of layer 29 is 0.18125909566879272.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1316.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 923.0221557617188.\n",
      "The relative quantization error of layer 30 is 0.4521019756793976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1971.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1519.347900390625.\n",
      "The relative quantization error of layer 31 is 0.3738541007041931.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1963.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 287.6408996582031.\n",
      "The relative quantization error of layer 32 is 0.22659145295619965.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 864.9127807617188.\n",
      "The relative quantization error of layer 33 is 0.4759557545185089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1963.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1710.3948974609375.\n",
      "The relative quantization error of layer 34 is 0.42024028301239014.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1990.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 237.38499450683594.\n",
      "The relative quantization error of layer 35 is 0.20067378878593445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1314.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1048.9608154296875.\n",
      "The relative quantization error of layer 36 is 0.523638129234314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1969.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1793.4498291015625.\n",
      "The relative quantization error of layer 37 is 0.447296679019928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1975.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 203.97732543945312.\n",
      "The relative quantization error of layer 38 is 0.20850104093551636.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1395.5504150390625.\n",
      "The relative quantization error of layer 39 is 0.5161690711975098.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1952.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1864.4832763671875.\n",
      "The relative quantization error of layer 40 is 0.45791110396385193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1972.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 179.7965087890625.\n",
      "The relative quantization error of layer 41 is 0.2225954234600067.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1306.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1480.6116943359375.\n",
      "The relative quantization error of layer 42 is 0.5548332333564758.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1781.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2596.17529296875.\n",
      "The relative quantization error of layer 43 is 0.46948134899139404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1975.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 161.5352325439453.\n",
      "The relative quantization error of layer 44 is 0.20299769937992096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1758.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 986.4878540039062.\n",
      "The relative quantization error of layer 45 is 0.4522280693054199.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 869.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2257.863037109375.\n",
      "The relative quantization error of layer 46 is 0.4797823131084442.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1994.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 477.080078125.\n",
      "The relative quantization error of layer 47 is 0.42221546173095703.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2000.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 110.22283935546875.\n",
      "The relative quantization error of layer 48 is 0.11321009695529938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1752.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 565.8367919921875.\n",
      "The relative quantization error of layer 49 is 0.6917344927787781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1986.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 463.96978759765625.\n",
      "The relative quantization error of layer 50 is 0.3076697289943695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 2005.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 55.27843475341797.\n",
      "The relative quantization error of layer 51 is 0.12294688820838928.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1773.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 122.7896499633789.\n",
      "The relative quantization error of layer 52 is 0.816017746925354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1990.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.45389175415039.\n",
      "The relative quantization error of layer 53 is 0.25764334201812744.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.222790\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.50it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.781.\n",
      "Top-5 accuracy of vgg16 is 0.945.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.526.\n",
      "Top-5 accuracy of quantized vgg16 is 0.889.\n",
      "\n",
      "Time used for evaluation: 0:00:04.098555\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4468\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 633.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.96643829345703.\n",
      "The relative quantization error of layer 0 is 0.018403280526399612.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 556.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 787.1782836914062.\n",
      "The relative quantization error of layer 1 is 0.04454384371638298.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1932.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 230.09092712402344.\n",
      "The relative quantization error of layer 2 is 0.05716020241379738.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 204.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3633.06591796875.\n",
      "The relative quantization error of layer 3 is 0.10346850007772446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1273.067626953125.\n",
      "The relative quantization error of layer 4 is 0.04399358108639717.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 455.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 536.2161865234375.\n",
      "The relative quantization error of layer 5 is 0.1927625685930252.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1824.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 259.0867004394531.\n",
      "The relative quantization error of layer 6 is 0.23437529802322388.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 248.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1095.251708984375.\n",
      "The relative quantization error of layer 7 is 0.23969370126724243.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 846.467529296875.\n",
      "The relative quantization error of layer 8 is 0.2564100921154022.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1959.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 542.512451171875.\n",
      "The relative quantization error of layer 9 is 0.2657734155654907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 248.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1589.674072265625.\n",
      "The relative quantization error of layer 10 is 0.2385234832763672.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1677.03173828125.\n",
      "The relative quantization error of layer 11 is 0.31126800179481506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1938.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1166.4908447265625.\n",
      "The relative quantization error of layer 12 is 0.30476492643356323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1432.0697021484375.\n",
      "The relative quantization error of layer 13 is 0.20972837507724762.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1827.18603515625.\n",
      "The relative quantization error of layer 14 is 0.2929741144180298.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1702.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1880.941162109375.\n",
      "The relative quantization error of layer 15 is 0.2664555311203003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1947.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 475.6022033691406.\n",
      "The relative quantization error of layer 16 is 0.22373197972774506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 685.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1104.0986328125.\n",
      "The relative quantization error of layer 17 is 0.37750011682510376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1718.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1726.9200439453125.\n",
      "The relative quantization error of layer 18 is 0.3052532374858856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1950.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 361.8216552734375.\n",
      "The relative quantization error of layer 19 is 0.2657945156097412.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1173.3465576171875.\n",
      "The relative quantization error of layer 20 is 0.2978406250476837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1738.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1904.918701171875.\n",
      "The relative quantization error of layer 21 is 0.3299771547317505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1982.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 453.42529296875.\n",
      "The relative quantization error of layer 22 is 0.28842777013778687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 832.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 934.4102783203125.\n",
      "The relative quantization error of layer 23 is 0.3935394287109375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1275.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3179.473388671875.\n",
      "The relative quantization error of layer 24 is 0.35620638728141785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1951.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 601.7963256835938.\n",
      "The relative quantization error of layer 25 is 0.3211471736431122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1315.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1356.3001708984375.\n",
      "The relative quantization error of layer 26 is 0.36857759952545166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 506.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3270.9677734375.\n",
      "The relative quantization error of layer 27 is 0.353855162858963.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1935.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1325.81201171875.\n",
      "The relative quantization error of layer 28 is 0.3431956470012665.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1961.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 261.95599365234375.\n",
      "The relative quantization error of layer 29 is 0.18161647021770477.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1316.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 981.6405639648438.\n",
      "The relative quantization error of layer 30 is 0.4643586277961731.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1912.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1493.00390625.\n",
      "The relative quantization error of layer 31 is 0.36625081300735474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1973.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.6305236816406.\n",
      "The relative quantization error of layer 32 is 0.22780980169773102.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1279.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 860.5110473632812.\n",
      "The relative quantization error of layer 33 is 0.4755275249481201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1940.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1662.5916748046875.\n",
      "The relative quantization error of layer 34 is 0.41098469495773315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1971.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 240.7477264404297.\n",
      "The relative quantization error of layer 35 is 0.20431247353553772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1044.75244140625.\n",
      "The relative quantization error of layer 36 is 0.5266582369804382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1944.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1769.34716796875.\n",
      "The relative quantization error of layer 37 is 0.4309413731098175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1971.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.17616271972656.\n",
      "The relative quantization error of layer 38 is 0.20984609425067902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1272.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1365.4783935546875.\n",
      "The relative quantization error of layer 39 is 0.5173512101173401.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1962.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1846.054931640625.\n",
      "The relative quantization error of layer 40 is 0.45909383893013.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1951.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 183.22642517089844.\n",
      "The relative quantization error of layer 41 is 0.2293165922164917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1297.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1470.6829833984375.\n",
      "The relative quantization error of layer 42 is 0.5573193430900574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1767.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2599.749267578125.\n",
      "The relative quantization error of layer 43 is 0.4748591184616089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1952.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.59512329101562.\n",
      "The relative quantization error of layer 44 is 0.20482060313224792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1681.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 973.3701171875.\n",
      "The relative quantization error of layer 45 is 0.45933204889297485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 863.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2269.13916015625.\n",
      "The relative quantization error of layer 46 is 0.47816482186317444.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1963.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 449.7923889160156.\n",
      "The relative quantization error of layer 47 is 0.41027969121932983.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1965.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.93492126464844.\n",
      "The relative quantization error of layer 48 is 0.1089056134223938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1735.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 551.7135009765625.\n",
      "The relative quantization error of layer 49 is 0.6939421892166138.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1961.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 486.93011474609375.\n",
      "The relative quantization error of layer 50 is 0.26994675397872925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1979.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 97.02747344970703.\n",
      "The relative quantization error of layer 51 is 0.17630624771118164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1774.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 134.63414001464844.\n",
      "The relative quantization error of layer 52 is 0.865818202495575.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1969.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 53.40614318847656.\n",
      "The relative quantization error of layer 53 is 0.30668893456459045.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.522868\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.746.\n",
      "Top-5 accuracy of vgg16 is 0.939.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.521.\n",
      "Top-5 accuracy of quantized vgg16 is 0.883.\n",
      "\n",
      "Time used for evaluation: 0:00:04.102290\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4446\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 622.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 76.66448211669922.\n",
      "The relative quantization error of layer 0 is 0.018149496987462044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 769.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 845.1869506835938.\n",
      "The relative quantization error of layer 1 is 0.047460347414016724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1949.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 221.84262084960938.\n",
      "The relative quantization error of layer 2 is 0.05209638178348541.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3324.991455078125.\n",
      "The relative quantization error of layer 3 is 0.09913808852434158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 218.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1307.8795166015625.\n",
      "The relative quantization error of layer 4 is 0.044588353484869.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 456.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 576.480712890625.\n",
      "The relative quantization error of layer 5 is 0.19698229432106018.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1853.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 263.14996337890625.\n",
      "The relative quantization error of layer 6 is 0.23308435082435608.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 229.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1013.75634765625.\n",
      "The relative quantization error of layer 7 is 0.21990984678268433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 890.291015625.\n",
      "The relative quantization error of layer 8 is 0.25757598876953125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1903.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 581.7227783203125.\n",
      "The relative quantization error of layer 9 is 0.272763729095459.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1523.406494140625.\n",
      "The relative quantization error of layer 10 is 0.23302219808101654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1675.659912109375.\n",
      "The relative quantization error of layer 11 is 0.30747511982917786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1948.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1216.086669921875.\n",
      "The relative quantization error of layer 12 is 0.2976924479007721.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 833.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1493.203125.\n",
      "The relative quantization error of layer 13 is 0.21269682049751282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1845.2755126953125.\n",
      "The relative quantization error of layer 14 is 0.2885972261428833.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1706.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1983.9654541015625.\n",
      "The relative quantization error of layer 15 is 0.2745804488658905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1964.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 504.52716064453125.\n",
      "The relative quantization error of layer 16 is 0.23828765749931335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 835.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1102.1605224609375.\n",
      "The relative quantization error of layer 17 is 0.37760302424430847.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1717.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1718.3291015625.\n",
      "The relative quantization error of layer 18 is 0.2953670024871826.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1925.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.3721618652344.\n",
      "The relative quantization error of layer 19 is 0.25828585028648376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1205.711181640625.\n",
      "The relative quantization error of layer 20 is 0.296785444021225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1712.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1912.584228515625.\n",
      "The relative quantization error of layer 21 is 0.3202713429927826.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1916.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 435.3512878417969.\n",
      "The relative quantization error of layer 22 is 0.2769078016281128.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 835.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 970.8140869140625.\n",
      "The relative quantization error of layer 23 is 0.38182294368743896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1260.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3253.841064453125.\n",
      "The relative quantization error of layer 24 is 0.3612513542175293.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1947.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 621.632080078125.\n",
      "The relative quantization error of layer 25 is 0.31650450825691223.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1306.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1331.10888671875.\n",
      "The relative quantization error of layer 26 is 0.3607417643070221.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 503.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3378.84033203125.\n",
      "The relative quantization error of layer 27 is 0.35071510076522827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1914.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1335.4267578125.\n",
      "The relative quantization error of layer 28 is 0.3358500897884369.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1923.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 256.224609375.\n",
      "The relative quantization error of layer 29 is 0.17498119175434113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1301.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 955.0162353515625.\n",
      "The relative quantization error of layer 30 is 0.43575379252433777.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1905.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1513.735595703125.\n",
      "The relative quantization error of layer 31 is 0.3676917552947998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1938.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 297.4243469238281.\n",
      "The relative quantization error of layer 32 is 0.22215138375759125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1306.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 918.0179443359375.\n",
      "The relative quantization error of layer 33 is 0.4970512092113495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1924.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1656.4896240234375.\n",
      "The relative quantization error of layer 34 is 0.41698020696640015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1949.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 239.14100646972656.\n",
      "The relative quantization error of layer 35 is 0.1998024433851242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1312.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1008.6680908203125.\n",
      "The relative quantization error of layer 36 is 0.5260554552078247.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1897.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1796.8546142578125.\n",
      "The relative quantization error of layer 37 is 0.43447649478912354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1955.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.44622802734375.\n",
      "The relative quantization error of layer 38 is 0.206120103597641.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1293.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1330.35888671875.\n",
      "The relative quantization error of layer 39 is 0.510283350944519.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1915.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1822.0728759765625.\n",
      "The relative quantization error of layer 40 is 0.43140149116516113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1946.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 172.44326782226562.\n",
      "The relative quantization error of layer 41 is 0.22035473585128784.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1307.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1406.841552734375.\n",
      "The relative quantization error of layer 42 is 0.5325993299484253.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1756.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2544.243896484375.\n",
      "The relative quantization error of layer 43 is 0.457905650138855.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1932.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.39537048339844.\n",
      "The relative quantization error of layer 44 is 0.2015066146850586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1689.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 937.631591796875.\n",
      "The relative quantization error of layer 45 is 0.4212638735771179.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 860.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2195.003662109375.\n",
      "The relative quantization error of layer 46 is 0.462353378534317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1933.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 429.5637512207031.\n",
      "The relative quantization error of layer 47 is 0.3767241835594177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1947.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 105.09967803955078.\n",
      "The relative quantization error of layer 48 is 0.10001372545957565.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1724.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 522.419677734375.\n",
      "The relative quantization error of layer 49 is 0.6503921747207642.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1919.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 484.0591125488281.\n",
      "The relative quantization error of layer 50 is 0.24530205130577087.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1967.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 74.6365966796875.\n",
      "The relative quantization error of layer 51 is 0.11659418791532516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1766.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 117.99713897705078.\n",
      "The relative quantization error of layer 52 is 0.8218681812286377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1948.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 32.722442626953125.\n",
      "The relative quantization error of layer 53 is 0.18990765511989594.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:01.536378\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.68it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.88.\n",
      "Top-5 accuracy of vgg16 is 0.978.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.792.\n",
      "Top-5 accuracy of quantized vgg16 is 0.975.\n",
      "\n",
      "Time used for evaluation: 0:00:04.104592\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4568\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 647.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 90.23900604248047.\n",
      "The relative quantization error of layer 0 is 0.01948956958949566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 765.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 962.469482421875.\n",
      "The relative quantization error of layer 1 is 0.05383836477994919.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1815.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 269.3935546875.\n",
      "The relative quantization error of layer 2 is 0.0604395754635334.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3587.426025390625.\n",
      "The relative quantization error of layer 3 is 0.10268556326627731.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1687.0849609375.\n",
      "The relative quantization error of layer 4 is 0.05731017142534256.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 457.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 666.141357421875.\n",
      "The relative quantization error of layer 5 is 0.21859833598136902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1972.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 278.33087158203125.\n",
      "The relative quantization error of layer 6 is 0.23496781289577484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1063.454345703125.\n",
      "The relative quantization error of layer 7 is 0.2377205193042755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 930.574462890625.\n",
      "The relative quantization error of layer 8 is 0.2687254846096039.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1937.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 602.7793579101562.\n",
      "The relative quantization error of layer 9 is 0.2816964089870453.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 248.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1649.408447265625.\n",
      "The relative quantization error of layer 10 is 0.24001280963420868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 261.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1793.7205810546875.\n",
      "The relative quantization error of layer 11 is 0.3118869960308075.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1976.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1249.31005859375.\n",
      "The relative quantization error of layer 12 is 0.30696290731430054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1575.3380126953125.\n",
      "The relative quantization error of layer 13 is 0.22497081756591797.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 71.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2246.036865234375.\n",
      "The relative quantization error of layer 14 is 0.29365819692611694.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1607.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2241.84716796875.\n",
      "The relative quantization error of layer 15 is 0.24467334151268005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1982.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 597.0010375976562.\n",
      "The relative quantization error of layer 16 is 0.24128344655036926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 840.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1337.364990234375.\n",
      "The relative quantization error of layer 17 is 0.39884909987449646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1720.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1893.9197998046875.\n",
      "The relative quantization error of layer 18 is 0.31669706106185913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1972.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 394.1226501464844.\n",
      "The relative quantization error of layer 19 is 0.2719469964504242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 839.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1285.817626953125.\n",
      "The relative quantization error of layer 20 is 0.3121851980686188.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1638.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2093.21826171875.\n",
      "The relative quantization error of layer 21 is 0.35145166516304016.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1981.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 472.32635498046875.\n",
      "The relative quantization error of layer 22 is 0.28509026765823364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1046.48876953125.\n",
      "The relative quantization error of layer 23 is 0.38239407539367676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1276.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3543.719970703125.\n",
      "The relative quantization error of layer 24 is 0.383358895778656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1975.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 658.5062866210938.\n",
      "The relative quantization error of layer 25 is 0.32270392775535583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1307.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1388.197021484375.\n",
      "The relative quantization error of layer 26 is 0.3771542012691498.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 499.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3599.556884765625.\n",
      "The relative quantization error of layer 27 is 0.3686518371105194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1979.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1370.2625732421875.\n",
      "The relative quantization error of layer 28 is 0.33285146951675415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1967.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 273.8836669921875.\n",
      "The relative quantization error of layer 29 is 0.180731862783432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1313.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1010.0930786132812.\n",
      "The relative quantization error of layer 30 is 0.4524184465408325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1976.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1565.7076416015625.\n",
      "The relative quantization error of layer 31 is 0.3665226399898529.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1991.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 296.91876220703125.\n",
      "The relative quantization error of layer 32 is 0.22070090472698212.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1302.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 909.4168090820312.\n",
      "The relative quantization error of layer 33 is 0.47935307025909424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1958.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1723.682373046875.\n",
      "The relative quantization error of layer 34 is 0.42664867639541626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1991.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.09588623046875.\n",
      "The relative quantization error of layer 35 is 0.19552652537822723.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1310.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1085.9066162109375.\n",
      "The relative quantization error of layer 36 is 0.5149186849594116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1968.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1832.2567138671875.\n",
      "The relative quantization error of layer 37 is 0.4178362786769867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 2005.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 204.2668914794922.\n",
      "The relative quantization error of layer 38 is 0.20377159118652344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1306.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1411.897216796875.\n",
      "The relative quantization error of layer 39 is 0.5184797048568726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1967.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1912.216552734375.\n",
      "The relative quantization error of layer 40 is 0.45372962951660156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1977.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.27647399902344.\n",
      "The relative quantization error of layer 41 is 0.21935513615608215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1292.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1405.319091796875.\n",
      "The relative quantization error of layer 42 is 0.5304442048072815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1773.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2625.495361328125.\n",
      "The relative quantization error of layer 43 is 0.47192883491516113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1966.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.0549774169922.\n",
      "The relative quantization error of layer 44 is 0.1910204440355301.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1686.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 906.2036743164062.\n",
      "The relative quantization error of layer 45 is 0.4180345833301544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 864.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2298.378662109375.\n",
      "The relative quantization error of layer 46 is 0.476456880569458.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1970.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 424.8740539550781.\n",
      "The relative quantization error of layer 47 is 0.4138515591621399.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1987.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 119.39356994628906.\n",
      "The relative quantization error of layer 48 is 0.11120021343231201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1758.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 560.44921875.\n",
      "The relative quantization error of layer 49 is 0.6791762113571167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1968.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 486.5344543457031.\n",
      "The relative quantization error of layer 50 is 0.3311653137207031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1998.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 49.382240295410156.\n",
      "The relative quantization error of layer 51 is 0.1326022893190384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1795.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 118.71326446533203.\n",
      "The relative quantization error of layer 52 is 0.8080637454986572.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 2005.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 35.825035095214844.\n",
      "The relative quantization error of layer 53 is 0.2120797485113144.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.114483\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.884.\n",
      "Top-5 accuracy of vgg16 is 0.981.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.779.\n",
      "Top-5 accuracy of quantized vgg16 is 0.981.\n",
      "\n",
      "Time used for evaluation: 0:00:04.093403\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4489\n"
     ]
    }
   ],
   "source": [
    "sc_options = ['True'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'vgg16' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 66, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.798484</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 27, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.150249</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.904</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'snail', 'lobster', 'spid...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.945</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 34, 66, 36, 42, 74, 80, 50, 88]</td>\n",
       "      <td>['possum', 'rabbit', 'fox', 'raccoon', 'hamste...</td>\n",
       "      <td>3.282271</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>1.016768</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.935</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[33, 67, 4, 72, 73, 55, 27, 93, 30, 95]</td>\n",
       "      <td>['forest', 'ray', 'beaver', 'seal', 'shark', '...</td>\n",
       "      <td>6.930972</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.742421</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 4, 38, 74, 15, 80, 50, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'beaver', 'kan...</td>\n",
       "      <td>1.423381</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.528430</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.883</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 69, 12, 76, 13, 81, 17, 85, 89, 90]</td>\n",
       "      <td>['house', 'rocket', 'bridge', 'skyscraper', 'b...</td>\n",
       "      <td>7.993174</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.750203</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 70, 6, 83, 53, 54, 57, 92, 62]</td>\n",
       "      <td>['apple', 'aquarium_fish', 'rose', 'bee', 'swe...</td>\n",
       "      <td>12.526491</td>\n",
       "      <td>0.203903</td>\n",
       "      <td>3.729304</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.861   \n",
       "2       vgg16  CIFAR100                       64                   0.884   \n",
       "3       vgg16  CIFAR100                       64                   0.879   \n",
       "4       vgg16  CIFAR100                       64                   0.872   \n",
       "5       vgg16  CIFAR100                       64                   0.879   \n",
       "6       vgg16  CIFAR100                       64                   0.873   \n",
       "7       vgg16  CIFAR100                       64                   0.815   \n",
       "8       vgg16  CIFAR100                       64                   0.808   \n",
       "9       vgg16  CIFAR100                       64                   0.751   \n",
       "10      vgg16  CIFAR100                       64                   0.781   \n",
       "11      vgg16  CIFAR100                       64                   0.746   \n",
       "12      vgg16  CIFAR100                       64                   0.880   \n",
       "13      vgg16  CIFAR100                       64                   0.884   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.935                   0.989                    0.991   \n",
       "1                     0.902                   0.987                    0.989   \n",
       "2                     0.960                   0.991                    0.996   \n",
       "3                     0.953                   0.987                    0.994   \n",
       "4                     0.952                   0.986                    0.994   \n",
       "5                     0.948                   0.986                    0.988   \n",
       "6                     0.945                   0.983                    0.992   \n",
       "7                     0.607                   0.949                    0.904   \n",
       "8                     0.661                   0.958                    0.945   \n",
       "9                     0.519                   0.949                    0.935   \n",
       "10                    0.526                   0.945                    0.889   \n",
       "11                    0.521                   0.939                    0.883   \n",
       "12                    0.792                   0.978                    0.975   \n",
       "13                    0.779                   0.981                    0.981   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2    [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3    [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4     [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "5    [0, 66, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "6    [0, 39, 49, 52, 53, 20, 62, 58, 27, 94]   \n",
       "7    [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "8   [64, 65, 34, 66, 36, 42, 74, 80, 50, 88]   \n",
       "9    [33, 67, 4, 72, 73, 55, 27, 93, 30, 95]   \n",
       "10   [64, 65, 66, 4, 38, 74, 15, 80, 50, 63]   \n",
       "11   [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "12  [37, 69, 12, 76, 13, 81, 17, 85, 89, 90]   \n",
       "13     [0, 1, 70, 6, 83, 53, 54, 57, 92, 62]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4   ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "5   ['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...  192.253176  0.844140   \n",
       "6   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "7   ['beetle', 'lizard', 'snail', 'lobster', 'spid...    0.969446  0.091850   \n",
       "8   ['possum', 'rabbit', 'fox', 'raccoon', 'hamste...    3.282271  0.111503   \n",
       "9   ['forest', 'ray', 'beaver', 'seal', 'shark', '...    6.930972  0.074397   \n",
       "10  ['possum', 'rabbit', 'raccoon', 'beaver', 'kan...    1.423381  0.111503   \n",
       "11  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "12  ['house', 'rocket', 'bridge', 'skyscraper', 'b...    7.993174  0.151836   \n",
       "13  ['apple', 'aquarium_fish', 'rose', 'bee', 'swe...   12.526491  0.203903   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                    NaN                    NaN   \n",
       "1   69.604010             False                    NaN                    NaN   \n",
       "2   73.300755             False                    NaN                    NaN   \n",
       "3   68.423650             False                    NaN                    NaN   \n",
       "4   68.367547             False                    NaN                    NaN   \n",
       "5   67.798484             False                    NaN                    NaN   \n",
       "6   68.150249             False                    NaN                    NaN   \n",
       "7    0.369210             False                    NaN                    NaN   \n",
       "8    1.016768             False                    NaN                    NaN   \n",
       "9    1.742421             False                    NaN                    NaN   \n",
       "10   0.528430             False                    NaN                    NaN   \n",
       "11   0.949666             False                    NaN                    NaN   \n",
       "12   1.750203             False                    NaN                    NaN   \n",
       "13   3.729304             False                    NaN                    NaN   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df = df[df[\"Classes Repeated\"] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03bc03e-1a1c-43ae-bc01-15060dca5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.957 0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.902 0.991]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.869 0.984]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.845 0.988]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.843 0.973]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.819 0.985]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.897 0.987]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.916 0.996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "# from data_loaders import data_loader\n",
    "# from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 64\n",
    "\n",
    "# topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "\n",
    "#     model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "#     model.to(device)  \n",
    "#     train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset = subset)\n",
    "\n",
    "# # ===========\n",
    "# #  CODE HERE\n",
    "# # ===========\n",
    "\n",
    "#     model.eval() \n",
    "#     original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "#     # maxk = max(topk)\n",
    "#     # topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "#     # correct_mat = []\n",
    "#     # for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     #     with torch.no_grad():\n",
    "#     #         y_pred = model(x_test.to(device))\n",
    "#     #     topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "#     #     target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "#     #     correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# # break    \n",
    "# # acc_items += [original_topk_accuracy]\n",
    "\n",
    "# # df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# # df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# # df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# # print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n",
    "\n",
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 5  # Set the number of fine-tuning epochs\n",
    "learning_rate = 1e-4  # Fine-tuning learning rate\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = [stage.item() if hasattr(stage, \"item\") else stage for stage in subset_stage]\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "    model.to(device)  \n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset=subset)\n",
    "\n",
    "    # Define optimizer & loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate after fine-tuning\n",
    "    model.eval()\n",
    "    original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "    print(f\"Top-1 and Top-5 Accuracy after fine-tuning: {original_topk_accuracy}\")\n",
    "\n",
    "    acc_items += [original_topk_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564bcc8-8a12-4965-9e9c-79909c3b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the printed output as input for raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c97c08-e8f2-4e8a-ba26-12b49693d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [1/5] - Loss: 0.1076\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0191\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0156\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0180\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0202\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.15it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1116\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0274\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0235\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0347\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0179\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.23it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.957 0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1063\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0147\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0112\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0089\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0132\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.29it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.0981\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0121\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0129\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0192\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0101\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.28it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.1196\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0227\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0120\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0148\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0160\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.33it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.0972\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0133\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0118\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0197\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0103\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.21it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1113\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0152\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0115\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0150\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0179\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.17it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [1/5] - Loss: 0.1710\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0216\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0221\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0222\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0128\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.24it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.902 0.991]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.2452\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0249\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0149\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0112\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0149\n",
    "100%|██████████| 16/16 [00:02<00:00,  5.96it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.869 0.984]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [1/5] - Loss: 0.2362\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0379\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0271\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0226\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0226\n",
    "100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.845 0.988]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [1/5] - Loss: 0.2375\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0243\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0213\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.75it/s]\n",
    "Epoch [4/5] - Loss: 0.0197\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0175\n",
    "100%|██████████| 16/16 [00:02<00:00,  5.97it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.843 0.973]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [1/5] - Loss: 0.1884\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [2/5] - Loss: 0.0267\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0150\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.74it/s]\n",
    "Epoch [4/5] - Loss: 0.0238\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0154\n",
    "100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.819 0.985]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.3091\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0341\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0205\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0143\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0215\n",
    "100%|██████████| 16/16 [00:02<00:00,  5.91it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.897 0.987]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [1/5] - Loss: 0.3486\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0595\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0341\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0275\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0113\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.32it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.916 0.996]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1726c059-fe07-4ee0-9236-bb67aba13d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# extracted = re.findall(r\"\\[[01]{1}.[0-9 ]{3} [01]{1}.[0-9 ]{3}\\]\", raw_text)\n",
    "extracted = re.findall(r\"Top-1 and Top-5 Accuracy after fine-tuning:\\s*(\\[[^\\]]+\\])\", raw_text)\n",
    "# data = list(map(lambda x: [float(x[1:6]), float(x[7:12])], extracted))\n",
    "data = [list(map(float, s.strip(\"[]\").split())) for s in extracted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "370887c8-4003-449d-93ff-700942aa2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[0.98  0.998]',\n",
       "  '[0.957 0.998]',\n",
       "  '[0.981 0.999]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.981 1.   ]',\n",
       "  '[0.983 1.   ]',\n",
       "  '[0.98  0.999]',\n",
       "  '[0.902 0.991]',\n",
       "  '[0.869 0.984]',\n",
       "  '[0.845 0.988]',\n",
       "  '[0.843 0.973]',\n",
       "  '[0.819 0.985]',\n",
       "  '[0.897 0.987]',\n",
       "  '[0.916 0.996]'],\n",
       " 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1879a6f-3f42-4c8f-bef8-b7a537282650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Trained Top1 Accuracy\", \"Trained Top5 Accuracy\"]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20aacbe-ec3d-4a21-a92d-82bb75e69a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 66, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.798484</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 27, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.150249</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.904</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'snail', 'lobster', 'spid...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.945</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 34, 66, 36, 42, 74, 80, 50, 88]</td>\n",
       "      <td>['possum', 'rabbit', 'fox', 'raccoon', 'hamste...</td>\n",
       "      <td>3.282271</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>1.016768</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.935</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[33, 67, 4, 72, 73, 55, 27, 93, 30, 95]</td>\n",
       "      <td>['forest', 'ray', 'beaver', 'seal', 'shark', '...</td>\n",
       "      <td>6.930972</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.742421</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 4, 38, 74, 15, 80, 50, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'beaver', 'kan...</td>\n",
       "      <td>1.423381</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.528430</td>\n",
       "      <td>False</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.883</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 69, 12, 76, 13, 81, 17, 85, 89, 90]</td>\n",
       "      <td>['house', 'rocket', 'bridge', 'skyscraper', 'b...</td>\n",
       "      <td>7.993174</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.750203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 70, 6, 83, 53, 54, 57, 92, 62]</td>\n",
       "      <td>['apple', 'aquarium_fish', 'rose', 'bee', 'swe...</td>\n",
       "      <td>12.526491</td>\n",
       "      <td>0.203903</td>\n",
       "      <td>3.729304</td>\n",
       "      <td>False</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.861   \n",
       "2       vgg16  CIFAR100                       64                   0.884   \n",
       "3       vgg16  CIFAR100                       64                   0.879   \n",
       "4       vgg16  CIFAR100                       64                   0.872   \n",
       "5       vgg16  CIFAR100                       64                   0.879   \n",
       "6       vgg16  CIFAR100                       64                   0.873   \n",
       "7       vgg16  CIFAR100                       64                   0.815   \n",
       "8       vgg16  CIFAR100                       64                   0.808   \n",
       "9       vgg16  CIFAR100                       64                   0.751   \n",
       "10      vgg16  CIFAR100                       64                   0.781   \n",
       "11      vgg16  CIFAR100                       64                   0.746   \n",
       "12      vgg16  CIFAR100                       64                   0.880   \n",
       "13      vgg16  CIFAR100                       64                   0.884   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.935                   0.989                    0.991   \n",
       "1                     0.902                   0.987                    0.989   \n",
       "2                     0.960                   0.991                    0.996   \n",
       "3                     0.953                   0.987                    0.994   \n",
       "4                     0.952                   0.986                    0.994   \n",
       "5                     0.948                   0.986                    0.988   \n",
       "6                     0.945                   0.983                    0.992   \n",
       "7                     0.607                   0.949                    0.904   \n",
       "8                     0.661                   0.958                    0.945   \n",
       "9                     0.519                   0.949                    0.935   \n",
       "10                    0.526                   0.945                    0.889   \n",
       "11                    0.521                   0.939                    0.883   \n",
       "12                    0.792                   0.978                    0.975   \n",
       "13                    0.779                   0.981                    0.981   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2    [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3    [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4     [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "5    [0, 66, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "6    [0, 39, 49, 52, 53, 20, 62, 58, 27, 94]   \n",
       "7    [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "8   [64, 65, 34, 66, 36, 42, 74, 80, 50, 88]   \n",
       "9    [33, 67, 4, 72, 73, 55, 27, 93, 30, 95]   \n",
       "10   [64, 65, 66, 4, 38, 74, 15, 80, 50, 63]   \n",
       "11   [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "12  [37, 69, 12, 76, 13, 81, 17, 85, 89, 90]   \n",
       "13     [0, 1, 70, 6, 83, 53, 54, 57, 92, 62]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4   ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "5   ['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...  192.253176  0.844140   \n",
       "6   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "7   ['beetle', 'lizard', 'snail', 'lobster', 'spid...    0.969446  0.091850   \n",
       "8   ['possum', 'rabbit', 'fox', 'raccoon', 'hamste...    3.282271  0.111503   \n",
       "9   ['forest', 'ray', 'beaver', 'seal', 'shark', '...    6.930972  0.074397   \n",
       "10  ['possum', 'rabbit', 'raccoon', 'beaver', 'kan...    1.423381  0.111503   \n",
       "11  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "12  ['house', 'rocket', 'bridge', 'skyscraper', 'b...    7.993174  0.151836   \n",
       "13  ['apple', 'aquarium_fish', 'rose', 'bee', 'swe...   12.526491  0.203903   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.980                  0.998   \n",
       "1   69.604010             False                  0.957                  0.998   \n",
       "2   73.300755             False                  0.981                  0.999   \n",
       "3   68.423650             False                  0.979                  1.000   \n",
       "4   68.367547             False                  0.981                  1.000   \n",
       "5   67.798484             False                  0.983                  1.000   \n",
       "6   68.150249             False                  0.980                  0.999   \n",
       "7    0.369210             False                  0.902                  0.991   \n",
       "8    1.016768             False                  0.869                  0.984   \n",
       "9    1.742421             False                  0.845                  0.988   \n",
       "10   0.528430             False                  0.843                  0.973   \n",
       "11   0.949666             False                  0.819                  0.985   \n",
       "12   1.750203             False                  0.897                  0.987   \n",
       "13   3.729304             False                  0.916                  0.996   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes = []\n",
    "# for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "#     topk_count = []\n",
    "#     filtered = correct_mat[np.isin(classes, subset)]\n",
    "#     for i, k in enumerate(topk):\n",
    "#         topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "#     return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "    \n",
    "#     acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "# acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import dist_matrix\n",
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "\n",
    "# G = nx.from_numpy_array(dist_matrix)\n",
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2b9e10-57f2-462e-8f96-5df897ffd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import community \n",
    "# partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae727e7e-c5e5-4627-bb52-ca17fdbd41c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dfe0db6-01b1-4965-a589-ce94866dd132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import class_names\n",
    "\n",
    "# grps = {}\n",
    "\n",
    "# for k,v in partition.items():\n",
    "#     if v not in grps:\n",
    "#         grps[v] = []\n",
    "#     grps[v] += [class_names[k].item()]\n",
    "\n",
    "# grps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e2b417d-386d-4233-80bd-e097adec7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100_subset_generation import dist_matrix, class_names\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "KL_data_all = []\n",
    "# new_col = []\n",
    "median = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    # print(list(map(lambda x: class_names[x].item(), subset))))\n",
    "\n",
    "    # new_col += [len(subset) != len(set(subset))]\n",
    "    \n",
    "    KL_data = []\n",
    "    for j in combinations(set(subset), 2):\n",
    "        KL_data += [dist_matrix[j[0], j[1]].item()]\n",
    "\n",
    "    KL_data_all += [KL_data]\n",
    "\n",
    "    median += [np.median(KL_data).item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a011a4a-a284-4b40-b242-a757a73bfc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>55.650079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 66, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.798484</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>48.535313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 27, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.150249</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.999</td>\n",
       "      <td>65.348257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.904</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'snail', 'lobster', 'spid...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.309007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.945</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 34, 66, 36, 42, 74, 80, 50, 88]</td>\n",
       "      <td>['possum', 'rabbit', 'fox', 'raccoon', 'hamste...</td>\n",
       "      <td>3.282271</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>1.016768</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.604708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.935</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[33, 67, 4, 72, 73, 55, 27, 93, 30, 95]</td>\n",
       "      <td>['forest', 'ray', 'beaver', 'seal', 'shark', '...</td>\n",
       "      <td>6.930972</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.742421</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.352544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 4, 38, 74, 15, 80, 50, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'beaver', 'kan...</td>\n",
       "      <td>1.423381</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.528430</td>\n",
       "      <td>False</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.415386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.883</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.782209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 69, 12, 76, 13, 81, 17, 85, 89, 90]</td>\n",
       "      <td>['house', 'rocket', 'bridge', 'skyscraper', 'b...</td>\n",
       "      <td>7.993174</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.750203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.361525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 70, 6, 83, 53, 54, 57, 92, 62]</td>\n",
       "      <td>['apple', 'aquarium_fish', 'rose', 'bee', 'swe...</td>\n",
       "      <td>12.526491</td>\n",
       "      <td>0.203903</td>\n",
       "      <td>3.729304</td>\n",
       "      <td>False</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.996</td>\n",
       "      <td>2.366408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.861   \n",
       "2       vgg16  CIFAR100                       64                   0.884   \n",
       "3       vgg16  CIFAR100                       64                   0.879   \n",
       "4       vgg16  CIFAR100                       64                   0.872   \n",
       "5       vgg16  CIFAR100                       64                   0.879   \n",
       "6       vgg16  CIFAR100                       64                   0.873   \n",
       "7       vgg16  CIFAR100                       64                   0.815   \n",
       "8       vgg16  CIFAR100                       64                   0.808   \n",
       "9       vgg16  CIFAR100                       64                   0.751   \n",
       "10      vgg16  CIFAR100                       64                   0.781   \n",
       "11      vgg16  CIFAR100                       64                   0.746   \n",
       "12      vgg16  CIFAR100                       64                   0.880   \n",
       "13      vgg16  CIFAR100                       64                   0.884   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.935                   0.989                    0.991   \n",
       "1                     0.902                   0.987                    0.989   \n",
       "2                     0.960                   0.991                    0.996   \n",
       "3                     0.953                   0.987                    0.994   \n",
       "4                     0.952                   0.986                    0.994   \n",
       "5                     0.948                   0.986                    0.988   \n",
       "6                     0.945                   0.983                    0.992   \n",
       "7                     0.607                   0.949                    0.904   \n",
       "8                     0.661                   0.958                    0.945   \n",
       "9                     0.519                   0.949                    0.935   \n",
       "10                    0.526                   0.945                    0.889   \n",
       "11                    0.521                   0.939                    0.883   \n",
       "12                    0.792                   0.978                    0.975   \n",
       "13                    0.779                   0.981                    0.981   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2    [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3    [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4     [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "5    [0, 66, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "6    [0, 39, 49, 52, 53, 20, 62, 58, 27, 94]   \n",
       "7    [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "8   [64, 65, 34, 66, 36, 42, 74, 80, 50, 88]   \n",
       "9    [33, 67, 4, 72, 73, 55, 27, 93, 30, 95]   \n",
       "10   [64, 65, 66, 4, 38, 74, 15, 80, 50, 63]   \n",
       "11   [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "12  [37, 69, 12, 76, 13, 81, 17, 85, 89, 90]   \n",
       "13     [0, 1, 70, 6, 83, 53, 54, 57, 92, 62]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4   ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "5   ['apple', 'raccoon', 'keyboard', 'sea', 'oak_t...  192.253176  0.844140   \n",
       "6   ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "7   ['beetle', 'lizard', 'snail', 'lobster', 'spid...    0.969446  0.091850   \n",
       "8   ['possum', 'rabbit', 'fox', 'raccoon', 'hamste...    3.282271  0.111503   \n",
       "9   ['forest', 'ray', 'beaver', 'seal', 'shark', '...    6.930972  0.074397   \n",
       "10  ['possum', 'rabbit', 'raccoon', 'beaver', 'kan...    1.423381  0.111503   \n",
       "11  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "12  ['house', 'rocket', 'bridge', 'skyscraper', 'b...    7.993174  0.151836   \n",
       "13  ['apple', 'aquarium_fish', 'rose', 'bee', 'swe...   12.526491  0.203903   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.980                  0.998   \n",
       "1   69.604010             False                  0.957                  0.998   \n",
       "2   73.300755             False                  0.981                  0.999   \n",
       "3   68.423650             False                  0.979                  1.000   \n",
       "4   68.367547             False                  0.981                  1.000   \n",
       "5   67.798484             False                  0.983                  1.000   \n",
       "6   68.150249             False                  0.980                  0.999   \n",
       "7    0.369210             False                  0.902                  0.991   \n",
       "8    1.016768             False                  0.869                  0.984   \n",
       "9    1.742421             False                  0.845                  0.988   \n",
       "10   0.528430             False                  0.843                  0.973   \n",
       "11   0.949666             False                  0.819                  0.985   \n",
       "12   1.750203             False                  0.897                  0.987   \n",
       "13   3.729304             False                  0.916                  0.996   \n",
       "\n",
       "    Median_KL  \n",
       "0   66.980437  \n",
       "1   66.877609  \n",
       "2   66.980437  \n",
       "3   50.328013  \n",
       "4   55.650079  \n",
       "5   48.535313  \n",
       "6   65.348257  \n",
       "7    0.309007  \n",
       "8    0.604708  \n",
       "9    1.352544  \n",
       "10   0.415386  \n",
       "11   0.782209  \n",
       "12   1.361525  \n",
       "13   2.366408  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Median_KL\"] = median\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dd02952-818a-4588-bfaa-bbfce9e4d30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "pd.DataFrame(KL_data_all, index = df[\"Quantized Top1 Accuracy\"]).T.boxplot(vert = False, positions = df[\"Quantized Top1 Accuracy\"] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0724d809-8a16-40f1-aad0-cd9252c5c0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[\"Classes Repeated\"] = new_col\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61e9939a-6dcb-4678-8a83-9ad2ba3012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3593c-43f4-4388-9121-057b93a9b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626567-9b3d-40c0-981e-484ed7d33fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7102e16-7f17-4da8-b66c-ff7d8260d341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3058420-34ee-470e-a70b-492d24039904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "621a9e36-75ad-4db7-9d8e-305ecfec26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.2246467991473532e-16, 6.123233995736766e-17, 1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "cmap = colormaps['rainbow']\n",
    "cmap(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8658d7d950>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    plt.plot(df.iloc[i][[\"Min_KL\", \"Max_KL\"]], [df.iloc[i][\"Quantized Top1 Accuracy\"]] * 2, color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Min_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Max_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_35533/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35533/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "072a7807-ef35-47de-807e-713dcf873518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35533/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(100):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized VGG16 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e647349-11a1-48f2-bb7f-80b685680da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35533/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(80):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fc909a7-7edb-48b6-a0ad-876549adac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35533/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(80):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b67a379b-ea0d-41f1-8e05-11ab681a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35533/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(80):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57a59db2-c5d9-448d-bd08-831468fc95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Median KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized VGG16 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973c463-7a01-4b31-81d8-98ff135a4621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
