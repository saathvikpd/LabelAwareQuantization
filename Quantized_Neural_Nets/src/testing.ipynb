{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f376d630-cea9-4230-9c3f-5299c7c71ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 1020.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.25868225097656.\n",
      "The relative quantization error of layer 0 is 0.018667027354240417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1516.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 919.8924560546875.\n",
      "The relative quantization error of layer 1 is 0.05143042653799057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3746.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 259.67718505859375.\n",
      "The relative quantization error of layer 2 is 0.056695107370615005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 525.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3183.9365234375.\n",
      "The relative quantization error of layer 3 is 0.09853951632976532.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 533.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1507.2630615234375.\n",
      "The relative quantization error of layer 4 is 0.051438312977552414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 609.8460083007812.\n",
      "The relative quantization error of layer 5 is 0.20754067599773407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3788.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 263.0293273925781.\n",
      "The relative quantization error of layer 6 is 0.23148156702518463.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 534.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1081.296875.\n",
      "The relative quantization error of layer 7 is 0.2292228639125824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1312.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 921.7966918945312.\n",
      "The relative quantization error of layer 8 is 0.2665657103061676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3716.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 588.6195678710938.\n",
      "The relative quantization error of layer 9 is 0.2680821418762207.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 414.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1617.55908203125.\n",
      "The relative quantization error of layer 10 is 0.24035416543483734.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 776.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1724.647705078125.\n",
      "The relative quantization error of layer 11 is 0.3110990524291992.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3749.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1195.7432861328125.\n",
      "The relative quantization error of layer 12 is 0.2979004681110382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1365.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1545.7452392578125.\n",
      "The relative quantization error of layer 13 is 0.22156988084316254.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 219.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2042.521484375.\n",
      "The relative quantization error of layer 14 is 0.29466283321380615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2924.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2140.883544921875.\n",
      "The relative quantization error of layer 15 is 0.2660849988460541.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3759.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 521.1537475585938.\n",
      "The relative quantization error of layer 16 is 0.24051159620285034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1365.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1220.732177734375.\n",
      "The relative quantization error of layer 17 is 0.39060214161872864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2913.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1824.0615234375.\n",
      "The relative quantization error of layer 18 is 0.3049943745136261.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3783.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 378.19989013671875.\n",
      "The relative quantization error of layer 19 is 0.262408971786499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1368.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1256.73876953125.\n",
      "The relative quantization error of layer 20 is 0.30605489015579224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2916.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2007.701904296875.\n",
      "The relative quantization error of layer 21 is 0.33714067935943604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3803.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 457.488037109375.\n",
      "The relative quantization error of layer 22 is 0.28020602464675903.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1365.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1015.2341918945312.\n",
      "The relative quantization error of layer 23 is 0.39246422052383423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2129.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3397.072021484375.\n",
      "The relative quantization error of layer 24 is 0.37408000230789185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2676.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 616.3438720703125.\n",
      "The relative quantization error of layer 25 is 0.3146092891693115.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1851.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1363.956298828125.\n",
      "The relative quantization error of layer 26 is 0.369507759809494.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 713.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3485.387451171875.\n",
      "The relative quantization error of layer 27 is 0.36046072840690613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2693.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1363.0609130859375.\n",
      "The relative quantization error of layer 28 is 0.3342120051383972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2703.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.09356689453125.\n",
      "The relative quantization error of layer 29 is 0.17873108386993408.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1870.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1000.287353515625.\n",
      "The relative quantization error of layer 30 is 0.42507070302963257.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2688.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1541.5484619140625.\n",
      "The relative quantization error of layer 31 is 0.36213749647140503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2712.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.61907958984375.\n",
      "The relative quantization error of layer 32 is 0.2189416140317917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1566.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 894.71044921875.\n",
      "The relative quantization error of layer 33 is 0.477460116147995.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2633.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1645.159423828125.\n",
      "The relative quantization error of layer 34 is 0.40508124232292175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2693.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.95437622070312.\n",
      "The relative quantization error of layer 35 is 0.20240391790866852.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1795.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1084.1536865234375.\n",
      "The relative quantization error of layer 36 is 0.5001992583274841.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2661.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1792.5523681640625.\n",
      "The relative quantization error of layer 37 is 0.41370218992233276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2710.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.10107421875.\n",
      "The relative quantization error of layer 38 is 0.20951752364635468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1867.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1394.7078857421875.\n",
      "The relative quantization error of layer 39 is 0.5158043503761292.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2690.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1847.211181640625.\n",
      "The relative quantization error of layer 40 is 0.4288470149040222.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2705.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 186.44300842285156.\n",
      "The relative quantization error of layer 41 is 0.22142459452152252.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1859.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1409.6756591796875.\n",
      "The relative quantization error of layer 42 is 0.5233061909675598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2489.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2570.044189453125.\n",
      "The relative quantization error of layer 43 is 0.4603261351585388.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2737.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.90036010742188.\n",
      "The relative quantization error of layer 44 is 0.19432879984378815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2465.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 903.89599609375.\n",
      "The relative quantization error of layer 45 is 0.4170771837234497.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1259.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2195.5302734375.\n",
      "The relative quantization error of layer 46 is 0.46626707911491394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2676.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.1070861816406.\n",
      "The relative quantization error of layer 47 is 0.3695369362831116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2732.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.86519622802734.\n",
      "The relative quantization error of layer 48 is 0.1099458634853363.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2429.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 522.2960205078125.\n",
      "The relative quantization error of layer 49 is 0.6628208756446838.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2728.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 464.1393737792969.\n",
      "The relative quantization error of layer 50 is 0.2775249779224396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2746.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 54.06114959716797.\n",
      "The relative quantization error of layer 51 is 0.10475318878889084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2531.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 106.4520263671875.\n",
      "The relative quantization error of layer 52 is 0.7699555158615112.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2753.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 23.89202308654785.\n",
      "The relative quantization error of layer 53 is 0.14712192118167877.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:40.542271\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.58it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.879.\n",
      "Top-5 accuracy of resnet50 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.959.\n",
      "Top-5 accuracy of quantized resnet50 is 0.996.\n",
      "\n",
      "Time used for evaluation: 0:00:02.122809\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4518\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 793.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 82.67253875732422.\n",
      "The relative quantization error of layer 0 is 0.018066363409161568.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1553.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 886.3926391601562.\n",
      "The relative quantization error of layer 1 is 0.04997831955552101.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 4065.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 262.1341857910156.\n",
      "The relative quantization error of layer 2 is 0.05956287682056427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 525.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3435.358154296875.\n",
      "The relative quantization error of layer 3 is 0.10564426332712173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 505.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1411.25146484375.\n",
      "The relative quantization error of layer 4 is 0.048448286950588226.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1319.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 570.707763671875.\n",
      "The relative quantization error of layer 5 is 0.1970520168542862.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3935.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 278.21826171875.\n",
      "The relative quantization error of layer 6 is 0.24138151109218597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 533.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1131.116943359375.\n",
      "The relative quantization error of layer 7 is 0.2370920479297638.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1330.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 873.094482421875.\n",
      "The relative quantization error of layer 8 is 0.2610575258731842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3985.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 571.666015625.\n",
      "The relative quantization error of layer 9 is 0.2711918354034424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 434.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1656.4305419921875.\n",
      "The relative quantization error of layer 10 is 0.24115243554115295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 782.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1772.4005126953125.\n",
      "The relative quantization error of layer 11 is 0.3077490031719208.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4052.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1237.26416015625.\n",
      "The relative quantization error of layer 12 is 0.3153768479824066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1376.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1506.0950927734375.\n",
      "The relative quantization error of layer 13 is 0.21841910481452942.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 219.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2082.158447265625.\n",
      "The relative quantization error of layer 14 is 0.29635363817214966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2983.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1972.725341796875.\n",
      "The relative quantization error of layer 15 is 0.2726633846759796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4010.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 518.7636108398438.\n",
      "The relative quantization error of layer 16 is 0.23731859028339386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 943.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1180.4521484375.\n",
      "The relative quantization error of layer 17 is 0.39222925901412964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3014.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1757.5213623046875.\n",
      "The relative quantization error of layer 18 is 0.29626283049583435.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4015.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 369.95831298828125.\n",
      "The relative quantization error of layer 19 is 0.2571905255317688.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1370.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1224.266357421875.\n",
      "The relative quantization error of layer 20 is 0.30892521142959595.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2542.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1992.4268798828125.\n",
      "The relative quantization error of layer 21 is 0.3279474079608917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 4056.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 439.351318359375.\n",
      "The relative quantization error of layer 22 is 0.27537378668785095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1371.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1041.42626953125.\n",
      "The relative quantization error of layer 23 is 0.3771046996116638.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2156.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3254.855712890625.\n",
      "The relative quantization error of layer 24 is 0.362995982170105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4005.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 609.6557006835938.\n",
      "The relative quantization error of layer 25 is 0.3205397427082062.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2185.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1324.9051513671875.\n",
      "The relative quantization error of layer 26 is 0.3656837046146393.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 738.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3446.158203125.\n",
      "The relative quantization error of layer 27 is 0.36406752467155457.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3927.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1361.0943603515625.\n",
      "The relative quantization error of layer 28 is 0.34062865376472473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4032.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 267.6166076660156.\n",
      "The relative quantization error of layer 29 is 0.17356839776039124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2173.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 959.3692626953125.\n",
      "The relative quantization error of layer 30 is 0.448760062456131.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3943.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1552.3961181640625.\n",
      "The relative quantization error of layer 31 is 0.3643822968006134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4002.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 300.7493896484375.\n",
      "The relative quantization error of layer 32 is 0.22212699055671692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2171.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 857.0930786132812.\n",
      "The relative quantization error of layer 33 is 0.4600355327129364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3930.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1687.543212890625.\n",
      "The relative quantization error of layer 34 is 0.40021762251853943.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3996.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 236.9340057373047.\n",
      "The relative quantization error of layer 35 is 0.1978081613779068.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2165.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1027.8065185546875.\n",
      "The relative quantization error of layer 36 is 0.516859233379364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3966.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1734.84326171875.\n",
      "The relative quantization error of layer 37 is 0.412689208984375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4048.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 209.02728271484375.\n",
      "The relative quantization error of layer 38 is 0.20588958263397217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2166.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1312.7176513671875.\n",
      "The relative quantization error of layer 39 is 0.4907645583152771.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3948.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1835.1458740234375.\n",
      "The relative quantization error of layer 40 is 0.4102799892425537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 4045.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.3257598876953.\n",
      "The relative quantization error of layer 41 is 0.2196783572435379.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2165.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1411.414794921875.\n",
      "The relative quantization error of layer 42 is 0.5246043801307678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3068.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2451.154541015625.\n",
      "The relative quantization error of layer 43 is 0.4471129775047302.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 4045.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 155.71437072753906.\n",
      "The relative quantization error of layer 44 is 0.19913135468959808.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3040.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 897.8058471679688.\n",
      "The relative quantization error of layer 45 is 0.4224497973918915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1378.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2179.855224609375.\n",
      "The relative quantization error of layer 46 is 0.4692097306251526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 4016.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 398.3265075683594.\n",
      "The relative quantization error of layer 47 is 0.3723844587802887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 4037.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 99.94123077392578.\n",
      "The relative quantization error of layer 48 is 0.10283108055591583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3053.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 507.6412658691406.\n",
      "The relative quantization error of layer 49 is 0.6598610281944275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 4014.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 423.13189697265625.\n",
      "The relative quantization error of layer 50 is 0.21961934864521027.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 4068.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 59.907325744628906.\n",
      "The relative quantization error of layer 51 is 0.10418416559696198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3014.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 105.85540008544922.\n",
      "The relative quantization error of layer 52 is 0.7784426212310791.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 4073.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 24.503665924072266.\n",
      "The relative quantization error of layer 53 is 0.15679076313972473.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:35.513325\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.51it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.875.\n",
      "Top-5 accuracy of resnet50 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.936.\n",
      "Top-5 accuracy of quantized resnet50 is 0.995.\n",
      "\n",
      "Time used for evaluation: 0:00:02.496410\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4532\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 949.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 86.57965850830078.\n",
      "The relative quantization error of layer 0 is 0.018398107960820198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1362.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 939.4945678710938.\n",
      "The relative quantization error of layer 1 is 0.052460070699453354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2708.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 244.10719299316406.\n",
      "The relative quantization error of layer 2 is 0.05497860908508301.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 416.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3616.0966796875.\n",
      "The relative quantization error of layer 3 is 0.10662053525447845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 513.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1469.5452880859375.\n",
      "The relative quantization error of layer 4 is 0.048213887959718704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1202.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 605.8867797851562.\n",
      "The relative quantization error of layer 5 is 0.19880074262619019.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2614.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 267.2186584472656.\n",
      "The relative quantization error of layer 6 is 0.2273433953523636.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 463.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1070.5546875.\n",
      "The relative quantization error of layer 7 is 0.22395294904708862.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1204.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 895.9044189453125.\n",
      "The relative quantization error of layer 8 is 0.2567254900932312.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2658.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 579.94287109375.\n",
      "The relative quantization error of layer 9 is 0.2735258638858795.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 461.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1713.9544677734375.\n",
      "The relative quantization error of layer 10 is 0.2534652054309845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 649.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1719.36865234375.\n",
      "The relative quantization error of layer 11 is 0.30059388279914856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2723.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1253.4512939453125.\n",
      "The relative quantization error of layer 12 is 0.3103722631931305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1238.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1587.9466552734375.\n",
      "The relative quantization error of layer 13 is 0.22549672424793243.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 219.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2086.960205078125.\n",
      "The relative quantization error of layer 14 is 0.29301559925079346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2416.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2016.4215087890625.\n",
      "The relative quantization error of layer 15 is 0.27213019132614136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2448.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 517.9285278320312.\n",
      "The relative quantization error of layer 16 is 0.23909083008766174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 857.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1185.439697265625.\n",
      "The relative quantization error of layer 17 is 0.3835861086845398.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2423.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1814.1795654296875.\n",
      "The relative quantization error of layer 18 is 0.3070027530193329.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2684.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.8594055175781.\n",
      "The relative quantization error of layer 19 is 0.255059152841568.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1033.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1257.9185791015625.\n",
      "The relative quantization error of layer 20 is 0.3084912598133087.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2423.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1978.0496826171875.\n",
      "The relative quantization error of layer 21 is 0.3253321349620819.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2736.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 444.9275207519531.\n",
      "The relative quantization error of layer 22 is 0.27662256360054016.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1240.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1035.030517578125.\n",
      "The relative quantization error of layer 23 is 0.36826497316360474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1790.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3316.50830078125.\n",
      "The relative quantization error of layer 24 is 0.3596660792827606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3841.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 613.3984985351562.\n",
      "The relative quantization error of layer 25 is 0.324272483587265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1371.0025634765625.\n",
      "The relative quantization error of layer 26 is 0.37062275409698486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 716.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3446.833984375.\n",
      "The relative quantization error of layer 27 is 0.3585032820701599.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3820.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1331.2701416015625.\n",
      "The relative quantization error of layer 28 is 0.3257729411125183.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3861.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 260.81439208984375.\n",
      "The relative quantization error of layer 29 is 0.17570717632770538.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2133.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 994.7686157226562.\n",
      "The relative quantization error of layer 30 is 0.4146839678287506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3785.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1510.794921875.\n",
      "The relative quantization error of layer 31 is 0.3587844669818878.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3832.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 295.537353515625.\n",
      "The relative quantization error of layer 32 is 0.21822594106197357.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1701.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 874.859375.\n",
      "The relative quantization error of layer 33 is 0.45415809750556946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3738.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1652.8017578125.\n",
      "The relative quantization error of layer 34 is 0.4027976095676422.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3790.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 240.80165100097656.\n",
      "The relative quantization error of layer 35 is 0.20069405436515808.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2131.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1038.25390625.\n",
      "The relative quantization error of layer 36 is 0.507318377494812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3790.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1739.92431640625.\n",
      "The relative quantization error of layer 37 is 0.412383109331131.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3788.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.36404418945312.\n",
      "The relative quantization error of layer 38 is 0.20685696601867676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1935.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1362.0079345703125.\n",
      "The relative quantization error of layer 39 is 0.5070965886116028.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3785.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1833.070556640625.\n",
      "The relative quantization error of layer 40 is 0.43215620517730713.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3788.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.2353515625.\n",
      "The relative quantization error of layer 41 is 0.21723905205726624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2131.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1406.083984375.\n",
      "The relative quantization error of layer 42 is 0.5247406363487244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2984.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2470.558837890625.\n",
      "The relative quantization error of layer 43 is 0.4428553283214569.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3817.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 152.83798217773438.\n",
      "The relative quantization error of layer 44 is 0.19303388893604279.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2482.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 866.580322265625.\n",
      "The relative quantization error of layer 45 is 0.40279853343963623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1326.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2171.34814453125.\n",
      "The relative quantization error of layer 46 is 0.4605098366737366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3806.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 411.28302001953125.\n",
      "The relative quantization error of layer 47 is 0.37212425470352173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3846.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.92135620117188.\n",
      "The relative quantization error of layer 48 is 0.10550122708082199.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3041.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 512.2210693359375.\n",
      "The relative quantization error of layer 49 is 0.6424877047538757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2719.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 413.8765563964844.\n",
      "The relative quantization error of layer 50 is 0.31973281502723694.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2754.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 94.48297882080078.\n",
      "The relative quantization error of layer 51 is 0.12750256061553955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2298.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 104.97677612304688.\n",
      "The relative quantization error of layer 52 is 0.7692346572875977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2726.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 34.98757553100586.\n",
      "The relative quantization error of layer 53 is 0.20695041120052338.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:38.482083\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.40it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.872.\n",
      "Top-5 accuracy of resnet50 is 0.988.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.943.\n",
      "Top-5 accuracy of quantized resnet50 is 0.99.\n",
      "\n",
      "Time used for evaluation: 0:00:02.689171\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4569\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 974.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 80.99386596679688.\n",
      "The relative quantization error of layer 0 is 0.01928429864346981.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1525.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 856.3876953125.\n",
      "The relative quantization error of layer 1 is 0.04858523607254028.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3203.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 253.30760192871094.\n",
      "The relative quantization error of layer 2 is 0.058130089193582535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 526.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3424.944580078125.\n",
      "The relative quantization error of layer 3 is 0.10422839224338531.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 533.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1529.0386962890625.\n",
      "The relative quantization error of layer 4 is 0.05229247361421585.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1209.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 602.9034423828125.\n",
      "The relative quantization error of layer 5 is 0.20205962657928467.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2691.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 265.8553771972656.\n",
      "The relative quantization error of layer 6 is 0.23877383768558502.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 530.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1039.3843994140625.\n",
      "The relative quantization error of layer 7 is 0.22677691280841827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1213.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 888.7112426757812.\n",
      "The relative quantization error of layer 8 is 0.2645128071308136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2732.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 589.251220703125.\n",
      "The relative quantization error of layer 9 is 0.2788447141647339.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 530.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1557.033203125.\n",
      "The relative quantization error of layer 10 is 0.2363600879907608.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 728.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1714.784423828125.\n",
      "The relative quantization error of layer 11 is 0.3137339949607849.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2760.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1202.179443359375.\n",
      "The relative quantization error of layer 12 is 0.30513811111450195.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1253.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1509.155029296875.\n",
      "The relative quantization error of layer 13 is 0.21863600611686707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 210.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2065.835205078125.\n",
      "The relative quantization error of layer 14 is 0.29396021366119385.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2946.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2073.09912109375.\n",
      "The relative quantization error of layer 15 is 0.2680208086967468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3873.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 548.2672729492188.\n",
      "The relative quantization error of layer 16 is 0.2426668405532837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 991.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1176.9627685546875.\n",
      "The relative quantization error of layer 17 is 0.38863611221313477.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2927.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1882.0211181640625.\n",
      "The relative quantization error of layer 18 is 0.313688188791275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3856.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.3186340332031.\n",
      "The relative quantization error of layer 19 is 0.25994354486465454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1365.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1221.6962890625.\n",
      "The relative quantization error of layer 20 is 0.30469968914985657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2931.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2023.3729248046875.\n",
      "The relative quantization error of layer 21 is 0.33439621329307556.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3848.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 452.3130798339844.\n",
      "The relative quantization error of layer 22 is 0.2801378667354584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1366.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 983.7943725585938.\n",
      "The relative quantization error of layer 23 is 0.38213685154914856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2133.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3387.254150390625.\n",
      "The relative quantization error of layer 24 is 0.3755239248275757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3858.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 644.376220703125.\n",
      "The relative quantization error of layer 25 is 0.32382774353027344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2135.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1344.16796875.\n",
      "The relative quantization error of layer 26 is 0.3685973584651947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 683.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3350.6796875.\n",
      "The relative quantization error of layer 27 is 0.3477533459663391.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3838.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1351.6368408203125.\n",
      "The relative quantization error of layer 28 is 0.3368400037288666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2772.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.1098937988281.\n",
      "The relative quantization error of layer 29 is 0.17838263511657715.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1864.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 947.1434936523438.\n",
      "The relative quantization error of layer 30 is 0.4442673623561859.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3829.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1525.42333984375.\n",
      "The relative quantization error of layer 31 is 0.3622575104236603.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3890.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.480712890625.\n",
      "The relative quantization error of layer 32 is 0.22133471071720123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2105.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 898.7361450195312.\n",
      "The relative quantization error of layer 33 is 0.4850913882255554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3794.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1679.9234619140625.\n",
      "The relative quantization error of layer 34 is 0.41453760862350464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3881.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.30352783203125.\n",
      "The relative quantization error of layer 35 is 0.19985714554786682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2147.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1063.9088134765625.\n",
      "The relative quantization error of layer 36 is 0.5212388634681702.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3806.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1756.4207763671875.\n",
      "The relative quantization error of layer 37 is 0.4258359670639038.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3842.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.8434295654297.\n",
      "The relative quantization error of layer 38 is 0.21258457005023956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2132.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1346.06201171875.\n",
      "The relative quantization error of layer 39 is 0.5070159435272217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3837.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1790.8836669921875.\n",
      "The relative quantization error of layer 40 is 0.4312495291233063.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3903.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.25958251953125.\n",
      "The relative quantization error of layer 41 is 0.22640131413936615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1721.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1427.8621826171875.\n",
      "The relative quantization error of layer 42 is 0.5343882441520691.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3008.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2502.626953125.\n",
      "The relative quantization error of layer 43 is 0.45612818002700806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3864.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.97518920898438.\n",
      "The relative quantization error of layer 44 is 0.20504167675971985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2700.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 908.948974609375.\n",
      "The relative quantization error of layer 45 is 0.4294094443321228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1370.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2184.045166015625.\n",
      "The relative quantization error of layer 46 is 0.463750958442688.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3890.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 421.6549377441406.\n",
      "The relative quantization error of layer 47 is 0.41263774037361145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3871.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 101.17697143554688.\n",
      "The relative quantization error of layer 48 is 0.09980092942714691.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2962.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 521.3602905273438.\n",
      "The relative quantization error of layer 49 is 0.6647730469703674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3886.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 426.4159851074219.\n",
      "The relative quantization error of layer 50 is 0.2497781217098236.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3943.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 87.97250366210938.\n",
      "The relative quantization error of layer 51 is 0.13815757632255554.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3038.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 114.4450454711914.\n",
      "The relative quantization error of layer 52 is 0.8065856695175171.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3893.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 38.8483772277832.\n",
      "The relative quantization error of layer 53 is 0.23362649977207184.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:37.036757\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.83it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.863.\n",
      "Top-5 accuracy of resnet50 is 0.982.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.951.\n",
      "Top-5 accuracy of quantized resnet50 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:00:02.370260\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.454\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 947.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.48269653320312.\n",
      "The relative quantization error of layer 0 is 0.018520433455705643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 755.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 887.4028930664062.\n",
      "The relative quantization error of layer 1 is 0.050292566418647766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2708.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 247.6575927734375.\n",
      "The relative quantization error of layer 2 is 0.057676270604133606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 455.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3360.39404296875.\n",
      "The relative quantization error of layer 3 is 0.10116514563560486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 464.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1478.83056640625.\n",
      "The relative quantization error of layer 4 is 0.05023512616753578.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1202.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 628.0390625.\n",
      "The relative quantization error of layer 5 is 0.21087591350078583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2280.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 282.60394287109375.\n",
      "The relative quantization error of layer 6 is 0.2578422427177429.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 529.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1096.234619140625.\n",
      "The relative quantization error of layer 7 is 0.2384306937456131.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1205.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 927.806640625.\n",
      "The relative quantization error of layer 8 is 0.269636869430542.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2144.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 589.5130004882812.\n",
      "The relative quantization error of layer 9 is 0.2835773825645447.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 473.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1609.6143798828125.\n",
      "The relative quantization error of layer 10 is 0.24291813373565674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 685.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1812.8497314453125.\n",
      "The relative quantization error of layer 11 is 0.3164750337600708.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2714.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1226.1748046875.\n",
      "The relative quantization error of layer 12 is 0.2982918918132782.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1233.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1556.2532958984375.\n",
      "The relative quantization error of layer 13 is 0.22338321805000305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 218.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2002.7525634765625.\n",
      "The relative quantization error of layer 14 is 0.28939089179039.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2371.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2072.719970703125.\n",
      "The relative quantization error of layer 15 is 0.27011561393737793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2646.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 567.1126098632812.\n",
      "The relative quantization error of layer 16 is 0.2473834753036499.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1236.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1221.962890625.\n",
      "The relative quantization error of layer 17 is 0.3921258747577667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2408.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1773.013916015625.\n",
      "The relative quantization error of layer 18 is 0.30308109521865845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2692.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 386.9423522949219.\n",
      "The relative quantization error of layer 19 is 0.27293941378593445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1241.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1241.2705078125.\n",
      "The relative quantization error of layer 20 is 0.3073967695236206.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2392.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1959.13232421875.\n",
      "The relative quantization error of layer 21 is 0.3308194577693939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2705.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 439.2359924316406.\n",
      "The relative quantization error of layer 22 is 0.2815001308917999.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 892.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1050.579345703125.\n",
      "The relative quantization error of layer 23 is 0.3937615752220154.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1776.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3388.09130859375.\n",
      "The relative quantization error of layer 24 is 0.3750985562801361.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2743.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 648.7936401367188.\n",
      "The relative quantization error of layer 25 is 0.3226624131202698.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1857.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1370.5340576171875.\n",
      "The relative quantization error of layer 26 is 0.3764989674091339.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 730.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3421.155029296875.\n",
      "The relative quantization error of layer 27 is 0.36170023679733276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2724.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1356.397705078125.\n",
      "The relative quantization error of layer 28 is 0.3350902199745178.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2752.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.3877868652344.\n",
      "The relative quantization error of layer 29 is 0.18160481750965118.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1864.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 977.9571533203125.\n",
      "The relative quantization error of layer 30 is 0.4529084861278534.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2716.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1506.2843017578125.\n",
      "The relative quantization error of layer 31 is 0.36007416248321533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2740.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 288.56182861328125.\n",
      "The relative quantization error of layer 32 is 0.21898336708545685.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1856.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 900.849609375.\n",
      "The relative quantization error of layer 33 is 0.4786961078643799.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2719.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1682.7130126953125.\n",
      "The relative quantization error of layer 34 is 0.412898987531662.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2738.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.28506469726562.\n",
      "The relative quantization error of layer 35 is 0.20507961511611938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1549.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1045.9461669921875.\n",
      "The relative quantization error of layer 36 is 0.5037575960159302.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2729.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1748.77490234375.\n",
      "The relative quantization error of layer 37 is 0.4193490743637085.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2752.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 209.00856018066406.\n",
      "The relative quantization error of layer 38 is 0.20988839864730835.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1861.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1364.361328125.\n",
      "The relative quantization error of layer 39 is 0.5098974108695984.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2720.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1827.8563232421875.\n",
      "The relative quantization error of layer 40 is 0.42270126938819885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2758.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.36061096191406.\n",
      "The relative quantization error of layer 41 is 0.2217329889535904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1861.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1412.7044677734375.\n",
      "The relative quantization error of layer 42 is 0.5182616114616394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2493.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2476.92822265625.\n",
      "The relative quantization error of layer 43 is 0.45043620467185974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2708.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.49790954589844.\n",
      "The relative quantization error of layer 44 is 0.20319266617298126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2433.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 911.7360229492188.\n",
      "The relative quantization error of layer 45 is 0.4247213900089264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1250.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2127.66162109375.\n",
      "The relative quantization error of layer 46 is 0.4574333429336548.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2722.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.9452819824219.\n",
      "The relative quantization error of layer 47 is 0.37799832224845886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2727.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 89.48702239990234.\n",
      "The relative quantization error of layer 48 is 0.09127609431743622.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2448.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 540.050048828125.\n",
      "The relative quantization error of layer 49 is 0.6761535406112671.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2720.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 429.0533142089844.\n",
      "The relative quantization error of layer 50 is 0.27889421582221985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2773.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 93.627197265625.\n",
      "The relative quantization error of layer 51 is 0.18314646184444427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2482.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 117.52862548828125.\n",
      "The relative quantization error of layer 52 is 0.8120081424713135.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2741.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 27.204875946044922.\n",
      "The relative quantization error of layer 53 is 0.1722264140844345.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:41.440425\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.15it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.883.\n",
      "Top-5 accuracy of resnet50 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.924.\n",
      "Top-5 accuracy of quantized resnet50 is 0.99.\n",
      "\n",
      "Time used for evaluation: 0:00:02.296096\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4576\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 1003.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.8729019165039.\n",
      "The relative quantization error of layer 0 is 0.01853044517338276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1536.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 899.4108276367188.\n",
      "The relative quantization error of layer 1 is 0.050704363733530045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3872.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 249.40321350097656.\n",
      "The relative quantization error of layer 2 is 0.0558813214302063.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 455.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3552.014892578125.\n",
      "The relative quantization error of layer 3 is 0.10606289654970169.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 495.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1399.59765625.\n",
      "The relative quantization error of layer 4 is 0.047971419990062714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1322.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 588.8404541015625.\n",
      "The relative quantization error of layer 5 is 0.19963255524635315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3857.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 266.2255554199219.\n",
      "The relative quantization error of layer 6 is 0.23492129147052765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 365.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1050.5631103515625.\n",
      "The relative quantization error of layer 7 is 0.2283429503440857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1324.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 870.0462646484375.\n",
      "The relative quantization error of layer 8 is 0.25782519578933716.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3849.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 577.1045532226562.\n",
      "The relative quantization error of layer 9 is 0.278300017118454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 533.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1643.987060546875.\n",
      "The relative quantization error of layer 10 is 0.2468518763780594.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 781.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1714.576171875.\n",
      "The relative quantization error of layer 11 is 0.3090154230594635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3857.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1206.6712646484375.\n",
      "The relative quantization error of layer 12 is 0.30766910314559937.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1364.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1516.187744140625.\n",
      "The relative quantization error of layer 13 is 0.22033466398715973.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 219.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1996.6595458984375.\n",
      "The relative quantization error of layer 14 is 0.29531171917915344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2938.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2061.180419921875.\n",
      "The relative quantization error of layer 15 is 0.27274826169013977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3873.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 491.6739807128906.\n",
      "The relative quantization error of layer 16 is 0.22989101707935333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1058.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1242.5020751953125.\n",
      "The relative quantization error of layer 17 is 0.41297614574432373.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2431.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1806.6502685546875.\n",
      "The relative quantization error of layer 18 is 0.30483171343803406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2747.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 377.7310485839844.\n",
      "The relative quantization error of layer 19 is 0.263175368309021.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 916.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1226.719970703125.\n",
      "The relative quantization error of layer 20 is 0.30712074041366577.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2441.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2031.8941650390625.\n",
      "The relative quantization error of layer 21 is 0.3407854735851288.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2743.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 437.6290283203125.\n",
      "The relative quantization error of layer 22 is 0.27677762508392334.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1251.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1068.3089599609375.\n",
      "The relative quantization error of layer 23 is 0.3890294134616852.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1871.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3328.87451171875.\n",
      "The relative quantization error of layer 24 is 0.3626638948917389.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2763.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 624.4286499023438.\n",
      "The relative quantization error of layer 25 is 0.32599109411239624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1859.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1364.4981689453125.\n",
      "The relative quantization error of layer 26 is 0.3722563683986664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 730.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3436.5556640625.\n",
      "The relative quantization error of layer 27 is 0.3588131070137024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2712.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1370.41455078125.\n",
      "The relative quantization error of layer 28 is 0.34237775206565857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2741.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 270.37890625.\n",
      "The relative quantization error of layer 29 is 0.1838414967060089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1867.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 956.1428833007812.\n",
      "The relative quantization error of layer 30 is 0.43918052315711975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2721.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1520.0225830078125.\n",
      "The relative quantization error of layer 31 is 0.36012905836105347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2725.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 298.9830017089844.\n",
      "The relative quantization error of layer 32 is 0.22495895624160767.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1767.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 848.8528442382812.\n",
      "The relative quantization error of layer 33 is 0.46888479590415955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2736.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1651.9954833984375.\n",
      "The relative quantization error of layer 34 is 0.4141511917114258.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2755.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 238.2113800048828.\n",
      "The relative quantization error of layer 35 is 0.19862473011016846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1859.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 998.5573120117188.\n",
      "The relative quantization error of layer 36 is 0.5001060962677002.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2725.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1744.494140625.\n",
      "The relative quantization error of layer 37 is 0.4205356240272522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2764.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.5126953125.\n",
      "The relative quantization error of layer 38 is 0.20503248274326324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1871.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1346.203857421875.\n",
      "The relative quantization error of layer 39 is 0.5039861798286438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2711.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1815.3095703125.\n",
      "The relative quantization error of layer 40 is 0.4308036267757416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2767.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.79104614257812.\n",
      "The relative quantization error of layer 41 is 0.22876980900764465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1867.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1421.1312255859375.\n",
      "The relative quantization error of layer 42 is 0.533198356628418.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2507.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2491.47802734375.\n",
      "The relative quantization error of layer 43 is 0.448640376329422.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2766.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.76840209960938.\n",
      "The relative quantization error of layer 44 is 0.20375128090381622.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2453.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 900.0006713867188.\n",
      "The relative quantization error of layer 45 is 0.40697431564331055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1251.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2176.87109375.\n",
      "The relative quantization error of layer 46 is 0.4728339910507202.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2719.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 404.71630859375.\n",
      "The relative quantization error of layer 47 is 0.3884606957435608.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2790.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 102.25160217285156.\n",
      "The relative quantization error of layer 48 is 0.09543854743242264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2477.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 517.300537109375.\n",
      "The relative quantization error of layer 49 is 0.6584972739219666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2759.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 465.30322265625.\n",
      "The relative quantization error of layer 50 is 0.23192213475704193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2816.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 107.80675506591797.\n",
      "The relative quantization error of layer 51 is 0.19074827432632446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2537.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.31959533691406.\n",
      "The relative quantization error of layer 52 is 0.7898905873298645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2776.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 38.90998077392578.\n",
      "The relative quantization error of layer 53 is 0.24325409531593323.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:41.094830\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.29it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.874.\n",
      "Top-5 accuracy of resnet50 is 0.987.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.943.\n",
      "Top-5 accuracy of quantized resnet50 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:00:02.245617\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.456\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing resnet50 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 1036.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.95285034179688.\n",
      "The relative quantization error of layer 0 is 0.018532713875174522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1061.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 909.4345703125.\n",
      "The relative quantization error of layer 1 is 0.05109177902340889.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3252.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 259.9146728515625.\n",
      "The relative quantization error of layer 2 is 0.05618519335985184.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 372.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3565.40380859375.\n",
      "The relative quantization error of layer 3 is 0.10540476441383362.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 425.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1462.1634521484375.\n",
      "The relative quantization error of layer 4 is 0.050037190318107605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1318.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 617.9783325195312.\n",
      "The relative quantization error of layer 5 is 0.2070067971944809.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3883.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 278.8985290527344.\n",
      "The relative quantization error of layer 6 is 0.2288159430027008.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 387.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1050.4765625.\n",
      "The relative quantization error of layer 7 is 0.22387680411338806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1312.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 872.9520263671875.\n",
      "The relative quantization error of layer 8 is 0.25318190455436707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3827.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 564.4717407226562.\n",
      "The relative quantization error of layer 9 is 0.26681697368621826.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 435.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1737.4501953125.\n",
      "The relative quantization error of layer 10 is 0.2500591576099396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 779.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1718.46923828125.\n",
      "The relative quantization error of layer 11 is 0.29966479539871216.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3932.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1206.358642578125.\n",
      "The relative quantization error of layer 12 is 0.29932525753974915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1018.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1520.7373046875.\n",
      "The relative quantization error of layer 13 is 0.21725155413150787.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:01<00:00, 219.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1976.9754638671875.\n",
      "The relative quantization error of layer 14 is 0.29459965229034424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2964.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2112.47998046875.\n",
      "The relative quantization error of layer 15 is 0.2693089246749878.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3883.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 531.2091064453125.\n",
      "The relative quantization error of layer 16 is 0.23949596285820007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1370.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1167.5185546875.\n",
      "The relative quantization error of layer 17 is 0.37124231457710266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2934.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1810.63720703125.\n",
      "The relative quantization error of layer 18 is 0.29707077145576477.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3869.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 381.53448486328125.\n",
      "The relative quantization error of layer 19 is 0.2610062062740326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1366.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1279.243408203125.\n",
      "The relative quantization error of layer 20 is 0.3106552064418793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2943.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1981.5992431640625.\n",
      "The relative quantization error of layer 21 is 0.3236944079399109.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3859.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 449.7208251953125.\n",
      "The relative quantization error of layer 22 is 0.26999735832214355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1368.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1027.18798828125.\n",
      "The relative quantization error of layer 23 is 0.33158084750175476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2141.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3254.436767578125.\n",
      "The relative quantization error of layer 24 is 0.35571035742759705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3906.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 618.1249389648438.\n",
      "The relative quantization error of layer 25 is 0.31837186217308044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2138.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1369.6031494140625.\n",
      "The relative quantization error of layer 26 is 0.3710400462150574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 702.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3471.093017578125.\n",
      "The relative quantization error of layer 27 is 0.35180139541625977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3839.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1363.655029296875.\n",
      "The relative quantization error of layer 28 is 0.3394448459148407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3885.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.54510498046875.\n",
      "The relative quantization error of layer 29 is 0.18245689570903778.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2148.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 986.1129760742188.\n",
      "The relative quantization error of layer 30 is 0.41410234570503235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3842.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1545.8905029296875.\n",
      "The relative quantization error of layer 31 is 0.3607402741909027.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3887.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.1600646972656.\n",
      "The relative quantization error of layer 32 is 0.21825675666332245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2137.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 885.834228515625.\n",
      "The relative quantization error of layer 33 is 0.4668273627758026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3840.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1663.5303955078125.\n",
      "The relative quantization error of layer 34 is 0.3845718204975128.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3888.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 240.5940704345703.\n",
      "The relative quantization error of layer 35 is 0.20136618614196777.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2121.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1037.532958984375.\n",
      "The relative quantization error of layer 36 is 0.511882483959198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3818.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1755.0113525390625.\n",
      "The relative quantization error of layer 37 is 0.3933265805244446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3870.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.2965545654297.\n",
      "The relative quantization error of layer 38 is 0.20937074720859528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2134.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1332.354248046875.\n",
      "The relative quantization error of layer 39 is 0.500324010848999.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3840.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1808.44677734375.\n",
      "The relative quantization error of layer 40 is 0.4273858666419983.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3900.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 173.6673583984375.\n",
      "The relative quantization error of layer 41 is 0.2229890078306198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2135.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1404.5181884765625.\n",
      "The relative quantization error of layer 42 is 0.5247981548309326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3013.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2483.980224609375.\n",
      "The relative quantization error of layer 43 is 0.4460740387439728.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3899.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.1068572998047.\n",
      "The relative quantization error of layer 44 is 0.19576966762542725.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2984.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 914.9019775390625.\n",
      "The relative quantization error of layer 45 is 0.4309147894382477.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1369.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2173.204833984375.\n",
      "The relative quantization error of layer 46 is 0.463999480009079.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3875.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.3514099121094.\n",
      "The relative quantization error of layer 47 is 0.39024725556373596.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3913.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 108.32135009765625.\n",
      "The relative quantization error of layer 48 is 0.09772654622793198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2985.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 538.6808471679688.\n",
      "The relative quantization error of layer 49 is 0.6723278760910034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3872.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 452.6038818359375.\n",
      "The relative quantization error of layer 50 is 0.294232040643692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3943.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 79.90744018554688.\n",
      "The relative quantization error of layer 51 is 0.13987763226032257.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3019.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 111.13929748535156.\n",
      "The relative quantization error of layer 52 is 0.8019050359725952.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2757.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.50258445739746.\n",
      "The relative quantization error of layer 53 is 0.1810094267129898.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:36.060161\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.74it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.856.\n",
      "Top-5 accuracy of resnet50 is 0.979.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized resnet50 is 0.931.\n",
      "Top-5 accuracy of quantized resnet50 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:00:02.610261\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4573\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['False'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'resnet50' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantized Sparsity</th>\n",
       "      <th>Retain_rate</th>\n",
       "      <th>Fusion</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.917</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.911</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.955</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.906</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.910</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.952</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.909</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.957</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(11), np.int64(59), np....</td>\n",
       "      <td>['shrew', 'boy', 'pine_tree', 'television', 't...</td>\n",
       "      <td>68.943547</td>\n",
       "      <td>0.703137</td>\n",
       "      <td>12.946819</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.959</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4509</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(3), np.int64(43), np.i...</td>\n",
       "      <td>['lamp', 'bear', 'lion', 'forest', 'palm_tree'...</td>\n",
       "      <td>24.482168</td>\n",
       "      <td>0.459166</td>\n",
       "      <td>8.783600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.956</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(22), np.int64(40), np.int64(86), np....</td>\n",
       "      <td>['clock', 'lamp', 'telephone', 'lobster', 'leo...</td>\n",
       "      <td>63.911466</td>\n",
       "      <td>0.238287</td>\n",
       "      <td>12.797301</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(48), np.int64(35), np.int64(26), np....</td>\n",
       "      <td>['motorcycle', 'girl', 'crab', 'flatfish', 'ro...</td>\n",
       "      <td>36.237008</td>\n",
       "      <td>0.142821</td>\n",
       "      <td>8.417093</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.949</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4449</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(35), np.int64(15), np....</td>\n",
       "      <td>['shrew', 'girl', 'camel', 'willow_tree', 'sha...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>6.765886</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.965</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4511</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(65), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['rabbit', 'train', 'rocket', 'raccoon', 'bear...</td>\n",
       "      <td>35.807582</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>11.366363</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 48, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'motorcycle', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.260865</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'bear', 'keyboard', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.130501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.929204</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 52, 53, 62, 90, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.614852</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 72, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'seal', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.859487</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                   0.815   \n",
       "2    resnet50  CIFAR100                       64                   0.863   \n",
       "3    resnet50  CIFAR100                       64                   0.799   \n",
       "4    resnet50  CIFAR100                       64                   0.887   \n",
       "5    resnet50  CIFAR100                       64                   0.797   \n",
       "6    resnet50  CIFAR100                       64                   0.830   \n",
       "8    resnet50  CIFAR100                       64                   0.767   \n",
       "9    resnet50  CIFAR100                       64                   0.867   \n",
       "10   resnet50  CIFAR100                       64                   0.834   \n",
       "11   resnet50  CIFAR100                       64                   0.840   \n",
       "12   resnet50  CIFAR100                       64                   0.821   \n",
       "13   resnet50  CIFAR100                       64                   0.775   \n",
       "15   resnet50  CIFAR100                       64                   0.808   \n",
       "16   resnet50  CIFAR100                       64                   0.877   \n",
       "19   resnet50  CIFAR100                       64                   0.823   \n",
       "20   resnet50  CIFAR100                       64                   0.871   \n",
       "22   resnet50  CIFAR100                       64                   0.845   \n",
       "23   resnet50  CIFAR100                       64                   0.746   \n",
       "24   resnet50  CIFAR100                       64                   0.873   \n",
       "26   resnet50  CIFAR100                       64                   0.848   \n",
       "27   resnet50  CIFAR100                       64                   0.771   \n",
       "28   resnet50  CIFAR100                       64                   0.872   \n",
       "30   resnet50  CIFAR100                       64                   0.826   \n",
       "31   resnet50  CIFAR100                       64                   0.781   \n",
       "32   resnet50  CIFAR100                       64                   0.861   \n",
       "33   resnet50  CIFAR100                       64                   0.806   \n",
       "34   resnet50  CIFAR100                       64                   0.848   \n",
       "35   resnet50  CIFAR100                       64                   0.884   \n",
       "36   resnet50  CIFAR100                       64                   0.879   \n",
       "37   resnet50  CIFAR100                       64                   0.831   \n",
       "38   resnet50  CIFAR100                       64                   0.779   \n",
       "39   resnet50  CIFAR100                       64                   0.793   \n",
       "40   resnet50  CIFAR100                       64                   0.820   \n",
       "41   resnet50  CIFAR100                       64                   0.819   \n",
       "42   resnet50  CIFAR100                       64                   0.838   \n",
       "43   resnet50  CIFAR100                       64                   0.762   \n",
       "44   resnet50  CIFAR100                       64                   0.859   \n",
       "45   resnet50  CIFAR100                       64                   0.873   \n",
       "46   resnet50  CIFAR100                       64                   0.879   \n",
       "47   resnet50  CIFAR100                       64                   0.875   \n",
       "48   resnet50  CIFAR100                       64                   0.872   \n",
       "49   resnet50  CIFAR100                       64                   0.863   \n",
       "50   resnet50  CIFAR100                       64                   0.883   \n",
       "51   resnet50  CIFAR100                       64                   0.874   \n",
       "52   resnet50  CIFAR100                       64                   0.856   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.603                   0.949                    0.917   \n",
       "2                     0.843                   0.983                    0.989   \n",
       "3                     0.615                   0.951                    0.911   \n",
       "4                     0.944                   0.988                    0.995   \n",
       "5                     0.830                   0.973                    0.974   \n",
       "6                     0.737                   0.968                    0.955   \n",
       "8                     0.693                   0.961                    0.975   \n",
       "9                     0.946                   0.986                    0.995   \n",
       "10                    0.808                   0.968                    0.974   \n",
       "11                    0.884                   0.974                    0.988   \n",
       "12                    0.794                   0.968                    0.963   \n",
       "13                    0.681                   0.964                    0.974   \n",
       "15                    0.734                   0.986                    0.984   \n",
       "16                    0.957                   0.988                    0.995   \n",
       "19                    0.753                   0.963                    0.958   \n",
       "20                    0.936                   0.988                    0.992   \n",
       "22                    0.876                   0.972                    0.958   \n",
       "23                    0.520                   0.939                    0.906   \n",
       "24                    0.932                   0.986                    0.989   \n",
       "26                    0.866                   0.973                    0.988   \n",
       "27                    0.556                   0.950                    0.910   \n",
       "28                    0.944                   0.988                    0.993   \n",
       "30                    0.712                   0.952                    0.952   \n",
       "31                    0.566                   0.946                    0.909   \n",
       "32                    0.930                   0.985                    0.983   \n",
       "33                    0.869                   0.965                    0.988   \n",
       "34                    0.793                   0.974                    0.981   \n",
       "35                    0.754                   0.981                    0.972   \n",
       "36                    0.962                   0.987                    0.992   \n",
       "37                    0.790                   0.952                    0.972   \n",
       "38                    0.802                   0.968                    0.958   \n",
       "39                    0.782                   0.969                    0.957   \n",
       "40                    0.765                   0.966                    0.959   \n",
       "41                    0.804                   0.956                    0.956   \n",
       "42                    0.776                   0.976                    0.976   \n",
       "43                    0.636                   0.964                    0.949   \n",
       "44                    0.799                   0.968                    0.965   \n",
       "45                    0.942                   0.986                    0.986   \n",
       "46                    0.959                   0.989                    0.996   \n",
       "47                    0.936                   0.989                    0.995   \n",
       "48                    0.943                   0.988                    0.990   \n",
       "49                    0.951                   0.982                    0.993   \n",
       "50                    0.924                   0.989                    0.990   \n",
       "51                    0.943                   0.987                    0.993   \n",
       "52                    0.931                   0.979                    0.993   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Quantized Sparsity  \\\n",
       "0      4                 1.16                 1.16  ...              0.4454   \n",
       "2      4                 1.16                 1.16  ...              0.4504   \n",
       "3      4                 1.16                 1.16  ...              0.4483   \n",
       "4      4                 1.16                 1.16  ...              0.4543   \n",
       "5      4                 1.16                 1.16  ...              0.4480   \n",
       "6      4                 1.16                 1.16  ...              0.4464   \n",
       "8      4                 1.16                 1.16  ...              0.4510   \n",
       "9      4                 1.16                 1.16  ...              0.4540   \n",
       "10     4                 1.16                 1.16  ...              0.4535   \n",
       "11     4                 1.16                 1.16  ...              0.4516   \n",
       "12     4                 1.16                 1.16  ...              0.4575   \n",
       "13     4                 1.16                 1.16  ...              0.4521   \n",
       "15     4                 1.16                 1.16  ...              0.4458   \n",
       "16     4                 1.16                 1.16  ...              0.4522   \n",
       "19     4                 1.16                 1.16  ...              0.4582   \n",
       "20     4                 1.16                 1.16  ...              0.4486   \n",
       "22     4                 1.16                 1.16  ...              0.4507   \n",
       "23     4                 1.16                 1.16  ...              0.4450   \n",
       "24     4                 1.16                 1.16  ...              0.4553   \n",
       "26     4                 1.16                 1.16  ...              0.4527   \n",
       "27     4                 1.16                 1.16  ...              0.4477   \n",
       "28     4                 1.16                 1.16  ...              0.4532   \n",
       "30     4                 1.16                 1.16  ...              0.4535   \n",
       "31     4                 1.16                 1.16  ...              0.4512   \n",
       "32     4                 1.16                 1.16  ...              0.4534   \n",
       "33     4                 1.16                 1.16  ...              0.4503   \n",
       "34     4                 1.16                 1.16  ...              0.4460   \n",
       "35     4                 1.16                 1.16  ...              0.4542   \n",
       "36     4                 1.16                 1.16  ...              0.4544   \n",
       "37     4                 1.16                 1.16  ...              0.4479   \n",
       "38     4                 1.16                 1.16  ...              0.4515   \n",
       "39     4                 1.16                 1.16  ...              0.4515   \n",
       "40     4                 1.16                 1.16  ...              0.4509   \n",
       "41     4                 1.16                 1.16  ...              0.4504   \n",
       "42     4                 1.16                 1.16  ...              0.4553   \n",
       "43     4                 1.16                 1.16  ...              0.4449   \n",
       "44     4                 1.16                 1.16  ...              0.4511   \n",
       "45     4                 1.16                 1.16  ...              0.4561   \n",
       "46     4                 1.16                 1.16  ...              0.4518   \n",
       "47     4                 1.16                 1.16  ...              0.4532   \n",
       "48     4                 1.16                 1.16  ...              0.4569   \n",
       "49     4                 1.16                 1.16  ...              0.4540   \n",
       "50     4                 1.16                 1.16  ...              0.4576   \n",
       "51     4                 1.16                 1.16  ...              0.4560   \n",
       "52     4                 1.16                 1.16  ...              0.4573   \n",
       "\n",
       "    Retain_rate  Fusion  Seed  \\\n",
       "0          0.25   False     0   \n",
       "2          0.25   False     0   \n",
       "3          0.25   False     0   \n",
       "4          0.25   False     0   \n",
       "5          0.25   False     0   \n",
       "6          0.25   False     0   \n",
       "8          0.25   False     0   \n",
       "9          0.25   False     0   \n",
       "10         0.25   False     0   \n",
       "11         0.25   False     0   \n",
       "12         0.25   False     0   \n",
       "13         0.25   False     0   \n",
       "15         0.25   False     0   \n",
       "16         0.25   False     0   \n",
       "19         0.25   False     0   \n",
       "20         0.25   False     0   \n",
       "22         0.25   False     0   \n",
       "23         0.25   False     0   \n",
       "24         0.25   False     0   \n",
       "26         0.25   False     0   \n",
       "27         0.25   False     0   \n",
       "28         0.25   False     0   \n",
       "30         0.25   False     0   \n",
       "31         0.25   False     0   \n",
       "32         0.25   False     0   \n",
       "33         0.25   False     0   \n",
       "34         0.25   False     0   \n",
       "35         0.25   False     0   \n",
       "36         0.25   False     0   \n",
       "37         0.25   False     0   \n",
       "38         0.25   False     0   \n",
       "39         0.25   False     0   \n",
       "40         0.25   False     0   \n",
       "41         0.25   False     0   \n",
       "42         0.25   False     0   \n",
       "43         0.25   False     0   \n",
       "44         0.25   False     0   \n",
       "45         0.25   False     0   \n",
       "46         0.25   False     0   \n",
       "47         0.25   False     0   \n",
       "48         0.25   False     0   \n",
       "49         0.25   False     0   \n",
       "50         0.25   False     0   \n",
       "51         0.25   False     0   \n",
       "52         0.25   False     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "39  [np.int64(74), np.int64(11), np.int64(59), np....   \n",
       "40  [np.int64(40), np.int64(3), np.int64(43), np.i...   \n",
       "41  [np.int64(22), np.int64(40), np.int64(86), np....   \n",
       "42  [np.int64(48), np.int64(35), np.int64(26), np....   \n",
       "43  [np.int64(74), np.int64(35), np.int64(15), np....   \n",
       "44  [np.int64(65), np.int64(90), np.int64(69), np....   \n",
       "45            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "46            [0, 39, 48, 49, 52, 53, 62, 58, 61, 94]   \n",
       "47            [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "48             [0, 3, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "49             [0, 4, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "50            [0, 58, 39, 71, 52, 53, 62, 90, 61, 94]   \n",
       "51            [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "52            [0, 39, 72, 49, 52, 53, 20, 62, 58, 94]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "39  ['shrew', 'boy', 'pine_tree', 'television', 't...   68.943547  0.703137   \n",
       "40  ['lamp', 'bear', 'lion', 'forest', 'palm_tree'...   24.482168  0.459166   \n",
       "41  ['clock', 'lamp', 'telephone', 'lobster', 'leo...   63.911466  0.238287   \n",
       "42  ['motorcycle', 'girl', 'crab', 'flatfish', 'ro...   36.237008  0.142821   \n",
       "43  ['shrew', 'girl', 'camel', 'willow_tree', 'sha...   29.710575  0.399795   \n",
       "44  ['rabbit', 'train', 'rocket', 'raccoon', 'bear...   35.807582  0.185234   \n",
       "45  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "46  ['apple', 'keyboard', 'motorcycle', 'mountain'...  192.253176  0.844140   \n",
       "47  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "48  ['apple', 'bear', 'keyboard', 'mountain', 'oak...  192.253176  0.844140   \n",
       "49  ['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...  192.253176  0.844140   \n",
       "50  ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.844140   \n",
       "51  ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "52  ['apple', 'keyboard', 'seal', 'mountain', 'oak...  192.253176  0.844140   \n",
       "\n",
       "       Avg_KL  Classes Repeated  \n",
       "0    0.369210             False  \n",
       "2   66.416617             False  \n",
       "3    0.578157             False  \n",
       "4   69.558004             False  \n",
       "5   14.820982             False  \n",
       "6    8.848314             False  \n",
       "8    1.950773             False  \n",
       "9   66.299283             False  \n",
       "10  14.212071             False  \n",
       "11  21.038719             False  \n",
       "12   2.107963             False  \n",
       "13   7.046100             False  \n",
       "15   2.298235             False  \n",
       "16  66.114634             False  \n",
       "19   1.931516             False  \n",
       "20  66.564161             False  \n",
       "22  18.962063             False  \n",
       "23   0.949666             False  \n",
       "24  73.389381             False  \n",
       "26  25.333189             False  \n",
       "27   0.994000             False  \n",
       "28  67.623141             False  \n",
       "30   9.783706             False  \n",
       "31   0.669352             False  \n",
       "32  66.601175             False  \n",
       "33  17.543812             False  \n",
       "34  22.350282             False  \n",
       "35   1.885359             False  \n",
       "36  68.423650             False  \n",
       "37  17.354552             False  \n",
       "38  11.636914             False  \n",
       "39  12.946819             False  \n",
       "40   8.783600             False  \n",
       "41  12.797301             False  \n",
       "42   8.417093             False  \n",
       "43   6.765886             False  \n",
       "44  11.366363             False  \n",
       "45  73.389381             False  \n",
       "46  68.260865             False  \n",
       "47  68.148521             False  \n",
       "48  69.130501             False  \n",
       "49  67.929204             False  \n",
       "50  68.614852             False  \n",
       "51  67.253203             False  \n",
       "52  67.859487             False  \n",
       "\n",
       "[45 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df = df[df[\"Classes Repeated\"] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621a9e36-75ad-4db7-9d8e-305ecfec26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0),\n",
       " np.float64(1.2246467991473532e-16),\n",
       " np.float64(6.123233995736766e-17),\n",
       " np.float64(1.0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "cmap = colormaps['rainbow']\n",
    "cmap(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x16c78f5d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    plt.plot(df.iloc[i][[\"Min_KL\", \"Max_KL\"]], [df.iloc[i][\"Quantized Top1 Accuracy\"]] * 2, color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Min_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Max_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_375/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "072a7807-ef35-47de-807e-713dcf873518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(100):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized ResNet50 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/resnet50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e647349-11a1-48f2-bb7f-80b685680da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_375/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(80):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fc909a7-7edb-48b6-a0ad-876549adac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(80):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b67a379b-ea0d-41f1-8e05-11ab681a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(80):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a59db2-c5d9-448d-bd08-831468fc95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Median KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized ResNet50 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/resnet50_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e03bc03e-1a1c-43ae-bc01-15060dca5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.917</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.309007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.911</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "      <td>False</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.431084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.176886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.955</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.996</td>\n",
       "      <td>6.435661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "      <td>48.794365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "      <td>False</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.996</td>\n",
       "      <td>11.245003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "      <td>False</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.998</td>\n",
       "      <td>18.305028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.881019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>3.904329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.995</td>\n",
       "      <td>2.015194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>46.540651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.563030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "      <td>False</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "      <td>False</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.997</td>\n",
       "      <td>11.365514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.906</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.782209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.999</td>\n",
       "      <td>68.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "      <td>False</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.994</td>\n",
       "      <td>16.188352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.910</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.767096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>62.712475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.952</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "      <td>False</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4.917178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.909</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>False</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.600811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.000</td>\n",
       "      <td>46.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "      <td>False</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.116350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "      <td>12.299855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.417347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.995</td>\n",
       "      <td>16.034085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "      <td>False</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.994</td>\n",
       "      <td>8.859941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.957</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(11), np.int64(59), np....</td>\n",
       "      <td>['shrew', 'boy', 'pine_tree', 'television', 't...</td>\n",
       "      <td>68.943547</td>\n",
       "      <td>0.703137</td>\n",
       "      <td>12.946819</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.995</td>\n",
       "      <td>8.363780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.959</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(3), np.int64(43), np.i...</td>\n",
       "      <td>['lamp', 'bear', 'lion', 'forest', 'palm_tree'...</td>\n",
       "      <td>24.482168</td>\n",
       "      <td>0.459166</td>\n",
       "      <td>8.783600</td>\n",
       "      <td>False</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.285556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.956</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(22), np.int64(40), np.int64(86), np....</td>\n",
       "      <td>['clock', 'lamp', 'telephone', 'lobster', 'leo...</td>\n",
       "      <td>63.911466</td>\n",
       "      <td>0.238287</td>\n",
       "      <td>12.797301</td>\n",
       "      <td>False</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.995</td>\n",
       "      <td>8.649378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(48), np.int64(35), np.int64(26), np....</td>\n",
       "      <td>['motorcycle', 'girl', 'crab', 'flatfish', 'ro...</td>\n",
       "      <td>36.237008</td>\n",
       "      <td>0.142821</td>\n",
       "      <td>8.417093</td>\n",
       "      <td>False</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.974991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.949</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(35), np.int64(15), np....</td>\n",
       "      <td>['shrew', 'girl', 'camel', 'willow_tree', 'sha...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>6.765886</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4.689097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.965</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(65), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['rabbit', 'train', 'rocket', 'raccoon', 'bear...</td>\n",
       "      <td>35.807582</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>11.366363</td>\n",
       "      <td>False</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.387416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "      <td>68.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 48, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'motorcycle', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.260865</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>54.749677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.999</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'bear', 'keyboard', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.130501</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.929204</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 52, 53, 62, 90, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.614852</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>57.309081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 72, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'seal', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.859487</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.999</td>\n",
       "      <td>61.625243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                   0.815   \n",
       "1    resnet50  CIFAR100                       64                   0.863   \n",
       "2    resnet50  CIFAR100                       64                   0.799   \n",
       "3    resnet50  CIFAR100                       64                   0.887   \n",
       "4    resnet50  CIFAR100                       64                   0.797   \n",
       "5    resnet50  CIFAR100                       64                   0.830   \n",
       "6    resnet50  CIFAR100                       64                   0.767   \n",
       "7    resnet50  CIFAR100                       64                   0.867   \n",
       "8    resnet50  CIFAR100                       64                   0.834   \n",
       "9    resnet50  CIFAR100                       64                   0.840   \n",
       "10   resnet50  CIFAR100                       64                   0.821   \n",
       "11   resnet50  CIFAR100                       64                   0.775   \n",
       "12   resnet50  CIFAR100                       64                   0.808   \n",
       "13   resnet50  CIFAR100                       64                   0.877   \n",
       "14   resnet50  CIFAR100                       64                   0.823   \n",
       "15   resnet50  CIFAR100                       64                   0.871   \n",
       "16   resnet50  CIFAR100                       64                   0.845   \n",
       "17   resnet50  CIFAR100                       64                   0.746   \n",
       "18   resnet50  CIFAR100                       64                   0.873   \n",
       "19   resnet50  CIFAR100                       64                   0.848   \n",
       "20   resnet50  CIFAR100                       64                   0.771   \n",
       "21   resnet50  CIFAR100                       64                   0.872   \n",
       "22   resnet50  CIFAR100                       64                   0.826   \n",
       "23   resnet50  CIFAR100                       64                   0.781   \n",
       "24   resnet50  CIFAR100                       64                   0.861   \n",
       "25   resnet50  CIFAR100                       64                   0.806   \n",
       "26   resnet50  CIFAR100                       64                   0.848   \n",
       "27   resnet50  CIFAR100                       64                   0.884   \n",
       "28   resnet50  CIFAR100                       64                   0.879   \n",
       "29   resnet50  CIFAR100                       64                   0.831   \n",
       "30   resnet50  CIFAR100                       64                   0.779   \n",
       "31   resnet50  CIFAR100                       64                   0.793   \n",
       "32   resnet50  CIFAR100                       64                   0.820   \n",
       "33   resnet50  CIFAR100                       64                   0.819   \n",
       "34   resnet50  CIFAR100                       64                   0.838   \n",
       "35   resnet50  CIFAR100                       64                   0.762   \n",
       "36   resnet50  CIFAR100                       64                   0.859   \n",
       "37   resnet50  CIFAR100                       64                   0.873   \n",
       "38   resnet50  CIFAR100                       64                   0.879   \n",
       "39   resnet50  CIFAR100                       64                   0.875   \n",
       "40   resnet50  CIFAR100                       64                   0.872   \n",
       "41   resnet50  CIFAR100                       64                   0.863   \n",
       "42   resnet50  CIFAR100                       64                   0.883   \n",
       "43   resnet50  CIFAR100                       64                   0.874   \n",
       "44   resnet50  CIFAR100                       64                   0.856   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.603                   0.949                    0.917   \n",
       "1                     0.843                   0.983                    0.989   \n",
       "2                     0.615                   0.951                    0.911   \n",
       "3                     0.944                   0.988                    0.995   \n",
       "4                     0.830                   0.973                    0.974   \n",
       "5                     0.737                   0.968                    0.955   \n",
       "6                     0.693                   0.961                    0.975   \n",
       "7                     0.946                   0.986                    0.995   \n",
       "8                     0.808                   0.968                    0.974   \n",
       "9                     0.884                   0.974                    0.988   \n",
       "10                    0.794                   0.968                    0.963   \n",
       "11                    0.681                   0.964                    0.974   \n",
       "12                    0.734                   0.986                    0.984   \n",
       "13                    0.957                   0.988                    0.995   \n",
       "14                    0.753                   0.963                    0.958   \n",
       "15                    0.936                   0.988                    0.992   \n",
       "16                    0.876                   0.972                    0.958   \n",
       "17                    0.520                   0.939                    0.906   \n",
       "18                    0.932                   0.986                    0.989   \n",
       "19                    0.866                   0.973                    0.988   \n",
       "20                    0.556                   0.950                    0.910   \n",
       "21                    0.944                   0.988                    0.993   \n",
       "22                    0.712                   0.952                    0.952   \n",
       "23                    0.566                   0.946                    0.909   \n",
       "24                    0.930                   0.985                    0.983   \n",
       "25                    0.869                   0.965                    0.988   \n",
       "26                    0.793                   0.974                    0.981   \n",
       "27                    0.754                   0.981                    0.972   \n",
       "28                    0.962                   0.987                    0.992   \n",
       "29                    0.790                   0.952                    0.972   \n",
       "30                    0.802                   0.968                    0.958   \n",
       "31                    0.782                   0.969                    0.957   \n",
       "32                    0.765                   0.966                    0.959   \n",
       "33                    0.804                   0.956                    0.956   \n",
       "34                    0.776                   0.976                    0.976   \n",
       "35                    0.636                   0.964                    0.949   \n",
       "36                    0.799                   0.968                    0.965   \n",
       "37                    0.942                   0.986                    0.986   \n",
       "38                    0.959                   0.989                    0.996   \n",
       "39                    0.936                   0.989                    0.995   \n",
       "40                    0.943                   0.988                    0.990   \n",
       "41                    0.951                   0.982                    0.993   \n",
       "42                    0.924                   0.989                    0.990   \n",
       "43                    0.943                   0.987                    0.993   \n",
       "44                    0.931                   0.979                    0.993   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "14     4                 1.16                 1.16  ...     0   \n",
       "15     4                 1.16                 1.16  ...     0   \n",
       "16     4                 1.16                 1.16  ...     0   \n",
       "17     4                 1.16                 1.16  ...     0   \n",
       "18     4                 1.16                 1.16  ...     0   \n",
       "19     4                 1.16                 1.16  ...     0   \n",
       "20     4                 1.16                 1.16  ...     0   \n",
       "21     4                 1.16                 1.16  ...     0   \n",
       "22     4                 1.16                 1.16  ...     0   \n",
       "23     4                 1.16                 1.16  ...     0   \n",
       "24     4                 1.16                 1.16  ...     0   \n",
       "25     4                 1.16                 1.16  ...     0   \n",
       "26     4                 1.16                 1.16  ...     0   \n",
       "27     4                 1.16                 1.16  ...     0   \n",
       "28     4                 1.16                 1.16  ...     0   \n",
       "29     4                 1.16                 1.16  ...     0   \n",
       "30     4                 1.16                 1.16  ...     0   \n",
       "31     4                 1.16                 1.16  ...     0   \n",
       "32     4                 1.16                 1.16  ...     0   \n",
       "33     4                 1.16                 1.16  ...     0   \n",
       "34     4                 1.16                 1.16  ...     0   \n",
       "35     4                 1.16                 1.16  ...     0   \n",
       "36     4                 1.16                 1.16  ...     0   \n",
       "37     4                 1.16                 1.16  ...     0   \n",
       "38     4                 1.16                 1.16  ...     0   \n",
       "39     4                 1.16                 1.16  ...     0   \n",
       "40     4                 1.16                 1.16  ...     0   \n",
       "41     4                 1.16                 1.16  ...     0   \n",
       "42     4                 1.16                 1.16  ...     0   \n",
       "43     4                 1.16                 1.16  ...     0   \n",
       "44     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "1             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "2              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "3             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "4   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "5   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "6            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "7             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "8   [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "9   [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "10             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "11  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "12           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "13            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "14              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "15             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "16  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "17            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "18            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "19  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "20             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "21            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "22  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "23             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "24            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "25  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "26  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "27           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "28            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "29  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "30  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "31  [np.int64(74), np.int64(11), np.int64(59), np....   \n",
       "32  [np.int64(40), np.int64(3), np.int64(43), np.i...   \n",
       "33  [np.int64(22), np.int64(40), np.int64(86), np....   \n",
       "34  [np.int64(48), np.int64(35), np.int64(26), np....   \n",
       "35  [np.int64(74), np.int64(35), np.int64(15), np....   \n",
       "36  [np.int64(65), np.int64(90), np.int64(69), np....   \n",
       "37            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "38            [0, 39, 48, 49, 52, 53, 62, 58, 61, 94]   \n",
       "39            [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "40             [0, 3, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "41             [0, 4, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "42            [0, 58, 39, 71, 52, 53, 62, 90, 61, 94]   \n",
       "43            [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "44            [0, 39, 72, 49, 52, 53, 20, 62, 58, 94]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "1   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "2   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "3   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "4   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "5   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "6   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "7   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "8   ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "9   ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "10  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "11  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "12  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "13  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "14  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "15  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "16  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "17  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "18  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "19  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "20  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "21  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "22  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "23  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "24  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "25  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "26  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "27  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "28  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "29  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "30  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "31  ['shrew', 'boy', 'pine_tree', 'television', 't...   68.943547  0.703137   \n",
       "32  ['lamp', 'bear', 'lion', 'forest', 'palm_tree'...   24.482168  0.459166   \n",
       "33  ['clock', 'lamp', 'telephone', 'lobster', 'leo...   63.911466  0.238287   \n",
       "34  ['motorcycle', 'girl', 'crab', 'flatfish', 'ro...   36.237008  0.142821   \n",
       "35  ['shrew', 'girl', 'camel', 'willow_tree', 'sha...   29.710575  0.399795   \n",
       "36  ['rabbit', 'train', 'rocket', 'raccoon', 'bear...   35.807582  0.185234   \n",
       "37  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "38  ['apple', 'keyboard', 'motorcycle', 'mountain'...  192.253176  0.844140   \n",
       "39  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "40  ['apple', 'bear', 'keyboard', 'mountain', 'oak...  192.253176  0.844140   \n",
       "41  ['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...  192.253176  0.844140   \n",
       "42  ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.844140   \n",
       "43  ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "44  ['apple', 'keyboard', 'seal', 'mountain', 'oak...  192.253176  0.844140   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0    0.369210             False                  0.898                  0.992   \n",
       "1   66.416617             False                  0.979                  1.000   \n",
       "2    0.578157             False                  0.873                  0.985   \n",
       "3   69.558004             False                  0.983                  0.998   \n",
       "4   14.820982             False                  0.952                  0.996   \n",
       "5    8.848314             False                  0.955                  0.996   \n",
       "6    1.950773             False                  0.839                  0.993   \n",
       "7   66.299283             False                  0.984                  0.999   \n",
       "8   14.212071             False                  0.931                  0.996   \n",
       "9   21.038719             False                  0.960                  0.998   \n",
       "10   2.107963             False                  0.915                  0.998   \n",
       "11   7.046100             False                  0.901                  0.992   \n",
       "12   2.298235             False                  0.856                  0.995   \n",
       "13  66.114634             False                  0.983                  1.000   \n",
       "14   1.931516             False                  0.896                  0.993   \n",
       "15  66.564161             False                  0.976                  1.000   \n",
       "16  18.962063             False                  0.968                  0.997   \n",
       "17   0.949666             False                  0.831                  0.985   \n",
       "18  73.389381             False                  0.985                  0.999   \n",
       "19  25.333189             False                  0.943                  0.994   \n",
       "20   0.994000             False                  0.853                  0.982   \n",
       "21  67.623141             False                  0.980                  0.998   \n",
       "22   9.783706             False                  0.919                  0.994   \n",
       "23   0.669352             False                  0.854                  0.978   \n",
       "24  66.601175             False                  0.982                  1.000   \n",
       "25  17.543812             False                  0.958                  1.000   \n",
       "26  22.350282             False                  0.955                  0.999   \n",
       "27   1.885359             False                  0.903                  0.992   \n",
       "28  68.423650             False                  0.983                  1.000   \n",
       "29  17.354552             False                  0.952                  0.995   \n",
       "30  11.636914             False                  0.946                  0.994   \n",
       "31  12.946819             False                  0.947                  0.995   \n",
       "32   8.783600             False                  0.954                  0.996   \n",
       "33  12.797301             False                  0.945                  0.995   \n",
       "34   8.417093             False                  0.935                  0.996   \n",
       "35   6.765886             False                  0.915                  0.993   \n",
       "36  11.366363             False                  0.944                  0.996   \n",
       "37  73.389381             False                  0.984                  0.999   \n",
       "38  68.260865             False                  0.986                  1.000   \n",
       "39  68.148521             False                  0.972                  0.999   \n",
       "40  69.130501             False                  0.979                  0.998   \n",
       "41  67.929204             False                  0.981                  0.999   \n",
       "42  68.614852             False                  0.986                  1.000   \n",
       "43  67.253203             False                  0.977                  1.000   \n",
       "44  67.859487             False                  0.983                  0.999   \n",
       "\n",
       "    Median_KL  \n",
       "0    0.309007  \n",
       "1   49.097501  \n",
       "2    0.431084  \n",
       "3   66.980437  \n",
       "4    8.176886  \n",
       "5    6.435661  \n",
       "6    1.666552  \n",
       "7   48.794365  \n",
       "8   11.245003  \n",
       "9   18.305028  \n",
       "10   1.881019  \n",
       "11   3.904329  \n",
       "12   2.015194  \n",
       "13  46.540651  \n",
       "14   1.563030  \n",
       "15  49.097501  \n",
       "16  11.365514  \n",
       "17   0.782209  \n",
       "18  68.004669  \n",
       "19  16.188352  \n",
       "20   0.767096  \n",
       "21  62.712475  \n",
       "22   4.917178  \n",
       "23   0.600811  \n",
       "24  46.604676  \n",
       "25  15.116350  \n",
       "26  12.299855  \n",
       "27   1.417347  \n",
       "28  50.328013  \n",
       "29  16.034085  \n",
       "30   8.859941  \n",
       "31   8.363780  \n",
       "32   8.285556  \n",
       "33   8.649378  \n",
       "34   5.974991  \n",
       "35   4.689097  \n",
       "36   8.387416  \n",
       "37  68.004669  \n",
       "38  54.749677  \n",
       "39  60.747142  \n",
       "40  66.877609  \n",
       "41  49.097501  \n",
       "42  57.309081  \n",
       "43  49.097501  \n",
       "44  61.625243  \n",
       "\n",
       "[45 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.898 0.992]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.873 0.985]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.952 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.955 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.839 0.993]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.931 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.96  0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.901 0.992]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.856 0.995]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.896 0.993]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.976 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.968 0.997]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.831 0.985]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.985 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.943 0.994]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.853 0.982]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.919 0.994]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.854 0.978]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.982 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.958 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.955 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.903 0.992]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.952 0.995]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.946 0.994]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.947 0.995]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.954 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.945 0.995]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.935 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.993]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.944 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.986 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.972 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.986 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.977 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "# from data_loaders import data_loader\n",
    "# from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 64\n",
    "\n",
    "# topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "\n",
    "#     model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "#     model.to(device)  \n",
    "#     train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset = subset)\n",
    "\n",
    "# # ===========\n",
    "# #  CODE HERE\n",
    "# # ===========\n",
    "\n",
    "#     model.eval() \n",
    "#     original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "#     # maxk = max(topk)\n",
    "#     # topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "#     # correct_mat = []\n",
    "#     # for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     #     with torch.no_grad():\n",
    "#     #         y_pred = model(x_test.to(device))\n",
    "#     #     topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "#     #     target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "#     #     correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# # break    \n",
    "# # acc_items += [original_topk_accuracy]\n",
    "\n",
    "# # df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# # df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# # df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# # print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n",
    "\n",
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 5  # Set the number of fine-tuning epochs\n",
    "learning_rate = 1e-4  # Fine-tuning learning rate\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = [stage.item() if hasattr(stage, \"item\") else stage for stage in subset_stage]\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "    model.to(device)  \n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset=subset)\n",
    "\n",
    "    # Define optimizer & loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate after fine-tuning\n",
    "    model.eval()\n",
    "    original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "    print(f\"Top-1 and Top-5 Accuracy after fine-tuning: {original_topk_accuracy}\")\n",
    "\n",
    "    acc_items += [original_topk_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c97c08-e8f2-4e8a-ba26-12b49693d284",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_text = \"\"\"Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.89it/s]\n",
    "Epoch [1/5] - Loss: 0.1697\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.94it/s]\n",
    "Epoch [2/5] - Loss: 0.0341\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.92it/s]\n",
    "Epoch [3/5] - Loss: 0.0186\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.92it/s]\n",
    "Epoch [4/5] - Loss: 0.0149\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.90it/s]\n",
    "Epoch [5/5] - Loss: 0.0205\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.898 0.992]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.90it/s]\n",
    "Epoch [1/5] - Loss: 0.0909\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [2/5] - Loss: 0.0150\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0155\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0082\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [5/5] - Loss: 0.0091\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.77it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [1/5] - Loss: 0.2346\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [2/5] - Loss: 0.0319\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0162\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0121\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0137\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.66it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.873 0.985]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [1/5] - Loss: 0.0988\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [2/5] - Loss: 0.0165\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [3/5] - Loss: 0.0068\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [4/5] - Loss: 0.0075\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [5/5] - Loss: 0.0102\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.78it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.1025\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [2/5] - Loss: 0.0189\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [3/5] - Loss: 0.0164\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [4/5] - Loss: 0.0145\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [5/5] - Loss: 0.0139\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.42it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.952 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.0955\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [2/5] - Loss: 0.0204\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0154\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0072\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0127\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.38it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.955 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2173\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0382\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0390\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0357\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0155\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.74it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.839 0.993]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [1/5] - Loss: 0.1132\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0162\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0169\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0153\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0123\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.60it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [1/5] - Loss: 0.0998\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0185\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [3/5] - Loss: 0.0118\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0105\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0140\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.71it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.931 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [1/5] - Loss: 0.0956\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0172\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0129\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n",
    "Epoch [4/5] - Loss: 0.0148\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n",
    "Epoch [5/5] - Loss: 0.0075\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.06it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.96  0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [1/5] - Loss: 0.2456\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0282\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0088\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0085\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0162\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1429\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n",
    "Epoch [2/5] - Loss: 0.0323\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [3/5] - Loss: 0.0186\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [4/5] - Loss: 0.0146\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [5/5] - Loss: 0.0128\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.901 0.992]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [1/5] - Loss: 0.3497\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0565\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [3/5] - Loss: 0.0359\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0349\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.72it/s]\n",
    "Epoch [5/5] - Loss: 0.0394\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.856 0.995]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [1/5] - Loss: 0.0981\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [2/5] - Loss: 0.0204\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n",
    "Epoch [3/5] - Loss: 0.0142\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.71it/s]\n",
    "Epoch [4/5] - Loss: 0.0091\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n",
    "Epoch [5/5] - Loss: 0.0057\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.90it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [1/5] - Loss: 0.3086\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [2/5] - Loss: 0.0445\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0324\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [4/5] - Loss: 0.0331\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [5/5] - Loss: 0.0363\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.896 0.993]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [1/5] - Loss: 0.1042\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [2/5] - Loss: 0.0252\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n",
    "Epoch [3/5] - Loss: 0.0169\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n",
    "Epoch [4/5] - Loss: 0.0164\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [5/5] - Loss: 0.0107\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.976 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [1/5] - Loss: 0.0789\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0154\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0277\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0198\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0271\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.49it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.968 0.997]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2126\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0338\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [3/5] - Loss: 0.0295\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [4/5] - Loss: 0.0207\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [5/5] - Loss: 0.0215\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.45it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.831 0.985]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [1/5] - Loss: 0.1013\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [2/5] - Loss: 0.0220\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [3/5] - Loss: 0.0189\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0089\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n",
    "Epoch [5/5] - Loss: 0.0173\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.985 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [1/5] - Loss: 0.1751\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [2/5] - Loss: 0.0272\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n",
    "Epoch [3/5] - Loss: 0.0188\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0132\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [5/5] - Loss: 0.0111\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.943 0.994]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2478\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0380\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0394\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.76it/s]\n",
    "Epoch [4/5] - Loss: 0.0354\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0181\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.853 0.982]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [1/5] - Loss: 0.0944\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
    "Epoch [2/5] - Loss: 0.0192\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [3/5] - Loss: 0.0123\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:21<00:00,  3.73it/s]\n",
    "Epoch [4/5] - Loss: 0.0216\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n",
    "Epoch [5/5] - Loss: 0.0309\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.55it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.1089\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0193\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0226\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [4/5] - Loss: 0.0403\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [5/5] - Loss: 0.0199\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.09it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.919 0.994]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.2541\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [2/5] - Loss: 0.0365\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [3/5] - Loss: 0.0196\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0209\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [5/5] - Loss: 0.0264\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.854 0.978]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [1/5] - Loss: 0.1026\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [2/5] - Loss: 0.0124\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0127\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0063\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [5/5] - Loss: 0.0136\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.77it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.982 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [1/5] - Loss: 0.0795\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [2/5] - Loss: 0.0182\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0078\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [4/5] - Loss: 0.0159\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0156\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.10it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.958 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [1/5] - Loss: 0.1087\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [2/5] - Loss: 0.0207\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0104\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0099\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0140\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.84it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.955 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.3290\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0312\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [3/5] - Loss: 0.0178\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [4/5] - Loss: 0.0369\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [5/5] - Loss: 0.0242\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.12it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.903 0.992]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.1122\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [2/5] - Loss: 0.0138\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0114\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [4/5] - Loss: 0.0103\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [5/5] - Loss: 0.0114\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.68it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [1/5] - Loss: 0.1155\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [2/5] - Loss: 0.0240\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0120\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n",
    "Epoch [4/5] - Loss: 0.0140\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [5/5] - Loss: 0.0247\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.80it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.952 0.995]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [1/5] - Loss: 0.0972\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [2/5] - Loss: 0.0219\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [3/5] - Loss: 0.0153\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0258\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
    "Epoch [5/5] - Loss: 0.0373\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.40it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.946 0.994]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [1/5] - Loss: 0.0996\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [2/5] - Loss: 0.0245\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [3/5] - Loss: 0.0168\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0176\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [5/5] - Loss: 0.0122\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.70it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.947 0.995]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.0951\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0196\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0110\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0144\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0135\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.04it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.954 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.1095\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [2/5] - Loss: 0.0218\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0195\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0140\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0104\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.49it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.945 0.995]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.1185\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0205\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [3/5] - Loss: 0.0180\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0162\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0167\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.85it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.935 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [1/5] - Loss: 0.1151\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [2/5] - Loss: 0.0242\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0248\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [4/5] - Loss: 0.0212\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0109\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.31it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.993]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.0999\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n",
    "Epoch [2/5] - Loss: 0.0137\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0112\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0097\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0094\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.47it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.944 0.996]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.1141\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0091\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [3/5] - Loss: 0.0168\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0239\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0160\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.94it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.1181\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0138\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [3/5] - Loss: 0.0084\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [4/5] - Loss: 0.0289\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [5/5] - Loss: 0.0184\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.99it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.986 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.1466\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [2/5] - Loss: 0.0274\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [3/5] - Loss: 0.0145\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [4/5] - Loss: 0.0156\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0203\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.23it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.972 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [1/5] - Loss: 0.0836\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [2/5] - Loss: 0.0114\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0106\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0096\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [5/5] - Loss: 0.0206\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.88it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.0793\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [2/5] - Loss: 0.0099\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0059\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n",
    "Epoch [4/5] - Loss: 0.0129\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0299\n",
    "100%|██████████| 16/16 [00:01<00:00,  8.43it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.1317\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0236\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0147\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [4/5] - Loss: 0.0088\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0077\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.02it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.986 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n",
    "Epoch [1/5] - Loss: 0.0865\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [2/5] - Loss: 0.0228\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [3/5] - Loss: 0.0229\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0119\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
    "Epoch [5/5] - Loss: 0.0092\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.42it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.977 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [1/5] - Loss: 0.0839\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [2/5] - Loss: 0.0112\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [3/5] - Loss: 0.0167\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n",
    "Epoch [4/5] - Loss: 0.0140\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n",
    "Epoch [5/5] - Loss: 0.0070\n",
    "100%|██████████| 16/16 [00:01<00:00,  9.43it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.999]\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "extracted = re.findall(r\"\\[[01]{1}.[0-9 ]{3} [01]{1}.[0-9 ]{3}\\]\", raw_text)\n",
    "data = list(map(lambda x: [float(x[1:6]), float(x[7:12])], extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1879a6f-3f42-4c8f-bef8-b7a537282650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Trained Top1 Accuracy\", \"Trained Top5 Accuracy\"]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d20aacbe-ec3d-4a21-a92d-82bb75e69a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Fusion</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.917</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.911</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "      <td>False</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.955</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "      <td>False</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "      <td>False</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "      <td>False</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "      <td>False</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.906</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "      <td>False</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.910</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.952</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "      <td>False</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.909</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>False</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "      <td>False</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "      <td>False</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.957</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(11), np.int64(59), np....</td>\n",
       "      <td>['shrew', 'boy', 'pine_tree', 'television', 't...</td>\n",
       "      <td>68.943547</td>\n",
       "      <td>0.703137</td>\n",
       "      <td>12.946819</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.959</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(3), np.int64(43), np.i...</td>\n",
       "      <td>['lamp', 'bear', 'lion', 'forest', 'palm_tree'...</td>\n",
       "      <td>24.482168</td>\n",
       "      <td>0.459166</td>\n",
       "      <td>8.783600</td>\n",
       "      <td>False</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.956</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(22), np.int64(40), np.int64(86), np....</td>\n",
       "      <td>['clock', 'lamp', 'telephone', 'lobster', 'leo...</td>\n",
       "      <td>63.911466</td>\n",
       "      <td>0.238287</td>\n",
       "      <td>12.797301</td>\n",
       "      <td>False</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(48), np.int64(35), np.int64(26), np....</td>\n",
       "      <td>['motorcycle', 'girl', 'crab', 'flatfish', 'ro...</td>\n",
       "      <td>36.237008</td>\n",
       "      <td>0.142821</td>\n",
       "      <td>8.417093</td>\n",
       "      <td>False</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.949</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(35), np.int64(15), np....</td>\n",
       "      <td>['shrew', 'girl', 'camel', 'willow_tree', 'sha...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>6.765886</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.965</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(65), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['rabbit', 'train', 'rocket', 'raccoon', 'bear...</td>\n",
       "      <td>35.807582</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>11.366363</td>\n",
       "      <td>False</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 48, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'motorcycle', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.260865</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'bear', 'keyboard', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.130501</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.929204</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 52, 53, 62, 90, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.614852</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 72, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'seal', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.859487</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                   0.815   \n",
       "2    resnet50  CIFAR100                       64                   0.863   \n",
       "3    resnet50  CIFAR100                       64                   0.799   \n",
       "4    resnet50  CIFAR100                       64                   0.887   \n",
       "5    resnet50  CIFAR100                       64                   0.797   \n",
       "6    resnet50  CIFAR100                       64                   0.830   \n",
       "8    resnet50  CIFAR100                       64                   0.767   \n",
       "9    resnet50  CIFAR100                       64                   0.867   \n",
       "10   resnet50  CIFAR100                       64                   0.834   \n",
       "11   resnet50  CIFAR100                       64                   0.840   \n",
       "12   resnet50  CIFAR100                       64                   0.821   \n",
       "13   resnet50  CIFAR100                       64                   0.775   \n",
       "15   resnet50  CIFAR100                       64                   0.808   \n",
       "16   resnet50  CIFAR100                       64                   0.877   \n",
       "19   resnet50  CIFAR100                       64                   0.823   \n",
       "20   resnet50  CIFAR100                       64                   0.871   \n",
       "22   resnet50  CIFAR100                       64                   0.845   \n",
       "23   resnet50  CIFAR100                       64                   0.746   \n",
       "24   resnet50  CIFAR100                       64                   0.873   \n",
       "26   resnet50  CIFAR100                       64                   0.848   \n",
       "27   resnet50  CIFAR100                       64                   0.771   \n",
       "28   resnet50  CIFAR100                       64                   0.872   \n",
       "30   resnet50  CIFAR100                       64                   0.826   \n",
       "31   resnet50  CIFAR100                       64                   0.781   \n",
       "32   resnet50  CIFAR100                       64                   0.861   \n",
       "33   resnet50  CIFAR100                       64                   0.806   \n",
       "34   resnet50  CIFAR100                       64                   0.848   \n",
       "35   resnet50  CIFAR100                       64                   0.884   \n",
       "36   resnet50  CIFAR100                       64                   0.879   \n",
       "37   resnet50  CIFAR100                       64                   0.831   \n",
       "38   resnet50  CIFAR100                       64                   0.779   \n",
       "39   resnet50  CIFAR100                       64                   0.793   \n",
       "40   resnet50  CIFAR100                       64                   0.820   \n",
       "41   resnet50  CIFAR100                       64                   0.819   \n",
       "42   resnet50  CIFAR100                       64                   0.838   \n",
       "43   resnet50  CIFAR100                       64                   0.762   \n",
       "44   resnet50  CIFAR100                       64                   0.859   \n",
       "45   resnet50  CIFAR100                       64                   0.873   \n",
       "46   resnet50  CIFAR100                       64                   0.879   \n",
       "47   resnet50  CIFAR100                       64                   0.875   \n",
       "48   resnet50  CIFAR100                       64                   0.872   \n",
       "49   resnet50  CIFAR100                       64                   0.863   \n",
       "50   resnet50  CIFAR100                       64                   0.883   \n",
       "51   resnet50  CIFAR100                       64                   0.874   \n",
       "52   resnet50  CIFAR100                       64                   0.856   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.603                   0.949                    0.917   \n",
       "2                     0.843                   0.983                    0.989   \n",
       "3                     0.615                   0.951                    0.911   \n",
       "4                     0.944                   0.988                    0.995   \n",
       "5                     0.830                   0.973                    0.974   \n",
       "6                     0.737                   0.968                    0.955   \n",
       "8                     0.693                   0.961                    0.975   \n",
       "9                     0.946                   0.986                    0.995   \n",
       "10                    0.808                   0.968                    0.974   \n",
       "11                    0.884                   0.974                    0.988   \n",
       "12                    0.794                   0.968                    0.963   \n",
       "13                    0.681                   0.964                    0.974   \n",
       "15                    0.734                   0.986                    0.984   \n",
       "16                    0.957                   0.988                    0.995   \n",
       "19                    0.753                   0.963                    0.958   \n",
       "20                    0.936                   0.988                    0.992   \n",
       "22                    0.876                   0.972                    0.958   \n",
       "23                    0.520                   0.939                    0.906   \n",
       "24                    0.932                   0.986                    0.989   \n",
       "26                    0.866                   0.973                    0.988   \n",
       "27                    0.556                   0.950                    0.910   \n",
       "28                    0.944                   0.988                    0.993   \n",
       "30                    0.712                   0.952                    0.952   \n",
       "31                    0.566                   0.946                    0.909   \n",
       "32                    0.930                   0.985                    0.983   \n",
       "33                    0.869                   0.965                    0.988   \n",
       "34                    0.793                   0.974                    0.981   \n",
       "35                    0.754                   0.981                    0.972   \n",
       "36                    0.962                   0.987                    0.992   \n",
       "37                    0.790                   0.952                    0.972   \n",
       "38                    0.802                   0.968                    0.958   \n",
       "39                    0.782                   0.969                    0.957   \n",
       "40                    0.765                   0.966                    0.959   \n",
       "41                    0.804                   0.956                    0.956   \n",
       "42                    0.776                   0.976                    0.976   \n",
       "43                    0.636                   0.964                    0.949   \n",
       "44                    0.799                   0.968                    0.965   \n",
       "45                    0.942                   0.986                    0.986   \n",
       "46                    0.959                   0.989                    0.996   \n",
       "47                    0.936                   0.989                    0.995   \n",
       "48                    0.943                   0.988                    0.990   \n",
       "49                    0.951                   0.982                    0.993   \n",
       "50                    0.924                   0.989                    0.990   \n",
       "51                    0.943                   0.987                    0.993   \n",
       "52                    0.931                   0.979                    0.993   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Fusion  Seed  \\\n",
       "0      4                 1.16                 1.16  ...   False     0   \n",
       "2      4                 1.16                 1.16  ...   False     0   \n",
       "3      4                 1.16                 1.16  ...   False     0   \n",
       "4      4                 1.16                 1.16  ...   False     0   \n",
       "5      4                 1.16                 1.16  ...   False     0   \n",
       "6      4                 1.16                 1.16  ...   False     0   \n",
       "8      4                 1.16                 1.16  ...   False     0   \n",
       "9      4                 1.16                 1.16  ...   False     0   \n",
       "10     4                 1.16                 1.16  ...   False     0   \n",
       "11     4                 1.16                 1.16  ...   False     0   \n",
       "12     4                 1.16                 1.16  ...   False     0   \n",
       "13     4                 1.16                 1.16  ...   False     0   \n",
       "15     4                 1.16                 1.16  ...   False     0   \n",
       "16     4                 1.16                 1.16  ...   False     0   \n",
       "19     4                 1.16                 1.16  ...   False     0   \n",
       "20     4                 1.16                 1.16  ...   False     0   \n",
       "22     4                 1.16                 1.16  ...   False     0   \n",
       "23     4                 1.16                 1.16  ...   False     0   \n",
       "24     4                 1.16                 1.16  ...   False     0   \n",
       "26     4                 1.16                 1.16  ...   False     0   \n",
       "27     4                 1.16                 1.16  ...   False     0   \n",
       "28     4                 1.16                 1.16  ...   False     0   \n",
       "30     4                 1.16                 1.16  ...   False     0   \n",
       "31     4                 1.16                 1.16  ...   False     0   \n",
       "32     4                 1.16                 1.16  ...   False     0   \n",
       "33     4                 1.16                 1.16  ...   False     0   \n",
       "34     4                 1.16                 1.16  ...   False     0   \n",
       "35     4                 1.16                 1.16  ...   False     0   \n",
       "36     4                 1.16                 1.16  ...   False     0   \n",
       "37     4                 1.16                 1.16  ...   False     0   \n",
       "38     4                 1.16                 1.16  ...   False     0   \n",
       "39     4                 1.16                 1.16  ...   False     0   \n",
       "40     4                 1.16                 1.16  ...   False     0   \n",
       "41     4                 1.16                 1.16  ...   False     0   \n",
       "42     4                 1.16                 1.16  ...   False     0   \n",
       "43     4                 1.16                 1.16  ...   False     0   \n",
       "44     4                 1.16                 1.16  ...   False     0   \n",
       "45     4                 1.16                 1.16  ...   False     0   \n",
       "46     4                 1.16                 1.16  ...   False     0   \n",
       "47     4                 1.16                 1.16  ...   False     0   \n",
       "48     4                 1.16                 1.16  ...   False     0   \n",
       "49     4                 1.16                 1.16  ...   False     0   \n",
       "50     4                 1.16                 1.16  ...   False     0   \n",
       "51     4                 1.16                 1.16  ...   False     0   \n",
       "52     4                 1.16                 1.16  ...   False     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "39  [np.int64(74), np.int64(11), np.int64(59), np....   \n",
       "40  [np.int64(40), np.int64(3), np.int64(43), np.i...   \n",
       "41  [np.int64(22), np.int64(40), np.int64(86), np....   \n",
       "42  [np.int64(48), np.int64(35), np.int64(26), np....   \n",
       "43  [np.int64(74), np.int64(35), np.int64(15), np....   \n",
       "44  [np.int64(65), np.int64(90), np.int64(69), np....   \n",
       "45            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "46            [0, 39, 48, 49, 52, 53, 62, 58, 61, 94]   \n",
       "47            [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "48             [0, 3, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "49             [0, 4, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "50            [0, 58, 39, 71, 52, 53, 62, 90, 61, 94]   \n",
       "51            [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "52            [0, 39, 72, 49, 52, 53, 20, 62, 58, 94]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "39  ['shrew', 'boy', 'pine_tree', 'television', 't...   68.943547  0.703137   \n",
       "40  ['lamp', 'bear', 'lion', 'forest', 'palm_tree'...   24.482168  0.459166   \n",
       "41  ['clock', 'lamp', 'telephone', 'lobster', 'leo...   63.911466  0.238287   \n",
       "42  ['motorcycle', 'girl', 'crab', 'flatfish', 'ro...   36.237008  0.142821   \n",
       "43  ['shrew', 'girl', 'camel', 'willow_tree', 'sha...   29.710575  0.399795   \n",
       "44  ['rabbit', 'train', 'rocket', 'raccoon', 'bear...   35.807582  0.185234   \n",
       "45  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "46  ['apple', 'keyboard', 'motorcycle', 'mountain'...  192.253176  0.844140   \n",
       "47  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "48  ['apple', 'bear', 'keyboard', 'mountain', 'oak...  192.253176  0.844140   \n",
       "49  ['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...  192.253176  0.844140   \n",
       "50  ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.844140   \n",
       "51  ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "52  ['apple', 'keyboard', 'seal', 'mountain', 'oak...  192.253176  0.844140   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \n",
       "0    0.369210             False                  0.898                  0.992  \n",
       "2   66.416617             False                  0.979                  1.000  \n",
       "3    0.578157             False                  0.873                  0.985  \n",
       "4   69.558004             False                  0.983                  0.998  \n",
       "5   14.820982             False                  0.952                  0.996  \n",
       "6    8.848314             False                  0.955                  0.996  \n",
       "8    1.950773             False                  0.839                  0.993  \n",
       "9   66.299283             False                  0.984                  0.999  \n",
       "10  14.212071             False                  0.931                  0.996  \n",
       "11  21.038719             False                  0.960                  0.998  \n",
       "12   2.107963             False                  0.915                  0.998  \n",
       "13   7.046100             False                  0.901                  0.992  \n",
       "15   2.298235             False                  0.856                  0.995  \n",
       "16  66.114634             False                  0.983                  1.000  \n",
       "19   1.931516             False                  0.896                  0.993  \n",
       "20  66.564161             False                  0.976                  1.000  \n",
       "22  18.962063             False                  0.968                  0.997  \n",
       "23   0.949666             False                  0.831                  0.985  \n",
       "24  73.389381             False                  0.985                  0.999  \n",
       "26  25.333189             False                  0.943                  0.994  \n",
       "27   0.994000             False                  0.853                  0.982  \n",
       "28  67.623141             False                  0.980                  0.998  \n",
       "30   9.783706             False                  0.919                  0.994  \n",
       "31   0.669352             False                  0.854                  0.978  \n",
       "32  66.601175             False                  0.982                  1.000  \n",
       "33  17.543812             False                  0.958                  1.000  \n",
       "34  22.350282             False                  0.955                  0.999  \n",
       "35   1.885359             False                  0.903                  0.992  \n",
       "36  68.423650             False                  0.983                  1.000  \n",
       "37  17.354552             False                  0.952                  0.995  \n",
       "38  11.636914             False                  0.946                  0.994  \n",
       "39  12.946819             False                  0.947                  0.995  \n",
       "40   8.783600             False                  0.954                  0.996  \n",
       "41  12.797301             False                  0.945                  0.995  \n",
       "42   8.417093             False                  0.935                  0.996  \n",
       "43   6.765886             False                  0.915                  0.993  \n",
       "44  11.366363             False                  0.944                  0.996  \n",
       "45  73.389381             False                  0.984                  0.999  \n",
       "46  68.260865             False                  0.986                  1.000  \n",
       "47  68.148521             False                  0.972                  0.999  \n",
       "48  69.130501             False                  0.979                  0.998  \n",
       "49  67.929204             False                  0.981                  0.999  \n",
       "50  68.614852             False                  0.986                  1.000  \n",
       "51  67.253203             False                  0.977                  1.000  \n",
       "52  67.859487             False                  0.983                  0.999  \n",
       "\n",
       "[45 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:19<00:00,  8.17it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (157,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (x_test, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader)):\n\u001b[1;32m      3\u001b[0m     classes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [target]\n\u001b[0;32m----> 4\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (157,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "    classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.815, 0.949]),\n",
       " array([0.82888889, 0.96777778]),\n",
       " array([0.863, 0.983]),\n",
       " array([0.799, 0.951]),\n",
       " array([0.887, 0.988]),\n",
       " array([0.797, 0.973]),\n",
       " array([0.83 , 0.968]),\n",
       " array([0.79444444, 0.96666667]),\n",
       " array([0.767, 0.961]),\n",
       " array([0.867, 0.986]),\n",
       " array([0.834, 0.968]),\n",
       " array([0.84 , 0.974]),\n",
       " array([0.821, 0.968]),\n",
       " array([0.775, 0.964]),\n",
       " array([0.85  , 0.9675]),\n",
       " array([0.808, 0.986]),\n",
       " array([0.877, 0.988]),\n",
       " array([0.86444444, 0.97333333]),\n",
       " array([0.81555556, 0.96444444]),\n",
       " array([0.823, 0.963]),\n",
       " array([0.871, 0.988]),\n",
       " array([0.81125, 0.95375]),\n",
       " array([0.845, 0.972]),\n",
       " array([0.746, 0.939]),\n",
       " array([0.873, 0.986]),\n",
       " array([0.84222222, 0.97888889]),\n",
       " array([0.848, 0.973]),\n",
       " array([0.771, 0.95 ]),\n",
       " array([0.872, 0.988]),\n",
       " array([0.86111111, 0.97111111]),\n",
       " array([0.826, 0.952]),\n",
       " array([0.781, 0.946]),\n",
       " array([0.861, 0.985]),\n",
       " array([0.806, 0.965]),\n",
       " array([0.848, 0.974]),\n",
       " array([0.884, 0.981]),\n",
       " array([0.879, 0.987]),\n",
       " array([0.831, 0.952]),\n",
       " array([0.779, 0.968])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "    topk_count = []\n",
    "    filtered = correct_mat[np.isin(classes, subset)]\n",
    "    for i, k in enumerate(topk):\n",
    "        topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "    return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2c9b89090>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cifar100_subset_generation import dist_matrix\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.from_numpy_array(dist_matrix)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa2b9e10-57f2-462e-8f96-5df897ffd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community \n",
    "partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae727e7e-c5e5-4627-bb52-ca17fdbd41c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 1,\n",
       " 4: 2,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 2,\n",
       " 9: 1,\n",
       " 10: 1,\n",
       " 11: 2,\n",
       " 12: 2,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 1,\n",
       " 17: 0,\n",
       " 18: 0,\n",
       " 19: 0,\n",
       " 20: 1,\n",
       " 21: 2,\n",
       " 22: 1,\n",
       " 23: 2,\n",
       " 24: 2,\n",
       " 25: 1,\n",
       " 26: 0,\n",
       " 27: 1,\n",
       " 28: 1,\n",
       " 29: 0,\n",
       " 30: 1,\n",
       " 31: 0,\n",
       " 32: 2,\n",
       " 33: 1,\n",
       " 34: 1,\n",
       " 35: 2,\n",
       " 36: 2,\n",
       " 37: 2,\n",
       " 38: 2,\n",
       " 39: 1,\n",
       " 40: 1,\n",
       " 41: 2,\n",
       " 42: 0,\n",
       " 43: 2,\n",
       " 44: 0,\n",
       " 45: 0,\n",
       " 46: 0,\n",
       " 47: 1,\n",
       " 48: 2,\n",
       " 49: 0,\n",
       " 50: 0,\n",
       " 51: 0,\n",
       " 52: 1,\n",
       " 53: 2,\n",
       " 54: 0,\n",
       " 55: 2,\n",
       " 56: 1,\n",
       " 57: 0,\n",
       " 58: 0,\n",
       " 59: 1,\n",
       " 60: 0,\n",
       " 61: 2,\n",
       " 62: 1,\n",
       " 63: 0,\n",
       " 64: 0,\n",
       " 65: 0,\n",
       " 66: 0,\n",
       " 67: 2,\n",
       " 68: 2,\n",
       " 69: 2,\n",
       " 70: 0,\n",
       " 71: 0,\n",
       " 72: 2,\n",
       " 73: 2,\n",
       " 74: 2,\n",
       " 75: 2,\n",
       " 76: 2,\n",
       " 77: 0,\n",
       " 78: 0,\n",
       " 79: 0,\n",
       " 80: 0,\n",
       " 81: 0,\n",
       " 82: 0,\n",
       " 83: 0,\n",
       " 84: 1,\n",
       " 85: 2,\n",
       " 86: 2,\n",
       " 87: 0,\n",
       " 88: 0,\n",
       " 89: 2,\n",
       " 90: 2,\n",
       " 91: 0,\n",
       " 92: 0,\n",
       " 93: 2,\n",
       " 94: 0,\n",
       " 95: 2,\n",
       " 96: 1,\n",
       " 97: 1,\n",
       " 98: 2,\n",
       " 99: 0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dfe0db6-01b1-4965-a589-ce94866dd132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['apple',\n",
       "  'baby',\n",
       "  'beaver',\n",
       "  'bicycle',\n",
       "  'boy',\n",
       "  'bridge',\n",
       "  'chimpanzee',\n",
       "  'cloud',\n",
       "  'cockroach',\n",
       "  'flatfish',\n",
       "  'girl',\n",
       "  'hamster',\n",
       "  'house',\n",
       "  'kangaroo',\n",
       "  'lawn_mower',\n",
       "  'lion',\n",
       "  'motorcycle',\n",
       "  'orange',\n",
       "  'otter',\n",
       "  'plate',\n",
       "  'ray',\n",
       "  'road',\n",
       "  'rocket',\n",
       "  'seal',\n",
       "  'shark',\n",
       "  'shrew',\n",
       "  'skunk',\n",
       "  'skyscraper',\n",
       "  'tank',\n",
       "  'telephone',\n",
       "  'tractor',\n",
       "  'train',\n",
       "  'turtle',\n",
       "  'whale',\n",
       "  'woman'],\n",
       " 1: ['aquarium_fish',\n",
       "  'bear',\n",
       "  'bottle',\n",
       "  'bowl',\n",
       "  'can',\n",
       "  'chair',\n",
       "  'clock',\n",
       "  'couch',\n",
       "  'crocodile',\n",
       "  'cup',\n",
       "  'dolphin',\n",
       "  'forest',\n",
       "  'fox',\n",
       "  'keyboard',\n",
       "  'lamp',\n",
       "  'maple_tree',\n",
       "  'oak_tree',\n",
       "  'palm_tree',\n",
       "  'pine_tree',\n",
       "  'poppy',\n",
       "  'table',\n",
       "  'willow_tree',\n",
       "  'wolf'],\n",
       " 0: ['bed',\n",
       "  'bee',\n",
       "  'beetle',\n",
       "  'bus',\n",
       "  'butterfly',\n",
       "  'camel',\n",
       "  'castle',\n",
       "  'caterpillar',\n",
       "  'cattle',\n",
       "  'crab',\n",
       "  'dinosaur',\n",
       "  'elephant',\n",
       "  'leopard',\n",
       "  'lizard',\n",
       "  'lobster',\n",
       "  'man',\n",
       "  'mountain',\n",
       "  'mouse',\n",
       "  'mushroom',\n",
       "  'orchid',\n",
       "  'pear',\n",
       "  'pickup_truck',\n",
       "  'plain',\n",
       "  'porcupine',\n",
       "  'possum',\n",
       "  'rabbit',\n",
       "  'raccoon',\n",
       "  'rose',\n",
       "  'sea',\n",
       "  'snail',\n",
       "  'snake',\n",
       "  'spider',\n",
       "  'squirrel',\n",
       "  'streetcar',\n",
       "  'sunflower',\n",
       "  'sweet_pepper',\n",
       "  'television',\n",
       "  'tiger',\n",
       "  'trout',\n",
       "  'tulip',\n",
       "  'wardrobe',\n",
       "  'worm']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cifar100_subset_generation import class_names\n",
    "\n",
    "grps = {}\n",
    "\n",
    "for k,v in partition.items():\n",
    "    if v not in grps:\n",
    "        grps[v] = []\n",
    "    grps[v] += [class_names[k].item()]\n",
    "\n",
    "grps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e2b417d-386d-4233-80bd-e097adec7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100_subset_generation import dist_matrix, class_names\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "KL_data_all = []\n",
    "# new_col = []\n",
    "median = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    # print(list(map(lambda x: class_names[x].item(), subset))))\n",
    "\n",
    "    # new_col += [len(subset) != len(set(subset))]\n",
    "    \n",
    "    KL_data = []\n",
    "    for j in combinations(set(subset), 2):\n",
    "        KL_data += [dist_matrix[j[0], j[1]].item()]\n",
    "\n",
    "    KL_data_all += [KL_data]\n",
    "\n",
    "    median += [np.median(KL_data).item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a011a4a-a284-4b40-b242-a757a73bfc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.917</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.309007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.911</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "      <td>False</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.431084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.176886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.955</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.996</td>\n",
       "      <td>6.435661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "      <td>48.794365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "      <td>False</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.996</td>\n",
       "      <td>11.245003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "      <td>False</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.998</td>\n",
       "      <td>18.305028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.881019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>3.904329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.995</td>\n",
       "      <td>2.015194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>46.540651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.563030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "      <td>False</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "      <td>False</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.997</td>\n",
       "      <td>11.365514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.906</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.782209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.999</td>\n",
       "      <td>68.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "      <td>False</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.994</td>\n",
       "      <td>16.188352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.910</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.767096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>62.712475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.952</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "      <td>False</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4.917178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.909</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>False</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.600811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.000</td>\n",
       "      <td>46.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "      <td>False</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.116350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "      <td>12.299855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.417347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "      <td>False</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.995</td>\n",
       "      <td>16.034085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.958</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "      <td>False</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.994</td>\n",
       "      <td>8.859941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.957</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(11), np.int64(59), np....</td>\n",
       "      <td>['shrew', 'boy', 'pine_tree', 'television', 't...</td>\n",
       "      <td>68.943547</td>\n",
       "      <td>0.703137</td>\n",
       "      <td>12.946819</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.995</td>\n",
       "      <td>8.363780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.959</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(3), np.int64(43), np.i...</td>\n",
       "      <td>['lamp', 'bear', 'lion', 'forest', 'palm_tree'...</td>\n",
       "      <td>24.482168</td>\n",
       "      <td>0.459166</td>\n",
       "      <td>8.783600</td>\n",
       "      <td>False</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.285556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.956</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(22), np.int64(40), np.int64(86), np....</td>\n",
       "      <td>['clock', 'lamp', 'telephone', 'lobster', 'leo...</td>\n",
       "      <td>63.911466</td>\n",
       "      <td>0.238287</td>\n",
       "      <td>12.797301</td>\n",
       "      <td>False</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.995</td>\n",
       "      <td>8.649378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(48), np.int64(35), np.int64(26), np....</td>\n",
       "      <td>['motorcycle', 'girl', 'crab', 'flatfish', 'ro...</td>\n",
       "      <td>36.237008</td>\n",
       "      <td>0.142821</td>\n",
       "      <td>8.417093</td>\n",
       "      <td>False</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.974991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.949</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(74), np.int64(35), np.int64(15), np....</td>\n",
       "      <td>['shrew', 'girl', 'camel', 'willow_tree', 'sha...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>6.765886</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4.689097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.965</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(65), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['rabbit', 'train', 'rocket', 'raccoon', 'bear...</td>\n",
       "      <td>35.807582</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>11.366363</td>\n",
       "      <td>False</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.996</td>\n",
       "      <td>8.387416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.999</td>\n",
       "      <td>68.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 48, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'motorcycle', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.260865</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>54.749677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.999</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'bear', 'keyboard', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.130501</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.998</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.929204</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 52, 53, 62, 90, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.614852</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>57.309081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 72, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'seal', 'mountain', 'oak...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.859487</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.999</td>\n",
       "      <td>61.625243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                   0.815   \n",
       "2    resnet50  CIFAR100                       64                   0.863   \n",
       "3    resnet50  CIFAR100                       64                   0.799   \n",
       "4    resnet50  CIFAR100                       64                   0.887   \n",
       "5    resnet50  CIFAR100                       64                   0.797   \n",
       "6    resnet50  CIFAR100                       64                   0.830   \n",
       "8    resnet50  CIFAR100                       64                   0.767   \n",
       "9    resnet50  CIFAR100                       64                   0.867   \n",
       "10   resnet50  CIFAR100                       64                   0.834   \n",
       "11   resnet50  CIFAR100                       64                   0.840   \n",
       "12   resnet50  CIFAR100                       64                   0.821   \n",
       "13   resnet50  CIFAR100                       64                   0.775   \n",
       "15   resnet50  CIFAR100                       64                   0.808   \n",
       "16   resnet50  CIFAR100                       64                   0.877   \n",
       "19   resnet50  CIFAR100                       64                   0.823   \n",
       "20   resnet50  CIFAR100                       64                   0.871   \n",
       "22   resnet50  CIFAR100                       64                   0.845   \n",
       "23   resnet50  CIFAR100                       64                   0.746   \n",
       "24   resnet50  CIFAR100                       64                   0.873   \n",
       "26   resnet50  CIFAR100                       64                   0.848   \n",
       "27   resnet50  CIFAR100                       64                   0.771   \n",
       "28   resnet50  CIFAR100                       64                   0.872   \n",
       "30   resnet50  CIFAR100                       64                   0.826   \n",
       "31   resnet50  CIFAR100                       64                   0.781   \n",
       "32   resnet50  CIFAR100                       64                   0.861   \n",
       "33   resnet50  CIFAR100                       64                   0.806   \n",
       "34   resnet50  CIFAR100                       64                   0.848   \n",
       "35   resnet50  CIFAR100                       64                   0.884   \n",
       "36   resnet50  CIFAR100                       64                   0.879   \n",
       "37   resnet50  CIFAR100                       64                   0.831   \n",
       "38   resnet50  CIFAR100                       64                   0.779   \n",
       "39   resnet50  CIFAR100                       64                   0.793   \n",
       "40   resnet50  CIFAR100                       64                   0.820   \n",
       "41   resnet50  CIFAR100                       64                   0.819   \n",
       "42   resnet50  CIFAR100                       64                   0.838   \n",
       "43   resnet50  CIFAR100                       64                   0.762   \n",
       "44   resnet50  CIFAR100                       64                   0.859   \n",
       "45   resnet50  CIFAR100                       64                   0.873   \n",
       "46   resnet50  CIFAR100                       64                   0.879   \n",
       "47   resnet50  CIFAR100                       64                   0.875   \n",
       "48   resnet50  CIFAR100                       64                   0.872   \n",
       "49   resnet50  CIFAR100                       64                   0.863   \n",
       "50   resnet50  CIFAR100                       64                   0.883   \n",
       "51   resnet50  CIFAR100                       64                   0.874   \n",
       "52   resnet50  CIFAR100                       64                   0.856   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.603                   0.949                    0.917   \n",
       "2                     0.843                   0.983                    0.989   \n",
       "3                     0.615                   0.951                    0.911   \n",
       "4                     0.944                   0.988                    0.995   \n",
       "5                     0.830                   0.973                    0.974   \n",
       "6                     0.737                   0.968                    0.955   \n",
       "8                     0.693                   0.961                    0.975   \n",
       "9                     0.946                   0.986                    0.995   \n",
       "10                    0.808                   0.968                    0.974   \n",
       "11                    0.884                   0.974                    0.988   \n",
       "12                    0.794                   0.968                    0.963   \n",
       "13                    0.681                   0.964                    0.974   \n",
       "15                    0.734                   0.986                    0.984   \n",
       "16                    0.957                   0.988                    0.995   \n",
       "19                    0.753                   0.963                    0.958   \n",
       "20                    0.936                   0.988                    0.992   \n",
       "22                    0.876                   0.972                    0.958   \n",
       "23                    0.520                   0.939                    0.906   \n",
       "24                    0.932                   0.986                    0.989   \n",
       "26                    0.866                   0.973                    0.988   \n",
       "27                    0.556                   0.950                    0.910   \n",
       "28                    0.944                   0.988                    0.993   \n",
       "30                    0.712                   0.952                    0.952   \n",
       "31                    0.566                   0.946                    0.909   \n",
       "32                    0.930                   0.985                    0.983   \n",
       "33                    0.869                   0.965                    0.988   \n",
       "34                    0.793                   0.974                    0.981   \n",
       "35                    0.754                   0.981                    0.972   \n",
       "36                    0.962                   0.987                    0.992   \n",
       "37                    0.790                   0.952                    0.972   \n",
       "38                    0.802                   0.968                    0.958   \n",
       "39                    0.782                   0.969                    0.957   \n",
       "40                    0.765                   0.966                    0.959   \n",
       "41                    0.804                   0.956                    0.956   \n",
       "42                    0.776                   0.976                    0.976   \n",
       "43                    0.636                   0.964                    0.949   \n",
       "44                    0.799                   0.968                    0.965   \n",
       "45                    0.942                   0.986                    0.986   \n",
       "46                    0.959                   0.989                    0.996   \n",
       "47                    0.936                   0.989                    0.995   \n",
       "48                    0.943                   0.988                    0.990   \n",
       "49                    0.951                   0.982                    0.993   \n",
       "50                    0.924                   0.989                    0.990   \n",
       "51                    0.943                   0.987                    0.993   \n",
       "52                    0.931                   0.979                    0.993   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "15     4                 1.16                 1.16  ...     0   \n",
       "16     4                 1.16                 1.16  ...     0   \n",
       "19     4                 1.16                 1.16  ...     0   \n",
       "20     4                 1.16                 1.16  ...     0   \n",
       "22     4                 1.16                 1.16  ...     0   \n",
       "23     4                 1.16                 1.16  ...     0   \n",
       "24     4                 1.16                 1.16  ...     0   \n",
       "26     4                 1.16                 1.16  ...     0   \n",
       "27     4                 1.16                 1.16  ...     0   \n",
       "28     4                 1.16                 1.16  ...     0   \n",
       "30     4                 1.16                 1.16  ...     0   \n",
       "31     4                 1.16                 1.16  ...     0   \n",
       "32     4                 1.16                 1.16  ...     0   \n",
       "33     4                 1.16                 1.16  ...     0   \n",
       "34     4                 1.16                 1.16  ...     0   \n",
       "35     4                 1.16                 1.16  ...     0   \n",
       "36     4                 1.16                 1.16  ...     0   \n",
       "37     4                 1.16                 1.16  ...     0   \n",
       "38     4                 1.16                 1.16  ...     0   \n",
       "39     4                 1.16                 1.16  ...     0   \n",
       "40     4                 1.16                 1.16  ...     0   \n",
       "41     4                 1.16                 1.16  ...     0   \n",
       "42     4                 1.16                 1.16  ...     0   \n",
       "43     4                 1.16                 1.16  ...     0   \n",
       "44     4                 1.16                 1.16  ...     0   \n",
       "45     4                 1.16                 1.16  ...     0   \n",
       "46     4                 1.16                 1.16  ...     0   \n",
       "47     4                 1.16                 1.16  ...     0   \n",
       "48     4                 1.16                 1.16  ...     0   \n",
       "49     4                 1.16                 1.16  ...     0   \n",
       "50     4                 1.16                 1.16  ...     0   \n",
       "51     4                 1.16                 1.16  ...     0   \n",
       "52     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "39  [np.int64(74), np.int64(11), np.int64(59), np....   \n",
       "40  [np.int64(40), np.int64(3), np.int64(43), np.i...   \n",
       "41  [np.int64(22), np.int64(40), np.int64(86), np....   \n",
       "42  [np.int64(48), np.int64(35), np.int64(26), np....   \n",
       "43  [np.int64(74), np.int64(35), np.int64(15), np....   \n",
       "44  [np.int64(65), np.int64(90), np.int64(69), np....   \n",
       "45            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "46            [0, 39, 48, 49, 52, 53, 62, 58, 61, 94]   \n",
       "47            [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "48             [0, 3, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "49             [0, 4, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "50            [0, 58, 39, 71, 52, 53, 62, 90, 61, 94]   \n",
       "51            [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "52            [0, 39, 72, 49, 52, 53, 20, 62, 58, 94]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "39  ['shrew', 'boy', 'pine_tree', 'television', 't...   68.943547  0.703137   \n",
       "40  ['lamp', 'bear', 'lion', 'forest', 'palm_tree'...   24.482168  0.459166   \n",
       "41  ['clock', 'lamp', 'telephone', 'lobster', 'leo...   63.911466  0.238287   \n",
       "42  ['motorcycle', 'girl', 'crab', 'flatfish', 'ro...   36.237008  0.142821   \n",
       "43  ['shrew', 'girl', 'camel', 'willow_tree', 'sha...   29.710575  0.399795   \n",
       "44  ['rabbit', 'train', 'rocket', 'raccoon', 'bear...   35.807582  0.185234   \n",
       "45  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "46  ['apple', 'keyboard', 'motorcycle', 'mountain'...  192.253176  0.844140   \n",
       "47  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "48  ['apple', 'bear', 'keyboard', 'mountain', 'oak...  192.253176  0.844140   \n",
       "49  ['apple', 'beaver', 'keyboard', 'sea', 'oak_tr...  192.253176  0.844140   \n",
       "50  ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.844140   \n",
       "51  ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "52  ['apple', 'keyboard', 'seal', 'mountain', 'oak...  192.253176  0.844140   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0    0.369210             False                  0.898                  0.992   \n",
       "2   66.416617             False                  0.979                  1.000   \n",
       "3    0.578157             False                  0.873                  0.985   \n",
       "4   69.558004             False                  0.983                  0.998   \n",
       "5   14.820982             False                  0.952                  0.996   \n",
       "6    8.848314             False                  0.955                  0.996   \n",
       "8    1.950773             False                  0.839                  0.993   \n",
       "9   66.299283             False                  0.984                  0.999   \n",
       "10  14.212071             False                  0.931                  0.996   \n",
       "11  21.038719             False                  0.960                  0.998   \n",
       "12   2.107963             False                  0.915                  0.998   \n",
       "13   7.046100             False                  0.901                  0.992   \n",
       "15   2.298235             False                  0.856                  0.995   \n",
       "16  66.114634             False                  0.983                  1.000   \n",
       "19   1.931516             False                  0.896                  0.993   \n",
       "20  66.564161             False                  0.976                  1.000   \n",
       "22  18.962063             False                  0.968                  0.997   \n",
       "23   0.949666             False                  0.831                  0.985   \n",
       "24  73.389381             False                  0.985                  0.999   \n",
       "26  25.333189             False                  0.943                  0.994   \n",
       "27   0.994000             False                  0.853                  0.982   \n",
       "28  67.623141             False                  0.980                  0.998   \n",
       "30   9.783706             False                  0.919                  0.994   \n",
       "31   0.669352             False                  0.854                  0.978   \n",
       "32  66.601175             False                  0.982                  1.000   \n",
       "33  17.543812             False                  0.958                  1.000   \n",
       "34  22.350282             False                  0.955                  0.999   \n",
       "35   1.885359             False                  0.903                  0.992   \n",
       "36  68.423650             False                  0.983                  1.000   \n",
       "37  17.354552             False                  0.952                  0.995   \n",
       "38  11.636914             False                  0.946                  0.994   \n",
       "39  12.946819             False                  0.947                  0.995   \n",
       "40   8.783600             False                  0.954                  0.996   \n",
       "41  12.797301             False                  0.945                  0.995   \n",
       "42   8.417093             False                  0.935                  0.996   \n",
       "43   6.765886             False                  0.915                  0.993   \n",
       "44  11.366363             False                  0.944                  0.996   \n",
       "45  73.389381             False                  0.984                  0.999   \n",
       "46  68.260865             False                  0.986                  1.000   \n",
       "47  68.148521             False                  0.972                  0.999   \n",
       "48  69.130501             False                  0.979                  0.998   \n",
       "49  67.929204             False                  0.981                  0.999   \n",
       "50  68.614852             False                  0.986                  1.000   \n",
       "51  67.253203             False                  0.977                  1.000   \n",
       "52  67.859487             False                  0.983                  0.999   \n",
       "\n",
       "    Median_KL  \n",
       "0    0.309007  \n",
       "2   49.097501  \n",
       "3    0.431084  \n",
       "4   66.980437  \n",
       "5    8.176886  \n",
       "6    6.435661  \n",
       "8    1.666552  \n",
       "9   48.794365  \n",
       "10  11.245003  \n",
       "11  18.305028  \n",
       "12   1.881019  \n",
       "13   3.904329  \n",
       "15   2.015194  \n",
       "16  46.540651  \n",
       "19   1.563030  \n",
       "20  49.097501  \n",
       "22  11.365514  \n",
       "23   0.782209  \n",
       "24  68.004669  \n",
       "26  16.188352  \n",
       "27   0.767096  \n",
       "28  62.712475  \n",
       "30   4.917178  \n",
       "31   0.600811  \n",
       "32  46.604676  \n",
       "33  15.116350  \n",
       "34  12.299855  \n",
       "35   1.417347  \n",
       "36  50.328013  \n",
       "37  16.034085  \n",
       "38   8.859941  \n",
       "39   8.363780  \n",
       "40   8.285556  \n",
       "41   8.649378  \n",
       "42   5.974991  \n",
       "43   4.689097  \n",
       "44   8.387416  \n",
       "45  68.004669  \n",
       "46  54.749677  \n",
       "47  60.747142  \n",
       "48  66.877609  \n",
       "49  49.097501  \n",
       "50  57.309081  \n",
       "51  49.097501  \n",
       "52  61.625243  \n",
       "\n",
       "[45 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Median_KL\"] = median\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5dd02952-818a-4588-bfaa-bbfce9e4d30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "pd.DataFrame(KL_data_all, index = df[\"Quantized Top1 Accuracy\"]).T.boxplot(vert = False, positions = df[\"Quantized Top1 Accuracy\"] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0724d809-8a16-40f1-aad0-cd9252c5c0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantized Sparsity</th>\n",
       "      <th>Retain_rate</th>\n",
       "      <th>Fusion</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>[np.str_('beetle'), np.str_('lizard'), np.str_...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(47), np.int64(64), np....</td>\n",
       "      <td>['lizard', 'maple_tree', 'possum', 'ray', 'ray...</td>\n",
       "      <td>44.511445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.637726</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 44, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'lizard', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.416617</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 3, 4, 38, 15, 80, 19, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'bear', 'beave...</td>\n",
       "      <td>1.338502</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.578157</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'rocket', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.558004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(89), np.int64(73), np.int64(85), np....</td>\n",
       "      <td>['tractor', 'shark', 'tank', 'mouse', 'castle'...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.218817</td>\n",
       "      <td>14.820982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(6), np.int64(18), np.int64(19), np.i...</td>\n",
       "      <td>['bee', 'caterpillar', 'cattle', 'woman', 'sha...</td>\n",
       "      <td>40.082360</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>8.848314</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(59), np.int64(90), np.int64(69), np....</td>\n",
       "      <td>['pine_tree', 'train', 'rocket', 'table', 'mot...</td>\n",
       "      <td>50.340385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.589799</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 58, 39, 71, 49, 52, 53, 26, 61, 94]</td>\n",
       "      <td>['apple', 'pickup_truck', 'keyboard', 'sea', '...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.299283</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(86), np.int64(33), np.int64(83), np....</td>\n",
       "      <td>['telephone', 'forest', 'sweet_pepper', 'pear'...</td>\n",
       "      <td>37.432873</td>\n",
       "      <td>0.619711</td>\n",
       "      <td>14.212071</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(47), np.int64(39), np.int64(70), np....</td>\n",
       "      <td>['maple_tree', 'keyboard', 'rose', 'telephone'...</td>\n",
       "      <td>53.628338</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>21.038719</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 41, 11, 48, 84, 86, 87, 25]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...</td>\n",
       "      <td>7.314820</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>2.107963</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(44), np.int64(74), np.int64(52), np....</td>\n",
       "      <td>['lizard', 'shrew', 'oak_tree', 'mountain', 'r...</td>\n",
       "      <td>23.928885</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>7.046100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(40), np.int64(19), np.int64(20), np....</td>\n",
       "      <td>['lamp', 'cattle', 'chair', 'apple', 'cattle',...</td>\n",
       "      <td>82.345975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.351426</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.864444</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(76), np.int64(48), np.int64(41), np....</td>\n",
       "      <td>['skyscraper', 'motorcycle', 'lawn_mower', 'ta...</td>\n",
       "      <td>23.021616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.481517</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(29), np.int64(9), np.int64(65), np.i...</td>\n",
       "      <td>['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...</td>\n",
       "      <td>29.710575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.606611</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 9, 10, 8, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'beetle', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.564161</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.811250</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(72), np.int64(69), np.int64(48), np....</td>\n",
       "      <td>['seal', 'rocket', 'motorcycle', 'snake', 'can...</td>\n",
       "      <td>30.303197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.778188</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(23), np.int64(87), np.int64(0), np.i...</td>\n",
       "      <td>['cloud', 'television', 'apple', 'pear', 'bicy...</td>\n",
       "      <td>78.162471</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>18.962063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.978889</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(36), np.int64(65), np.int64(26), np....</td>\n",
       "      <td>['hamster', 'rabbit', 'crab', 'bear', 'motorcy...</td>\n",
       "      <td>58.464503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.427204</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(19), np.int64(40), np.int64(21), np....</td>\n",
       "      <td>['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...</td>\n",
       "      <td>154.865995</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>25.333189</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 38, 72, 74, 15, 19, 21, 55, 31]</td>\n",
       "      <td>['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...</td>\n",
       "      <td>3.494798</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 33, 39, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'forest', 'keyboard', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.623141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.867778</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(66), np.int64(75), np.int64(60), np....</td>\n",
       "      <td>['raccoon', 'skunk', 'plain', 'orange', 'lion'...</td>\n",
       "      <td>142.446653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.135427</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(12), np.int64(41), np.int64(58), np....</td>\n",
       "      <td>['bridge', 'lawn_mower', 'pickup_truck', 'spid...</td>\n",
       "      <td>33.629118</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>9.783706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 66, 3, 4, 38, 74, 15, 19, 63, 31]</td>\n",
       "      <td>['possum', 'raccoon', 'bear', 'beaver', 'kanga...</td>\n",
       "      <td>1.883920</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 46, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'man', 'oak_tree'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.601175</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(73), np.int64(17), np.int64(42), np....</td>\n",
       "      <td>['shark', 'castle', 'leopard', 'bear', 'sunflo...</td>\n",
       "      <td>62.210392</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>17.543812</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(37), np.int64(42), np.int64(17), np....</td>\n",
       "      <td>['house', 'leopard', 'castle', 'caterpillar', ...</td>\n",
       "      <td>142.825071</td>\n",
       "      <td>0.116613</td>\n",
       "      <td>22.350282</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(42), np.int64(27), np.int64(97), np....</td>\n",
       "      <td>['leopard', 'crocodile', 'wolf', 'possum', 'ro...</td>\n",
       "      <td>63.390176</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>17.354552</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[np.int64(50), np.int64(21), np.int64(56), np....</td>\n",
       "      <td>['mouse', 'chimpanzee', 'palm_tree', 'shark', ...</td>\n",
       "      <td>38.084479</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>11.636914</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0    resnet50  CIFAR100                       64                0.815000   \n",
       "1    resnet50  CIFAR100                       64                0.828889   \n",
       "2    resnet50  CIFAR100                       64                0.863000   \n",
       "3    resnet50  CIFAR100                       64                0.799000   \n",
       "4    resnet50  CIFAR100                       64                0.887000   \n",
       "5    resnet50  CIFAR100                       64                0.797000   \n",
       "6    resnet50  CIFAR100                       64                0.830000   \n",
       "7    resnet50  CIFAR100                       64                0.794444   \n",
       "8    resnet50  CIFAR100                       64                0.767000   \n",
       "9    resnet50  CIFAR100                       64                0.867000   \n",
       "10   resnet50  CIFAR100                       64                0.834000   \n",
       "11   resnet50  CIFAR100                       64                0.840000   \n",
       "12   resnet50  CIFAR100                       64                0.821000   \n",
       "13   resnet50  CIFAR100                       64                0.775000   \n",
       "14   resnet50  CIFAR100                       64                0.850000   \n",
       "15   resnet50  CIFAR100                       64                0.808000   \n",
       "16   resnet50  CIFAR100                       64                0.877000   \n",
       "17   resnet50  CIFAR100                       64                0.864444   \n",
       "18   resnet50  CIFAR100                       64                0.815556   \n",
       "19   resnet50  CIFAR100                       64                0.823000   \n",
       "20   resnet50  CIFAR100                       64                0.871000   \n",
       "21   resnet50  CIFAR100                       64                0.811250   \n",
       "22   resnet50  CIFAR100                       64                0.845000   \n",
       "23   resnet50  CIFAR100                       64                0.746000   \n",
       "24   resnet50  CIFAR100                       64                0.873000   \n",
       "25   resnet50  CIFAR100                       64                0.842222   \n",
       "26   resnet50  CIFAR100                       64                0.848000   \n",
       "27   resnet50  CIFAR100                       64                0.771000   \n",
       "28   resnet50  CIFAR100                       64                0.872000   \n",
       "29   resnet50  CIFAR100                       64                0.861111   \n",
       "30   resnet50  CIFAR100                       64                0.826000   \n",
       "31   resnet50  CIFAR100                       64                0.781000   \n",
       "32   resnet50  CIFAR100                       64                0.861000   \n",
       "33   resnet50  CIFAR100                       64                0.806000   \n",
       "34   resnet50  CIFAR100                       64                0.848000   \n",
       "35   resnet50  CIFAR100                       64                0.884000   \n",
       "36   resnet50  CIFAR100                       64                0.879000   \n",
       "37   resnet50  CIFAR100                       64                0.831000   \n",
       "38   resnet50  CIFAR100                       64                0.779000   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                  0.603000                0.949000                 0.917000   \n",
       "1                  0.848889                0.967778                 0.970000   \n",
       "2                  0.843000                0.983000                 0.989000   \n",
       "3                  0.615000                0.951000                 0.911000   \n",
       "4                  0.944000                0.988000                 0.995000   \n",
       "5                  0.830000                0.973000                 0.974000   \n",
       "6                  0.737000                0.968000                 0.955000   \n",
       "7                  0.776667                0.966667                 0.983333   \n",
       "8                  0.693000                0.961000                 0.975000   \n",
       "9                  0.946000                0.986000                 0.995000   \n",
       "10                 0.808000                0.968000                 0.974000   \n",
       "11                 0.884000                0.974000                 0.988000   \n",
       "12                 0.794000                0.968000                 0.963000   \n",
       "13                 0.681000                0.964000                 0.974000   \n",
       "14                 0.876250                0.967500                 0.988750   \n",
       "15                 0.734000                0.986000                 0.984000   \n",
       "16                 0.957000                0.988000                 0.995000   \n",
       "17                 0.844444                0.973333                 0.967778   \n",
       "18                 0.757778                0.964444                 0.962222   \n",
       "19                 0.753000                0.963000                 0.958000   \n",
       "20                 0.936000                0.988000                 0.992000   \n",
       "21                 0.758750                0.953750                 0.932500   \n",
       "22                 0.876000                0.972000                 0.958000   \n",
       "23                 0.520000                0.939000                 0.906000   \n",
       "24                 0.932000                0.986000                 0.989000   \n",
       "25                 0.842222                0.978889                 0.984444   \n",
       "26                 0.866000                0.973000                 0.988000   \n",
       "27                 0.556000                0.950000                 0.910000   \n",
       "28                 0.944000                0.988000                 0.993000   \n",
       "29                 0.867778                0.971111                 0.988889   \n",
       "30                 0.712000                0.952000                 0.952000   \n",
       "31                 0.566000                0.946000                 0.909000   \n",
       "32                 0.930000                0.985000                 0.983000   \n",
       "33                 0.869000                0.965000                 0.988000   \n",
       "34                 0.793000                0.974000                 0.981000   \n",
       "35                 0.754000                0.981000                 0.972000   \n",
       "36                 0.962000                0.987000                 0.992000   \n",
       "37                 0.790000                0.952000                 0.972000   \n",
       "38                 0.802000                0.968000                 0.958000   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Quantized Sparsity  \\\n",
       "0      4                 1.16                 1.16  ...              0.4454   \n",
       "1      4                 1.16                 1.16  ...              0.4474   \n",
       "2      4                 1.16                 1.16  ...              0.4504   \n",
       "3      4                 1.16                 1.16  ...              0.4483   \n",
       "4      4                 1.16                 1.16  ...              0.4543   \n",
       "5      4                 1.16                 1.16  ...              0.4480   \n",
       "6      4                 1.16                 1.16  ...              0.4464   \n",
       "7      4                 1.16                 1.16  ...              0.4539   \n",
       "8      4                 1.16                 1.16  ...              0.4510   \n",
       "9      4                 1.16                 1.16  ...              0.4540   \n",
       "10     4                 1.16                 1.16  ...              0.4535   \n",
       "11     4                 1.16                 1.16  ...              0.4516   \n",
       "12     4                 1.16                 1.16  ...              0.4575   \n",
       "13     4                 1.16                 1.16  ...              0.4521   \n",
       "14     4                 1.16                 1.16  ...              0.4586   \n",
       "15     4                 1.16                 1.16  ...              0.4458   \n",
       "16     4                 1.16                 1.16  ...              0.4522   \n",
       "17     4                 1.16                 1.16  ...              0.4533   \n",
       "18     4                 1.16                 1.16  ...              0.4500   \n",
       "19     4                 1.16                 1.16  ...              0.4582   \n",
       "20     4                 1.16                 1.16  ...              0.4486   \n",
       "21     4                 1.16                 1.16  ...              0.4497   \n",
       "22     4                 1.16                 1.16  ...              0.4507   \n",
       "23     4                 1.16                 1.16  ...              0.4450   \n",
       "24     4                 1.16                 1.16  ...              0.4553   \n",
       "25     4                 1.16                 1.16  ...              0.4522   \n",
       "26     4                 1.16                 1.16  ...              0.4527   \n",
       "27     4                 1.16                 1.16  ...              0.4477   \n",
       "28     4                 1.16                 1.16  ...              0.4532   \n",
       "29     4                 1.16                 1.16  ...              0.4473   \n",
       "30     4                 1.16                 1.16  ...              0.4535   \n",
       "31     4                 1.16                 1.16  ...              0.4512   \n",
       "32     4                 1.16                 1.16  ...              0.4534   \n",
       "33     4                 1.16                 1.16  ...              0.4503   \n",
       "34     4                 1.16                 1.16  ...              0.4460   \n",
       "35     4                 1.16                 1.16  ...              0.4542   \n",
       "36     4                 1.16                 1.16  ...              0.4544   \n",
       "37     4                 1.16                 1.16  ...              0.4479   \n",
       "38     4                 1.16                 1.16  ...              0.4515   \n",
       "\n",
       "    Retain_rate  Fusion  Seed  \\\n",
       "0          0.25   False     0   \n",
       "1          0.25   False     0   \n",
       "2          0.25   False     0   \n",
       "3          0.25   False     0   \n",
       "4          0.25   False     0   \n",
       "5          0.25   False     0   \n",
       "6          0.25   False     0   \n",
       "7          0.25   False     0   \n",
       "8          0.25   False     0   \n",
       "9          0.25   False     0   \n",
       "10         0.25   False     0   \n",
       "11         0.25   False     0   \n",
       "12         0.25   False     0   \n",
       "13         0.25   False     0   \n",
       "14         0.25   False     0   \n",
       "15         0.25   False     0   \n",
       "16         0.25   False     0   \n",
       "17         0.25   False     0   \n",
       "18         0.25   False     0   \n",
       "19         0.25   False     0   \n",
       "20         0.25   False     0   \n",
       "21         0.25   False     0   \n",
       "22         0.25   False     0   \n",
       "23         0.25   False     0   \n",
       "24         0.25   False     0   \n",
       "25         0.25   False     0   \n",
       "26         0.25   False     0   \n",
       "27         0.25   False     0   \n",
       "28         0.25   False     0   \n",
       "29         0.25   False     0   \n",
       "30         0.25   False     0   \n",
       "31         0.25   False     0   \n",
       "32         0.25   False     0   \n",
       "33         0.25   False     0   \n",
       "34         0.25   False     0   \n",
       "35         0.25   False     0   \n",
       "36         0.25   False     0   \n",
       "37         0.25   False     0   \n",
       "38         0.25   False     0   \n",
       "\n",
       "                                          Subset_Inds  \\\n",
       "0             [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "1   [np.int64(44), np.int64(47), np.int64(64), np....   \n",
       "2             [0, 71, 39, 44, 49, 52, 53, 58, 61, 94]   \n",
       "3              [64, 65, 66, 3, 4, 38, 15, 80, 19, 63]   \n",
       "4             [0, 69, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "5   [np.int64(89), np.int64(73), np.int64(85), np....   \n",
       "6   [np.int64(6), np.int64(18), np.int64(19), np.i...   \n",
       "7   [np.int64(59), np.int64(90), np.int64(69), np....   \n",
       "8            [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "9             [0, 58, 39, 71, 49, 52, 53, 26, 61, 94]   \n",
       "10  [np.int64(86), np.int64(33), np.int64(83), np....   \n",
       "11  [np.int64(47), np.int64(39), np.int64(70), np....   \n",
       "12             [5, 8, 40, 41, 11, 48, 84, 86, 87, 25]   \n",
       "13  [np.int64(44), np.int64(74), np.int64(52), np....   \n",
       "14  [np.int64(40), np.int64(19), np.int64(20), np....   \n",
       "15           [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "16            [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "17  [np.int64(76), np.int64(48), np.int64(41), np....   \n",
       "18  [np.int64(29), np.int64(9), np.int64(65), np.i...   \n",
       "19              [5, 40, 9, 10, 8, 16, 84, 22, 25, 28]   \n",
       "20             [0, 7, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "21  [np.int64(72), np.int64(69), np.int64(48), np....   \n",
       "22  [np.int64(23), np.int64(87), np.int64(0), np.i...   \n",
       "23            [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "24            [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "25  [np.int64(36), np.int64(65), np.int64(26), np....   \n",
       "26  [np.int64(19), np.int64(40), np.int64(21), np....   \n",
       "27             [3, 4, 38, 72, 74, 15, 19, 21, 55, 31]   \n",
       "28            [0, 33, 39, 49, 52, 53, 20, 62, 58, 94]   \n",
       "29  [np.int64(66), np.int64(75), np.int64(60), np....   \n",
       "30  [np.int64(12), np.int64(41), np.int64(58), np....   \n",
       "31             [64, 66, 3, 4, 38, 74, 15, 19, 63, 31]   \n",
       "32            [0, 71, 39, 46, 52, 53, 62, 58, 61, 94]   \n",
       "33  [np.int64(73), np.int64(17), np.int64(42), np....   \n",
       "34  [np.int64(37), np.int64(42), np.int64(17), np....   \n",
       "35           [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "36            [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "37  [np.int64(42), np.int64(27), np.int64(97), np....   \n",
       "38  [np.int64(50), np.int64(21), np.int64(56), np....   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   [np.str_('beetle'), np.str_('lizard'), np.str_...    0.969446  0.091850   \n",
       "1   ['lizard', 'maple_tree', 'possum', 'ray', 'ray...   44.511445  0.000000   \n",
       "2   ['apple', 'sea', 'keyboard', 'lizard', 'mounta...  192.253176  0.544018   \n",
       "3   ['possum', 'rabbit', 'raccoon', 'bear', 'beave...    1.338502  0.109146   \n",
       "4   ['apple', 'rocket', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "5   ['tractor', 'shark', 'tank', 'mouse', 'castle'...   58.464503  0.218817   \n",
       "6   ['bee', 'caterpillar', 'cattle', 'woman', 'sha...   40.082360  0.155198   \n",
       "7   ['pine_tree', 'train', 'rocket', 'table', 'mot...   50.340385  0.000000   \n",
       "8   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "9   ['apple', 'pickup_truck', 'keyboard', 'sea', '...  192.253176  0.544018   \n",
       "10  ['telephone', 'forest', 'sweet_pepper', 'pear'...   37.432873  0.619711   \n",
       "11  ['maple_tree', 'keyboard', 'rose', 'telephone'...   53.628338  0.832424   \n",
       "12  ['bed', 'bicycle', 'lamp', 'lawn_mower', 'boy'...    7.314820  0.207834   \n",
       "13  ['lizard', 'shrew', 'oak_tree', 'mountain', 'r...   23.928885  0.197318   \n",
       "14  ['lamp', 'cattle', 'chair', 'apple', 'cattle',...   82.345975  0.000000   \n",
       "15  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "16  ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "17  ['skyscraper', 'motorcycle', 'lawn_mower', 'ta...   23.021616  0.000000   \n",
       "18  ['dinosaur', 'bottle', 'rabbit', 'dolphin', 'c...   29.710575  0.000000   \n",
       "19  ['bed', 'lamp', 'bottle', 'bowl', 'bicycle', '...    6.644043  0.207834   \n",
       "20  ['apple', 'beetle', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "21  ['seal', 'rocket', 'motorcycle', 'snake', 'can...   30.303197  0.000000   \n",
       "22  ['cloud', 'television', 'apple', 'pear', 'bicy...   78.162471  0.901540   \n",
       "23  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "24  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "25  ['hamster', 'rabbit', 'crab', 'bear', 'motorcy...   58.464503  0.000000   \n",
       "26  ['cattle', 'lamp', 'chimpanzee', 'plate', 'bow...  154.865995  0.639066   \n",
       "27  ['bear', 'beaver', 'kangaroo', 'seal', 'shrew'...    3.494798  0.074397   \n",
       "28  ['apple', 'forest', 'keyboard', 'mountain', 'o...  192.253176  0.844140   \n",
       "29  ['raccoon', 'skunk', 'plain', 'orange', 'lion'...  142.446653  0.000000   \n",
       "30  ['bridge', 'lawn_mower', 'pickup_truck', 'spid...   33.629118  0.110622   \n",
       "31  ['possum', 'raccoon', 'bear', 'beaver', 'kanga...    1.883920  0.109146   \n",
       "32  ['apple', 'sea', 'keyboard', 'man', 'oak_tree'...  192.253176  0.844140   \n",
       "33  ['shark', 'castle', 'leopard', 'bear', 'sunflo...   62.210392  0.700755   \n",
       "34  ['house', 'leopard', 'castle', 'caterpillar', ...  142.825071  0.116613   \n",
       "35  ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "36  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "37  ['leopard', 'crocodile', 'wolf', 'possum', 'ro...   63.390176  0.178146   \n",
       "38  ['mouse', 'chimpanzee', 'palm_tree', 'shark', ...   38.084479  0.411724   \n",
       "\n",
       "       Avg_KL  Classes Repeated  \n",
       "0    0.369210             False  \n",
       "1   12.637726              True  \n",
       "2   66.416617             False  \n",
       "3    0.578157             False  \n",
       "4   69.558004             False  \n",
       "5   14.820982             False  \n",
       "6    8.848314             False  \n",
       "7    8.589799              True  \n",
       "8    1.950773             False  \n",
       "9   66.299283             False  \n",
       "10  14.212071             False  \n",
       "11  21.038719             False  \n",
       "12   2.107963             False  \n",
       "13   7.046100             False  \n",
       "14  17.351426              True  \n",
       "15   2.298235             False  \n",
       "16  66.114634             False  \n",
       "17   7.481517              True  \n",
       "18   6.606611              True  \n",
       "19   1.931516             False  \n",
       "20  66.564161             False  \n",
       "21   7.778188              True  \n",
       "22  18.962063             False  \n",
       "23   0.949666             False  \n",
       "24  73.389381             False  \n",
       "25  12.427204              True  \n",
       "26  25.333189             False  \n",
       "27   0.994000             False  \n",
       "28  67.623141             False  \n",
       "29  17.135427              True  \n",
       "30   9.783706             False  \n",
       "31   0.669352             False  \n",
       "32  66.601175             False  \n",
       "33  17.543812             False  \n",
       "34  22.350282             False  \n",
       "35   1.885359             False  \n",
       "36  68.423650             False  \n",
       "37  17.354552             False  \n",
       "38  11.636914             False  \n",
       "\n",
       "[39 rows x 26 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Classes Repeated\"] = new_col\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61e9939a-6dcb-4678-8a83-9ad2ba3012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3593c-43f4-4388-9121-057b93a9b985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
