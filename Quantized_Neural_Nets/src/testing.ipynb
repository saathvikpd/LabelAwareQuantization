{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f376d630-cea9-4230-9c3f-5299c7c71ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 724.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 88.67660522460938.\n",
      "The relative quantization error of layer 0 is 0.01911812648177147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 611.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 940.3062133789062.\n",
      "The relative quantization error of layer 1 is 0.05271701514720917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1562.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 247.2531280517578.\n",
      "The relative quantization error of layer 2 is 0.056039780378341675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 233.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3503.92041015625.\n",
      "The relative quantization error of layer 3 is 0.1009669154882431.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 233.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1539.6884765625.\n",
      "The relative quantization error of layer 4 is 0.051969245076179504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 476.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 609.913330078125.\n",
      "The relative quantization error of layer 5 is 0.20109553635120392.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1536.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 276.4471130371094.\n",
      "The relative quantization error of layer 6 is 0.22164927423000336.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 253.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1068.9234619140625.\n",
      "The relative quantization error of layer 7 is 0.22123801708221436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 468.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 900.6463623046875.\n",
      "The relative quantization error of layer 8 is 0.25722452998161316.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1814.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 584.6071166992188.\n",
      "The relative quantization error of layer 9 is 0.270363986492157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 253.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1636.24755859375.\n",
      "The relative quantization error of layer 10 is 0.23104563355445862.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 272.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1717.3265380859375.\n",
      "The relative quantization error of layer 11 is 0.3034229576587677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1765.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1193.0369873046875.\n",
      "The relative quantization error of layer 12 is 0.29905495047569275.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 852.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1517.9783935546875.\n",
      "The relative quantization error of layer 13 is 0.21816101670265198.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2061.599853515625.\n",
      "The relative quantization error of layer 14 is 0.29384076595306396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1590.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2062.436279296875.\n",
      "The relative quantization error of layer 15 is 0.26823729276657104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1751.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 543.7785034179688.\n",
      "The relative quantization error of layer 16 is 0.2453145682811737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 849.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1211.7593994140625.\n",
      "The relative quantization error of layer 17 is 0.38789188861846924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1697.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1774.4183349609375.\n",
      "The relative quantization error of layer 18 is 0.2958214282989502.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1827.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.7424621582031.\n",
      "The relative quantization error of layer 19 is 0.25464165210723877.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 848.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1242.260986328125.\n",
      "The relative quantization error of layer 20 is 0.30474305152893066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1669.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1965.01025390625.\n",
      "The relative quantization error of layer 21 is 0.3224579691886902.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1828.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 447.1703186035156.\n",
      "The relative quantization error of layer 22 is 0.27158689498901367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 804.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1005.3828125.\n",
      "The relative quantization error of layer 23 is 0.3658970892429352.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1280.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3338.917724609375.\n",
      "The relative quantization error of layer 24 is 0.3600340783596039.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1842.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 628.3137817382812.\n",
      "The relative quantization error of layer 25 is 0.3197019398212433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1311.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1366.052734375.\n",
      "The relative quantization error of layer 26 is 0.3722333312034607.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 505.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3434.38818359375.\n",
      "The relative quantization error of layer 27 is 0.3527572453022003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1843.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1326.8040771484375.\n",
      "The relative quantization error of layer 28 is 0.329397976398468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1847.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.0052490234375.\n",
      "The relative quantization error of layer 29 is 0.17635121941566467.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1315.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 965.2799682617188.\n",
      "The relative quantization error of layer 30 is 0.41558775305747986.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1832.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1497.247802734375.\n",
      "The relative quantization error of layer 31 is 0.3539978563785553.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1788.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.76409912109375.\n",
      "The relative quantization error of layer 32 is 0.21635040640830994.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1288.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 865.872802734375.\n",
      "The relative quantization error of layer 33 is 0.4663301408290863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1823.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1660.9522705078125.\n",
      "The relative quantization error of layer 34 is 0.40623295307159424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1833.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.525390625.\n",
      "The relative quantization error of layer 35 is 0.19956836104393005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1303.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1022.259033203125.\n",
      "The relative quantization error of layer 36 is 0.4960893988609314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1839.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1693.4764404296875.\n",
      "The relative quantization error of layer 37 is 0.3918311893939972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1839.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.1611328125.\n",
      "The relative quantization error of layer 38 is 0.2065420001745224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1302.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1338.8740234375.\n",
      "The relative quantization error of layer 39 is 0.5046133399009705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1843.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1826.6551513671875.\n",
      "The relative quantization error of layer 40 is 0.42689189314842224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1845.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.11752319335938.\n",
      "The relative quantization error of layer 41 is 0.2189737856388092.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1307.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1385.435546875.\n",
      "The relative quantization error of layer 42 is 0.527224063873291.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1749.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2494.15380859375.\n",
      "The relative quantization error of layer 43 is 0.444347620010376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1838.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 152.49513244628906.\n",
      "The relative quantization error of layer 44 is 0.2009885460138321.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1681.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 894.6072387695312.\n",
      "The relative quantization error of layer 45 is 0.4191319942474365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 877.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2166.607177734375.\n",
      "The relative quantization error of layer 46 is 0.4609715938568115.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1848.43it/s]\n",
      "  8%|▊         | 368/4608 [00:00<00:02, 1835.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.1153564453125.\n",
      "The relative quantization error of layer 47 is 0.3894883990287781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1845.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 108.141357421875.\n",
      "The relative quantization error of layer 48 is 0.0921451523900032.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1711.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 520.2020263671875.\n",
      "The relative quantization error of layer 49 is 0.6542603373527527.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1846.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 449.0841979980469.\n",
      "The relative quantization error of layer 50 is 0.24890604615211487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1859.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 63.28251647949219.\n",
      "The relative quantization error of layer 51 is 0.13510820269584656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1758.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 108.30496215820312.\n",
      "The relative quantization error of layer 52 is 0.7596396803855896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1854.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 25.402511596679688.\n",
      "The relative quantization error of layer 53 is 0.15534283220767975.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.098140\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.46it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.887.\n",
      "Top-5 accuracy of vgg16 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.944.\n",
      "Top-5 accuracy of quantized vgg16 is 0.991.\n",
      "\n",
      "Time used for evaluation: 0:00:04.304084\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4536\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 800.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 80.85393524169922.\n",
      "The relative quantization error of layer 0 is 0.01829959638416767.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 699.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 894.8817138671875.\n",
      "The relative quantization error of layer 1 is 0.050224341452121735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1748.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 255.0712432861328.\n",
      "The relative quantization error of layer 2 is 0.057021964341402054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3472.736328125.\n",
      "The relative quantization error of layer 3 is 0.10273605585098267.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 198.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1405.674072265625.\n",
      "The relative quantization error of layer 4 is 0.048802006989717484.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 479.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 585.8372802734375.\n",
      "The relative quantization error of layer 5 is 0.20077857375144958.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1682.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 275.0473937988281.\n",
      "The relative quantization error of layer 6 is 0.23831212520599365.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 211.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1019.5071411132812.\n",
      "The relative quantization error of layer 7 is 0.22046463191509247.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 459.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 900.71240234375.\n",
      "The relative quantization error of layer 8 is 0.26464149355888367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1828.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 559.8687744140625.\n",
      "The relative quantization error of layer 9 is 0.278467059135437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 209.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1581.599365234375.\n",
      "The relative quantization error of layer 10 is 0.24015925824642181.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 278.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1720.67578125.\n",
      "The relative quantization error of layer 11 is 0.30799806118011475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1842.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1166.0831298828125.\n",
      "The relative quantization error of layer 12 is 0.3038090765476227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 807.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1557.3592529296875.\n",
      "The relative quantization error of layer 13 is 0.22293587028980255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2030.025634765625.\n",
      "The relative quantization error of layer 14 is 0.29939648509025574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1688.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1970.3760986328125.\n",
      "The relative quantization error of layer 15 is 0.2768745720386505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1833.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 505.5555419921875.\n",
      "The relative quantization error of layer 16 is 0.2357569932937622.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 846.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1119.5286865234375.\n",
      "The relative quantization error of layer 17 is 0.3854140639305115.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1648.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1781.2833251953125.\n",
      "The relative quantization error of layer 18 is 0.30775073170661926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1830.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.12042236328125.\n",
      "The relative quantization error of layer 19 is 0.25974759459495544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 846.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1254.9337158203125.\n",
      "The relative quantization error of layer 20 is 0.3100539743900299.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1682.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2023.406005859375.\n",
      "The relative quantization error of layer 21 is 0.3376784026622772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1833.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 442.02484130859375.\n",
      "The relative quantization error of layer 22 is 0.2822003662586212.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 848.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1033.12060546875.\n",
      "The relative quantization error of layer 23 is 0.39187487959861755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1272.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3344.087890625.\n",
      "The relative quantization error of layer 24 is 0.37285107374191284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1833.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 611.136474609375.\n",
      "The relative quantization error of layer 25 is 0.3260546326637268.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1303.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1378.777587890625.\n",
      "The relative quantization error of layer 26 is 0.3767983615398407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 511.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3425.2333984375.\n",
      "The relative quantization error of layer 27 is 0.35818129777908325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1815.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1303.70068359375.\n",
      "The relative quantization error of layer 28 is 0.33352264761924744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1823.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 273.06494140625.\n",
      "The relative quantization error of layer 29 is 0.19041426479816437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1293.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1010.9307250976562.\n",
      "The relative quantization error of layer 30 is 0.4564160704612732.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1807.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1514.5989990234375.\n",
      "The relative quantization error of layer 31 is 0.3647482693195343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1833.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.01123046875.\n",
      "The relative quantization error of layer 32 is 0.2209433615207672.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1268.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 888.1016235351562.\n",
      "The relative quantization error of layer 33 is 0.47726231813430786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1810.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1698.12890625.\n",
      "The relative quantization error of layer 34 is 0.3982262909412384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1832.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.96726989746094.\n",
      "The relative quantization error of layer 35 is 0.20369528234004974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1305.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1078.4139404296875.\n",
      "The relative quantization error of layer 36 is 0.5282115936279297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1809.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1754.6986083984375.\n",
      "The relative quantization error of layer 37 is 0.40999722480773926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1817.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.4062957763672.\n",
      "The relative quantization error of layer 38 is 0.21233190596103668.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1288.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1338.347900390625.\n",
      "The relative quantization error of layer 39 is 0.5144878029823303.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1808.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1814.637939453125.\n",
      "The relative quantization error of layer 40 is 0.43682917952537537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1829.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 184.70510864257812.\n",
      "The relative quantization error of layer 41 is 0.23102211952209473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1292.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1431.0367431640625.\n",
      "The relative quantization error of layer 42 is 0.5270217657089233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1729.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2521.2431640625.\n",
      "The relative quantization error of layer 43 is 0.4573308527469635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1826.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.0026092529297.\n",
      "The relative quantization error of layer 44 is 0.20296324789524078.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1707.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 912.9776611328125.\n",
      "The relative quantization error of layer 45 is 0.4160662591457367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 872.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2172.55419921875.\n",
      "The relative quantization error of layer 46 is 0.46740350127220154.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1824.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 415.1411437988281.\n",
      "The relative quantization error of layer 47 is 0.37496888637542725.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1823.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 105.42982482910156.\n",
      "The relative quantization error of layer 48 is 0.1163279265165329.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1707.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 536.2277221679688.\n",
      "The relative quantization error of layer 49 is 0.6677123308181763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1830.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 483.0294494628906.\n",
      "The relative quantization error of layer 50 is 0.24460789561271667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1850.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 94.54096221923828.\n",
      "The relative quantization error of layer 51 is 0.1409349888563156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1741.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.4556655883789.\n",
      "The relative quantization error of layer 52 is 0.7900533080101013.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1825.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 39.13304901123047.\n",
      "The relative quantization error of layer 53 is 0.24085666239261627.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.158803\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.855.\n",
      "Top-5 accuracy of vgg16 is 0.984.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.951.\n",
      "Top-5 accuracy of quantized vgg16 is 0.995.\n",
      "\n",
      "Time used for evaluation: 0:00:04.189124\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.453\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 801.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 78.35137176513672.\n",
      "The relative quantization error of layer 0 is 0.01819893904030323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 512.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 900.23193359375.\n",
      "The relative quantization error of layer 1 is 0.05108828842639923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2681.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 249.38197326660156.\n",
      "The relative quantization error of layer 2 is 0.0533231683075428.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 212.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3349.34033203125.\n",
      "The relative quantization error of layer 3 is 0.10219639539718628.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 229.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1372.387939453125.\n",
      "The relative quantization error of layer 4 is 0.04628856107592583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 573.8430786132812.\n",
      "The relative quantization error of layer 5 is 0.199172705411911.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2559.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 260.2993469238281.\n",
      "The relative quantization error of layer 6 is 0.23202726244926453.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 229.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1055.9757080078125.\n",
      "The relative quantization error of layer 7 is 0.22906573116779327.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 872.6992797851562.\n",
      "The relative quantization error of layer 8 is 0.2642393410205841.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2650.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 580.1952514648438.\n",
      "The relative quantization error of layer 9 is 0.27853724360466003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 234.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1626.1666259765625.\n",
      "The relative quantization error of layer 10 is 0.24119359254837036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 286.71it/s]\n",
      " 46%|████▋     | 533/1152 [00:00<00:00, 2662.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1673.1031494140625.\n",
      "The relative quantization error of layer 11 is 0.3078515827655792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2652.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1201.287109375.\n",
      "The relative quantization error of layer 12 is 0.30662569403648376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 858.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1477.3572998046875.\n",
      "The relative quantization error of layer 13 is 0.214580237865448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2019.0970458984375.\n",
      "The relative quantization error of layer 14 is 0.29665258526802063.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2075.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1984.8348388671875.\n",
      "The relative quantization error of layer 15 is 0.2723388671875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2652.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 498.8657531738281.\n",
      "The relative quantization error of layer 16 is 0.23247718811035156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 751.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1141.354736328125.\n",
      "The relative quantization error of layer 17 is 0.3863257169723511.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2073.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1763.2413330078125.\n",
      "The relative quantization error of layer 18 is 0.2982591688632965.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2643.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 354.6940612792969.\n",
      "The relative quantization error of layer 19 is 0.250746488571167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 904.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1228.690673828125.\n",
      "The relative quantization error of layer 20 is 0.30738088488578796.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2068.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1923.6055908203125.\n",
      "The relative quantization error of layer 21 is 0.3283490538597107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2629.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 429.9677734375.\n",
      "The relative quantization error of layer 22 is 0.27463147044181824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 906.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 984.8569946289062.\n",
      "The relative quantization error of layer 23 is 0.3969762623310089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1481.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3289.951904296875.\n",
      "The relative quantization error of layer 24 is 0.3642725646495819.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2637.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 611.5709838867188.\n",
      "The relative quantization error of layer 25 is 0.3249637484550476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1523.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1365.746337890625.\n",
      "The relative quantization error of layer 26 is 0.3705294728279114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 525.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3385.222900390625.\n",
      "The relative quantization error of layer 27 is 0.35714998841285706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2624.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1319.583984375.\n",
      "The relative quantization error of layer 28 is 0.3312188386917114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2638.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 260.3865661621094.\n",
      "The relative quantization error of layer 29 is 0.1801983267068863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1515.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 995.502197265625.\n",
      "The relative quantization error of layer 30 is 0.43858712911605835.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2619.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1494.979736328125.\n",
      "The relative quantization error of layer 31 is 0.3637838065624237.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2642.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.3187561035156.\n",
      "The relative quantization error of layer 32 is 0.22060319781303406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1505.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 868.1851196289062.\n",
      "The relative quantization error of layer 33 is 0.4680511951446533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2606.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1618.5189208984375.\n",
      "The relative quantization error of layer 34 is 0.4071504771709442.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2617.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.2058868408203.\n",
      "The relative quantization error of layer 35 is 0.2079121619462967.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1484.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1032.2935791015625.\n",
      "The relative quantization error of layer 36 is 0.5173187255859375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2631.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1759.85400390625.\n",
      "The relative quantization error of layer 37 is 0.43460148572921753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2644.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 208.44105529785156.\n",
      "The relative quantization error of layer 38 is 0.21281148493289948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1514.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1358.7913818359375.\n",
      "The relative quantization error of layer 39 is 0.5079455971717834.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2610.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1839.8509521484375.\n",
      "The relative quantization error of layer 40 is 0.43186503648757935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2572.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 173.74534606933594.\n",
      "The relative quantization error of layer 41 is 0.21555012464523315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1507.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1436.5301513671875.\n",
      "The relative quantization error of layer 42 is 0.5251224637031555.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2131.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2491.78369140625.\n",
      "The relative quantization error of layer 43 is 0.45312899351119995.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2588.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.71334838867188.\n",
      "The relative quantization error of layer 44 is 0.2070990800857544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2100.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 929.2376098632812.\n",
      "The relative quantization error of layer 45 is 0.42593109607696533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 931.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2150.4326171875.\n",
      "The relative quantization error of layer 46 is 0.46663469076156616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2633.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 405.27838134765625.\n",
      "The relative quantization error of layer 47 is 0.4038676917552948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2628.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 111.01114654541016.\n",
      "The relative quantization error of layer 48 is 0.11651667952537537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2081.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 508.58453369140625.\n",
      "The relative quantization error of layer 49 is 0.6510392427444458.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2601.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 469.44915771484375.\n",
      "The relative quantization error of layer 50 is 0.2978600561618805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2613.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 103.89295959472656.\n",
      "The relative quantization error of layer 51 is 0.168709859251976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2066.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 110.49446868896484.\n",
      "The relative quantization error of layer 52 is 0.7972344160079956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2530.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 28.965166091918945.\n",
      "The relative quantization error of layer 53 is 0.19200628995895386.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:51.355043\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.14it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.882.\n",
      "Top-5 accuracy of vgg16 is 0.99.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.946.\n",
      "Top-5 accuracy of quantized vgg16 is 0.996.\n",
      "\n",
      "Time used for evaluation: 0:00:03.890845\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4544\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 787.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.89012145996094.\n",
      "The relative quantization error of layer 0 is 0.019167840480804443.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 839.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 905.6229858398438.\n",
      "The relative quantization error of layer 1 is 0.05111963674426079.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1625.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 250.60699462890625.\n",
      "The relative quantization error of layer 2 is 0.056809306144714355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3377.907958984375.\n",
      "The relative quantization error of layer 3 is 0.10090906172990799.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1438.98291015625.\n",
      "The relative quantization error of layer 4 is 0.04826762527227402.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 499.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 606.91650390625.\n",
      "The relative quantization error of layer 5 is 0.20841985940933228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1870.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 273.3678894042969.\n",
      "The relative quantization error of layer 6 is 0.23603005707263947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1068.906982421875.\n",
      "The relative quantization error of layer 7 is 0.23172977566719055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 469.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 900.930419921875.\n",
      "The relative quantization error of layer 8 is 0.27170032262802124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1886.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 565.4446411132812.\n",
      "The relative quantization error of layer 9 is 0.27051088213920593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1684.6646728515625.\n",
      "The relative quantization error of layer 10 is 0.24723055958747864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 268.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1719.10986328125.\n",
      "The relative quantization error of layer 11 is 0.30734482407569885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1868.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1209.4427490234375.\n",
      "The relative quantization error of layer 12 is 0.3063122630119324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 749.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1555.2274169921875.\n",
      "The relative quantization error of layer 13 is 0.2240394651889801.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 74.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2060.465087890625.\n",
      "The relative quantization error of layer 14 is 0.2997734546661377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1720.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2064.1123046875.\n",
      "The relative quantization error of layer 15 is 0.2678960859775543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1878.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 531.7324829101562.\n",
      "The relative quantization error of layer 16 is 0.24139206111431122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 604.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1234.3399658203125.\n",
      "The relative quantization error of layer 17 is 0.3952684700489044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1716.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1819.0513916015625.\n",
      "The relative quantization error of layer 18 is 0.3080456852912903.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1884.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 363.66107177734375.\n",
      "The relative quantization error of layer 19 is 0.26076579093933105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 922.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1262.913818359375.\n",
      "The relative quantization error of layer 20 is 0.31107696890830994.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1724.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1979.26416015625.\n",
      "The relative quantization error of layer 21 is 0.32976990938186646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1878.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 439.71136474609375.\n",
      "The relative quantization error of layer 22 is 0.26732465624809265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 852.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 976.058349609375.\n",
      "The relative quantization error of layer 23 is 0.3854347765445709.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1279.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3323.729736328125.\n",
      "The relative quantization error of layer 24 is 0.3657473027706146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1881.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 629.0110473632812.\n",
      "The relative quantization error of layer 25 is 0.322188138961792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1314.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1403.07861328125.\n",
      "The relative quantization error of layer 26 is 0.3766232132911682.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 506.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3351.16552734375.\n",
      "The relative quantization error of layer 27 is 0.35480859875679016.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1855.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1359.3223876953125.\n",
      "The relative quantization error of layer 28 is 0.3366410732269287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1860.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.6163024902344.\n",
      "The relative quantization error of layer 29 is 0.17998471856117249.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1287.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 979.4896240234375.\n",
      "The relative quantization error of layer 30 is 0.43234163522720337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1868.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1509.4708251953125.\n",
      "The relative quantization error of layer 31 is 0.3598090410232544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1882.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.77044677734375.\n",
      "The relative quantization error of layer 32 is 0.2198874056339264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1294.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 909.671875.\n",
      "The relative quantization error of layer 33 is 0.48687538504600525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1762.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1675.5369873046875.\n",
      "The relative quantization error of layer 34 is 0.4022539556026459.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1889.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 242.3742218017578.\n",
      "The relative quantization error of layer 35 is 0.20340575277805328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1323.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1031.7999267578125.\n",
      "The relative quantization error of layer 36 is 0.5183924436569214.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1873.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1796.1282958984375.\n",
      "The relative quantization error of layer 37 is 0.4267931878566742.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1884.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 216.5331573486328.\n",
      "The relative quantization error of layer 38 is 0.21441970765590668.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1313.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1359.0982666015625.\n",
      "The relative quantization error of layer 39 is 0.5146685242652893.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1864.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1826.7589111328125.\n",
      "The relative quantization error of layer 40 is 0.42923542857170105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1875.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 185.0052947998047.\n",
      "The relative quantization error of layer 41 is 0.22667410969734192.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1302.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1433.083984375.\n",
      "The relative quantization error of layer 42 is 0.5296229124069214.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1756.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2498.1357421875.\n",
      "The relative quantization error of layer 43 is 0.45539867877960205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1864.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.17620849609375.\n",
      "The relative quantization error of layer 44 is 0.20090611279010773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1689.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 911.1334228515625.\n",
      "The relative quantization error of layer 45 is 0.4097706079483032.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 862.72it/s]\n",
      " 14%|█▍        | 283/2048 [00:00<00:01, 1492.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2211.158447265625.\n",
      "The relative quantization error of layer 46 is 0.470444917678833.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1799.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 415.6470031738281.\n",
      "The relative quantization error of layer 47 is 0.3943102955818176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1882.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.18248748779297.\n",
      "The relative quantization error of layer 48 is 0.10934246331453323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1744.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 522.0003051757812.\n",
      "The relative quantization error of layer 49 is 0.6641844511032104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1796.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 417.7257385253906.\n",
      "The relative quantization error of layer 50 is 0.2764683961868286.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1884.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 89.08644104003906.\n",
      "The relative quantization error of layer 51 is 0.19796337187290192.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1762.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 104.36941528320312.\n",
      "The relative quantization error of layer 52 is 0.7652929425239563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1894.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 27.68667221069336.\n",
      "The relative quantization error of layer 53 is 0.17485754191875458.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.184650\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.80it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.862.\n",
      "Top-5 accuracy of vgg16 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.93.\n",
      "Top-5 accuracy of quantized vgg16 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:00:04.295980\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4547\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 739.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 84.33745574951172.\n",
      "The relative quantization error of layer 0 is 0.018561456352472305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 531.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 904.3998413085938.\n",
      "The relative quantization error of layer 1 is 0.05032113566994667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2544.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 258.4042053222656.\n",
      "The relative quantization error of layer 2 is 0.054876480251550674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 230.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3422.429931640625.\n",
      "The relative quantization error of layer 3 is 0.10530338436365128.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 227.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1537.5833740234375.\n",
      "The relative quantization error of layer 4 is 0.05224573239684105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 512.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 623.8082275390625.\n",
      "The relative quantization error of layer 5 is 0.20749983191490173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2321.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 274.5920104980469.\n",
      "The relative quantization error of layer 6 is 0.2245262861251831.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 207.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1109.88720703125.\n",
      "The relative quantization error of layer 7 is 0.22646494209766388.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 480.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 893.6316528320312.\n",
      "The relative quantization error of layer 8 is 0.25524798035621643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1804.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 579.10986328125.\n",
      "The relative quantization error of layer 9 is 0.269026517868042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 221.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1618.0638427734375.\n",
      "The relative quantization error of layer 10 is 0.23711885511875153.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 269.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1734.568359375.\n",
      "The relative quantization error of layer 11 is 0.29829180240631104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1831.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1242.54833984375.\n",
      "The relative quantization error of layer 12 is 0.3111538290977478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 785.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1540.864990234375.\n",
      "The relative quantization error of layer 13 is 0.2169172167778015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2108.044189453125.\n",
      "The relative quantization error of layer 14 is 0.29492810368537903.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1686.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2122.487060546875.\n",
      "The relative quantization error of layer 15 is 0.2747114896774292.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1869.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 528.8832397460938.\n",
      "The relative quantization error of layer 16 is 0.23841805756092072.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 849.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1187.533203125.\n",
      "The relative quantization error of layer 17 is 0.38236212730407715.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1677.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1814.422607421875.\n",
      "The relative quantization error of layer 18 is 0.3045988082885742.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1763.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 362.628173828125.\n",
      "The relative quantization error of layer 19 is 0.25554898381233215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 850.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1253.0946044921875.\n",
      "The relative quantization error of layer 20 is 0.3052307963371277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1713.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1986.6270751953125.\n",
      "The relative quantization error of layer 21 is 0.3185252249240875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1866.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 452.3100280761719.\n",
      "The relative quantization error of layer 22 is 0.27771344780921936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 927.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1069.653076171875.\n",
      "The relative quantization error of layer 23 is 0.34185969829559326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1467.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3325.251953125.\n",
      "The relative quantization error of layer 24 is 0.36224275827407837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2647.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 626.8052978515625.\n",
      "The relative quantization error of layer 25 is 0.32384011149406433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1318.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1355.9129638671875.\n",
      "The relative quantization error of layer 26 is 0.36693593859672546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 505.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3403.5712890625.\n",
      "The relative quantization error of layer 27 is 0.3423934876918793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1852.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1363.0052490234375.\n",
      "The relative quantization error of layer 28 is 0.33029869198799133.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1863.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 267.1644592285156.\n",
      "The relative quantization error of layer 29 is 0.18380700051784515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1322.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1015.2432861328125.\n",
      "The relative quantization error of layer 30 is 0.4216373562812805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2486.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1523.3331298828125.\n",
      "The relative quantization error of layer 31 is 0.35603541135787964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1869.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.56390380859375.\n",
      "The relative quantization error of layer 32 is 0.217652827501297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1499.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 889.2074584960938.\n",
      "The relative quantization error of layer 33 is 0.47592806816101074.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2601.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1651.6065673828125.\n",
      "The relative quantization error of layer 34 is 0.37084439396858215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2656.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 248.12545776367188.\n",
      "The relative quantization error of layer 35 is 0.2047930508852005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1357.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1018.9838256835938.\n",
      "The relative quantization error of layer 36 is 0.515023410320282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2622.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1759.4097900390625.\n",
      "The relative quantization error of layer 37 is 0.41148489713668823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2632.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.3004913330078.\n",
      "The relative quantization error of layer 38 is 0.2130783498287201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1506.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1385.103271484375.\n",
      "The relative quantization error of layer 39 is 0.5151770710945129.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2638.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1822.6915283203125.\n",
      "The relative quantization error of layer 40 is 0.4130740761756897.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2652.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 174.67921447753906.\n",
      "The relative quantization error of layer 41 is 0.22012463212013245.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1260.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1378.3568115234375.\n",
      "The relative quantization error of layer 42 is 0.5286539793014526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1760.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2488.346435546875.\n",
      "The relative quantization error of layer 43 is 0.44565507769584656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1868.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.25051879882812.\n",
      "The relative quantization error of layer 44 is 0.2018263041973114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1735.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 912.644775390625.\n",
      "The relative quantization error of layer 45 is 0.4278055429458618.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 868.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2194.9326171875.\n",
      "The relative quantization error of layer 46 is 0.4651336073875427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1855.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.5895690917969.\n",
      "The relative quantization error of layer 47 is 0.40150582790374756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1871.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 98.36309814453125.\n",
      "The relative quantization error of layer 48 is 0.09631757438182831.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2034.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 506.7144470214844.\n",
      "The relative quantization error of layer 49 is 0.6576493382453918.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2648.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 434.4486999511719.\n",
      "The relative quantization error of layer 50 is 0.2414952516555786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2673.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 89.95700073242188.\n",
      "The relative quantization error of layer 51 is 0.1283097118139267.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1937.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 113.64743041992188.\n",
      "The relative quantization error of layer 52 is 0.7823771238327026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1869.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 30.658641815185547.\n",
      "The relative quantization error of layer 53 is 0.18697550892829895.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:56.172211\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.886.\n",
      "Top-5 accuracy of vgg16 is 0.99.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.947.\n",
      "Top-5 accuracy of quantized vgg16 is 0.993.\n",
      "\n",
      "Time used for evaluation: 0:00:04.698836\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4552\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 763.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 86.75579833984375.\n",
      "The relative quantization error of layer 0 is 0.018261121585965157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 811.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 903.6868286132812.\n",
      "The relative quantization error of layer 1 is 0.05095059424638748.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2380.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 239.4674530029297.\n",
      "The relative quantization error of layer 2 is 0.05387425795197487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 208.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3555.63623046875.\n",
      "The relative quantization error of layer 3 is 0.10614656656980515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 214.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1389.2537841796875.\n",
      "The relative quantization error of layer 4 is 0.04767350107431412.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 491.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 591.1036376953125.\n",
      "The relative quantization error of layer 5 is 0.199986532330513.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2563.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 269.1793518066406.\n",
      "The relative quantization error of layer 6 is 0.23920375108718872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 208.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1040.2958984375.\n",
      "The relative quantization error of layer 7 is 0.2263888269662857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 453.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 862.238037109375.\n",
      "The relative quantization error of layer 8 is 0.25604814291000366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1796.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 570.1082763671875.\n",
      "The relative quantization error of layer 9 is 0.2764444947242737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 201.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1497.5321044921875.\n",
      "The relative quantization error of layer 10 is 0.22487089037895203.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 286.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1699.1593017578125.\n",
      "The relative quantization error of layer 11 is 0.3035706579685211.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2584.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1202.717041015625.\n",
      "The relative quantization error of layer 12 is 0.3061000108718872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 927.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1507.400634765625.\n",
      "The relative quantization error of layer 13 is 0.21960696578025818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1993.0091552734375.\n",
      "The relative quantization error of layer 14 is 0.29438358545303345.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1612.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2059.97509765625.\n",
      "The relative quantization error of layer 15 is 0.27321553230285645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1806.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 504.6844482421875.\n",
      "The relative quantization error of layer 16 is 0.23575161397457123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 835.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1155.8392333984375.\n",
      "The relative quantization error of layer 17 is 0.3841703534126282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1577.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1778.9093017578125.\n",
      "The relative quantization error of layer 18 is 0.29982829093933105.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1786.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 373.9676513671875.\n",
      "The relative quantization error of layer 19 is 0.26349109411239624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 807.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1202.583984375.\n",
      "The relative quantization error of layer 20 is 0.30182161927223206.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1674.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2004.4117431640625.\n",
      "The relative quantization error of layer 21 is 0.3336550295352936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1850.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 429.3339538574219.\n",
      "The relative quantization error of layer 22 is 0.27311083674430847.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 724.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1002.9813842773438.\n",
      "The relative quantization error of layer 23 is 0.3653798997402191.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1264.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3283.7607421875.\n",
      "The relative quantization error of layer 24 is 0.3578028380870819.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1754.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 618.1268920898438.\n",
      "The relative quantization error of layer 25 is 0.32574257254600525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1197.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1356.5982666015625.\n",
      "The relative quantization error of layer 26 is 0.3691614866256714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 495.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3404.025146484375.\n",
      "The relative quantization error of layer 27 is 0.352237343788147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1749.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1361.9705810546875.\n",
      "The relative quantization error of layer 28 is 0.34124019742012024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1799.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.8088073730469.\n",
      "The relative quantization error of layer 29 is 0.18246419727802277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1250.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 965.8873901367188.\n",
      "The relative quantization error of layer 30 is 0.4433227479457855.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1836.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1507.5880126953125.\n",
      "The relative quantization error of layer 31 is 0.3614288568496704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1827.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 287.314697265625.\n",
      "The relative quantization error of layer 32 is 0.2183823138475418.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1309.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 848.85009765625.\n",
      "The relative quantization error of layer 33 is 0.4661790728569031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1767.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1642.754638671875.\n",
      "The relative quantization error of layer 34 is 0.41143715381622314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1831.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 235.71380615234375.\n",
      "The relative quantization error of layer 35 is 0.19998383522033691.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1297.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1012.92138671875.\n",
      "The relative quantization error of layer 36 is 0.5118944644927979.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1821.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1753.5316162109375.\n",
      "The relative quantization error of layer 37 is 0.41272857785224915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1831.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 215.07321166992188.\n",
      "The relative quantization error of layer 38 is 0.21870791912078857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1288.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1359.4749755859375.\n",
      "The relative quantization error of layer 39 is 0.5121570229530334.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2544.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1841.1988525390625.\n",
      "The relative quantization error of layer 40 is 0.4307842552661896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2491.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 182.19720458984375.\n",
      "The relative quantization error of layer 41 is 0.23081086575984955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1501.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1415.4569091796875.\n",
      "The relative quantization error of layer 42 is 0.5304448008537292.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1734.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2507.35498046875.\n",
      "The relative quantization error of layer 43 is 0.44797539710998535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1829.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.7386016845703.\n",
      "The relative quantization error of layer 44 is 0.2086174488067627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1703.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 893.80810546875.\n",
      "The relative quantization error of layer 45 is 0.42343616485595703.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 850.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2188.931396484375.\n",
      "The relative quantization error of layer 46 is 0.4743112623691559.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1827.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 400.13720703125.\n",
      "The relative quantization error of layer 47 is 0.4093954265117645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1832.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.43901062011719.\n",
      "The relative quantization error of layer 48 is 0.09537234157323837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1656.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 513.469482421875.\n",
      "The relative quantization error of layer 49 is 0.6660493612289429.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1805.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 418.51593017578125.\n",
      "The relative quantization error of layer 50 is 0.24620580673217773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1852.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 81.12300109863281.\n",
      "The relative quantization error of layer 51 is 0.15193450450897217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1756.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 108.6007308959961.\n",
      "The relative quantization error of layer 52 is 0.7703381776809692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1840.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 35.970062255859375.\n",
      "The relative quantization error of layer 53 is 0.2248745709657669.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:01:00.212729\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.874.\n",
      "Top-5 accuracy of vgg16 is 0.987.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.948.\n",
      "Top-5 accuracy of quantized vgg16 is 0.991.\n",
      "\n",
      "Time used for evaluation: 0:00:04.402029\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4546\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 709.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 89.27447509765625.\n",
      "The relative quantization error of layer 0 is 0.01934090629220009.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 578.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 920.7059936523438.\n",
      "The relative quantization error of layer 1 is 0.051977481693029404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1742.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 257.8160705566406.\n",
      "The relative quantization error of layer 2 is 0.05873752757906914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 240.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3388.5478515625.\n",
      "The relative quantization error of layer 3 is 0.10112575441598892.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 250.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1419.88232421875.\n",
      "The relative quantization error of layer 4 is 0.04770844429731369.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 467.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 594.603515625.\n",
      "The relative quantization error of layer 5 is 0.20351897180080414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1840.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 269.75885009765625.\n",
      "The relative quantization error of layer 6 is 0.23601368069648743.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 242.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1052.0767822265625.\n",
      "The relative quantization error of layer 7 is 0.2275242954492569.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 482.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 882.2095947265625.\n",
      "The relative quantization error of layer 8 is 0.2653671205043793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1836.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 545.9188842773438.\n",
      "The relative quantization error of layer 9 is 0.26500192284584045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 207.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1603.3006591796875.\n",
      "The relative quantization error of layer 10 is 0.23952633142471313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 278.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1705.5684814453125.\n",
      "The relative quantization error of layer 11 is 0.30420345067977905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1857.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1213.5057373046875.\n",
      "The relative quantization error of layer 12 is 0.3057256042957306.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 853.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1546.5526123046875.\n",
      "The relative quantization error of layer 13 is 0.22276818752288818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2064.904541015625.\n",
      "The relative quantization error of layer 14 is 0.29914265871047974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1699.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2083.3623046875.\n",
      "The relative quantization error of layer 15 is 0.2681421637535095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1853.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 539.8947143554688.\n",
      "The relative quantization error of layer 16 is 0.24229682981967926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 770.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1213.851318359375.\n",
      "The relative quantization error of layer 17 is 0.3890332877635956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1708.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1794.077880859375.\n",
      "The relative quantization error of layer 18 is 0.30439186096191406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2465.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.92449951171875.\n",
      "The relative quantization error of layer 19 is 0.2620881199836731.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 934.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1263.2550048828125.\n",
      "The relative quantization error of layer 20 is 0.3111918866634369.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2077.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1981.1064453125.\n",
      "The relative quantization error of layer 21 is 0.3316405713558197.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2674.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 437.41534423828125.\n",
      "The relative quantization error of layer 22 is 0.2687627673149109.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 849.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 981.2176513671875.\n",
      "The relative quantization error of layer 23 is 0.387801855802536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1476.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3346.814208984375.\n",
      "The relative quantization error of layer 24 is 0.36694973707199097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2660.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 635.7677001953125.\n",
      "The relative quantization error of layer 25 is 0.3239920735359192.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1523.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1409.148681640625.\n",
      "The relative quantization error of layer 26 is 0.37830331921577454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 527.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3379.242919921875.\n",
      "The relative quantization error of layer 27 is 0.35330578684806824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2602.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1363.3385009765625.\n",
      "The relative quantization error of layer 28 is 0.33709073066711426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2632.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.22265625.\n",
      "The relative quantization error of layer 29 is 0.17754100263118744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1408.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 971.234130859375.\n",
      "The relative quantization error of layer 30 is 0.4295338988304138.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2640.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1519.7880859375.\n",
      "The relative quantization error of layer 31 is 0.35919591784477234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1784.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.06878662109375.\n",
      "The relative quantization error of layer 32 is 0.22189413011074066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1321.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 883.021728515625.\n",
      "The relative quantization error of layer 33 is 0.4735986888408661.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1829.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1671.6588134765625.\n",
      "The relative quantization error of layer 34 is 0.3975113034248352.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1858.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.516357421875.\n",
      "The relative quantization error of layer 35 is 0.20296207070350647.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1306.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1013.971435546875.\n",
      "The relative quantization error of layer 36 is 0.510500431060791.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1814.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1773.05615234375.\n",
      "The relative quantization error of layer 37 is 0.4242551028728485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1855.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.8218231201172.\n",
      "The relative quantization error of layer 38 is 0.20732149481773376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1298.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1342.7471923828125.\n",
      "The relative quantization error of layer 39 is 0.5058521032333374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1856.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1804.4334716796875.\n",
      "The relative quantization error of layer 40 is 0.4267679452896118.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1857.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.39108276367188.\n",
      "The relative quantization error of layer 41 is 0.22703176736831665.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1299.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1421.851806640625.\n",
      "The relative quantization error of layer 42 is 0.5282170176506042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1756.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2474.48681640625.\n",
      "The relative quantization error of layer 43 is 0.45017823576927185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1867.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 154.987548828125.\n",
      "The relative quantization error of layer 44 is 0.19384656846523285.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1692.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 912.22509765625.\n",
      "The relative quantization error of layer 45 is 0.4163094758987427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 846.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2167.833984375.\n",
      "The relative quantization error of layer 46 is 0.46300992369651794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1865.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 403.0813293457031.\n",
      "The relative quantization error of layer 47 is 0.39504075050354004.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1875.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.95487213134766.\n",
      "The relative quantization error of layer 48 is 0.10130167752504349.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1731.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 525.3132934570312.\n",
      "The relative quantization error of layer 49 is 0.665189266204834.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1857.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 467.394287109375.\n",
      "The relative quantization error of layer 50 is 0.22779034078121185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1890.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 69.22754669189453.\n",
      "The relative quantization error of layer 51 is 0.11945626884698868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1771.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 102.8030014038086.\n",
      "The relative quantization error of layer 52 is 0.7491175532341003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1873.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 30.130157470703125.\n",
      "The relative quantization error of layer 53 is 0.19028957188129425.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:58.478643\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.71it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.862.\n",
      "Top-5 accuracy of vgg16 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.953.\n",
      "Top-5 accuracy of quantized vgg16 is 0.996.\n",
      "\n",
      "Time used for evaluation: 0:00:03.904055\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4536\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['False'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'vgg16' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9969179e-0865-48e8-a11d-cc1e1f526b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 814.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 79.18983459472656.\n",
      "The relative quantization error of layer 0 is 0.017937103286385536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 795.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 915.5927124023438.\n",
      "The relative quantization error of layer 1 is 0.05166284367442131.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2415.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 249.12124633789062.\n",
      "The relative quantization error of layer 2 is 0.05615992099046707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3495.139404296875.\n",
      "The relative quantization error of layer 3 is 0.10258244723081589.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 258.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1322.158935546875.\n",
      "The relative quantization error of layer 4 is 0.04460630193352699.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 501.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 601.9247436523438.\n",
      "The relative quantization error of layer 5 is 0.20196589827537537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2347.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 259.57464599609375.\n",
      "The relative quantization error of layer 6 is 0.22677530348300934.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 229.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1073.3197021484375.\n",
      "The relative quantization error of layer 7 is 0.23176351189613342.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 523.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 881.2799682617188.\n",
      "The relative quantization error of layer 8 is 0.25785237550735474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2454.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 580.8161010742188.\n",
      "The relative quantization error of layer 9 is 0.2689887583255768.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.56it/s]\n",
      "  9%|▊         | 22/256 [00:00<00:01, 219.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1806.1715087890625.\n",
      "The relative quantization error of layer 10 is 0.2723209857940674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 278.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1705.726806640625.\n",
      "The relative quantization error of layer 11 is 0.31348541378974915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2597.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1211.3631591796875.\n",
      "The relative quantization error of layer 12 is 0.3016032576560974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 828.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1503.02294921875.\n",
      "The relative quantization error of layer 13 is 0.2162328064441681.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1930.79150390625.\n",
      "The relative quantization error of layer 14 is 0.2908203601837158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1937.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1920.715087890625.\n",
      "The relative quantization error of layer 15 is 0.2673567831516266.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2599.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 533.9315185546875.\n",
      "The relative quantization error of layer 16 is 0.23869137465953827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 752.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1210.3697509765625.\n",
      "The relative quantization error of layer 17 is 0.3911731243133545.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2051.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1758.4444580078125.\n",
      "The relative quantization error of layer 18 is 0.2971687912940979.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2557.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 373.0640563964844.\n",
      "The relative quantization error of layer 19 is 0.25696396827697754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 930.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1245.154541015625.\n",
      "The relative quantization error of layer 20 is 0.3011234402656555.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2053.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1978.456298828125.\n",
      "The relative quantization error of layer 21 is 0.323356956243515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2446.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 446.1996154785156.\n",
      "The relative quantization error of layer 22 is 0.27402567863464355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 823.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1020.0242309570312.\n",
      "The relative quantization error of layer 23 is 0.3587457835674286.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1274.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3319.76123046875.\n",
      "The relative quantization error of layer 24 is 0.3701818585395813.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1817.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 619.5941162109375.\n",
      "The relative quantization error of layer 25 is 0.3125075697898865.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1318.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1364.892822265625.\n",
      "The relative quantization error of layer 26 is 0.3655535578727722.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 493.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3429.04443359375.\n",
      "The relative quantization error of layer 27 is 0.35516422986984253.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1815.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1352.9437255859375.\n",
      "The relative quantization error of layer 28 is 0.32886558771133423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1855.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.14337158203125.\n",
      "The relative quantization error of layer 29 is 0.1767372488975525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1211.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 989.5321655273438.\n",
      "The relative quantization error of layer 30 is 0.4188704192638397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1843.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1512.044921875.\n",
      "The relative quantization error of layer 31 is 0.3545414209365845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1861.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.81500244140625.\n",
      "The relative quantization error of layer 32 is 0.21651528775691986.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1322.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 914.1348876953125.\n",
      "The relative quantization error of layer 33 is 0.47722840309143066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1848.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1704.30126953125.\n",
      "The relative quantization error of layer 34 is 0.4046589136123657.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1858.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.69058227539062.\n",
      "The relative quantization error of layer 35 is 0.1987006813287735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1308.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1070.360107421875.\n",
      "The relative quantization error of layer 36 is 0.5131272077560425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1834.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1791.7889404296875.\n",
      "The relative quantization error of layer 37 is 0.4167488217353821.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1836.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 204.18443298339844.\n",
      "The relative quantization error of layer 38 is 0.20252268016338348.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1310.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1375.4287109375.\n",
      "The relative quantization error of layer 39 is 0.5074701905250549.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1847.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1917.83740234375.\n",
      "The relative quantization error of layer 40 is 0.44545674324035645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1860.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 183.29388427734375.\n",
      "The relative quantization error of layer 41 is 0.21721524000167847.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1247.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1511.1102294921875.\n",
      "The relative quantization error of layer 42 is 0.5416288375854492.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1720.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2651.3212890625.\n",
      "The relative quantization error of layer 43 is 0.4759092926979065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1860.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.27194213867188.\n",
      "The relative quantization error of layer 44 is 0.19975632429122925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1701.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 956.9845581054688.\n",
      "The relative quantization error of layer 45 is 0.435820072889328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 879.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2214.32177734375.\n",
      "The relative quantization error of layer 46 is 0.4711315631866455.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1863.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 427.8607482910156.\n",
      "The relative quantization error of layer 47 is 0.41669219732284546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1862.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 109.67539978027344.\n",
      "The relative quantization error of layer 48 is 0.10982560366392136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1721.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 563.713134765625.\n",
      "The relative quantization error of layer 49 is 0.6960425972938538.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1852.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 493.40899658203125.\n",
      "The relative quantization error of layer 50 is 0.31518951058387756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1888.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 83.375.\n",
      "The relative quantization error of layer 51 is 0.11976117640733719.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1754.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 117.81690979003906.\n",
      "The relative quantization error of layer 52 is 0.8212533593177795.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1875.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 49.59126663208008.\n",
      "The relative quantization error of layer 53 is 0.2902979552745819.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:58.572178\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.61it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.748.\n",
      "Top-5 accuracy of vgg16 is 0.963.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.612.\n",
      "Top-5 accuracy of quantized vgg16 is 0.969.\n",
      "\n",
      "Time used for evaluation: 0:00:04.011680\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4548\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 648.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.62364196777344.\n",
      "The relative quantization error of layer 0 is 0.019786646589636803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 831.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 925.7462768554688.\n",
      "The relative quantization error of layer 1 is 0.051850028336048126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2270.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 276.2176513671875.\n",
      "The relative quantization error of layer 2 is 0.06506473571062088.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3503.749755859375.\n",
      "The relative quantization error of layer 3 is 0.09723402559757233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 244.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1699.073486328125.\n",
      "The relative quantization error of layer 4 is 0.05757688730955124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 500.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 641.5879516601562.\n",
      "The relative quantization error of layer 5 is 0.21799209713935852.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2406.53it/s]\n",
      " 36%|███▌      | 23/64 [00:00<00:00, 218.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 278.6830139160156.\n",
      "The relative quantization error of layer 6 is 0.2498450130224228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 242.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1094.9481201171875.\n",
      "The relative quantization error of layer 7 is 0.24143412709236145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 501.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 917.7347412109375.\n",
      "The relative quantization error of layer 8 is 0.27202388644218445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2642.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 595.7665405273438.\n",
      "The relative quantization error of layer 9 is 0.2782991826534271.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1741.7310791015625.\n",
      "The relative quantization error of layer 10 is 0.27345040440559387.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 286.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1840.1778564453125.\n",
      "The relative quantization error of layer 11 is 0.32094138860702515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2677.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1267.7078857421875.\n",
      "The relative quantization error of layer 12 is 0.3039422035217285.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 876.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1611.601806640625.\n",
      "The relative quantization error of layer 13 is 0.228933185338974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2186.04052734375.\n",
      "The relative quantization error of layer 14 is 0.2925514280796051.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2070.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2282.369140625.\n",
      "The relative quantization error of layer 15 is 0.25070422887802124.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2647.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 596.7225341796875.\n",
      "The relative quantization error of layer 16 is 0.2368193417787552.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 856.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1347.98876953125.\n",
      "The relative quantization error of layer 17 is 0.4064001739025116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2048.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1917.6937255859375.\n",
      "The relative quantization error of layer 18 is 0.32572880387306213.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2658.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 386.2915954589844.\n",
      "The relative quantization error of layer 19 is 0.2746941149234772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 718.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1263.4764404296875.\n",
      "The relative quantization error of layer 20 is 0.3118242919445038.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2026.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2046.9617919921875.\n",
      "The relative quantization error of layer 21 is 0.34922075271606445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2560.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 473.1293640136719.\n",
      "The relative quantization error of layer 22 is 0.29200491309165955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 930.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1116.74951171875.\n",
      "The relative quantization error of layer 23 is 0.42804160714149475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1472.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3517.48046875.\n",
      "The relative quantization error of layer 24 is 0.3913404643535614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2644.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 676.1531982421875.\n",
      "The relative quantization error of layer 25 is 0.3365314304828644.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1514.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1414.8890380859375.\n",
      "The relative quantization error of layer 26 is 0.3853967487812042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 517.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3621.68017578125.\n",
      "The relative quantization error of layer 27 is 0.3766477704048157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2625.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1460.732421875.\n",
      "The relative quantization error of layer 28 is 0.35081925988197327.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2622.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 269.81817626953125.\n",
      "The relative quantization error of layer 29 is 0.18249769508838654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1516.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1017.3364868164062.\n",
      "The relative quantization error of layer 30 is 0.461280882358551.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2612.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1594.029541015625.\n",
      "The relative quantization error of layer 31 is 0.3821878731250763.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2630.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 302.6871032714844.\n",
      "The relative quantization error of layer 32 is 0.22703620791435242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1514.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 946.8554077148438.\n",
      "The relative quantization error of layer 33 is 0.5032684803009033.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2624.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1777.1116943359375.\n",
      "The relative quantization error of layer 34 is 0.431281715631485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2651.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.0586700439453.\n",
      "The relative quantization error of layer 35 is 0.20356598496437073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1511.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1084.67138671875.\n",
      "The relative quantization error of layer 36 is 0.5322376489639282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2614.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1879.1865234375.\n",
      "The relative quantization error of layer 37 is 0.45710623264312744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2629.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 226.83468627929688.\n",
      "The relative quantization error of layer 38 is 0.22228841483592987.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1516.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1424.63720703125.\n",
      "The relative quantization error of layer 39 is 0.5228042006492615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2612.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1955.1915283203125.\n",
      "The relative quantization error of layer 40 is 0.46613237261772156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2628.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 196.40560913085938.\n",
      "The relative quantization error of layer 41 is 0.23831744492053986.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1489.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1485.490234375.\n",
      "The relative quantization error of layer 42 is 0.5556219220161438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2123.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2678.445556640625.\n",
      "The relative quantization error of layer 43 is 0.4810797870159149.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2637.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 169.90963745117188.\n",
      "The relative quantization error of layer 44 is 0.21013988554477692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1719.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1033.7227783203125.\n",
      "The relative quantization error of layer 45 is 0.461313396692276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 864.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2421.840087890625.\n",
      "The relative quantization error of layer 46 is 0.4956323802471161.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1860.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 474.34075927734375.\n",
      "The relative quantization error of layer 47 is 0.4367530643939972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:02<00:00, 1869.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 129.84130859375.\n",
      "The relative quantization error of layer 48 is 0.14097684621810913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1699.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 550.1221923828125.\n",
      "The relative quantization error of layer 49 is 0.6980744004249573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1855.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 537.2481689453125.\n",
      "The relative quantization error of layer 50 is 0.37875106930732727.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2660.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 87.50128936767578.\n",
      "The relative quantization error of layer 51 is 0.2130182981491089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2137.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 123.1880874633789.\n",
      "The relative quantization error of layer 52 is 0.835862398147583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2652.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 47.93203353881836.\n",
      "The relative quantization error of layer 53 is 0.2723606526851654.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.694643\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.869.\n",
      "Top-5 accuracy of vgg16 is 0.973.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.703.\n",
      "Top-5 accuracy of quantized vgg16 is 0.972.\n",
      "\n",
      "Time used for evaluation: 0:00:04.507837\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4503\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 724.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.76351165771484.\n",
      "The relative quantization error of layer 0 is 0.01792801357805729.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 833.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 854.1956176757812.\n",
      "The relative quantization error of layer 1 is 0.047643210738897324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2657.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 237.56813049316406.\n",
      "The relative quantization error of layer 2 is 0.05408084765076637.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 194.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3637.830322265625.\n",
      "The relative quantization error of layer 3 is 0.10382901132106781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 228.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1275.031005859375.\n",
      "The relative quantization error of layer 4 is 0.04316263645887375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 519.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 564.2144165039062.\n",
      "The relative quantization error of layer 5 is 0.19653162360191345.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2591.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 248.7753448486328.\n",
      "The relative quantization error of layer 6 is 0.2215537577867508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 225.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1061.6239013671875.\n",
      "The relative quantization error of layer 7 is 0.23016957938671112.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 490.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 884.78857421875.\n",
      "The relative quantization error of layer 8 is 0.2578276991844177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1824.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 557.9125366210938.\n",
      "The relative quantization error of layer 9 is 0.2651877999305725.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 215.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1557.532470703125.\n",
      "The relative quantization error of layer 10 is 0.23324890434741974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 271.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1664.162841796875.\n",
      "The relative quantization error of layer 11 is 0.3017382025718689.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1864.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1224.338134765625.\n",
      "The relative quantization error of layer 12 is 0.2956552505493164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 732.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1545.269287109375.\n",
      "The relative quantization error of layer 13 is 0.21832552552223206.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1897.2962646484375.\n",
      "The relative quantization error of layer 14 is 0.2917161285877228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2073.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1971.4420166015625.\n",
      "The relative quantization error of layer 15 is 0.27161285281181335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2641.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 489.87213134765625.\n",
      "The relative quantization error of layer 16 is 0.2303670048713684.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 879.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1181.41796875.\n",
      "The relative quantization error of layer 17 is 0.38983622193336487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2028.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1761.8895263671875.\n",
      "The relative quantization error of layer 18 is 0.2947319746017456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2585.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 360.0555114746094.\n",
      "The relative quantization error of layer 19 is 0.2512318193912506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 929.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1232.662109375.\n",
      "The relative quantization error of layer 20 is 0.3003918528556824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2062.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1933.9443359375.\n",
      "The relative quantization error of layer 21 is 0.32526910305023193.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2627.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 422.1208801269531.\n",
      "The relative quantization error of layer 22 is 0.2664508521556854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 930.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 992.582275390625.\n",
      "The relative quantization error of layer 23 is 0.36930954456329346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1469.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3288.9130859375.\n",
      "The relative quantization error of layer 24 is 0.35835808515548706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2540.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 605.0841064453125.\n",
      "The relative quantization error of layer 25 is 0.31328508257865906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1514.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1361.955810546875.\n",
      "The relative quantization error of layer 26 is 0.36166954040527344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 532.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3365.184326171875.\n",
      "The relative quantization error of layer 27 is 0.3481539189815521.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2587.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1346.497802734375.\n",
      "The relative quantization error of layer 28 is 0.3377632200717926.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2600.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 254.05599975585938.\n",
      "The relative quantization error of layer 29 is 0.17379145324230194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1509.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1005.726318359375.\n",
      "The relative quantization error of layer 30 is 0.4440340995788574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2607.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1523.19287109375.\n",
      "The relative quantization error of layer 31 is 0.3654872477054596.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2620.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 290.74578857421875.\n",
      "The relative quantization error of layer 32 is 0.2188737839460373.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1504.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 891.9424438476562.\n",
      "The relative quantization error of layer 33 is 0.48091834783554077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2582.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1694.4161376953125.\n",
      "The relative quantization error of layer 34 is 0.4168890416622162.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1860.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 236.62234497070312.\n",
      "The relative quantization error of layer 35 is 0.20005126297473907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1315.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1016.6640625.\n",
      "The relative quantization error of layer 36 is 0.510468065738678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1843.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1783.20458984375.\n",
      "The relative quantization error of layer 37 is 0.4267587661743164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2610.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.81056213378906.\n",
      "The relative quantization error of layer 38 is 0.20290271937847137.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1508.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1336.080078125.\n",
      "The relative quantization error of layer 39 is 0.511127233505249.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2573.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1809.0035400390625.\n",
      "The relative quantization error of layer 40 is 0.42165741324424744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2608.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.20396423339844.\n",
      "The relative quantization error of layer 41 is 0.2157699167728424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1395.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1447.5450439453125.\n",
      "The relative quantization error of layer 42 is 0.5282923579216003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2117.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2518.032470703125.\n",
      "The relative quantization error of layer 43 is 0.4575226604938507.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2617.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.69247436523438.\n",
      "The relative quantization error of layer 44 is 0.19374050199985504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2056.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 950.58935546875.\n",
      "The relative quantization error of layer 45 is 0.4272024929523468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 938.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2191.92529296875.\n",
      "The relative quantization error of layer 46 is 0.46680426597595215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2545.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 407.663818359375.\n",
      "The relative quantization error of layer 47 is 0.39318957924842834.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2624.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 102.85762023925781.\n",
      "The relative quantization error of layer 48 is 0.0966925397515297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2055.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 538.4009399414062.\n",
      "The relative quantization error of layer 49 is 0.652813196182251.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2601.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 525.2628784179688.\n",
      "The relative quantization error of layer 50 is 0.3169841766357422.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2575.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 82.17800903320312.\n",
      "The relative quantization error of layer 51 is 0.13356521725654602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2075.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 120.41199493408203.\n",
      "The relative quantization error of layer 52 is 0.8008237481117249.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2555.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 37.788455963134766.\n",
      "The relative quantization error of layer 53 is 0.21099095046520233.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.831214\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.56it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.884.\n",
      "Top-5 accuracy of vgg16 is 0.981.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.759.\n",
      "Top-5 accuracy of quantized vgg16 is 0.973.\n",
      "\n",
      "Time used for evaluation: 0:00:04.189730\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4536\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 789.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 69.54862976074219.\n",
      "The relative quantization error of layer 0 is 0.0174278374761343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 838.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 793.3832397460938.\n",
      "The relative quantization error of layer 1 is 0.04498197138309479.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1787.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 224.066650390625.\n",
      "The relative quantization error of layer 2 is 0.05273161083459854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 242.15it/s]\n",
      " 64%|██████▍   | 41/64 [00:00<00:00, 210.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3632.2490234375.\n",
      "The relative quantization error of layer 3 is 0.10026739537715912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1238.887451171875.\n",
      "The relative quantization error of layer 4 is 0.042376160621643066.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 484.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 556.4949951171875.\n",
      "The relative quantization error of layer 5 is 0.19981598854064941.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2311.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 239.99078369140625.\n",
      "The relative quantization error of layer 6 is 0.23068663477897644.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 961.6033935546875.\n",
      "The relative quantization error of layer 7 is 0.21573521196842194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 497.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 862.7957763671875.\n",
      "The relative quantization error of layer 8 is 0.2604252099990845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2443.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 565.569580078125.\n",
      "The relative quantization error of layer 9 is 0.2804632782936096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1426.9161376953125.\n",
      "The relative quantization error of layer 10 is 0.23009812831878662.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 286.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1564.628662109375.\n",
      "The relative quantization error of layer 11 is 0.2978040874004364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2626.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1149.2686767578125.\n",
      "The relative quantization error of layer 12 is 0.298983097076416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 860.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1449.0992431640625.\n",
      "The relative quantization error of layer 13 is 0.21117812395095825.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1962.84619140625.\n",
      "The relative quantization error of layer 14 is 0.30012473464012146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2069.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1958.2783203125.\n",
      "The relative quantization error of layer 15 is 0.27609983086586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2583.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 521.365966796875.\n",
      "The relative quantization error of layer 16 is 0.24186688661575317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 756.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1154.6622314453125.\n",
      "The relative quantization error of layer 17 is 0.3927755653858185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1841.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1743.7484130859375.\n",
      "The relative quantization error of layer 18 is 0.3090106248855591.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2455.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 359.46844482421875.\n",
      "The relative quantization error of layer 19 is 0.2653815746307373.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 845.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1182.84033203125.\n",
      "The relative quantization error of layer 20 is 0.30258485674858093.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1674.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1842.7955322265625.\n",
      "The relative quantization error of layer 21 is 0.32874783873558044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1860.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 419.0355529785156.\n",
      "The relative quantization error of layer 22 is 0.28377193212509155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 784.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 914.5049438476562.\n",
      "The relative quantization error of layer 23 is 0.39271190762519836.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1275.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3211.017333984375.\n",
      "The relative quantization error of layer 24 is 0.36411285400390625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1825.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 623.449951171875.\n",
      "The relative quantization error of layer 25 is 0.32626771926879883.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1275.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1353.6600341796875.\n",
      "The relative quantization error of layer 26 is 0.36933931708335876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 489.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3293.96240234375.\n",
      "The relative quantization error of layer 27 is 0.3619067072868347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2593.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1353.81103515625.\n",
      "The relative quantization error of layer 28 is 0.3474680781364441.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2575.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 250.18247985839844.\n",
      "The relative quantization error of layer 29 is 0.17751444876194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1520.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 964.63232421875.\n",
      "The relative quantization error of layer 30 is 0.4621778428554535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2595.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1496.255615234375.\n",
      "The relative quantization error of layer 31 is 0.3694017231464386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2625.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 287.9263000488281.\n",
      "The relative quantization error of layer 32 is 0.22822797298431396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1508.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 866.70263671875.\n",
      "The relative quantization error of layer 33 is 0.48869556188583374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2592.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1656.0504150390625.\n",
      "The relative quantization error of layer 34 is 0.43161675333976746.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1841.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 237.369873046875.\n",
      "The relative quantization error of layer 35 is 0.20646898448467255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1511.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1030.5240478515625.\n",
      "The relative quantization error of layer 36 is 0.5454202890396118.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2594.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1756.668701171875.\n",
      "The relative quantization error of layer 37 is 0.4487742781639099.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2612.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.85365295410156.\n",
      "The relative quantization error of layer 38 is 0.2161298245191574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1508.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1380.9554443359375.\n",
      "The relative quantization error of layer 39 is 0.5260893702507019.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2601.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1837.7933349609375.\n",
      "The relative quantization error of layer 40 is 0.4509362280368805.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2616.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.740478515625.\n",
      "The relative quantization error of layer 41 is 0.2329065501689911.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1514.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1458.8070068359375.\n",
      "The relative quantization error of layer 42 is 0.5608685612678528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2119.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2533.25341796875.\n",
      "The relative quantization error of layer 43 is 0.4607543647289276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2619.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.24737548828125.\n",
      "The relative quantization error of layer 44 is 0.20567908883094788.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2060.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 954.4879150390625.\n",
      "The relative quantization error of layer 45 is 0.4499659836292267.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 955.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2228.584716796875.\n",
      "The relative quantization error of layer 46 is 0.4712463915348053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2627.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 436.5193176269531.\n",
      "The relative quantization error of layer 47 is 0.41604140400886536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2606.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 113.9792709350586.\n",
      "The relative quantization error of layer 48 is 0.11216720938682556.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1749.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 558.8316650390625.\n",
      "The relative quantization error of layer 49 is 0.6773425936698914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2610.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 458.27825927734375.\n",
      "The relative quantization error of layer 50 is 0.32905593514442444.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2657.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 70.54198455810547.\n",
      "The relative quantization error of layer 51 is 0.10657036304473877.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2108.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 124.90019989013672.\n",
      "The relative quantization error of layer 52 is 0.815818190574646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2636.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 41.368247985839844.\n",
      "The relative quantization error of layer 53 is 0.2407318651676178.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.602389\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.79it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.767.\n",
      "Top-5 accuracy of vgg16 is 0.961.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.685.\n",
      "Top-5 accuracy of quantized vgg16 is 0.973.\n",
      "\n",
      "Time used for evaluation: 0:00:04.596399\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4455\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 746.47it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 764.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 87.61417388916016.\n",
      "The relative quantization error of layer 0 is 0.019811149686574936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n",
      "The quantization error of layer 1 is 934.4608154296875.\n",
      "The relative quantization error of layer 1 is 0.05232491344213486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1776.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 272.3672790527344.\n",
      "The relative quantization error of layer 2 is 0.06423955410718918.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 251.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3501.012451171875.\n",
      "The relative quantization error of layer 3 is 0.09715655446052551.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 253.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1695.4488525390625.\n",
      "The relative quantization error of layer 4 is 0.057488877326250076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 462.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 644.0676879882812.\n",
      "The relative quantization error of layer 5 is 0.21828728914260864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1810.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 269.15740966796875.\n",
      "The relative quantization error of layer 6 is 0.24055834114551544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 216.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1052.2867431640625.\n",
      "The relative quantization error of layer 7 is 0.23186591267585754.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 473.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 917.0626220703125.\n",
      "The relative quantization error of layer 8 is 0.2708015739917755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1775.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 595.1390380859375.\n",
      "The relative quantization error of layer 9 is 0.2773158848285675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 222.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1606.45263671875.\n",
      "The relative quantization error of layer 10 is 0.251241534948349.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 264.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1821.2520751953125.\n",
      "The relative quantization error of layer 11 is 0.3158218264579773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1785.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1266.3372802734375.\n",
      "The relative quantization error of layer 12 is 0.30458179116249084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 817.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1603.6766357421875.\n",
      "The relative quantization error of layer 13 is 0.2277008295059204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2195.28125.\n",
      "The relative quantization error of layer 14 is 0.2937239408493042.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1677.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2291.54052734375.\n",
      "The relative quantization error of layer 15 is 0.25121137499809265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1834.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 600.2894897460938.\n",
      "The relative quantization error of layer 16 is 0.23818129301071167.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 713.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1348.0277099609375.\n",
      "The relative quantization error of layer 17 is 0.405941903591156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1541.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1917.1322021484375.\n",
      "The relative quantization error of layer 18 is 0.32463783025741577.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1839.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 385.626708984375.\n",
      "The relative quantization error of layer 19 is 0.2741672992706299.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 786.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1286.1544189453125.\n",
      "The relative quantization error of layer 20 is 0.31634756922721863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1548.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2051.425537109375.\n",
      "The relative quantization error of layer 21 is 0.3492013216018677.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1825.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 474.9549560546875.\n",
      "The relative quantization error of layer 22 is 0.2929530739784241.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 746.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1123.2369384765625.\n",
      "The relative quantization error of layer 23 is 0.43174660205841064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1248.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3499.535888671875.\n",
      "The relative quantization error of layer 24 is 0.39034128189086914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1771.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 670.9075927734375.\n",
      "The relative quantization error of layer 25 is 0.33342084288597107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1257.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1421.541748046875.\n",
      "The relative quantization error of layer 26 is 0.38473638892173767.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 475.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3607.234619140625.\n",
      "The relative quantization error of layer 27 is 0.37556836009025574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1719.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1454.2562255859375.\n",
      "The relative quantization error of layer 28 is 0.3503861129283905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1812.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 282.6084289550781.\n",
      "The relative quantization error of layer 29 is 0.19198277592658997.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1271.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1005.1259155273438.\n",
      "The relative quantization error of layer 30 is 0.4561886787414551.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1769.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1599.1192626953125.\n",
      "The relative quantization error of layer 31 is 0.3840099573135376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1774.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 309.6099548339844.\n",
      "The relative quantization error of layer 32 is 0.2296917736530304.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1264.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 910.1634521484375.\n",
      "The relative quantization error of layer 33 is 0.4865650236606598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1752.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1745.6109619140625.\n",
      "The relative quantization error of layer 34 is 0.4282878339290619.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1783.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 245.6609344482422.\n",
      "The relative quantization error of layer 35 is 0.20095762610435486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1287.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1066.0703125.\n",
      "The relative quantization error of layer 36 is 0.5200852155685425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1796.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1851.5208740234375.\n",
      "The relative quantization error of layer 37 is 0.4523169696331024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1800.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 218.14939880371094.\n",
      "The relative quantization error of layer 38 is 0.20825228095054626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1256.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1412.678955078125.\n",
      "The relative quantization error of layer 39 is 0.517981231212616.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2448.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1932.59765625.\n",
      "The relative quantization error of layer 40 is 0.4608513414859772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2430.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 193.06155395507812.\n",
      "The relative quantization error of layer 41 is 0.22894732654094696.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1495.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1460.7818603515625.\n",
      "The relative quantization error of layer 42 is 0.5472925901412964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2077.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2639.53662109375.\n",
      "The relative quantization error of layer 43 is 0.475477933883667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2482.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 165.71560668945312.\n",
      "The relative quantization error of layer 44 is 0.2031307816505432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2020.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 991.0834350585938.\n",
      "The relative quantization error of layer 45 is 0.4457971751689911.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 952.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2380.56103515625.\n",
      "The relative quantization error of layer 46 is 0.4896233379840851.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2516.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 455.61871337890625.\n",
      "The relative quantization error of layer 47 is 0.4201716482639313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2527.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 116.07962036132812.\n",
      "The relative quantization error of layer 48 is 0.12518177926540375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2000.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 563.715087890625.\n",
      "The relative quantization error of layer 49 is 0.678950846195221.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2525.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 474.9122009277344.\n",
      "The relative quantization error of layer 50 is 0.34432071447372437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2538.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 68.53242492675781.\n",
      "The relative quantization error of layer 51 is 0.1891447752714157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2092.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 123.30243682861328.\n",
      "The relative quantization error of layer 52 is 0.8282890915870667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2551.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 42.64942169189453.\n",
      "The relative quantization error of layer 53 is 0.24234364926815033.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:57.228848\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.55it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.869.\n",
      "Top-5 accuracy of vgg16 is 0.973.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.73.\n",
      "Top-5 accuracy of quantized vgg16 is 0.973.\n",
      "\n",
      "Time used for evaluation: 0:00:04.799301\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4521\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 767.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 60.88755416870117.\n",
      "The relative quantization error of layer 0 is 0.017865026369690895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 819.99it/s]\n",
      " 70%|██████▉   | 402/576 [00:00<00:00, 2058.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 765.4349365234375.\n",
      "The relative quantization error of layer 1 is 0.043753743171691895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2132.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 236.17274475097656.\n",
      "The relative quantization error of layer 2 is 0.057330839335918427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 220.58it/s]\n",
      " 19%|█▉        | 12/64 [00:00<00:00, 116.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3400.352783203125.\n",
      "The relative quantization error of layer 3 is 0.09721057862043381.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1206.310302734375.\n",
      "The relative quantization error of layer 4 is 0.041616957634687424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 521.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 540.6943359375.\n",
      "The relative quantization error of layer 5 is 0.19278386235237122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2137.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 234.7112274169922.\n",
      "The relative quantization error of layer 6 is 0.2148132622241974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 204.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 883.98779296875.\n",
      "The relative quantization error of layer 7 is 0.2054564505815506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 457.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 840.0377197265625.\n",
      "The relative quantization error of layer 8 is 0.2567121386528015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2396.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 526.012451171875.\n",
      "The relative quantization error of layer 9 is 0.2599523961544037.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 212.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1427.08740234375.\n",
      "The relative quantization error of layer 10 is 0.22665032744407654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 278.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1579.4849853515625.\n",
      "The relative quantization error of layer 11 is 0.30099332332611084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2651.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1126.6248779296875.\n",
      "The relative quantization error of layer 12 is 0.28387153148651123.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 717.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1419.2974853515625.\n",
      "The relative quantization error of layer 13 is 0.20629078149795532.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1867.197021484375.\n",
      "The relative quantization error of layer 14 is 0.29097864031791687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2081.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1901.1365966796875.\n",
      "The relative quantization error of layer 15 is 0.2715332508087158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2587.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 492.2520446777344.\n",
      "The relative quantization error of layer 16 is 0.23070693016052246.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 727.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1056.0316162109375.\n",
      "The relative quantization error of layer 17 is 0.37180376052856445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1704.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1701.7147216796875.\n",
      "The relative quantization error of layer 18 is 0.3063039779663086.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1878.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 354.5127258300781.\n",
      "The relative quantization error of layer 19 is 0.2615215480327606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 829.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1182.1932373046875.\n",
      "The relative quantization error of layer 20 is 0.29568707942962646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1693.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1856.240234375.\n",
      "The relative quantization error of layer 21 is 0.3371080756187439.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1812.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 420.0096435546875.\n",
      "The relative quantization error of layer 22 is 0.28478002548217773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 852.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 906.2366333007812.\n",
      "The relative quantization error of layer 23 is 0.3852274715900421.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1157.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3113.1787109375.\n",
      "The relative quantization error of layer 24 is 0.35442033410072327.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1869.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 603.8997802734375.\n",
      "The relative quantization error of layer 25 is 0.3121236562728882.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1489.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1289.9814453125.\n",
      "The relative quantization error of layer 26 is 0.35096678137779236.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 529.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3177.09814453125.\n",
      "The relative quantization error of layer 27 is 0.35562020540237427.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2625.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1310.154541015625.\n",
      "The relative quantization error of layer 28 is 0.3423466086387634.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2635.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 251.3282012939453.\n",
      "The relative quantization error of layer 29 is 0.17589573562145233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1523.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 942.8903198242188.\n",
      "The relative quantization error of layer 30 is 0.45872315764427185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2634.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1516.1246337890625.\n",
      "The relative quantization error of layer 31 is 0.37758636474609375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2648.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 290.05340576171875.\n",
      "The relative quantization error of layer 32 is 0.2218802273273468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1520.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 863.1271362304688.\n",
      "The relative quantization error of layer 33 is 0.477925568819046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2630.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1693.805908203125.\n",
      "The relative quantization error of layer 34 is 0.42775264382362366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2653.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 238.05116271972656.\n",
      "The relative quantization error of layer 35 is 0.19882383942604065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1526.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1071.9747314453125.\n",
      "The relative quantization error of layer 36 is 0.5259668231010437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2622.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1792.9132080078125.\n",
      "The relative quantization error of layer 37 is 0.44868502020835876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2653.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 215.8376922607422.\n",
      "The relative quantization error of layer 38 is 0.2142907679080963.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1412.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1453.8223876953125.\n",
      "The relative quantization error of layer 39 is 0.534701943397522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2619.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1924.95068359375.\n",
      "The relative quantization error of layer 40 is 0.468284010887146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:01<00:00, 1856.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 188.3483123779297.\n",
      "The relative quantization error of layer 41 is 0.22582605481147766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1500.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1525.447509765625.\n",
      "The relative quantization error of layer 42 is 0.5569967031478882.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2122.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2626.42041015625.\n",
      "The relative quantization error of layer 43 is 0.47422489523887634.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2583.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.0147705078125.\n",
      "The relative quantization error of layer 44 is 0.19440720975399017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1941.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1042.873046875.\n",
      "The relative quantization error of layer 45 is 0.4709473252296448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 925.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2237.5302734375.\n",
      "The relative quantization error of layer 46 is 0.4730302393436432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2596.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 471.0758361816406.\n",
      "The relative quantization error of layer 47 is 0.42979782819747925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2577.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 120.1197509765625.\n",
      "The relative quantization error of layer 48 is 0.1419340819120407.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2044.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 576.8849487304688.\n",
      "The relative quantization error of layer 49 is 0.7086440324783325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2486.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 531.35205078125.\n",
      "The relative quantization error of layer 50 is 0.31105315685272217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2615.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 65.41484069824219.\n",
      "The relative quantization error of layer 51 is 0.13922354578971863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2110.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 123.7320785522461.\n",
      "The relative quantization error of layer 52 is 0.8253483176231384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2617.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 46.80827331542969.\n",
      "The relative quantization error of layer 53 is 0.2820357382297516.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.312936\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.81it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.823.\n",
      "Top-5 accuracy of vgg16 is 0.955.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.645.\n",
      "Top-5 accuracy of quantized vgg16 is 0.931.\n",
      "\n",
      "Time used for evaluation: 0:00:03.998737\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4502\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing vgg16 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 700.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 73.2799301147461.\n",
      "The relative quantization error of layer 0 is 0.0178282018750906.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 706.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 849.73291015625.\n",
      "The relative quantization error of layer 1 is 0.048019323498010635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1743.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 244.50177001953125.\n",
      "The relative quantization error of layer 2 is 0.05791746452450752.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 249.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3533.907958984375.\n",
      "The relative quantization error of layer 3 is 0.09895937889814377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1314.9747314453125.\n",
      "The relative quantization error of layer 4 is 0.04515472427010536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 491.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 595.6104125976562.\n",
      "The relative quantization error of layer 5 is 0.20524220168590546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2457.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 249.15182495117188.\n",
      "The relative quantization error of layer 6 is 0.2313934564590454.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 208.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1015.9784545898438.\n",
      "The relative quantization error of layer 7 is 0.2283126413822174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 875.65673828125.\n",
      "The relative quantization error of layer 8 is 0.264925479888916.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2173.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 573.5067749023438.\n",
      "The relative quantization error of layer 9 is 0.27497947216033936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1486.8658447265625.\n",
      "The relative quantization error of layer 10 is 0.2292252629995346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 280.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1700.325439453125.\n",
      "The relative quantization error of layer 11 is 0.3095437288284302.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2643.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1224.6500244140625.\n",
      "The relative quantization error of layer 12 is 0.3024088740348816.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 924.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1535.4732666015625.\n",
      "The relative quantization error of layer 13 is 0.2202496975660324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2021.9107666015625.\n",
      "The relative quantization error of layer 14 is 0.30088597536087036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2032.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2082.720458984375.\n",
      "The relative quantization error of layer 15 is 0.2705349922180176.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2643.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 526.1156005859375.\n",
      "The relative quantization error of layer 16 is 0.23618783056735992.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 934.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1153.64013671875.\n",
      "The relative quantization error of layer 17 is 0.3824179768562317.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2013.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1808.828125.\n",
      "The relative quantization error of layer 18 is 0.3137901723384857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2610.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 361.8601379394531.\n",
      "The relative quantization error of layer 19 is 0.2622178792953491.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 785.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1215.4847412109375.\n",
      "The relative quantization error of layer 20 is 0.3057173490524292.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2045.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1980.44970703125.\n",
      "The relative quantization error of layer 21 is 0.33574989438056946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2672.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 433.8448791503906.\n",
      "The relative quantization error of layer 22 is 0.28008875250816345.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 881.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1006.021484375.\n",
      "The relative quantization error of layer 23 is 0.3822757601737976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1476.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3271.7509765625.\n",
      "The relative quantization error of layer 24 is 0.3689783215522766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2643.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 619.0359497070312.\n",
      "The relative quantization error of layer 25 is 0.32172301411628723.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1516.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1357.251708984375.\n",
      "The relative quantization error of layer 26 is 0.3660333752632141.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 542.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3512.74072265625.\n",
      "The relative quantization error of layer 27 is 0.36352217197418213.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2587.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1377.3486328125.\n",
      "The relative quantization error of layer 28 is 0.3497248589992523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2636.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 260.26678466796875.\n",
      "The relative quantization error of layer 29 is 0.181770458817482.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1440.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 973.2047119140625.\n",
      "The relative quantization error of layer 30 is 0.45111754536628723.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2438.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1527.9200439453125.\n",
      "The relative quantization error of layer 31 is 0.37982377409935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2664.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.3492736816406.\n",
      "The relative quantization error of layer 32 is 0.22194026410579681.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1515.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 921.1920166015625.\n",
      "The relative quantization error of layer 33 is 0.49407368898391724.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2620.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1716.8023681640625.\n",
      "The relative quantization error of layer 34 is 0.4318566918373108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2667.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 250.15194702148438.\n",
      "The relative quantization error of layer 35 is 0.20422524213790894.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1521.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1065.99267578125.\n",
      "The relative quantization error of layer 36 is 0.5270906090736389.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2563.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1825.901123046875.\n",
      "The relative quantization error of layer 37 is 0.4431496262550354.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2663.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 207.5388641357422.\n",
      "The relative quantization error of layer 38 is 0.20878379046916962.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1499.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1432.7454833984375.\n",
      "The relative quantization error of layer 39 is 0.5224044322967529.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2644.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1902.5557861328125.\n",
      "The relative quantization error of layer 40 is 0.45863619446754456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2647.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.102783203125.\n",
      "The relative quantization error of layer 41 is 0.22242893278598785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1452.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1450.8748779296875.\n",
      "The relative quantization error of layer 42 is 0.5561591982841492.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2102.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2654.249267578125.\n",
      "The relative quantization error of layer 43 is 0.4789438843727112.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2663.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.88284301757812.\n",
      "The relative quantization error of layer 44 is 0.19918449223041534.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2074.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 985.9244384765625.\n",
      "The relative quantization error of layer 45 is 0.4541460871696472.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 950.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2248.165771484375.\n",
      "The relative quantization error of layer 46 is 0.472631573677063.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2545.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 427.357177734375.\n",
      "The relative quantization error of layer 47 is 0.4145558476448059.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2653.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 114.8457260131836.\n",
      "The relative quantization error of layer 48 is 0.11677223443984985.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2094.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 544.0916137695312.\n",
      "The relative quantization error of layer 49 is 0.6884225606918335.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2637.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 462.6585388183594.\n",
      "The relative quantization error of layer 50 is 0.29075556993484497.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2684.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 85.75370788574219.\n",
      "The relative quantization error of layer 51 is 0.1612701714038849.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2147.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 137.60833740234375.\n",
      "The relative quantization error of layer 52 is 0.8831640481948853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2667.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 46.40756607055664.\n",
      "The relative quantization error of layer 53 is 0.2793971598148346.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:51.448086\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.57it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of vgg16 is 0.83.\n",
      "Top-5 accuracy of vgg16 is 0.952.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized vgg16 is 0.64.\n",
      "Top-5 accuracy of quantized vgg16 is 0.932.\n",
      "\n",
      "Time used for evaluation: 0:00:04.293960\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4461\n"
     ]
    }
   ],
   "source": [
    "sc_options = ['True'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'vgg16' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                    NaN                    NaN   \n",
       "1   67.727136             False                    NaN                    NaN   \n",
       "2   71.281856             False                    NaN                    NaN   \n",
       "3   71.118622             False                    NaN                    NaN   \n",
       "4   66.670358             False                    NaN                    NaN   \n",
       "5   67.253203             False                    NaN                    NaN   \n",
       "6   71.118622             False                    NaN                    NaN   \n",
       "7    1.501770             False                    NaN                    NaN   \n",
       "8    1.929774             False                    NaN                    NaN   \n",
       "9    1.885359             False                    NaN                    NaN   \n",
       "10   1.950773             False                    NaN                    NaN   \n",
       "11   1.929774             False                    NaN                    NaN   \n",
       "12   0.773437             False                    NaN                    NaN   \n",
       "13   0.424285             False                    NaN                    NaN   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df = df[df[\"Classes Repeated\"] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e03bc03e-1a1c-43ae-bc01-15060dca5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.997]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.8   0.984]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.896 0.99 ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.9   0.992]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.84  0.992]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.994]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.889 0.987]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.901 0.992]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "# from data_loaders import data_loader\n",
    "# from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 64\n",
    "\n",
    "# topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "\n",
    "#     model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "#     model.to(device)  \n",
    "#     train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset = subset)\n",
    "\n",
    "# # ===========\n",
    "# #  CODE HERE\n",
    "# # ===========\n",
    "\n",
    "#     model.eval() \n",
    "#     original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "#     # maxk = max(topk)\n",
    "#     # topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "#     # correct_mat = []\n",
    "#     # for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     #     with torch.no_grad():\n",
    "#     #         y_pred = model(x_test.to(device))\n",
    "#     #     topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "#     #     target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "#     #     correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# # break    \n",
    "# # acc_items += [original_topk_accuracy]\n",
    "\n",
    "# # df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# # df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# # df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# # print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n",
    "\n",
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 5  # Set the number of fine-tuning epochs\n",
    "learning_rate = 1e-4  # Fine-tuning learning rate\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = [stage.item() if hasattr(stage, \"item\") else stage for stage in subset_stage]\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "    model.to(device)  \n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset=subset)\n",
    "\n",
    "    # Define optimizer & loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate after fine-tuning\n",
    "    model.eval()\n",
    "    original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "    print(f\"Top-1 and Top-5 Accuracy after fine-tuning: {original_topk_accuracy}\")\n",
    "\n",
    "    acc_items += [original_topk_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e564bcc8-8a12-4965-9e9c-79909c3b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the printed output as input for raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63c97c08-e8f2-4e8a-ba26-12b49693d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.81it/s]\n",
    "Epoch [1/5] - Loss: 0.0861\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0216\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0128\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
    "Epoch [4/5] - Loss: 0.0147\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0202\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [1/5] - Loss: 0.0826\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0148\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0177\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0076\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0083\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.98  0.998]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.1261\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [2/5] - Loss: 0.0184\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0092\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0055\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0057\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.981 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1050\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0211\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0150\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n",
    "Epoch [4/5] - Loss: 0.0121\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0098\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 0.999]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.0971\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0166\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0135\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0174\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0265\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.56it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.983 0.997]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.0976\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0170\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0229\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0240\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0170\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.1095\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0209\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [3/5] - Loss: 0.0178\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0179\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0092\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.02it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.979 1.   ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2715\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0334\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0259\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0161\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0100\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.40it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.8   0.984]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.3158\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0357\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0269\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [4/5] - Loss: 0.0442\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0430\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.43it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.896 0.99 ]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [1/5] - Loss: 0.3016\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0359\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0256\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0203\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0323\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.81it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.9   0.992]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2210\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0311\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0337\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0486\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0287\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.43it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.84  0.992]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.3029\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [2/5] - Loss: 0.0291\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0231\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0246\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [5/5] - Loss: 0.0210\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.61it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.915 0.994]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.2556\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0361\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0302\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0204\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0177\n",
    "100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.889 0.987]\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [1/5] - Loss: 0.1932\n",
    "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [2/5] - Loss: 0.0314\n",
    "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [3/5] - Loss: 0.0260\n",
    "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n",
    "Epoch [4/5] - Loss: 0.0173\n",
    "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n",
    "Epoch [5/5] - Loss: 0.0096\n",
    "100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n",
    "Top-1 and Top-5 Accuracy after fine-tuning: [0.901 0.992]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1726c059-fe07-4ee0-9236-bb67aba13d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# extracted = re.findall(r\"\\[[01]{1}.[0-9 ]{3} [01]{1}.[0-9 ]{3}\\]\", raw_text)\n",
    "extracted = re.findall(r\"Top-1 and Top-5 Accuracy after fine-tuning:\\s*(\\[[^\\]]+\\])\", raw_text)\n",
    "# data = list(map(lambda x: [float(x[1:6]), float(x[7:12])], extracted))\n",
    "data = [list(map(float, s.strip(\"[]\").split())) for s in extracted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "370887c8-4003-449d-93ff-700942aa2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[0.981 0.999]',\n",
       "  '[0.98  0.998]',\n",
       "  '[0.981 1.   ]',\n",
       "  '[0.979 0.999]',\n",
       "  '[0.983 0.997]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.8   0.984]',\n",
       "  '[0.896 0.99 ]',\n",
       "  '[0.9   0.992]',\n",
       "  '[0.84  0.992]',\n",
       "  '[0.915 0.994]',\n",
       "  '[0.889 0.987]',\n",
       "  '[0.901 0.992]'],\n",
       " 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1879a6f-3f42-4c8f-bef8-b7a537282650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Trained Top1 Accuracy\", \"Trained Top5 Accuracy\"]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d20aacbe-ec3d-4a21-a92d-82bb75e69a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes = []\n",
    "# for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "#     topk_count = []\n",
    "#     filtered = correct_mat[np.isin(classes, subset)]\n",
    "#     for i, k in enumerate(topk):\n",
    "#         topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "#     return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "    \n",
    "#     acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "# acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import dist_matrix\n",
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "\n",
    "# G = nx.from_numpy_array(dist_matrix)\n",
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa2b9e10-57f2-462e-8f96-5df897ffd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import community \n",
    "# partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae727e7e-c5e5-4627-bb52-ca17fdbd41c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dfe0db6-01b1-4965-a589-ce94866dd132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import class_names\n",
    "\n",
    "# grps = {}\n",
    "\n",
    "# for k,v in partition.items():\n",
    "#     if v not in grps:\n",
    "#         grps[v] = []\n",
    "#     grps[v] += [class_names[k].item()]\n",
    "\n",
    "# grps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e2b417d-386d-4233-80bd-e097adec7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100_subset_generation import dist_matrix, class_names\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "KL_data_all = []\n",
    "# new_col = []\n",
    "median = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    # print(list(map(lambda x: class_names[x].item(), subset))))\n",
    "\n",
    "    # new_col += [len(subset) != len(set(subset))]\n",
    "    \n",
    "    KL_data = []\n",
    "    for j in combinations(set(subset), 2):\n",
    "        KL_data += [dist_matrix[j[0], j[1]].item()]\n",
    "\n",
    "    KL_data_all += [KL_data]\n",
    "\n",
    "    median += [np.median(KL_data).item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a011a4a-a284-4b40-b242-a757a73bfc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>46.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.522912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.417347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.793771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.378134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0   66.980437  \n",
       "1   49.097501  \n",
       "2   60.747142  \n",
       "3   60.747142  \n",
       "4   46.604676  \n",
       "5   49.097501  \n",
       "6   60.747142  \n",
       "7    1.522912  \n",
       "8    1.549429  \n",
       "9    1.417347  \n",
       "10   1.666552  \n",
       "11   1.549429  \n",
       "12   0.793771  \n",
       "13   0.378134  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Median_KL\"] = median\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dd02952-818a-4588-bfaa-bbfce9e4d30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "pd.DataFrame(KL_data_all, index = df[\"Quantized Top1 Accuracy\"]).T.boxplot(vert = False, positions = df[\"Quantized Top1 Accuracy\"] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0724d809-8a16-40f1-aad0-cd9252c5c0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[\"Classes Repeated\"] = new_col\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e9939a-6dcb-4678-8a83-9ad2ba3012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3593c-43f4-4388-9121-057b93a9b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626567-9b3d-40c0-981e-484ed7d33fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3058420-34ee-470e-a70b-492d24039904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7102e16-7f17-4da8-b66c-ff7d8260d341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>55.650079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0      vgg16  CIFAR100                       64                   0.887   \n",
       "1      vgg16  CIFAR100                       64                   0.861   \n",
       "2      vgg16  CIFAR100                       64                   0.884   \n",
       "3      vgg16  CIFAR100                       64                   0.879   \n",
       "4      vgg16  CIFAR100                       64                   0.872   \n",
       "\n",
       "   Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                    0.935                   0.989                    0.991   \n",
       "1                    0.902                   0.987                    0.989   \n",
       "2                    0.960                   0.991                    0.996   \n",
       "3                    0.953                   0.987                    0.994   \n",
       "4                    0.952                   0.986                    0.994   \n",
       "\n",
       "   Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0     4                 1.16                 1.16  ...     0   \n",
       "1     4                 1.16                 1.16  ...     0   \n",
       "2     4                 1.16                 1.16  ...     0   \n",
       "3     4                 1.16                 1.16  ...     0   \n",
       "4     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                               Subset_Inds  \\\n",
       "0  [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1  [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2  [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3  [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4   [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "\n",
       "                                      Subset_Classes      Max_KL    Min_KL  \\\n",
       "0  ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4  ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "\n",
       "      Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0  68.940139             False                  0.982                  0.999   \n",
       "1  69.604010             False                  0.955                  0.999   \n",
       "2  73.300755             False                  0.975                  1.000   \n",
       "3  68.423650             False                  0.988                  1.000   \n",
       "4  68.367547             False                  0.983                  1.000   \n",
       "\n",
       "   Median_KL  \n",
       "0  66.980437  \n",
       "1  66.877609  \n",
       "2  66.980437  \n",
       "3  50.328013  \n",
       "4  55.650079  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "621a9e36-75ad-4db7-9d8e-305ecfec26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.2246467991473532e-16, 6.123233995736766e-17, 1.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "cmap = colormaps['rainbow']\n",
    "cmap(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f06af688250>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1kklEQVR4nO3de3xU1aH3/++eIZNJQjIYkCTILdLKLUolEQTU9mBNoYrai4Vj1ULBX/HUC8X6KI+npXg8xdpTHn1OhWILXornwK8VW32g9MSfqPigBwXaCvEOGi4TUm5JILfJzPr9MWSSSSb3SWYn+/M+r3l1z56996zNnpz9da2117KMMUYAAAA25kp0AQAAANpDYAEAALZHYAEAALZHYAEAALZHYAEAALZHYAEAALZHYAEAALZHYAEAALY3INEF6IhQKKSjR48qPT1dlmUlujgAAKADjDGqrKzUsGHD5HJ1r46kTwSWo0ePasSIEYkuBgAA6IJDhw5p+PDh3TpGnwgs6enpksInnJGRkeDSAACAjqioqNCIESMi9/Hu6BOBpaEZKCMjg8ACAEAfE4/uHHS6BQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAttcn5hLqScYY1RgjSfJaVlzmOwAAoC/oS/dAxweW6lBIM8s+liS9MvRzSnW7E1wioFEwZLTr4EmVVdZoaLpXU3Iz5XbZ9/+hAOhb+tI90PGBpa4mejk1LXFlAZrats+vFS8Vy1/e+CMdlJKkBTNydefMzxFcAHRbX7oH0ocFsKFt+/y6Y8OeqLAiSaerA/pfL3+o/IeLtG2fP0GlA4De5/gaFnOu7U6SakxI1SH+qxWJFTRGP/nTe9IAS639Gsvr6nXHxr16fJ7RNROye7V8APqPGhOKLDe9H9qR4wNLTZMLdGPlAakygYUBGtxygbI6sNlPVamfHuNHC6D7aggs9lZbFVRqfbjavcrtkSxayQAADmFCSg3WSQrfD5WelOACtc7xgaW+plqvbP6fkqTFL/5WoZO+BJcIAIDe4cos16+uv1WS9PHXN0jyJrZAbXB8YGnaR+CetZYuHE4NC3peUfEx/XRLsY5V1nX7WE8tuExTczPjUCoATnPgsCVtCS/bvQen4wOL1HjDsJJrpJRQG9sC3ffnfX794I9/Db9J6fpxLElZPq8KxvkkF79bAJ1nJTd9ErH7/wHVkxwfWOpC9ZHlZ3y7dba2G3cQoCM+L137YPyqXR8IvBa3YwFwljRftVaeW256P7QjxweW0KkzkeWVT61JYEkAAEic0KkzUm6iS9E6x3fYcAdrE10EAAASzu73Q8fXsASSGtv+j077nIIpyQksDQAAvcddXathb4bnEmp6P7Qjx9ewuFyBRBcBAICEs/v90PE1LHX1jRdo2P7Dko2n1gYAIK6ajG7b9H5oR9SwqDrRRQAAIOHsfj90fA1LyJMqZZx7xDQ9WXI5PsMBAJwi1NhvJeRJTWBB2uf4wGKlpUWagT6cMFJBjyfBJQIAoHe46+p00a5wp1srLS3BpWmb4wOLO6mxz0rIPUChAe4ElgYAgN5jBRtjQNP7oR05PrDI1fhP8MecS3QynckPAQDOkFlZrnF6P/zGZe9IYO/S9QKXO0Mnx+ZIkq6uvVwX+bITXCL0F+98elLf++3uLu1rWVGd9xvXn/vfR795iWaOz+p64QBA0oe1pTo5doek8P3QzhwfWOROUWn2YElSinugMiz6sCA+vjgqS0OSvPKX17S/cTOrb75UH5Wd0VP/91Odrm581DDH59XyORM0a0JOPIsKwKFS3AMj90C57T2XnuMDiyfJUt25Trcem7ffoW9xuywtnzNBizfs6fS+Lpele758ke6c+XntOnhSZZU1Gpru1ZTcTLld/E4BxEdfugc6PrAkKUnPDC+QJN18YoAq3MEElwj9ydRR5ysjyaPqus79rn68uVinK4Mamp6sS0edp4lZgyRJZ6vsPXQ2gL4lUDVA/3nuHrioOinBpWmb4wNLsCqoH7/9oiTp1ssGq1Y0CSGOLOnC+wd3adeNKju3dCh+5QGAJpJT6/Tb18P3wEMTr5Bs/NwJo6RFdWy0d3UYAADx1eS+F6Ojv504vobF7W1cPnrMq2oXNSwAAGdICTWOPdb0fmhHBBbT+ATG/1eyOoElAQAgcZreD+3I8U1C1KcAAGD/+6Hja1jS0hqfO6+b/ojSku09+RP6jmDI6JpVr+lYeU2rTcOWOtds/PSCKZpyYWYcSgcA0tnaKnl2PiAp+n5oR44PLC53YyWTK8kry52cwNKgPxnglu6/9hLdcW4clljBZPXNk3Vemkel5dX6ly3v6dTZupjbWZKyfV4VjMmWxTgsAOLEldQ4VELT+6Ed2bt0vcBrWTGXgXiYlZejNbdMVrYvujdbjs+rX90yWV+9JEfTxgzW1yYP10+/liep5bNqDe+Xz5nAoHEA4qov3QMdX8NiNblAls0vFvqmWXk5umZCdrsj1jaEmxUvFUcN55/dMBx/HsPxA4ivvnQPtIyJNcWavVRUVMjn86m8vFwZGfGdnMkYI4Xqwm9cHttfMPR/wZBhOH4AvaKn74HxvH9Tw2JZEv1WYCNul6VpY7o2Oi4AdEZfugc6vg8LAACwPwILAACwPQILAACwPQILAACwPQILAACwPQILAACwPQILAACwPQILAACwPccPHGeMFKgKLyelSgx0CwBwir50D3R8YAlUSQ+OCi//62eSJy2x5YEzMRw/gEToS/dAxwcWING27fO3mPAwhwkPASBKl/qwrF69Wrm5ufJ6vcrPz9eOHTva3P6JJ57Q+PHjlZKSorFjx+rZZ5/tUmGB/mbbPr/u2LAnKqxIUml5je7YsEfb9vkTVDIAsJdO17Bs2rRJS5Ys0erVqzVjxgytXbtWs2fPVnFxsUaOHNli+zVr1mjZsmX69a9/rcsuu0y7du3S7bffrvPOO09z5syJy0l0R9O5quuqElcOOE8wZPQvm9+XK+CO+bkl6V82v68vjsqmeQhAj2h632t6P7Qjy5jOFXHq1KmaPHmy1qxZE1k3fvx43XjjjVq5cmWL7adPn64ZM2bo5z//eWTdkiVL9M477+iNN97o0HfGc3rq5s78XVoxPq6HBACgz1n+njTw/PgeM5737041CdXV1Wn37t0qLCyMWl9YWKidO3fG3Ke2tlZerzdqXUpKinbt2qVAINDJ4gIAACfqVJPQ8ePHFQwGlZWVFbU+KytLpaWlMff5yle+ot/85je68cYbNXnyZO3evVvr169XIBDQ8ePHlZPTslNhbW2tamtrI+8rKio6U8xOSUppXF7+nuRJ7bGvAqL898ETmv/U2+1u9/SCyzQ1d3AvlAiA09RVNbYyNL0f2lGXnhKymj2obYxpsa7Bj370I5WWluryyy+XMUZZWVmaP3++Hn30UbndsdvuV65cqRUrVnSlaJ3WtNieVHs/0oX+ZfqETA0dkqTS8hrFape1JGX7vJo+IVNuhngE0MPsPAaL1MkmoSFDhsjtdreoTSkrK2tR69IgJSVF69evV1VVlT799FOVlJRo9OjRSk9P15AhQ2Lus2zZMpWXl0dehw4d6kwxgT7B7bK0fM4ESeFw0lTD++VzJtDhFgDUycDi8XiUn5+voqKiqPVFRUWaPn16m/smJSVp+PDhcrvd2rhxo6677jq5XLG/Pjk5WRkZGVEvoD+alZejNbdMVrYvup9Xts+rNbdMZhwWADin001CS5cu1a233qqCggJNmzZNTz75pEpKSrR48WJJ4dqRI0eORMZa+fDDD7Vr1y5NnTpVp06d0qpVq7Rv3z4988wz8T2TLkpKDY/u17AM9LZZeTm6ZkI2I90C6HV96R7Y6cAyd+5cnThxQg899JD8fr/y8vK0detWjRoVHtvX7/erpKQksn0wGNQvfvELffDBB0pKStI//MM/aOfOnRo9enTcTqI7LIt+K0g8t8vStDF0rAXQu/rSPbDT47AkQk+OwwIAAHpGwsZhAQAASAQCCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsD0CCwAAsL0BiS5AIhljFDIBSZLLSpJlWXHZFgAAxJejA0vIBPTOsf8lSSrI+oFkkrTr4EmVVdZoaLpXU3Iz5XZZMbd1W56ElRsAAKdxdGBpqqi4VCte+kj+8prIuhyfV8vnTNCsvJwElgwAANCH5ZwlG/8aFVYkqbS8Rnds2KNt+/wJKhUAAJAcHliMMZHlpAEhJTd7ec7978o/vau6UF3M/QAAQM9zdJNQSPWR5d987/02t/3b3/c22y+5p4oFAACacXQNCwAA6BscXcPianL6i9aOU1196/nt6QVfkCv1P1rsBwAAep6ja1iajqUSqHepNsarrt6lzLRU5Y8eGnM/AADQ8xwdWJprHkMa3i+fM0FuQgoAAAljmT7wyEtFRYV8Pp/Ky8uVkZERt+M2Hb22qPi4Vrz0XqvjsDDSLQAAnRPP+7ejO2NYlhUZsXZW3jBdMyGn1ZFum24LAAB6l6MDS3Nul6VpYwYnuhgAAKCZLvVhWb16tXJzc+X1epWfn68dO3a0uf1zzz2nSZMmKTU1VTk5OVqwYIFOnDjRpQIDAADn6XRg2bRpk5YsWaIHH3xQe/fu1ZVXXqnZs2erpKQk5vZvvPGGbrvtNi1cuFD79+/X7373O7399ttatGhRtwsPAACcodOBZdWqVVq4cKEWLVqk8ePH67HHHtOIESO0Zs2amNu/9dZbGj16tO6++27l5ubqiiuu0Pe+9z2988473S48AABwhk4Flrq6Ou3evVuFhYVR6wsLC7Vz586Y+0yfPl2HDx/W1q1bZYzRsWPH9Pvf/17XXnttq99TW1urioqKqBcAAHCuTgWW48ePKxgMKisrK2p9VlaWSktLY+4zffp0Pffcc5o7d648Ho+ys7M1aNAg/fu//3ur37Ny5Ur5fL7Ia8SIEZ0pZocZY3Q2GNLZYKhbExrG6zgAACC2LnW6bT4GiTGm1XFJiouLdffdd+vHP/6xdu/erW3btungwYNavHhxq8dftmyZysvLI69Dhw51pZjtqgoZjXznmEa+c0yV9SG9+ckJ/fEvR/TmJycUDHU8eDQ9TlUn9gMAAB3TqceahwwZIrfb3aI2paysrEWtS4OVK1dqxowZuu+++yRJl1xyidLS0nTllVfq4YcfVk5OTot9kpOTlZzcu7MhX7PqNR07VR1533TQOAAAkFidqmHxeDzKz89XUVFR1PqioiJNnz495j5VVVVyuaK/xu12S5Ktmk9KK2qj35fX6I4Ne7Rtnz9BJQIAAA06PXDc0qVLdeutt6qgoEDTpk3Tk08+qZKSkkgTz7Jly3TkyBE9++yzkqQ5c+bo9ttv15o1a/SVr3xFfr9fS5Ys0ZQpUzRs2LD4nk0n1QcbA5NxR4cqo/BcQsu3vKfpY4dGRryNparpcWwUwgAA6C86HVjmzp2rEydO6KGHHpLf71deXp62bt2qUaNGSZL8fn/UmCzz589XZWWlfvnLX+ree+/VoEGDNHPmTP3sZz+L31l00c7PTkaWz157ScxtKiXl7inr8DGrQ9LA7hYMAABEcfTkh7/dc0RLAvGdsPr9S4fqfI87rscEAKAvYvLDOLkg3SOdrJckpW35m6xgKOZ2Ty+4TFNyM1s9TlXQaNzecC1MSnzzDwAAkMMDS8HoTOlkOGhYwVCLwGJJyvZ5ddWFg9vswyI17tfa490AAKDrHF0f0DSENI8ZDe+Xz5nQTlgBAAA9zdGBJdx9J/wamhE97ku2z6snbr5UvhRPlwaTa+s7q0IhVYUYFRcAgI5ydJOQZUnpaeE+LC8vvUr7S8pVVlmjoelenTpbp3/ZUix/eU1k+9YGk0t1WSopyIost6XaGE0oPixJKp4wXKk0IQEA0C5H17A07W8ywO3StDGDdcMXLlB5dZ2+/x97osKK1PpgcpZlKc3tUprbRR8WAAB6gKNrWJo2yVSFwh1ngyGj5Vvfk3G3DB4NWy/f+p5mjGt7MLnWNHxP8+8HAACtc3RgqW4SGAreP9r4wVc/1+Z+xyRd/P6RuHx/WrePAgBA/+foJiEAANA3OLqGJaVJf5N3xg1Tqsul/z5wUgue2tXuvk8tmKKpF7Y+mFxrqkKhSG1OCv1dAADoEEcHlqYdZFNdLqW6XLrqwsHKGZis0vIaxeph0vHB5Dr3/QAAoHU0CTXjdllaPmeCJAaTAwDALggsMczKy9GaWyYr2+eNWp/t82rNLZNbjMMCAAB6lqNnazbGRJ4USrGsFk00wZDRroMnI4PJTcnN7HbNSnvfCQBAf8FszXFiWVabI826XZamjRncq98JAABaokkIAADYHoEFAADYHoEFAADYnqP7sMgYqfbcBIfJXgWNOt7Jttm+ol8KAAA9xtmBpbZGun2aJKnoBy/ox38+EDVDc47Pq+VzJsR+jLnJvvr1m5I3pTdKDACAI9EkdM49G/8SFVYkqbS8Rnds2KNt+/wJKhUAAJCcXsPSZPB9b6iu1aH4f/bHvbpmjE/ups0+tdUxjwMAAOLP2YGltrFGZc+xla1v55f0/7RzHG9q3IoFAACi0SQEAABsz9k1LMmNcwVNzlqmapen1U2fXnCZpuY2GfW2tlq6c2aL4wAAgPhzdmBpMh9zjcsTM7BYCk96WDD2AqnVeYR4pBkAgJ5Ek1ATzWNHw/vlcyZ0e9JDAADQdQSWcx6f9wVl+6KbdrJ9Xq25ZXLscVgAAECvsYwxtn8mN57TU0dhpFsAAHpMPO/fzu7DYllRI9S6LWnamMFt7ND6vgAAoOfQJAQAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGzPuSPdGiPVVIeXvSkdH1q/q/sBAIAuc25gqamWZo4NL7/ygZSSqmDItD+XUIz9AABAz3JuYGlm2z6/VrxULH95TWRdjs+r5XMmMFszAAAJRh8WSUXFpbpjw56osCJJpeU1umPDHm3b509QyQAAgOTkGhZjIourXvyrvEETczNL0s9e2KtrcjPCzUPVVTGPAQAAeo5jA4uprlJD75Q//dfd7e+wtZVjpKbFtVwAAKAlxzYJ1Stoi2MAAID2ObaGRd6UyOLUq36mipC3zc2fnj9FUy/MVKCqQknXXdbiGAAAoOc4N7A0GT8laeBAVZ91t7rpealJKhh/geSyJFMf8xgAAKDnODawmCYdZgckGSUltd6B1p1kFDD1ChlLAVOvpBjHAAAAPcexgaVeQXnOLd9252nVp3ja3P5Z/V4KSQNMnb4b4xgAAKDnODawyJui9UUPS5LqvUntbNyo3psU2W8efVgAAOgVjg0sA6wBkVqVx/51oAKBtvujPL3gMk3JHayAqdeGlBcixwAAAD3PsXdcy7Kkc11QBqem6PDxWsXqkWJJyvZ5dfnooXI3dLI1TY4BAAB6nGPHYWlq2exxkqTm8aPh/fI5E1pOgggAAHoNgUXSNROyteaWycr2RY/Fku3zas0tk5n8EACABLNMH3g2t6KiQj6fT+Xl5crIyIjLMY0xkZFqB8gty7IUDBntOnhSZZU1Gpru1ZTczBY1K7H2AwAALcXz/u3oPixJzU7f7bI0bczgTu8HAAB6Fk1CAADA9ggsAADA9pzbtmGMVFcTXvZ4Oz4vUFf3AwAAXebcwFJXI903M7z881ek5JQOdbqNtR8AAOhZzg0szWzb59eKl4rlL6+JrMvxebV8zgQeawYAIMHowyKpqLhUd2zYExVWJKm0vEZ3bNijbfv8CSoZAACQuhhYVq9erdzcXHm9XuXn52vHjh2tbjt//nxZltXiNXHixC4XOi6aDD+zasvf5DV1Smn2alj3sz/+RcHqKqm2WqqrjnkMAADQczrdJLRp0yYtWbJEq1ev1owZM7R27VrNnj1bxcXFGjlyZIvtH3/8cT3yyCOR9/X19Zo0aZJuuumm7pW8uwKNtSl/KnukjQ0lVUu6v5VjeFPjWiwAANBSp2tYVq1apYULF2rRokUaP368HnvsMY0YMUJr1qyJub3P51N2dnbk9c477+jUqVNasGBBtwsPAACcoVM1LHV1ddq9e7ceeOCBqPWFhYXauXNnh46xbt06ffnLX9aoUaNa3aa2tla1tbWR9xUVFZ0pZsckNc4bNNm7RNWWp83Nn14wRVNzM8NNQg9e2+IYAACg53SqhuX48eMKBoPKysqKWp+VlaXS0tJ29/f7/frTn/6kRYsWtbndypUr5fP5Iq8RI0Z0ppgd02T8FJ8vQzWWR9UxXjWWR4MGZajgomHhR5g9KTGPAQAAek6XOt02n/DPGNOhSQCffvppDRo0SDfeeGOb2y1btkzl5eWR16FDh7pSzA77n18dJ0lqfgYN75fPmdByPBYAANBrOhVYhgwZIrfb3aI2paysrEWtS3PGGK1fv1633nqrPJ62m1+Sk5OVkZER9epJ10zI1ppbJivbF93Ek+3zas0tkxmHBQCABOtUHxaPx6P8/HwVFRXpa1/7WmR9UVGRbrjhhjb3fe211/Txxx9r4cKFXStpvHm84ZFqzy3PysvRNROy2x/pttl+AACg53X6sealS5fq1ltvVUFBgaZNm6Ynn3xSJSUlWrx4saRwc86RI0f07LPPRu23bt06TZ06VXl5efEpeXdZVoth9d0uS9PGDO70fgAAoGd1OrDMnTtXJ06c0EMPPSS/36+8vDxt3bo18tSP3+9XSUlJ1D7l5eV6/vnn9fjjj8en1AAAwFEsY+w/XGtFRYV8Pp/Ky8vj15/FmPDItVK4xsSyOjb5YTvHAAAAYfG8fzt38sPaaukbl4aXn9+rbR+Xd37yw2bHYNRbAAB6BpMfiskPAQCwO+fWsDSd/PClv8obit0yZkn62R/26poLM1o2D9UwESIAAL3BuYGltsnkh7seaGPDc9qbq7G2RkpJ616ZAABATDQJAQAA23NuDUtyk8kPx69QtaudyQ/nT9HUCzOjV9ZUS9+e3uJ4AAAgvpwbWJpOfjgoQ6fOGMXqhWIpPER/wbgLpLYeceaRZgAAegxNQmLyQwAA7I7AIiY/BADA7hjpVmKkWwAAegAj3caDZbUYmbZDkx+2cwwAABB/NAkBAADbc2wNizFGQdVLktwaIKsLzTnxOAYAAGifYwNLUPXaenadJOmraQs1QEmd7sMS6xgAACD+HBtYmtu2z9/52ZoBAECvcGwflqYPR21777Du2rRb/vLqqG2YrRkAAHtwbGAJmPrI8sdjd+ufVtQqNTUkT1LjKylJ8iRJ//qnfaoN1qneBFq8GvSBp8MBAOizHNsk9MqHR6UR4eULq49Lkh5Z2vr2f67+pM3jBVWvJLU9HxEAAOgaR9awbNvn1z+/sC/RxQAAAB3kuBqWYMhoxUvFqmtsEdKBlCEylqVfPzxA9YGGDOeSNXSGJMmU/V89Pb9AU5rN1lxvAvqvqmclhR9rBgAAPcNxd9ldB0/KX16j9IzGx5WNZclYlkIaoLqmgaU+/Jjy0NRUTc0dKncb46wwBgsAAD3HcYGlrLKm1c+s86fJqklusf7er4xjtmYAABLIcYFlaHp4RubqakufpJ4vSWp4vqe+PnaXnpnjsmKud2uAvpq2MLIMAAB6huPuslNyM5Xj8+rvVdUyzZpxTNlOmUDDOpesrCskSSmt/CtZlsXotgAA9ALHPSXkdllaPmeCYjfwhCIvS6HIWvqnAACQWI6rYZGkWXk5+t+arH9+ZL8qBl4mKVy7Uh8IhxTiCQAA9uK4GpYGs/OG6dWlV6u+Pin8ClhqiCrZPq8e+8cvJLR8AACgkSNrWBoM9Fjaf2eqgiGjdw9N0d/PNM7S7LKkayaEt2utDwsAAOgdjr4VW5JSA1WSpOljMiXLkoyRqsPrUlNSw+sAAEBCOTqwqLpKunSUJOn/PPOmBp+fqSlZyXLnjw5/vvczKTUtceUDAACSHB5YiopLdc255ft+/66qByQrN1XantBSAQCA5hzb6XbbPr/u2fjXFuuPVdQmoDQAAKAtjqxhCYaMVry4X9666nCfFWN0Xk2FUtye6O2CIbkTVEYAANDIkYFl18GTOn2iXO/9x+3hFed5tXPjP4WXM1MiHW33fOjXZfnpCSolAABo4MgmobYmQGzq+JmObQcAAHqWIwPLp8erWv1seuEvIsuZgwf1QmkAAEB7HBdYgiGj/9xVEu670qDJco2rcTLDgtGZvVk0AADQCscFll0HT6q0okYp9U2eBjrduOwN1kWW3S4GjQMAwA4cF1g62n8FAADYh+MCy9B0rySpekByZN3Mb6yKLJ/yDNT4OU/qvzfvlVJSe718AACgJccFlim5mcrxeWU1mSPodHLjo8uWy6VBg30qGD+ceYQAALAJxwUWt8vS8jkT2txm+ZwJ9F8BAMBGHDlw3Ky8HLnnfUF6puVnj8/7gq7Jy+n1MgEAgNZZxjR9vteeKioq5PP5VF5eroyMjPgc1BgFz5zVO5+dUmmdlO2RCkadJ/fANJqCAACIg3jevx1ZwyJJsiy50wdqat7ARJcEAAC0w3F9WAAAQN9DYAEAALZHYAEAALZHYAEAALZHYAEAALZHYAEAALZHYAEAALbn2HFYjDEKql6S5DJuhaygJMmtAVHzDAEAgMRzbGAJmoB+fzY8Nn/ygatVNe51SdJcz7c1QEmSMVKgJrxxkpfRbwEASCDHBpZX3i3RvM3/KUnKdw3W0gfC6x/503u6euwFmnJBitwrrwuvfHCL5ElJUEkBAIAjA8u2fX7d//t3VRijB88zb5boN68fUm6GS9t7v2gAACAGx3W6DYaMVrxULKPGOR+TkprO/xhePlZR28slAwAArXFcYNl18KT85TVKcjeGlHu/VyZ3XUDuuoAyBgSUooC8CkQ+DwZDiSgqAAA4x3FNQmWV4Y603nNPCEnSTf/7d5HleZKUHL3Pnk9KdVnemF4oHQAAiMVxNSxD072SpPpgx/c5fobmIQAAEslxNSz5o86Ty5KqlRRZV+hdr+/eWSRJ+umj5ysQkFIU0J7kNZKkTF9GQsoKAADCHBdYdn92SiEjSY3jqtRYXgU94QBTrWQFFN1npSA3sxdLCAAAmnNck1BDH5bOcLsYNA4AgETqUmBZvXq1cnNz5fV6lZ+frx07drS5fW1trR588EGNGjVKycnJGjNmjNavX9+lAndXQx+WisAAXRK6W9MH/L86VZ2uX/z8m/rFz7+pQCD89FBqaqqKvrYuPGhckjchZQUAAGGdbhLatGmTlixZotWrV2vGjBlau3atZs+ereLiYo0cOTLmPt/61rd07NgxrVu3Tp/73OdUVlam+vr6mNv2tCm5mcrxeVVaXqOKwAAZ10BJUiDyFLOlzLQBenPZl+UZ4LgKKAAAbMkyxpj2N2s0depUTZ48WWvWrImsGz9+vG688UatXLmyxfbbtm3TvHnzdODAAWVmdq0vSEVFhXw+n8rLy5WR0f0OsNv2+XXHhj2SXBqY/A9Rn52p3a41t3xBs/Jyuv09AAA4WTzv352qQqirq9Pu3btVWFgYtb6wsFA7d+6Muc+LL76ogoICPfroo7rgggt00UUX6Yc//KGqq6u7XupumpWXozW3TFZWRsumnsfnEVYAALCbTjUJHT9+XMFgUFlZWVHrs7KyVFpaGnOfAwcO6I033pDX69ULL7yg48eP65/+6Z908uTJVvux1NbWqra2ceyTioqKzhSzQ2bl5ejL47P0xkenVFZZo/MHenVZ7nlKS86O+3cBAIDu6dJjzZYV/dSMMabFugahUEiWZem5556Tz+eTJK1atUrf/OY39cQTTyglpeUsyCtXrtSKFSu6UrROGeB26UvjBvf49wAAgO7pVJPQkCFD5Ha7W9SmlJWVtah1aZCTk6MLLrggElakcJ8XY4wOHz4cc59ly5apvLw88jp06FBnigkAAPqZTgUWj8ej/Px8FRUVRa0vKirS9OnTY+4zY8YMHT16VGfOnIms+/DDD+VyuTR8+PCY+yQnJysjIyPqBQAAnKvTz+0uXbpUv/nNb7R+/Xq99957+sEPfqCSkhItXrxYUrh25Lbbbotsf/PNN2vw4MFasGCBiouL9frrr+u+++7Td7/73ZjNQQAAAM11ug/L3LlzdeLECT300EPy+/3Ky8vT1q1bNWrUKEmS3+9XSUlJZPuBAweqqKhId911lwoKCjR48GB961vf0sMPPxy/swAAAP1ap8dhSYR4j8MCAAB6XsLGYQEAAEgEAgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALA9AgsAALC9AYkuQCIZGQUUlCQNkEv1CkmSkuSWJSuRRQMAAE04NrAYY1SjGv1CLyskSxP2TdT7efskSfdplpKtpASXEAAANHBsk1BI9Xrz1FpNP/WJXDJ66KV9mn7qE00/9Ylefu9IoosHAACacGxgKSoubfWz+373rrbt8/diaQAAQFscGViCIaMf/3F/1Dp3sxagBza/q2DI9GKpAABAaxwZWN765IROV9dF3rtMSDfdG4q8H5BkdLoqoLc+OZGI4gEAgGYcGVjePHBcngGNtSeXnz6oy08fjLxv+OzNA8d7vWwAAKAlRwYWtfPIcn2gY9sBAIDe4cjAMm3MYNXVN4aRtwbl6n/8JjfyvuGzaWMG93rZAABAS44ch+XyCwdrUIon8j5kuVRX33QLS+elJunyCwksAADYgSNrWNwuSw/dMLHNbVZ+/WK5XTQJAQBgB5YxxvbP7lZUVMjn86m8vFwZGRlxOaYxRtuKD+ln//W+Dp+sU31ASk0xyvIl6398eaJm510Ql+8BAMCp4nn/dmSTkCRZlqXZE0eqcPwI7Tp4UmWVNRqa7tWU3ExqVgAAsBnHBpYGbpdF51oAAGzOkX1YAABA30JgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtkdgAQAAtufouYSMMaoKhpdTXEbVofCkh6nu8OSIAADAHhwdWKqC0pA/npYkrR1Vpe99lipJOn7DIKU5+l8GAAB7cXSTUFFxaWT5n/+wL+Z6AACQeI4NLNv2+XXPxr/E/OyejX/Rtn3+3i0QAABolSMDSzBk9JOXihVyuWQa/s/V+E9hJP3kpWJVBEI6GzQyxiSusAAAwJmBZdfBkzpaWae/f2my5Av3uj0+qaBxA5dLRyvrNPS1Exq8/biqQrGPY4zR2UD4RagBAKDnODKwlFXWSFb3T72qXhr920qN/m2lqurjUDAAABCTIwPL0HSvoutDjAa/u6exeUiKbiKi9gQAgIRy5MO7U3Iz5Uv36O8NK3whHb/iEknh5qG/f2ly1PZVIWlgr5YQAAA05cjA4nZZKhyfpY87uH1lbUhpMQaSqwo01ryEa2EYbA4AgJ7gyMAiSVeMOV+rzw23knp4gGQkq2ngsKSzwwOSpCm/PyOXabv1rLpeGujpqdICAOBsjuzDIklfGHleZNllXHIbt1zGFXlZpjG8WNScAACQUI6tYUlLagwhKZ/skisY/ZiPcbl0ZkS4L8tvpwV01ZjBLY5RFTCasPFM+BiO/ZcEAKDnOfY223RyQ8uEZJnowVaaPhg0Y0xmVMBp73gAACC+HNsklOqSBh7yaOAhjxRqOTKcKxRS1ivvaOPQeqUPIIwAAJBIjq1hSUuy9NktGZKk19//gh76P8Xyl9dEPs/xebV8zgTNystp9RipA6RPb02PLAMAgJ7h2NusZVlKSwovz744R4UTs7Xr4EmVVdZoaLpXU3Iz5Xa13wzUcAwAANBzHBtYmnO7LE2L0bEWAAAknmP7sAAAgL6DwAIAAGyPwAIAAGyvS4Fl9erVys3NldfrVX5+vnbs2NHqtq+++qosy2rxev/997tcaAAA4CydDiybNm3SkiVL9OCDD2rv3r268sorNXv2bJWUlLS53wcffCC/3x95ff7zn+9yoQEAgLN0OrCsWrVKCxcu1KJFizR+/Hg99thjGjFihNasWdPmfkOHDlV2dnbk5Xa7u1xoAADgLJ0KLHV1ddq9e7cKCwuj1hcWFmrnzp1t7nvppZcqJydHV199tbZv397mtrW1taqoqIh6AQAA5+pUYDl+/LiCwaCysrKi1mdlZam0tDTmPjk5OXryySf1/PPPa/PmzRo7dqyuvvpqvf76661+z8qVK+Xz+SKvESNGdKaYAACgn+nSwHHNJ/ozxrQ6+d/YsWM1duzYyPtp06bp0KFD+rd/+zddddVVMfdZtmyZli5dGnlfUVFBaAEAwME6VcMyZMgQud3uFrUpZWVlLWpd2nL55Zfro48+avXz5ORkZWRkRL0AAIBzdSqweDwe5efnq6ioKGp9UVGRpk+f3uHj7N27Vzk5rU8qCAAA0FSnm4SWLl2qW2+9VQUFBZo2bZqefPJJlZSUaPHixZLCzTlHjhzRs88+K0l67LHHNHr0aE2cOFF1dXXasGGDnn/+eT3//PPxPRMAANBvdTqwzJ07VydOnNBDDz0kv9+vvLw8bd26VaNGjZIk+f3+qDFZ6urq9MMf/lBHjhxRSkqKJk6cqC1btuirX/1qh7/TGCNJPC0EAEAf0nDfbriPd4dl4nGUHnb48GE63QIA0EcdOnRIw4cP79Yx+kRgCYVCOnr0qNLT01t9GqkrGp4+OnToUL/v2Mu59j9OOU+Jc+2PnHKeknPONdZ5GmNUWVmpYcOGyeXq3vSFXXqsube5XK5uJ7O2OOlJJM61/3HKeUqca3/klPOUnHOuzc/T5/PF5bjM1gwAAGyPwAIAAGzP0YElOTlZy5cvV3JycqKL0uM41/7HKecpca79kVPOU3LOufb0efaJTrcAAMDZHF3DAgAA+gYCCwAAsD0CCwAAsD0CCwAAsD1HB5bVq1crNzdXXq9X+fn52rFjR6KL1C0rV67UZZddpvT0dA0dOlQ33nijPvjgg6ht5s+fL8uyol6XX355gkrcdT/5yU9anEd2dnbkc2OMfvKTn2jYsGFKSUnRl770Je3fvz+BJe6a0aNHtzhPy7L0/e9/X1Lfvp6vv/665syZo2HDhsmyLP3hD3+I+rwj17C2tlZ33XWXhgwZorS0NF1//fU6fPhwL55Fx7R1roFAQPfff78uvvhipaWladiwYbrtttt09OjRqGN86UtfanGt582b18tn0rb2rmlHfq/94ZpKivl3a1mWfv7zn0e26QvXtCP3ld76W3VsYNm0aZOWLFmiBx98UHv37tWVV16p2bNnR03c2Ne89tpr+v73v6+33npLRUVFqq+vV2Fhoc6ePRu13axZs+T3+yOvrVu3JqjE3TNx4sSo83j33Xcjnz366KNatWqVfvnLX+rtt99Wdna2rrnmGlVWViawxJ339ttvR51jUVGRJOmmm26KbNNXr+fZs2c1adIk/fKXv4z5eUeu4ZIlS/TCCy9o48aNeuONN3TmzBldd911CgaDvXUaHdLWuVZVVWnPnj360Y9+pD179mjz5s368MMPdf3117fY9vbbb4+61mvXru2N4ndYe9dUav/32h+uqaSoc/T7/Vq/fr0sy9I3vvGNqO3sfk07cl/ptb9V41BTpkwxixcvjlo3btw488ADDySoRPFXVlZmJJnXXnstsu473/mOueGGGxJXqDhZvny5mTRpUszPQqGQyc7ONo888khkXU1NjfH5fOZXv/pVL5WwZ9xzzz1mzJgxJhQKGWP6z/WUZF544YXI+45cw9OnT5ukpCSzcePGyDZHjhwxLpfLbNu2rdfK3lnNzzWWXbt2GUnms88+i6z74he/aO65556eLVwcxTrP9n6v/fma3nDDDWbmzJlR6/raNTWm5X2lN/9WHVnDUldXp927d6uwsDBqfWFhoXbu3JmgUsVfeXm5JCkzMzNq/auvvqqhQ4fqoosu0u23366ysrJEFK/bPvroIw0bNky5ubmaN2+eDhw4IEk6ePCgSktLo65vcnKyvvjFL/bp61tXV6cNGzbou9/9btQkoP3lejbVkWu4e/duBQKBqG2GDRumvLy8Pn2dpfDfrmVZGjRoUNT65557TkOGDNHEiRP1wx/+sM/VGEpt/1776zU9duyYtmzZooULF7b4rK9d0+b3ld78W+0Tkx/G2/HjxxUMBpWVlRW1PisrS6WlpQkqVXwZY7R06VJdccUVysvLi6yfPXu2brrpJo0aNUoHDx7Uj370I82cOVO7d+/uU6MwTp06Vc8++6wuuugiHTt2TA8//LCmT5+u/fv3R65hrOv72WefJaK4cfGHP/xBp0+f1vz58yPr+sv1bK4j17C0tFQej0fnnXdei2368t9xTU2NHnjgAd18881RE8h9+9vfVm5urrKzs7Vv3z4tW7ZMf/3rXyPNhH1Be7/X/npNn3nmGaWnp+vrX/961Pq+dk1j3Vd682/VkYGlQdP/SpXCF6P5ur7qzjvv1N/+9je98cYbUevnzp0bWc7Ly1NBQYFGjRqlLVu2tPhjsrPZs2dHli+++GJNmzZNY8aM0TPPPBPpxNffru+6des0e/ZsDRs2LLKuv1zP1nTlGvbl6xwIBDRv3jyFQiGtXr066rPbb789spyXl6fPf/7zKigo0J49ezR58uTeLmqXdPX32pevqSStX79e3/72t+X1eqPW97Vr2tp9Reqdv1VHNgkNGTJEbre7RbIrKytrkRL7orvuuksvvviitm/fruHDh7e5bU5OjkaNGqWPPvqol0rXM9LS0nTxxRfro48+ijwt1J+u72effaaXX35ZixYtanO7/nI9O3INs7OzVVdXp1OnTrW6TV8SCAT0rW99SwcPHlRRUVFU7UoskydPVlJSUp++1s1/r/3tmkrSjh079MEHH7T7tyvZ+5q2dl/pzb9VRwYWj8ej/Pz8FtVuRUVFmj59eoJK1X3GGN15553avHmzXnnlFeXm5ra7z4kTJ3To0CHl5OT0Qgl7Tm1trd577z3l5OREqlibXt+6ujq99tprffb6PvXUUxo6dKiuvfbaNrfrL9ezI9cwPz9fSUlJUdv4/X7t27evz13nhrDy0Ucf6eWXX9bgwYPb3Wf//v0KBAJ9+lo3/732p2vaYN26dcrPz9ekSZPa3daO17S9+0qv/q12p7dwX7Zx40aTlJRk1q1bZ4qLi82SJUtMWlqa+fTTTxNdtC674447jM/nM6+++qrx+/2RV1VVlTHGmMrKSnPvvfeanTt3moMHD5rt27ebadOmmQsuuMBUVFQkuPSdc++995pXX33VHDhwwLz11lvmuuuuM+np6ZHr98gjjxifz2c2b95s3n33XfOP//iPJicnp8+dpzHGBINBM3LkSHP//fdHre/r17OystLs3bvX7N2710gyq1atMnv37o08GdORa7h48WIzfPhw8/LLL5s9e/aYmTNnmkmTJpn6+vpEnVZMbZ1rIBAw119/vRk+fLj5y1/+EvW3W1tba4wx5uOPPzYrVqwwb7/9tjl48KDZsmWLGTdunLn00kttda5tnWdHf6/94Zo2KC8vN6mpqWbNmjUt9u8r17S9+4oxvfe36tjAYowxTzzxhBk1apTxeDxm8uTJUY//9kWSYr6eeuopY4wxVVVVprCw0Jx//vkmKSnJjBw50nznO98xJSUliS14F8ydO9fk5OSYpKQkM2zYMPP1r3/d7N+/P/J5KBQyy5cvN9nZ2SY5OdlcddVV5t13301gibvuz3/+s5FkPvjgg6j1ff16bt++Pebv9Tvf+Y4xpmPXsLq62tx5550mMzPTpKSkmOuuu86W59/WuR48eLDVv93t27cbY4wpKSkxV111lcnMzDQej8eMGTPG3H333ebEiROJPbFm2jrPjv5e+8M1bbB27VqTkpJiTp8+3WL/vnJN27uvGNN7f6vWuQIBAADYliP7sAAAgL6FwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwAIAAGzv/wcUkdgDHEyW4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    plt.plot(df.iloc[i][[\"Min_KL\", \"Max_KL\"]], [df.iloc[i][\"Quantized Top1 Accuracy\"]] * 2, color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Min_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Max_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "072a7807-ef35-47de-807e-713dcf873518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(100):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized VGG16 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e647349-11a1-48f2-bb7f-80b685680da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(80):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fc909a7-7edb-48b6-a0ad-876549adac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(80):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b67a379b-ea0d-41f1-8e05-11ab681a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(80):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57a59db2-c5d9-448d-bd08-831468fc95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Median KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized VGG16 On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973c463-7a01-4b31-81d8-98ff135a4621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
