{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f376d630-cea9-4230-9c3f-5299c7c71ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc51213-39a5-48f8-850a-3982505488b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 795.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 85.74182891845703.\n",
      "The relative quantization error of layer 0 is 0.0193336084485054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 785.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 926.7498779296875.\n",
      "The relative quantization error of layer 1 is 0.05214890465140343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2342.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 241.62966918945312.\n",
      "The relative quantization error of layer 2 is 0.056438229978084564.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 245.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3246.97265625.\n",
      "The relative quantization error of layer 3 is 0.09866929799318314.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 228.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1455.469970703125.\n",
      "The relative quantization error of layer 4 is 0.050248708575963974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 492.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 605.4962158203125.\n",
      "The relative quantization error of layer 5 is 0.20908458530902863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2443.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 268.2049865722656.\n",
      "The relative quantization error of layer 6 is 0.24077428877353668.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 206.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1070.3365478515625.\n",
      "The relative quantization error of layer 7 is 0.23224137723445892.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 523.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 881.5758056640625.\n",
      "The relative quantization error of layer 8 is 0.2682408094406128.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2597.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 558.8804931640625.\n",
      "The relative quantization error of layer 9 is 0.2788780629634857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1583.4613037109375.\n",
      "The relative quantization error of layer 10 is 0.2390093058347702.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 286.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1720.0968017578125.\n",
      "The relative quantization error of layer 11 is 0.30832770466804504.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2616.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1220.9527587890625.\n",
      "The relative quantization error of layer 12 is 0.31049513816833496.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 911.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1522.4935302734375.\n",
      "The relative quantization error of layer 13 is 0.21988138556480408.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2102.43994140625.\n",
      "The relative quantization error of layer 14 is 0.29792165756225586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2046.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2059.908447265625.\n",
      "The relative quantization error of layer 15 is 0.2657082974910736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2602.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 550.976318359375.\n",
      "The relative quantization error of layer 16 is 0.24154314398765564.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 757.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1239.763916015625.\n",
      "The relative quantization error of layer 17 is 0.4103192687034607.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2062.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1803.035400390625.\n",
      "The relative quantization error of layer 18 is 0.30779922008514404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2542.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 369.48974609375.\n",
      "The relative quantization error of layer 19 is 0.26304203271865845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 931.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1241.2994384765625.\n",
      "The relative quantization error of layer 20 is 0.3101326823234558.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2062.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2030.468505859375.\n",
      "The relative quantization error of layer 21 is 0.33349698781967163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2607.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 436.91571044921875.\n",
      "The relative quantization error of layer 22 is 0.28087347745895386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 929.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1042.996826171875.\n",
      "The relative quantization error of layer 23 is 0.40599825978279114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1470.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3440.09423828125.\n",
      "The relative quantization error of layer 24 is 0.37995585799217224.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2584.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 639.927734375.\n",
      "The relative quantization error of layer 25 is 0.332124799489975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1509.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1385.7718505859375.\n",
      "The relative quantization error of layer 26 is 0.3762155771255493.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 548.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3545.99169921875.\n",
      "The relative quantization error of layer 27 is 0.37376007437705994.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2608.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1377.7203369140625.\n",
      "The relative quantization error of layer 28 is 0.34219202399253845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2589.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 268.1658630371094.\n",
      "The relative quantization error of layer 29 is 0.18137520551681519.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1509.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 978.4284057617188.\n",
      "The relative quantization error of layer 30 is 0.44538143277168274.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2571.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1545.2574462890625.\n",
      "The relative quantization error of layer 31 is 0.36239543557167053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2598.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 302.41851806640625.\n",
      "The relative quantization error of layer 32 is 0.22469070553779602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 884.884521484375.\n",
      "The relative quantization error of layer 33 is 0.47154852747917175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2595.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1703.8177490234375.\n",
      "The relative quantization error of layer 34 is 0.41644906997680664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2598.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 246.81912231445312.\n",
      "The relative quantization error of layer 35 is 0.20276424288749695.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1492.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1088.9508056640625.\n",
      "The relative quantization error of layer 36 is 0.5187838673591614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2478.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1767.364990234375.\n",
      "The relative quantization error of layer 37 is 0.43796366453170776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2604.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 217.9065704345703.\n",
      "The relative quantization error of layer 38 is 0.2163715660572052.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1495.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1335.671875.\n",
      "The relative quantization error of layer 39 is 0.5107184648513794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2592.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1849.03564453125.\n",
      "The relative quantization error of layer 40 is 0.4272095859050751.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2598.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.61155700683594.\n",
      "The relative quantization error of layer 41 is 0.21890337765216827.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1501.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1480.8912353515625.\n",
      "The relative quantization error of layer 42 is 0.5481473207473755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2113.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2598.390869140625.\n",
      "The relative quantization error of layer 43 is 0.46147212386131287.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2608.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 163.39622497558594.\n",
      "The relative quantization error of layer 44 is 0.2054506242275238.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2033.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 917.9226684570312.\n",
      "The relative quantization error of layer 45 is 0.42187780141830444.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 943.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2165.030029296875.\n",
      "The relative quantization error of layer 46 is 0.47230225801467896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2628.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 413.78668212890625.\n",
      "The relative quantization error of layer 47 is 0.3905577063560486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2622.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 110.21734619140625.\n",
      "The relative quantization error of layer 48 is 0.10423797369003296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2066.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 527.4705200195312.\n",
      "The relative quantization error of layer 49 is 0.6829478144645691.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2564.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 431.5927734375.\n",
      "The relative quantization error of layer 50 is 0.28109145164489746.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2659.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 71.49744415283203.\n",
      "The relative quantization error of layer 51 is 0.15072736144065857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2137.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 112.496337890625.\n",
      "The relative quantization error of layer 52 is 0.7937270402908325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2646.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 32.23347091674805.\n",
      "The relative quantization error of layer 53 is 0.1995307207107544.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:51.975492\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.60it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.866.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.985.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.935.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.991.\n",
      "\n",
      "Time used for evaluation: 0:00:04.014517\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4526\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 791.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 89.92145538330078.\n",
      "The relative quantization error of layer 0 is 0.01966514252126217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 751.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 901.846435546875.\n",
      "The relative quantization error of layer 1 is 0.050424832850694656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2201.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 250.2135467529297.\n",
      "The relative quantization error of layer 2 is 0.05483349785208702.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 228.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3467.5341796875.\n",
      "The relative quantization error of layer 3 is 0.10348165035247803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 218.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1467.900634765625.\n",
      "The relative quantization error of layer 4 is 0.04893668368458748.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 521.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 609.5599975585938.\n",
      "The relative quantization error of layer 5 is 0.20366275310516357.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2385.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 281.59539794921875.\n",
      "The relative quantization error of layer 6 is 0.2322693020105362.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 212.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1056.9517822265625.\n",
      "The relative quantization error of layer 7 is 0.21835660934448242.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 517.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 953.7581176757812.\n",
      "The relative quantization error of layer 8 is 0.2730053961277008.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2465.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 602.256591796875.\n",
      "The relative quantization error of layer 9 is 0.2903316915035248.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 243.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1707.3966064453125.\n",
      "The relative quantization error of layer 10 is 0.2436588555574417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 284.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1696.2415771484375.\n",
      "The relative quantization error of layer 11 is 0.30046388506889343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2444.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1196.881591796875.\n",
      "The relative quantization error of layer 12 is 0.29182884097099304.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 796.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1517.6160888671875.\n",
      "The relative quantization error of layer 13 is 0.2169886827468872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2120.473388671875.\n",
      "The relative quantization error of layer 14 is 0.2997933030128479.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2015.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2144.09619140625.\n",
      "The relative quantization error of layer 15 is 0.269420862197876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2528.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 549.15576171875.\n",
      "The relative quantization error of layer 16 is 0.2453746199607849.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 831.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1182.7845458984375.\n",
      "The relative quantization error of layer 17 is 0.37839382886886597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1994.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1783.4974365234375.\n",
      "The relative quantization error of layer 18 is 0.29119759798049927.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2510.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 382.0137023925781.\n",
      "The relative quantization error of layer 19 is 0.25667256116867065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 700.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1282.4365234375.\n",
      "The relative quantization error of layer 20 is 0.31062284111976624.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2005.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1991.844482421875.\n",
      "The relative quantization error of layer 21 is 0.3279138505458832.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2513.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 459.89801025390625.\n",
      "The relative quantization error of layer 22 is 0.2769721746444702.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 852.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1031.4771728515625.\n",
      "The relative quantization error of layer 23 is 0.34951573610305786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1447.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3333.079833984375.\n",
      "The relative quantization error of layer 24 is 0.36597028374671936.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2533.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 621.5042114257812.\n",
      "The relative quantization error of layer 25 is 0.32092151045799255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1497.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1352.49365234375.\n",
      "The relative quantization error of layer 26 is 0.36661675572395325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 510.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3416.512939453125.\n",
      "The relative quantization error of layer 27 is 0.35419151186943054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2537.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1375.2532958984375.\n",
      "The relative quantization error of layer 28 is 0.33285966515541077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2537.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 266.5838623046875.\n",
      "The relative quantization error of layer 29 is 0.17793220281600952.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1488.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 974.3948974609375.\n",
      "The relative quantization error of layer 30 is 0.4128090441226959.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2528.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1552.2459716796875.\n",
      "The relative quantization error of layer 31 is 0.3653315007686615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2526.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.1053161621094.\n",
      "The relative quantization error of layer 32 is 0.218885600566864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1501.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 855.3795166015625.\n",
      "The relative quantization error of layer 33 is 0.46327680349349976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2498.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1681.31494140625.\n",
      "The relative quantization error of layer 34 is 0.3963925242424011.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2539.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 240.85414123535156.\n",
      "The relative quantization error of layer 35 is 0.20054297149181366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1479.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1054.3699951171875.\n",
      "The relative quantization error of layer 36 is 0.5267805457115173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2496.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1762.9371337890625.\n",
      "The relative quantization error of layer 37 is 0.3966190218925476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2498.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 206.14891052246094.\n",
      "The relative quantization error of layer 38 is 0.20629440248012543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1394.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1351.5533447265625.\n",
      "The relative quantization error of layer 39 is 0.5066500306129456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2534.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1822.76806640625.\n",
      "The relative quantization error of layer 40 is 0.43228238821029663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2524.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 179.7353057861328.\n",
      "The relative quantization error of layer 41 is 0.21438291668891907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1481.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1401.6558837890625.\n",
      "The relative quantization error of layer 42 is 0.5333102345466614.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2026.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2473.36962890625.\n",
      "The relative quantization error of layer 43 is 0.44095590710639954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2506.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.92611694335938.\n",
      "The relative quantization error of layer 44 is 0.201669842004776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1996.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 902.9845581054688.\n",
      "The relative quantization error of layer 45 is 0.41698551177978516.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 933.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2172.712890625.\n",
      "The relative quantization error of layer 46 is 0.45912447571754456.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2364.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 395.2474365234375.\n",
      "The relative quantization error of layer 47 is 0.3840257525444031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2486.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 99.58861541748047.\n",
      "The relative quantization error of layer 48 is 0.089872807264328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1962.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 533.9823608398438.\n",
      "The relative quantization error of layer 49 is 0.6880343556404114.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2528.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 421.80242919921875.\n",
      "The relative quantization error of layer 50 is 0.2608741223812103.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2561.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 55.064613342285156.\n",
      "The relative quantization error of layer 51 is 0.10138110816478729.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2094.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 111.27383422851562.\n",
      "The relative quantization error of layer 52 is 0.7744393944740295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2568.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.02129364013672.\n",
      "The relative quantization error of layer 53 is 0.1815255582332611.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.685390\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.76it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.861.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.987.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.906.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.988.\n",
      "\n",
      "Time used for evaluation: 0:00:04.315091\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.457\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 799.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 83.6058349609375.\n",
      "The relative quantization error of layer 0 is 0.018315812572836876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 564.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 908.8203735351562.\n",
      "The relative quantization error of layer 1 is 0.05093933269381523.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2481.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 252.8712158203125.\n",
      "The relative quantization error of layer 2 is 0.05825585871934891.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 226.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3402.794677734375.\n",
      "The relative quantization error of layer 3 is 0.10196121782064438.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1497.3629150390625.\n",
      "The relative quantization error of layer 4 is 0.05138183385133743.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 488.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 594.5543212890625.\n",
      "The relative quantization error of layer 5 is 0.20385199785232544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2365.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 257.904541015625.\n",
      "The relative quantization error of layer 6 is 0.23624739050865173.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 204.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1077.2294921875.\n",
      "The relative quantization error of layer 7 is 0.22574405372142792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 519.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 881.9137573242188.\n",
      "The relative quantization error of layer 8 is 0.25966012477874756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2529.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 577.8052368164062.\n",
      "The relative quantization error of layer 9 is 0.2749440371990204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 209.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1580.9404296875.\n",
      "The relative quantization error of layer 10 is 0.24000446498394012.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 282.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1696.4029541015625.\n",
      "The relative quantization error of layer 11 is 0.30470001697540283.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2525.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1180.710693359375.\n",
      "The relative quantization error of layer 12 is 0.29846006631851196.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 895.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1511.1141357421875.\n",
      "The relative quantization error of layer 13 is 0.21809302270412445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1986.9326171875.\n",
      "The relative quantization error of layer 14 is 0.29465219378471375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1948.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2050.941650390625.\n",
      "The relative quantization error of layer 15 is 0.2685294449329376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2537.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 520.9736328125.\n",
      "The relative quantization error of layer 16 is 0.23425886034965515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 848.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1203.6766357421875.\n",
      "The relative quantization error of layer 17 is 0.3994399607181549.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2002.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1829.7506103515625.\n",
      "The relative quantization error of layer 18 is 0.31020060181617737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2551.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 373.97064208984375.\n",
      "The relative quantization error of layer 19 is 0.2646913230419159.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 927.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1219.25390625.\n",
      "The relative quantization error of layer 20 is 0.30772292613983154.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2014.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1983.7373046875.\n",
      "The relative quantization error of layer 21 is 0.3386004865169525.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2549.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 425.8598937988281.\n",
      "The relative quantization error of layer 22 is 0.2755071818828583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 883.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1016.4049682617188.\n",
      "The relative quantization error of layer 23 is 0.3710692524909973.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1446.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3282.848876953125.\n",
      "The relative quantization error of layer 24 is 0.36193937063217163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2502.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 620.0806884765625.\n",
      "The relative quantization error of layer 25 is 0.32187724113464355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1476.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1383.937255859375.\n",
      "The relative quantization error of layer 26 is 0.36962541937828064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 545.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3385.981689453125.\n",
      "The relative quantization error of layer 27 is 0.3507315218448639.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2514.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1361.6617431640625.\n",
      "The relative quantization error of layer 28 is 0.33807989954948425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2530.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 263.05841064453125.\n",
      "The relative quantization error of layer 29 is 0.1774625927209854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1489.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 988.5435180664062.\n",
      "The relative quantization error of layer 30 is 0.40887197852134705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2518.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1520.7557373046875.\n",
      "The relative quantization error of layer 31 is 0.36061733961105347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2543.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 294.2082824707031.\n",
      "The relative quantization error of layer 32 is 0.21975336968898773.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1453.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 856.7911987304688.\n",
      "The relative quantization error of layer 33 is 0.4541780352592468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2523.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1666.2568359375.\n",
      "The relative quantization error of layer 34 is 0.4052933156490326.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2548.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.43678283691406.\n",
      "The relative quantization error of layer 35 is 0.19845855236053467.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1491.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1000.3191528320312.\n",
      "The relative quantization error of layer 36 is 0.4932726323604584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2501.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1717.614501953125.\n",
      "The relative quantization error of layer 37 is 0.3918590247631073.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2526.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 204.9700469970703.\n",
      "The relative quantization error of layer 38 is 0.20870080590248108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1483.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1329.3433837890625.\n",
      "The relative quantization error of layer 39 is 0.5060388445854187.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2473.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1791.33984375.\n",
      "The relative quantization error of layer 40 is 0.42010533809661865.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2512.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 176.96298217773438.\n",
      "The relative quantization error of layer 41 is 0.2165411114692688.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1472.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1408.2044677734375.\n",
      "The relative quantization error of layer 42 is 0.5265779495239258.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2055.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2489.01708984375.\n",
      "The relative quantization error of layer 43 is 0.44797590374946594.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2534.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 160.90638732910156.\n",
      "The relative quantization error of layer 44 is 0.20758789777755737.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2025.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 895.6395874023438.\n",
      "The relative quantization error of layer 45 is 0.42357873916625977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 918.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2214.242431640625.\n",
      "The relative quantization error of layer 46 is 0.46870550513267517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2438.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 401.5015563964844.\n",
      "The relative quantization error of layer 47 is 0.39666077494621277.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2509.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 101.65965270996094.\n",
      "The relative quantization error of layer 48 is 0.13352800905704498.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2020.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 521.6849975585938.\n",
      "The relative quantization error of layer 49 is 0.6554563641548157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2449.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 493.2829895019531.\n",
      "The relative quantization error of layer 50 is 0.27621936798095703.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2504.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 89.17879486083984.\n",
      "The relative quantization error of layer 51 is 0.1792018711566925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2063.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 109.98493957519531.\n",
      "The relative quantization error of layer 52 is 0.7732405662536621.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2509.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 29.140472412109375.\n",
      "The relative quantization error of layer 53 is 0.1830827295780182.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.220464\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.83it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.881.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.958.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.998.\n",
      "\n",
      "Time used for evaluation: 0:00:04.018837\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4528\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 773.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 83.84585571289062.\n",
      "The relative quantization error of layer 0 is 0.01851399801671505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 827.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 877.2958984375.\n",
      "The relative quantization error of layer 1 is 0.04949451982975006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2209.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 235.06326293945312.\n",
      "The relative quantization error of layer 2 is 0.054599329829216.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 240.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3404.0771484375.\n",
      "The relative quantization error of layer 3 is 0.10330010950565338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1345.5487060546875.\n",
      "The relative quantization error of layer 4 is 0.04632558301091194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 492.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 607.0988159179688.\n",
      "The relative quantization error of layer 5 is 0.20503154397010803.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2409.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 271.2785339355469.\n",
      "The relative quantization error of layer 6 is 0.2354208081960678.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 255.18it/s]\n",
      " 37%|███▋      | 94/256 [00:00<00:00, 472.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 980.8306884765625.\n",
      "The relative quantization error of layer 7 is 0.215343177318573.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 497.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 864.997314453125.\n",
      "The relative quantization error of layer 8 is 0.2643856406211853.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2514.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 540.1151733398438.\n",
      "The relative quantization error of layer 9 is 0.2675754725933075.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1602.709716796875.\n",
      "The relative quantization error of layer 10 is 0.2387835681438446.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 275.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1669.025634765625.\n",
      "The relative quantization error of layer 11 is 0.3081605136394501.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2568.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1180.02392578125.\n",
      "The relative quantization error of layer 12 is 0.30523061752319336.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 803.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1505.1146240234375.\n",
      "The relative quantization error of layer 13 is 0.21856583654880524.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1881.3570556640625.\n",
      "The relative quantization error of layer 14 is 0.29355907440185547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2013.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2034.3387451171875.\n",
      "The relative quantization error of layer 15 is 0.2777408957481384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2568.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 515.0678100585938.\n",
      "The relative quantization error of layer 16 is 0.24289388954639435.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 845.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1194.5042724609375.\n",
      "The relative quantization error of layer 17 is 0.402580589056015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1973.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1775.777099609375.\n",
      "The relative quantization error of layer 18 is 0.2997957468032837.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2540.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 368.74114990234375.\n",
      "The relative quantization error of layer 19 is 0.25987666845321655.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 915.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1230.792724609375.\n",
      "The relative quantization error of layer 20 is 0.3051271438598633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1999.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2029.2230224609375.\n",
      "The relative quantization error of layer 21 is 0.3302736282348633.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2540.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 441.37347412109375.\n",
      "The relative quantization error of layer 22 is 0.28070586919784546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 894.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1033.041748046875.\n",
      "The relative quantization error of layer 23 is 0.38535580039024353.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1449.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3306.360595703125.\n",
      "The relative quantization error of layer 24 is 0.3659856617450714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2524.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 613.6875.\n",
      "The relative quantization error of layer 25 is 0.32147833704948425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1490.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1318.65380859375.\n",
      "The relative quantization error of layer 26 is 0.3644258975982666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 545.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3307.344482421875.\n",
      "The relative quantization error of layer 27 is 0.35344335436820984.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2505.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1328.5496826171875.\n",
      "The relative quantization error of layer 28 is 0.33327001333236694.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2524.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 258.7705993652344.\n",
      "The relative quantization error of layer 29 is 0.1783449351787567.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1464.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 993.1569213867188.\n",
      "The relative quantization error of layer 30 is 0.440105676651001.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2507.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1500.7403564453125.\n",
      "The relative quantization error of layer 31 is 0.35875019431114197.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2518.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 292.86517333984375.\n",
      "The relative quantization error of layer 32 is 0.22530417144298553.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1491.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 901.5601806640625.\n",
      "The relative quantization error of layer 33 is 0.48266953229904175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2503.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1625.9874267578125.\n",
      "The relative quantization error of layer 34 is 0.41051343083381653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2533.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 253.72308349609375.\n",
      "The relative quantization error of layer 35 is 0.20764271914958954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1486.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1064.86962890625.\n",
      "The relative quantization error of layer 36 is 0.5252240896224976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2488.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1802.909423828125.\n",
      "The relative quantization error of layer 37 is 0.4293934404850006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2519.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.98912048339844.\n",
      "The relative quantization error of layer 38 is 0.2126699686050415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1481.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1369.8350830078125.\n",
      "The relative quantization error of layer 39 is 0.5157999992370605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2497.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1788.3780517578125.\n",
      "The relative quantization error of layer 40 is 0.4224238693714142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2523.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 188.73744201660156.\n",
      "The relative quantization error of layer 41 is 0.23612962663173676.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1484.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1443.970947265625.\n",
      "The relative quantization error of layer 42 is 0.5437530279159546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2062.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2451.907470703125.\n",
      "The relative quantization error of layer 43 is 0.4457133114337921.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2520.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.85598754882812.\n",
      "The relative quantization error of layer 44 is 0.20315201580524445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2022.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 950.7536010742188.\n",
      "The relative quantization error of layer 45 is 0.4425048232078552.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 935.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2179.79345703125.\n",
      "The relative quantization error of layer 46 is 0.4714101254940033.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2525.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 419.5712890625.\n",
      "The relative quantization error of layer 47 is 0.3797104060649872.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2518.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 102.42485046386719.\n",
      "The relative quantization error of layer 48 is 0.10132547467947006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2027.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 515.7593994140625.\n",
      "The relative quantization error of layer 49 is 0.6585074663162231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2495.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 445.75408935546875.\n",
      "The relative quantization error of layer 50 is 0.28352078795433044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2499.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 72.96337890625.\n",
      "The relative quantization error of layer 51 is 0.13375380635261536.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2058.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 113.62945556640625.\n",
      "The relative quantization error of layer 52 is 0.8083268404006958.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2509.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 35.98955154418945.\n",
      "The relative quantization error of layer 53 is 0.21699100732803345.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.530646\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.869.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.988.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.936.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.997.\n",
      "\n",
      "Time used for evaluation: 0:00:04.310919\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4494\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 819.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 82.83576202392578.\n",
      "The relative quantization error of layer 0 is 0.018028398975729942.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 835.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 891.319580078125.\n",
      "The relative quantization error of layer 1 is 0.050260741263628006.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2242.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 254.4524688720703.\n",
      "The relative quantization error of layer 2 is 0.057397667318582535.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 235.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3443.320556640625.\n",
      "The relative quantization error of layer 3 is 0.10598643124103546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 247.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1414.7958984375.\n",
      "The relative quantization error of layer 4 is 0.048570528626441956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 500.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 555.8195190429688.\n",
      "The relative quantization error of layer 5 is 0.19124342501163483.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2489.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 275.3162536621094.\n",
      "The relative quantization error of layer 6 is 0.23602530360221863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 255.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1082.7371826171875.\n",
      "The relative quantization error of layer 7 is 0.22703196108341217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 505.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 864.3116455078125.\n",
      "The relative quantization error of layer 8 is 0.2590509355068207.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2451.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 558.7783813476562.\n",
      "The relative quantization error of layer 9 is 0.26756224036216736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 220.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1603.5831298828125.\n",
      "The relative quantization error of layer 10 is 0.23712745308876038.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 278.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1750.5555419921875.\n",
      "The relative quantization error of layer 11 is 0.3031989634037018.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2524.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1184.0074462890625.\n",
      "The relative quantization error of layer 12 is 0.3026319146156311.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 929.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1491.553466796875.\n",
      "The relative quantization error of layer 13 is 0.21606439352035522.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2068.13818359375.\n",
      "The relative quantization error of layer 14 is 0.2954205870628357.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1938.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1962.5062255859375.\n",
      "The relative quantization error of layer 15 is 0.27045008540153503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2599.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 518.0838623046875.\n",
      "The relative quantization error of layer 16 is 0.23498515784740448.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 754.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1156.337646484375.\n",
      "The relative quantization error of layer 17 is 0.38322943449020386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2047.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1732.52587890625.\n",
      "The relative quantization error of layer 18 is 0.2917962074279785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2651.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 362.5977783203125.\n",
      "The relative quantization error of layer 19 is 0.2524030804634094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 928.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1189.208251953125.\n",
      "The relative quantization error of layer 20 is 0.29999348521232605.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2058.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1946.30859375.\n",
      "The relative quantization error of layer 21 is 0.3210245370864868.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2632.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 434.0484924316406.\n",
      "The relative quantization error of layer 22 is 0.269388347864151.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 880.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 985.60302734375.\n",
      "The relative quantization error of layer 23 is 0.35399746894836426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1383.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3232.042724609375.\n",
      "The relative quantization error of layer 24 is 0.35759177803993225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2623.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 608.5315551757812.\n",
      "The relative quantization error of layer 25 is 0.31647011637687683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1523.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1323.4930419921875.\n",
      "The relative quantization error of layer 26 is 0.36345186829566956.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 530.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3415.5810546875.\n",
      "The relative quantization error of layer 27 is 0.35958725214004517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2608.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1354.903564453125.\n",
      "The relative quantization error of layer 28 is 0.3395004868507385.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2640.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 265.8212585449219.\n",
      "The relative quantization error of layer 29 is 0.175135537981987.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1516.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 957.4569091796875.\n",
      "The relative quantization error of layer 30 is 0.44739675521850586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2508.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1535.0037841796875.\n",
      "The relative quantization error of layer 31 is 0.36380812525749207.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2610.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 293.9061279296875.\n",
      "The relative quantization error of layer 32 is 0.21889178454875946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1515.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 860.611328125.\n",
      "The relative quantization error of layer 33 is 0.46336984634399414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2604.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1680.44091796875.\n",
      "The relative quantization error of layer 34 is 0.39723512530326843.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2627.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 232.10873413085938.\n",
      "The relative quantization error of layer 35 is 0.19780248403549194.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1470.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1015.7213745117188.\n",
      "The relative quantization error of layer 36 is 0.5131084322929382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2534.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1728.43798828125.\n",
      "The relative quantization error of layer 37 is 0.41549766063690186.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2553.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 211.94009399414062.\n",
      "The relative quantization error of layer 38 is 0.21026137471199036.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1495.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1308.2921142578125.\n",
      "The relative quantization error of layer 39 is 0.49302956461906433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2626.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1813.9339599609375.\n",
      "The relative quantization error of layer 40 is 0.4103250205516815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2632.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 181.86524963378906.\n",
      "The relative quantization error of layer 41 is 0.2188427448272705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1343.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1418.65966796875.\n",
      "The relative quantization error of layer 42 is 0.5188300013542175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 1943.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2440.76708984375.\n",
      "The relative quantization error of layer 43 is 0.4462321698665619.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2652.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 157.23110961914062.\n",
      "The relative quantization error of layer 44 is 0.2016552835702896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2042.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 898.8095703125.\n",
      "The relative quantization error of layer 45 is 0.41612282395362854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 943.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2172.875732421875.\n",
      "The relative quantization error of layer 46 is 0.46749964356422424.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2630.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 394.5638122558594.\n",
      "The relative quantization error of layer 47 is 0.37639275193214417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2635.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 96.68215942382812.\n",
      "The relative quantization error of layer 48 is 0.08981498330831528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2073.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 512.6421508789062.\n",
      "The relative quantization error of layer 49 is 0.6457576155662537.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2620.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 457.78509521484375.\n",
      "The relative quantization error of layer 50 is 0.2774100601673126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2669.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 63.22250747680664.\n",
      "The relative quantization error of layer 51 is 0.10377257317304611.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2125.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 108.66561126708984.\n",
      "The relative quantization error of layer 52 is 0.7879734635353088.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2652.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 24.658554077148438.\n",
      "The relative quantization error of layer 53 is 0.15778183937072754.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:51.887567\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.24it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.875.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.943.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.994.\n",
      "\n",
      "Time used for evaluation: 0:00:04.015609\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4521\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 752.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 79.9247055053711.\n",
      "The relative quantization error of layer 0 is 0.01778266951441765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 682.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 853.6474609375.\n",
      "The relative quantization error of layer 1 is 0.048192232847213745.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2533.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 247.2825164794922.\n",
      "The relative quantization error of layer 2 is 0.056813132017850876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 212.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3369.201904296875.\n",
      "The relative quantization error of layer 3 is 0.10086502134799957.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 202.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1421.378173828125.\n",
      "The relative quantization error of layer 4 is 0.04800983518362045.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 499.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 595.097900390625.\n",
      "The relative quantization error of layer 5 is 0.2012736052274704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2424.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 260.0516357421875.\n",
      "The relative quantization error of layer 6 is 0.23060092329978943.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 255.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1016.938232421875.\n",
      "The relative quantization error of layer 7 is 0.22014719247817993.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 508.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 876.1554565429688.\n",
      "The relative quantization error of layer 8 is 0.26052066683769226.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2414.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 564.8565673828125.\n",
      "The relative quantization error of layer 9 is 0.27156969904899597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 219.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1664.3629150390625.\n",
      "The relative quantization error of layer 10 is 0.2523709535598755.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 273.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1721.086181640625.\n",
      "The relative quantization error of layer 11 is 0.3080052137374878.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2489.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1186.1055908203125.\n",
      "The relative quantization error of layer 12 is 0.3158639967441559.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 804.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1532.663330078125.\n",
      "The relative quantization error of layer 13 is 0.22032244503498077.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2070.642822265625.\n",
      "The relative quantization error of layer 14 is 0.3015393316745758.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1994.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2072.80712890625.\n",
      "The relative quantization error of layer 15 is 0.2786236107349396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2470.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 519.4611206054688.\n",
      "The relative quantization error of layer 16 is 0.24369436502456665.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 712.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1153.7911376953125.\n",
      "The relative quantization error of layer 17 is 0.3935864269733429.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1950.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1755.7852783203125.\n",
      "The relative quantization error of layer 18 is 0.2991699278354645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2479.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 367.9673156738281.\n",
      "The relative quantization error of layer 19 is 0.25996971130371094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 875.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1231.3367919921875.\n",
      "The relative quantization error of layer 20 is 0.3065744638442993.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1972.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1988.2530517578125.\n",
      "The relative quantization error of layer 21 is 0.335132360458374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2488.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 444.6264343261719.\n",
      "The relative quantization error of layer 22 is 0.2808360159397125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 915.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 945.8953247070312.\n",
      "The relative quantization error of layer 23 is 0.3833783268928528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1451.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3228.770751953125.\n",
      "The relative quantization error of layer 24 is 0.3574739098548889.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2471.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 615.4492797851562.\n",
      "The relative quantization error of layer 25 is 0.3203793466091156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1487.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1351.850341796875.\n",
      "The relative quantization error of layer 26 is 0.36784714460372925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 534.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3370.214599609375.\n",
      "The relative quantization error of layer 27 is 0.3599802851676941.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2479.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1337.67822265625.\n",
      "The relative quantization error of layer 28 is 0.3356817066669464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2482.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 267.7669982910156.\n",
      "The relative quantization error of layer 29 is 0.1808936446905136.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1203.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 972.807861328125.\n",
      "The relative quantization error of layer 30 is 0.4556705355644226.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2489.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1548.9691162109375.\n",
      "The relative quantization error of layer 31 is 0.3634355664253235.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2494.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 283.8853759765625.\n",
      "The relative quantization error of layer 32 is 0.2195376753807068.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1490.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 861.0933227539062.\n",
      "The relative quantization error of layer 33 is 0.4724145531654358.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2469.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1672.7685546875.\n",
      "The relative quantization error of layer 34 is 0.4053463041782379.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2494.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.5795440673828.\n",
      "The relative quantization error of layer 35 is 0.20482787489891052.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1365.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1036.02783203125.\n",
      "The relative quantization error of layer 36 is 0.5165832042694092.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2473.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1707.529296875.\n",
      "The relative quantization error of layer 37 is 0.4263935089111328.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2489.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 215.6757354736328.\n",
      "The relative quantization error of layer 38 is 0.21455983817577362.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1485.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1331.40771484375.\n",
      "The relative quantization error of layer 39 is 0.4969945251941681.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2479.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1822.607421875.\n",
      "The relative quantization error of layer 40 is 0.41885754466056824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2460.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 185.5859832763672.\n",
      "The relative quantization error of layer 41 is 0.22533409297466278.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1436.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1416.67626953125.\n",
      "The relative quantization error of layer 42 is 0.5251148343086243.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2060.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2505.360595703125.\n",
      "The relative quantization error of layer 43 is 0.44881898164749146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2482.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 162.64593505859375.\n",
      "The relative quantization error of layer 44 is 0.20386357605457306.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1972.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 902.1553955078125.\n",
      "The relative quantization error of layer 45 is 0.42451512813568115.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 922.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2156.992431640625.\n",
      "The relative quantization error of layer 46 is 0.463015079498291.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2487.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 401.3596496582031.\n",
      "The relative quantization error of layer 47 is 0.37509483098983765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2492.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 103.08463287353516.\n",
      "The relative quantization error of layer 48 is 0.11175204068422318.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2025.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 529.7763671875.\n",
      "The relative quantization error of layer 49 is 0.6596299409866333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2466.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 450.88494873046875.\n",
      "The relative quantization error of layer 50 is 0.25474417209625244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2537.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 71.76979064941406.\n",
      "The relative quantization error of layer 51 is 0.1296306699514389.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2046.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 112.2765884399414.\n",
      "The relative quantization error of layer 52 is 0.787777841091156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2497.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 26.287858963012695.\n",
      "The relative quantization error of layer 53 is 0.16537506878376007.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.518198\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.41it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.876.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.989.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.938.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.992.\n",
      "\n",
      "Time used for evaluation: 0:00:04.692120\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4535\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 814.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 89.22909545898438.\n",
      "The relative quantization error of layer 0 is 0.01943059451878071.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 833.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 913.1342163085938.\n",
      "The relative quantization error of layer 1 is 0.05154167115688324.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2303.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 254.74911499023438.\n",
      "The relative quantization error of layer 2 is 0.05779886990785599.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 218.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3369.80029296875.\n",
      "The relative quantization error of layer 3 is 0.10085486620664597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 225.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1436.507080078125.\n",
      "The relative quantization error of layer 4 is 0.048193227499723434.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 516.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 611.0791625976562.\n",
      "The relative quantization error of layer 5 is 0.20901982486248016.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2365.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 278.6567687988281.\n",
      "The relative quantization error of layer 6 is 0.23928599059581757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 234.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1070.4326171875.\n",
      "The relative quantization error of layer 7 is 0.2318456768989563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 511.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 902.0770263671875.\n",
      "The relative quantization error of layer 8 is 0.26911625266075134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2388.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 557.8223266601562.\n",
      "The relative quantization error of layer 9 is 0.2702745795249939.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 231.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1638.088623046875.\n",
      "The relative quantization error of layer 10 is 0.24271933734416962.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 277.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1727.47998046875.\n",
      "The relative quantization error of layer 11 is 0.3094876706600189.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2564.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1218.6025390625.\n",
      "The relative quantization error of layer 12 is 0.3081599473953247.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 738.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1548.952392578125.\n",
      "The relative quantization error of layer 13 is 0.22345449030399323.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 2053.593017578125.\n",
      "The relative quantization error of layer 14 is 0.29889243841171265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2042.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2070.1142578125.\n",
      "The relative quantization error of layer 15 is 0.2666873335838318.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2636.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 533.0053100585938.\n",
      "The relative quantization error of layer 16 is 0.24058857560157776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 807.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1216.5732421875.\n",
      "The relative quantization error of layer 17 is 0.39200469851493835.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1809.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1805.8701171875.\n",
      "The relative quantization error of layer 18 is 0.30586129426956177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2630.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.0216369628906.\n",
      "The relative quantization error of layer 19 is 0.2607157230377197.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 934.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1287.87451171875.\n",
      "The relative quantization error of layer 20 is 0.31661778688430786.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2002.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1988.24658203125.\n",
      "The relative quantization error of layer 21 is 0.3330554664134979.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2616.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 447.9768981933594.\n",
      "The relative quantization error of layer 22 is 0.27296146750450134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 877.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 994.9630737304688.\n",
      "The relative quantization error of layer 23 is 0.39398694038391113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1453.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3338.8056640625.\n",
      "The relative quantization error of layer 24 is 0.367138147354126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2616.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 630.254638671875.\n",
      "The relative quantization error of layer 25 is 0.32177454233169556.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1512.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1388.7911376953125.\n",
      "The relative quantization error of layer 26 is 0.37388134002685547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 547.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3361.9013671875.\n",
      "The relative quantization error of layer 27 is 0.35171476006507874.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2616.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1350.7418212890625.\n",
      "The relative quantization error of layer 28 is 0.33462774753570557.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2601.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.5020446777344.\n",
      "The relative quantization error of layer 29 is 0.1769135743379593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1286.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 968.5690307617188.\n",
      "The relative quantization error of layer 30 is 0.4262053966522217.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2563.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1513.4744873046875.\n",
      "The relative quantization error of layer 31 is 0.3576659560203552.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2621.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 288.9911804199219.\n",
      "The relative quantization error of layer 32 is 0.22017540037631989.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1491.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 886.7673950195312.\n",
      "The relative quantization error of layer 33 is 0.4710516631603241.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2597.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1648.978515625.\n",
      "The relative quantization error of layer 34 is 0.3957601487636566.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2623.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 247.8308868408203.\n",
      "The relative quantization error of layer 35 is 0.20185217261314392.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1224.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1026.563232421875.\n",
      "The relative quantization error of layer 36 is 0.5126679539680481.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2603.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1776.3282470703125.\n",
      "The relative quantization error of layer 37 is 0.42036962509155273.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2649.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 212.86936950683594.\n",
      "The relative quantization error of layer 38 is 0.21243037283420563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1507.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1341.8931884765625.\n",
      "The relative quantization error of layer 39 is 0.5066543817520142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2615.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1816.7698974609375.\n",
      "The relative quantization error of layer 40 is 0.428841769695282.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2637.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 172.26556396484375.\n",
      "The relative quantization error of layer 41 is 0.2199331820011139.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1243.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1435.8505859375.\n",
      "The relative quantization error of layer 42 is 0.5254884958267212.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2108.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2477.195556640625.\n",
      "The relative quantization error of layer 43 is 0.44319966435432434.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2633.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 159.3266143798828.\n",
      "The relative quantization error of layer 44 is 0.20128133893013.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2066.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 908.179931640625.\n",
      "The relative quantization error of layer 45 is 0.41642192006111145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 961.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2177.389404296875.\n",
      "The relative quantization error of layer 46 is 0.4626598656177521.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2624.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 389.2766418457031.\n",
      "The relative quantization error of layer 47 is 0.3754921555519104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2636.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 107.87715148925781.\n",
      "The relative quantization error of layer 48 is 0.10259798914194107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1948.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 522.2343139648438.\n",
      "The relative quantization error of layer 49 is 0.6828646659851074.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2636.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 497.28021240234375.\n",
      "The relative quantization error of layer 50 is 0.2596001625061035.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2633.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 87.59244537353516.\n",
      "The relative quantization error of layer 51 is 0.13848860561847687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2109.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 106.80742645263672.\n",
      "The relative quantization error of layer 52 is 0.7782974243164062.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2621.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 27.04422378540039.\n",
      "The relative quantization error of layer 53 is 0.1708001047372818.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.701430\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.31it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.862.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.939.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.995.\n",
      "\n",
      "Time used for evaluation: 0:00:04.404612\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4546\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subset_size = 10\n",
    "# num_exps = 15\n",
    "sc_options = ['False'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'efficientnet_b1' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9969179e-0865-48e8-a11d-cc1e1f526b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 799.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 75.1491470336914.\n",
      "The relative quantization error of layer 0 is 0.017610803246498108.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 833.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 836.73486328125.\n",
      "The relative quantization error of layer 1 is 0.04724784567952156.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2228.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 231.43270874023438.\n",
      "The relative quantization error of layer 2 is 0.054000742733478546.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 242.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3427.924072265625.\n",
      "The relative quantization error of layer 3 is 0.09969258308410645.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 230.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1322.848876953125.\n",
      "The relative quantization error of layer 4 is 0.044838886708021164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 509.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 577.0343627929688.\n",
      "The relative quantization error of layer 5 is 0.20084184408187866.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2604.03it/s]\n",
      " 62%|██████▎   | 40/64 [00:00<00:00, 209.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 247.05990600585938.\n",
      "The relative quantization error of layer 6 is 0.21882149577140808.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1062.4215087890625.\n",
      "The relative quantization error of layer 7 is 0.22990183532238007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 497.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 876.3643798828125.\n",
      "The relative quantization error of layer 8 is 0.25905391573905945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2591.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 566.4057006835938.\n",
      "The relative quantization error of layer 9 is 0.2674187421798706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 256.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1600.8170166015625.\n",
      "The relative quantization error of layer 10 is 0.23364262282848358.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 280.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1703.6312255859375.\n",
      "The relative quantization error of layer 11 is 0.3072451651096344.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2586.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1215.728515625.\n",
      "The relative quantization error of layer 12 is 0.2984677255153656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 926.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1473.32421875.\n",
      "The relative quantization error of layer 13 is 0.21332810819149017.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1936.623046875.\n",
      "The relative quantization error of layer 14 is 0.2946634888648987.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2039.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1952.661376953125.\n",
      "The relative quantization error of layer 15 is 0.2683910131454468.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2582.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 510.7358703613281.\n",
      "The relative quantization error of layer 16 is 0.23877325654029846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1145.437744140625.\n",
      "The relative quantization error of layer 17 is 0.37331244349479675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1840.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1752.9658203125.\n",
      "The relative quantization error of layer 18 is 0.3084457218647003.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2529.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 359.5951843261719.\n",
      "The relative quantization error of layer 19 is 0.2616218030452728.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 924.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1201.6927490234375.\n",
      "The relative quantization error of layer 20 is 0.29902634024620056.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2050.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1934.3817138671875.\n",
      "The relative quantization error of layer 21 is 0.3239201307296753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2572.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 433.58740234375.\n",
      "The relative quantization error of layer 22 is 0.27598413825035095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 848.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1071.74755859375.\n",
      "The relative quantization error of layer 23 is 0.3887961208820343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1442.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3330.600341796875.\n",
      "The relative quantization error of layer 24 is 0.36554476618766785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2530.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 616.8598022460938.\n",
      "The relative quantization error of layer 25 is 0.3199213147163391.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1500.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1360.9105224609375.\n",
      "The relative quantization error of layer 26 is 0.36542633175849915.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 518.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3352.02783203125.\n",
      "The relative quantization error of layer 27 is 0.3575480282306671.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2564.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1339.3076171875.\n",
      "The relative quantization error of layer 28 is 0.33431369066238403.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2587.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 264.05401611328125.\n",
      "The relative quantization error of layer 29 is 0.18179072439670563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1470.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1029.86474609375.\n",
      "The relative quantization error of layer 30 is 0.43564295768737793.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2436.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1574.468017578125.\n",
      "The relative quantization error of layer 31 is 0.37073007225990295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2482.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 298.48382568359375.\n",
      "The relative quantization error of layer 32 is 0.2235165238380432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1403.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 903.7500610351562.\n",
      "The relative quantization error of layer 33 is 0.48889976739883423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2575.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1724.8465576171875.\n",
      "The relative quantization error of layer 34 is 0.4083123505115509.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2600.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 249.7657928466797.\n",
      "The relative quantization error of layer 35 is 0.2054339051246643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1183.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1063.8455810546875.\n",
      "The relative quantization error of layer 36 is 0.5170431137084961.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2411.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1801.8748779296875.\n",
      "The relative quantization error of layer 37 is 0.4250473976135254.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2616.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 210.9373016357422.\n",
      "The relative quantization error of layer 38 is 0.20710356533527374.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1504.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1393.098388671875.\n",
      "The relative quantization error of layer 39 is 0.5190342664718628.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2572.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1887.553466796875.\n",
      "The relative quantization error of layer 40 is 0.44161590933799744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2606.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 180.90269470214844.\n",
      "The relative quantization error of layer 41 is 0.22068646550178528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1487.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1466.265869140625.\n",
      "The relative quantization error of layer 42 is 0.5514442324638367.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2121.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2621.525390625.\n",
      "The relative quantization error of layer 43 is 0.4648132622241974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2601.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 164.12574768066406.\n",
      "The relative quantization error of layer 44 is 0.20359468460083008.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2049.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 981.7783813476562.\n",
      "The relative quantization error of layer 45 is 0.4519283175468445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 959.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2258.384033203125.\n",
      "The relative quantization error of layer 46 is 0.4754132628440857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2604.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 434.5060119628906.\n",
      "The relative quantization error of layer 47 is 0.3906306028366089.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2613.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 101.5369873046875.\n",
      "The relative quantization error of layer 48 is 0.10603738576173782.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2086.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 576.9776000976562.\n",
      "The relative quantization error of layer 49 is 0.7027435302734375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2613.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 455.7283935546875.\n",
      "The relative quantization error of layer 50 is 0.35647764801979065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2640.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 87.4932632446289.\n",
      "The relative quantization error of layer 51 is 0.19767147302627563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2126.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 128.1978759765625.\n",
      "The relative quantization error of layer 52 is 0.8559902310371399.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2637.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 47.233253479003906.\n",
      "The relative quantization error of layer 53 is 0.287143349647522.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.440608\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.28it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.821.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.95.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.697.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.946.\n",
      "\n",
      "Time used for evaluation: 0:00:04.406559\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4487\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 806.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 82.12714385986328.\n",
      "The relative quantization error of layer 0 is 0.017714940011501312.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 830.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 849.777587890625.\n",
      "The relative quantization error of layer 1 is 0.047702111303806305.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2591.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 233.9553680419922.\n",
      "The relative quantization error of layer 2 is 0.0537501722574234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 207.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3636.588623046875.\n",
      "The relative quantization error of layer 3 is 0.10379460453987122.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 203.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1263.0872802734375.\n",
      "The relative quantization error of layer 4 is 0.04172689467668533.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 510.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 594.4644775390625.\n",
      "The relative quantization error of layer 5 is 0.19824635982513428.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2547.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 263.0600280761719.\n",
      "The relative quantization error of layer 6 is 0.2219020277261734.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 212.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1076.8524169921875.\n",
      "The relative quantization error of layer 7 is 0.22964459657669067.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 521.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 899.3880004882812.\n",
      "The relative quantization error of layer 8 is 0.2520477771759033.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2476.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 583.6072998046875.\n",
      "The relative quantization error of layer 9 is 0.2635118365287781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1592.583740234375.\n",
      "The relative quantization error of layer 10 is 0.23563972115516663.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 276.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1734.25830078125.\n",
      "The relative quantization error of layer 11 is 0.30058449506759644.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2491.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1214.205810546875.\n",
      "The relative quantization error of layer 12 is 0.2861391007900238.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 805.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1531.81201171875.\n",
      "The relative quantization error of layer 13 is 0.2146855890750885.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1882.4605712890625.\n",
      "The relative quantization error of layer 14 is 0.28915297985076904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1995.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1936.7926025390625.\n",
      "The relative quantization error of layer 15 is 0.26680082082748413.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2454.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 500.495849609375.\n",
      "The relative quantization error of layer 16 is 0.2342669814825058.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 786.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1161.09912109375.\n",
      "The relative quantization error of layer 17 is 0.3787589967250824.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2016.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1782.0914306640625.\n",
      "The relative quantization error of layer 18 is 0.29177775979042053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2531.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 371.35247802734375.\n",
      "The relative quantization error of layer 19 is 0.24978132545948029.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 784.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1234.0455322265625.\n",
      "The relative quantization error of layer 20 is 0.2992006540298462.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1897.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1940.16064453125.\n",
      "The relative quantization error of layer 21 is 0.3239688575267792.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2377.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 433.8391418457031.\n",
      "The relative quantization error of layer 22 is 0.2723909318447113.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1031.6392822265625.\n",
      "The relative quantization error of layer 23 is 0.33319583535194397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1420.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3265.90478515625.\n",
      "The relative quantization error of layer 24 is 0.3583298623561859.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2452.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 630.06298828125.\n",
      "The relative quantization error of layer 25 is 0.31549832224845886.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1482.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1357.1195068359375.\n",
      "The relative quantization error of layer 26 is 0.3611629605293274.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:01<00:00, 511.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3453.2470703125.\n",
      "The relative quantization error of layer 27 is 0.34651216864585876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2525.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1372.029296875.\n",
      "The relative quantization error of layer 28 is 0.3330964744091034.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2471.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 257.09246826171875.\n",
      "The relative quantization error of layer 29 is 0.1704125702381134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1143.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 960.9567260742188.\n",
      "The relative quantization error of layer 30 is 0.4090755879878998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2482.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1523.75927734375.\n",
      "The relative quantization error of layer 31 is 0.36399298906326294.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2459.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 291.5723876953125.\n",
      "The relative quantization error of layer 32 is 0.2202111780643463.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1490.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 891.58935546875.\n",
      "The relative quantization error of layer 33 is 0.46342650055885315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2455.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1681.8121337890625.\n",
      "The relative quantization error of layer 34 is 0.40597736835479736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2483.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 232.67251586914062.\n",
      "The relative quantization error of layer 35 is 0.1982002556324005.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1420.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1025.6427001953125.\n",
      "The relative quantization error of layer 36 is 0.5071860551834106.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2461.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1772.6478271484375.\n",
      "The relative quantization error of layer 37 is 0.4201953411102295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2528.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 199.94473266601562.\n",
      "The relative quantization error of layer 38 is 0.19965001940727234.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1457.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1312.51416015625.\n",
      "The relative quantization error of layer 39 is 0.5074085593223572.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2437.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1827.929443359375.\n",
      "The relative quantization error of layer 40 is 0.4153749346733093.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2512.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 166.19082641601562.\n",
      "The relative quantization error of layer 41 is 0.2062627524137497.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1460.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1438.317626953125.\n",
      "The relative quantization error of layer 42 is 0.5331345796585083.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2028.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2495.40185546875.\n",
      "The relative quantization error of layer 43 is 0.4427844285964966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2494.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 152.3663330078125.\n",
      "The relative quantization error of layer 44 is 0.19339695572853088.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2015.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 905.35205078125.\n",
      "The relative quantization error of layer 45 is 0.417928010225296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 919.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2186.0859375.\n",
      "The relative quantization error of layer 46 is 0.46263420581817627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2502.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 409.74188232421875.\n",
      "The relative quantization error of layer 47 is 0.39442160725593567.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2533.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 112.34563446044922.\n",
      "The relative quantization error of layer 48 is 0.09528353810310364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1924.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 527.1633911132812.\n",
      "The relative quantization error of layer 49 is 0.6766536831855774.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2525.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 440.39990234375.\n",
      "The relative quantization error of layer 50 is 0.2857256829738617.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2558.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 98.62783813476562.\n",
      "The relative quantization error of layer 51 is 0.16338783502578735.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2073.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 120.39764404296875.\n",
      "The relative quantization error of layer 52 is 0.8091512322425842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2534.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 22.461000442504883.\n",
      "The relative quantization error of layer 53 is 0.12918029725551605.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.624747\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.54it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.883.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.978.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.797.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.977.\n",
      "\n",
      "Time used for evaluation: 0:00:04.596094\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4578\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 825.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 77.9483871459961.\n",
      "The relative quantization error of layer 0 is 0.01865861564874649.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 836.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 829.5346069335938.\n",
      "The relative quantization error of layer 1 is 0.04737718403339386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2574.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 215.90676879882812.\n",
      "The relative quantization error of layer 2 is 0.05115581676363945.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 261.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3288.568115234375.\n",
      "The relative quantization error of layer 3 is 0.09753043204545975.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 259.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1244.1358642578125.\n",
      "The relative quantization error of layer 4 is 0.04304348677396774.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 477.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 552.039794921875.\n",
      "The relative quantization error of layer 5 is 0.1959562599658966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2398.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 237.2252197265625.\n",
      "The relative quantization error of layer 6 is 0.22624361515045166.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 215.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 990.6492309570312.\n",
      "The relative quantization error of layer 7 is 0.22302481532096863.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 802.12646484375.\n",
      "The relative quantization error of layer 8 is 0.25728073716163635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2185.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 523.0005493164062.\n",
      "The relative quantization error of layer 9 is 0.2654469609260559.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 220.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1526.6939697265625.\n",
      "The relative quantization error of layer 10 is 0.24073417484760284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 276.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1555.37841796875.\n",
      "The relative quantization error of layer 11 is 0.30754512548446655.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2314.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1131.7742919921875.\n",
      "The relative quantization error of layer 12 is 0.2975156307220459.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 830.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1429.513671875.\n",
      "The relative quantization error of layer 13 is 0.20971766114234924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1805.5264892578125.\n",
      "The relative quantization error of layer 14 is 0.2953565716743469.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2055.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1831.9603271484375.\n",
      "The relative quantization error of layer 15 is 0.2689698040485382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2493.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 490.30523681640625.\n",
      "The relative quantization error of layer 16 is 0.22986875474452972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 828.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1145.97509765625.\n",
      "The relative quantization error of layer 17 is 0.4112469553947449.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2025.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1708.1983642578125.\n",
      "The relative quantization error of layer 18 is 0.3020847737789154.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2570.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 360.14910888671875.\n",
      "The relative quantization error of layer 19 is 0.27095773816108704.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 812.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1207.455322265625.\n",
      "The relative quantization error of layer 20 is 0.31396690011024475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1989.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1876.56787109375.\n",
      "The relative quantization error of layer 21 is 0.3336324393749237.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2611.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 429.06121826171875.\n",
      "The relative quantization error of layer 22 is 0.2891484498977661.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 905.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 923.0888061523438.\n",
      "The relative quantization error of layer 23 is 0.3939180374145508.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1454.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3134.875732421875.\n",
      "The relative quantization error of layer 24 is 0.3627263307571411.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2591.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 605.7069091796875.\n",
      "The relative quantization error of layer 25 is 0.3274545669555664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1512.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1285.4521484375.\n",
      "The relative quantization error of layer 26 is 0.3609146773815155.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 532.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3131.847900390625.\n",
      "The relative quantization error of layer 27 is 0.35659095644950867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2584.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1263.38232421875.\n",
      "The relative quantization error of layer 28 is 0.3324301540851593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2607.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 249.99874877929688.\n",
      "The relative quantization error of layer 29 is 0.18019148707389832.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1501.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 953.8284912109375.\n",
      "The relative quantization error of layer 30 is 0.4545455276966095.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2595.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1493.8179931640625.\n",
      "The relative quantization error of layer 31 is 0.37460729479789734.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2362.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 282.3457946777344.\n",
      "The relative quantization error of layer 32 is 0.22470490634441376.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1485.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 848.2543334960938.\n",
      "The relative quantization error of layer 33 is 0.49078840017318726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2354.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1603.66357421875.\n",
      "The relative quantization error of layer 34 is 0.4365541934967041.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2620.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 235.9366455078125.\n",
      "The relative quantization error of layer 35 is 0.212545245885849.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1418.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 974.2361450195312.\n",
      "The relative quantization error of layer 36 is 0.5492147207260132.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2571.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1698.5478515625.\n",
      "The relative quantization error of layer 37 is 0.43285784125328064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2617.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 194.0233154296875.\n",
      "The relative quantization error of layer 38 is 0.21595491468906403.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1476.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1336.4552001953125.\n",
      "The relative quantization error of layer 39 is 0.5326874852180481.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2596.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1745.719482421875.\n",
      "The relative quantization error of layer 40 is 0.4404737949371338.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2604.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 177.70782470703125.\n",
      "The relative quantization error of layer 41 is 0.24766811728477478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1482.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1336.8505859375.\n",
      "The relative quantization error of layer 42 is 0.5413665175437927.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2116.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2459.75.\n",
      "The relative quantization error of layer 43 is 0.45384418964385986.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2610.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 154.89926147460938.\n",
      "The relative quantization error of layer 44 is 0.20364047586917877.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2045.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 935.3939819335938.\n",
      "The relative quantization error of layer 45 is 0.4187121093273163.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 910.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2155.372802734375.\n",
      "The relative quantization error of layer 46 is 0.46625372767448425.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2612.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 433.63299560546875.\n",
      "The relative quantization error of layer 47 is 0.400394082069397.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2612.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 110.60382843017578.\n",
      "The relative quantization error of layer 48 is 0.12239760905504227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2041.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 546.019775390625.\n",
      "The relative quantization error of layer 49 is 0.6654696464538574.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2557.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 425.608154296875.\n",
      "The relative quantization error of layer 50 is 0.2549603581428528.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2605.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 65.79584503173828.\n",
      "The relative quantization error of layer 51 is 0.11482178419828415.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1957.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 113.38343811035156.\n",
      "The relative quantization error of layer 52 is 0.7998915314674377.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2652.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 40.612396240234375.\n",
      "The relative quantization error of layer 53 is 0.24050623178482056.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.777349\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.67it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.808.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.986.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.728.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.984.\n",
      "\n",
      "Time used for evaluation: 0:00:04.190662\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4472\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 685.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 75.47093963623047.\n",
      "The relative quantization error of layer 0 is 0.01769222691655159.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 635.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 812.68359375.\n",
      "The relative quantization error of layer 1 is 0.045871879905462265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2588.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 224.70938110351562.\n",
      "The relative quantization error of layer 2 is 0.052498869597911835.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 198.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3432.384765625.\n",
      "The relative quantization error of layer 3 is 0.09970500320196152.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 201.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1326.466552734375.\n",
      "The relative quantization error of layer 4 is 0.04496341943740845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 494.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 579.0370483398438.\n",
      "The relative quantization error of layer 5 is 0.2017364501953125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2517.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 244.86062622070312.\n",
      "The relative quantization error of layer 6 is 0.2192479521036148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 213.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1104.5240478515625.\n",
      "The relative quantization error of layer 7 is 0.2383359968662262.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 503.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 861.9917602539062.\n",
      "The relative quantization error of layer 8 is 0.25548121333122253.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 566.2303466796875.\n",
      "The relative quantization error of layer 9 is 0.2674131691455841.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1731.404296875.\n",
      "The relative quantization error of layer 10 is 0.24944934248924255.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 277.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1707.5526123046875.\n",
      "The relative quantization error of layer 11 is 0.3075532019138336.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2479.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1200.5369873046875.\n",
      "The relative quantization error of layer 12 is 0.29723769426345825.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 702.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1481.10302734375.\n",
      "The relative quantization error of layer 13 is 0.21473459899425507.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 75.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1947.6756591796875.\n",
      "The relative quantization error of layer 14 is 0.29564037919044495.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2031.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1970.5888671875.\n",
      "The relative quantization error of layer 15 is 0.27070748805999756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2560.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 509.8951721191406.\n",
      "The relative quantization error of layer 16 is 0.23803982138633728.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 834.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1174.779541015625.\n",
      "The relative quantization error of layer 17 is 0.38282763957977295.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2020.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1766.7791748046875.\n",
      "The relative quantization error of layer 18 is 0.3101659417152405.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2560.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 365.0716247558594.\n",
      "The relative quantization error of layer 19 is 0.26552432775497437.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 901.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1215.442626953125.\n",
      "The relative quantization error of layer 20 is 0.302196741104126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2016.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1952.3497314453125.\n",
      "The relative quantization error of layer 21 is 0.3280278742313385.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2580.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 441.0067443847656.\n",
      "The relative quantization error of layer 22 is 0.27912622690200806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 921.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1017.2659912109375.\n",
      "The relative quantization error of layer 23 is 0.36550241708755493.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1454.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3337.18994140625.\n",
      "The relative quantization error of layer 24 is 0.3674352765083313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2486.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 620.3958740234375.\n",
      "The relative quantization error of layer 25 is 0.323608934879303.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1498.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1369.8525390625.\n",
      "The relative quantization error of layer 26 is 0.3688262403011322.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 513.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3377.703369140625.\n",
      "The relative quantization error of layer 27 is 0.36141258478164673.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2550.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1350.9267578125.\n",
      "The relative quantization error of layer 28 is 0.3387677073478699.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2539.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 274.26171875.\n",
      "The relative quantization error of layer 29 is 0.1854483187198639.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1488.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 978.5517578125.\n",
      "The relative quantization error of layer 30 is 0.40259259939193726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2561.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1543.755615234375.\n",
      "The relative quantization error of layer 31 is 0.3671770691871643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2473.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 302.3678283691406.\n",
      "The relative quantization error of layer 32 is 0.22317777574062347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1498.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 890.1395874023438.\n",
      "The relative quantization error of layer 33 is 0.48206305503845215.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2543.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1701.3067626953125.\n",
      "The relative quantization error of layer 34 is 0.4046878218650818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2513.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 244.74571228027344.\n",
      "The relative quantization error of layer 35 is 0.20025953650474548.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1055.607177734375.\n",
      "The relative quantization error of layer 36 is 0.5134828686714172.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2502.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1796.356689453125.\n",
      "The relative quantization error of layer 37 is 0.4293978810310364.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2542.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 205.4307098388672.\n",
      "The relative quantization error of layer 38 is 0.20739877223968506.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1478.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1381.966796875.\n",
      "The relative quantization error of layer 39 is 0.5177043080329895.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2509.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1870.2769775390625.\n",
      "The relative quantization error of layer 40 is 0.4444565176963806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2525.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 178.71556091308594.\n",
      "The relative quantization error of layer 41 is 0.22173501551151276.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1491.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1477.776123046875.\n",
      "The relative quantization error of layer 42 is 0.5502706170082092.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2098.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2580.658447265625.\n",
      "The relative quantization error of layer 43 is 0.46152716875076294.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2567.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 158.734375.\n",
      "The relative quantization error of layer 44 is 0.20117534697055817.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1983.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 957.3442993164062.\n",
      "The relative quantization error of layer 45 is 0.4444330632686615.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 936.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2239.19482421875.\n",
      "The relative quantization error of layer 46 is 0.4753437340259552.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2577.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 448.7477111816406.\n",
      "The relative quantization error of layer 47 is 0.42358842492103577.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2576.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 114.68302917480469.\n",
      "The relative quantization error of layer 48 is 0.1302696019411087.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2064.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 583.3350219726562.\n",
      "The relative quantization error of layer 49 is 0.7147215604782104.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2562.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 488.3870849609375.\n",
      "The relative quantization error of layer 50 is 0.3246876001358032.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2589.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 109.00946807861328.\n",
      "The relative quantization error of layer 51 is 0.20727281272411346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2040.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 132.63623046875.\n",
      "The relative quantization error of layer 52 is 0.8818968534469604.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2577.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 45.10575866699219.\n",
      "The relative quantization error of layer 53 is 0.27420973777770996.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.833603\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.92it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.821.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.95.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.7.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.937.\n",
      "\n",
      "Time used for evaluation: 0:00:04.320910\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4492\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 767.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 66.0009536743164.\n",
      "The relative quantization error of layer 0 is 0.017581505700945854.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 829.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 700.92822265625.\n",
      "The relative quantization error of layer 1 is 0.040007639676332474.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2324.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 225.08737182617188.\n",
      "The relative quantization error of layer 2 is 0.05423818901181221.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 244.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3401.54296875.\n",
      "The relative quantization error of layer 3 is 0.0964827686548233.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1166.6636962890625.\n",
      "The relative quantization error of layer 4 is 0.04044707864522934.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 487.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 537.9423217773438.\n",
      "The relative quantization error of layer 5 is 0.1941843032836914.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2391.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 235.0027313232422.\n",
      "The relative quantization error of layer 6 is 0.22739727795124054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 228.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 918.387451171875.\n",
      "The relative quantization error of layer 7 is 0.21527141332626343.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 522.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 799.5507202148438.\n",
      "The relative quantization error of layer 8 is 0.2540106773376465.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2205.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 534.6705322265625.\n",
      "The relative quantization error of layer 9 is 0.2589382827281952.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1507.084228515625.\n",
      "The relative quantization error of layer 10 is 0.2384919971227646.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 272.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1576.6854248046875.\n",
      "The relative quantization error of layer 11 is 0.30753201246261597.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2559.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1116.2606201171875.\n",
      "The relative quantization error of layer 12 is 0.29574066400527954.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 791.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1403.594970703125.\n",
      "The relative quantization error of layer 13 is 0.2063477337360382.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1776.7020263671875.\n",
      "The relative quantization error of layer 14 is 0.287901371717453.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1971.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1899.972412109375.\n",
      "The relative quantization error of layer 15 is 0.27421557903289795.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2456.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 486.7126159667969.\n",
      "The relative quantization error of layer 16 is 0.23094603419303894.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 838.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1104.147705078125.\n",
      "The relative quantization error of layer 17 is 0.38436269760131836.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1935.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1721.812744140625.\n",
      "The relative quantization error of layer 18 is 0.31276047229766846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2403.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 353.63214111328125.\n",
      "The relative quantization error of layer 19 is 0.26185494661331177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 908.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1179.421142578125.\n",
      "The relative quantization error of layer 20 is 0.30005788803100586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1992.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1915.0450439453125.\n",
      "The relative quantization error of layer 21 is 0.3440883457660675.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2522.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 427.89605712890625.\n",
      "The relative quantization error of layer 22 is 0.28358590602874756.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 921.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 981.2871704101562.\n",
      "The relative quantization error of layer 23 is 0.3803471624851227.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1456.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3248.880126953125.\n",
      "The relative quantization error of layer 24 is 0.3687478005886078.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2553.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 623.900634765625.\n",
      "The relative quantization error of layer 25 is 0.3294404149055481.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1486.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1337.150634765625.\n",
      "The relative quantization error of layer 26 is 0.36241254210472107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 545.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3177.453125.\n",
      "The relative quantization error of layer 27 is 0.3589175343513489.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2414.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1342.076904296875.\n",
      "The relative quantization error of layer 28 is 0.3482908010482788.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2370.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 251.1554718017578.\n",
      "The relative quantization error of layer 29 is 0.1758674532175064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1445.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 941.2684326171875.\n",
      "The relative quantization error of layer 30 is 0.4589688777923584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2414.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1528.8671875.\n",
      "The relative quantization error of layer 31 is 0.37369802594184875.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2397.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 296.2631530761719.\n",
      "The relative quantization error of layer 32 is 0.22648361325263977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1433.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 871.26806640625.\n",
      "The relative quantization error of layer 33 is 0.4831812381744385.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2269.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1702.8594970703125.\n",
      "The relative quantization error of layer 34 is 0.42567282915115356.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2422.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 242.290771484375.\n",
      "The relative quantization error of layer 35 is 0.20454038679599762.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1461.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1070.2470703125.\n",
      "The relative quantization error of layer 36 is 0.5348899364471436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2481.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1826.8323974609375.\n",
      "The relative quantization error of layer 37 is 0.45174989104270935.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2535.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 207.9044952392578.\n",
      "The relative quantization error of layer 38 is 0.21399527788162231.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1470.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1399.915771484375.\n",
      "The relative quantization error of layer 39 is 0.5172613859176636.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2307.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1885.3973388671875.\n",
      "The relative quantization error of layer 40 is 0.4610000252723694.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2546.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 185.05136108398438.\n",
      "The relative quantization error of layer 41 is 0.2276102602481842.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1487.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1485.3768310546875.\n",
      "The relative quantization error of layer 42 is 0.5558738708496094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2086.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2623.109619140625.\n",
      "The relative quantization error of layer 43 is 0.4772413969039917.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2541.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 163.87086486816406.\n",
      "The relative quantization error of layer 44 is 0.206295907497406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1709.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 997.4612426757812.\n",
      "The relative quantization error of layer 45 is 0.4608961343765259.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 953.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2253.04150390625.\n",
      "The relative quantization error of layer 46 is 0.4796541631221771.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2545.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 457.7873840332031.\n",
      "The relative quantization error of layer 47 is 0.4207508862018585.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2547.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 114.3874282836914.\n",
      "The relative quantization error of layer 48 is 0.11206060647964478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2045.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 555.2108764648438.\n",
      "The relative quantization error of layer 49 is 0.6841534972190857.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2544.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 497.15032958984375.\n",
      "The relative quantization error of layer 50 is 0.3329172432422638.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2534.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 89.8879623413086.\n",
      "The relative quantization error of layer 51 is 0.21362103521823883.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2032.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 126.22335052490234.\n",
      "The relative quantization error of layer 52 is 0.825888991355896.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2445.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 56.65061950683594.\n",
      "The relative quantization error of layer 53 is 0.32110902667045593.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.373777\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.68it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.781.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.945.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.562.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.897.\n",
      "\n",
      "Time used for evaluation: 0:00:04.394459\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4472\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 783.42it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 591.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 75.98471069335938.\n",
      "The relative quantization error of layer 0 is 0.01783963479101658.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n",
      "The quantization error of layer 1 is 827.6676025390625.\n",
      "The relative quantization error of layer 1 is 0.04656624048948288.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2280.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 237.27255249023438.\n",
      "The relative quantization error of layer 2 is 0.0532783567905426.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 229.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3492.160400390625.\n",
      "The relative quantization error of layer 3 is 0.10273215174674988.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 244.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1230.1651611328125.\n",
      "The relative quantization error of layer 4 is 0.04228518158197403.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 502.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 586.0858764648438.\n",
      "The relative quantization error of layer 5 is 0.19897007942199707.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2379.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 254.86151123046875.\n",
      "The relative quantization error of layer 6 is 0.2319120466709137.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 258.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1097.212890625.\n",
      "The relative quantization error of layer 7 is 0.23164469003677368.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 517.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 874.7669677734375.\n",
      "The relative quantization error of layer 8 is 0.2580828368663788.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1997.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 563.2288818359375.\n",
      "The relative quantization error of layer 9 is 0.2682512402534485.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 258.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1631.5142822265625.\n",
      "The relative quantization error of layer 10 is 0.23730488121509552.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 285.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1665.5740966796875.\n",
      "The relative quantization error of layer 11 is 0.303288996219635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2572.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1178.1005859375.\n",
      "The relative quantization error of layer 12 is 0.29745540022850037.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 873.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1516.1923828125.\n",
      "The relative quantization error of layer 13 is 0.2189776599407196.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1963.957763671875.\n",
      "The relative quantization error of layer 14 is 0.29825982451438904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2053.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 2030.461181640625.\n",
      "The relative quantization error of layer 15 is 0.2722831070423126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2640.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 521.1907958984375.\n",
      "The relative quantization error of layer 16 is 0.23659002780914307.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 921.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1231.07861328125.\n",
      "The relative quantization error of layer 17 is 0.3949999511241913.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2049.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1772.1083984375.\n",
      "The relative quantization error of layer 18 is 0.3009456992149353.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2640.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 366.2784729003906.\n",
      "The relative quantization error of layer 19 is 0.2608441710472107.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 881.53it/s]\n",
      " 78%|███████▊  | 398/512 [00:00<00:00, 2001.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1222.54931640625.\n",
      "The relative quantization error of layer 20 is 0.3030441105365753.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2002.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 2003.1483154296875.\n",
      "The relative quantization error of layer 21 is 0.3365159332752228.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2628.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 438.6473388671875.\n",
      "The relative quantization error of layer 22 is 0.2715061902999878.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 926.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 1028.33837890625.\n",
      "The relative quantization error of layer 23 is 0.3547159731388092.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1468.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3414.0517578125.\n",
      "The relative quantization error of layer 24 is 0.37053608894348145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2625.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 626.0770263671875.\n",
      "The relative quantization error of layer 25 is 0.3205587863922119.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1505.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1381.677490234375.\n",
      "The relative quantization error of layer 26 is 0.3722211718559265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 549.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3392.882080078125.\n",
      "The relative quantization error of layer 27 is 0.3568754494190216.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2630.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1347.5509033203125.\n",
      "The relative quantization error of layer 28 is 0.3395470380783081.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2637.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 256.9889221191406.\n",
      "The relative quantization error of layer 29 is 0.17967885732650757.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1508.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 942.9501342773438.\n",
      "The relative quantization error of layer 30 is 0.44970232248306274.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2643.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1527.87939453125.\n",
      "The relative quantization error of layer 31 is 0.3715304732322693.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2643.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 295.4598388671875.\n",
      "The relative quantization error of layer 32 is 0.22501203417778015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1523.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 881.3900146484375.\n",
      "The relative quantization error of layer 33 is 0.47373661398887634.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2640.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1697.26904296875.\n",
      "The relative quantization error of layer 34 is 0.4077058732509613.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2649.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 243.2408905029297.\n",
      "The relative quantization error of layer 35 is 0.2039349228143692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1506.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1054.1185302734375.\n",
      "The relative quantization error of layer 36 is 0.5119704008102417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2640.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1786.915771484375.\n",
      "The relative quantization error of layer 37 is 0.42192351818084717.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2652.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 203.59190368652344.\n",
      "The relative quantization error of layer 38 is 0.20245693624019623.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1520.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1398.16650390625.\n",
      "The relative quantization error of layer 39 is 0.5143897533416748.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2634.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1887.9407958984375.\n",
      "The relative quantization error of layer 40 is 0.444196879863739.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2660.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 173.64178466796875.\n",
      "The relative quantization error of layer 41 is 0.2187204509973526.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1515.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1486.71923828125.\n",
      "The relative quantization error of layer 42 is 0.5478096604347229.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2130.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2566.536376953125.\n",
      "The relative quantization error of layer 43 is 0.46696099638938904.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2595.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 154.85809326171875.\n",
      "The relative quantization error of layer 44 is 0.19141706824302673.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2019.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 942.4633178710938.\n",
      "The relative quantization error of layer 45 is 0.4468039274215698.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 911.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2245.852294921875.\n",
      "The relative quantization error of layer 46 is 0.4777861535549164.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2650.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 438.3904113769531.\n",
      "The relative quantization error of layer 47 is 0.3984546363353729.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2642.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 117.62605285644531.\n",
      "The relative quantization error of layer 48 is 0.12140187621116638.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2088.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 557.1795043945312.\n",
      "The relative quantization error of layer 49 is 0.6980164647102356.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2598.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 468.88238525390625.\n",
      "The relative quantization error of layer 50 is 0.38677138090133667.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2683.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 91.18700408935547.\n",
      "The relative quantization error of layer 51 is 0.16970832645893097.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2130.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 125.98613739013672.\n",
      "The relative quantization error of layer 52 is 0.8363370299339294.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2650.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 41.194149017333984.\n",
      "The relative quantization error of layer 53 is 0.24546460807323456.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:52.280035\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.54it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.821.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.952.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.666.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.938.\n",
      "\n",
      "Time used for evaluation: 0:00:04.412327\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4496\n",
      "Quantization mode: GPFQ\n",
      "\n",
      "Quantization hyperparameters:\n",
      "Quantizing efficientnet_b1 on cuda:0 with\n",
      "\t  dataset: CIFAR100, bits: 4, mlp_scalar: 1.16, cnn_scalar: 1.16, mlp_percentile: 1,         \n",
      "\tcnn_percentile: 1, retain_rate: 0.25, batch_size: 64\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 7, 7])\n",
      "shape of analog_layer_input: torch.Size([16448, 147])\n",
      "shape of quantized_layer_input: torch.Size([16448, 147])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 810.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 76.09367370605469.\n",
      "The relative quantization error of layer 0 is 0.017802854999899864.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 834.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 859.124755859375.\n",
      "The relative quantization error of layer 1 is 0.0482611320912838.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2436.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 225.68849182128906.\n",
      "The relative quantization error of layer 2 is 0.05282437801361084.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 3319.107666015625.\n",
      "The relative quantization error of layer 3 is 0.09876471757888794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 210.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 1307.259521484375.\n",
      "The relative quantization error of layer 4 is 0.04454950615763664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 506.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 580.2949829101562.\n",
      "The relative quantization error of layer 5 is 0.19774700701236725.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2587.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 263.2599182128906.\n",
      "The relative quantization error of layer 6 is 0.23004063963890076.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 260.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 1014.250732421875.\n",
      "The relative quantization error of layer 7 is 0.22089135646820068.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 482.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 889.0216064453125.\n",
      "The relative quantization error of layer 8 is 0.2563663423061371.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 576])\n",
      "shape of quantized_layer_input: torch.Size([5824, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2496.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 589.6859741210938.\n",
      "The relative quantization error of layer 9 is 0.27472132444381714.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 64])\n",
      "shape of quantized_layer_input: torch.Size([50240, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 234.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 1548.85009765625.\n",
      "The relative quantization error of layer 10 is 0.23661236464977264.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 277.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 1685.906982421875.\n",
      "The relative quantization error of layer 11 is 0.30811795592308044.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([5824, 1152])\n",
      "shape of quantized_layer_input: torch.Size([5824, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2576.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 1227.5443115234375.\n",
      "The relative quantization error of layer 12 is 0.3021901845932007.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 897.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 1491.7347412109375.\n",
      "The relative quantization error of layer 13 is 0.21297161281108856.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([50240, 256])\n",
      "shape of quantized_layer_input: torch.Size([50240, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:03<00:00, 76.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 1846.1029052734375.\n",
      "The relative quantization error of layer 14 is 0.29021310806274414.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2013.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 1985.546142578125.\n",
      "The relative quantization error of layer 15 is 0.27572473883628845.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2582.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 489.6484069824219.\n",
      "The relative quantization error of layer 16 is 0.23304039239883423.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 830.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 1110.0472412109375.\n",
      "The relative quantization error of layer 17 is 0.37917694449424744.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1732.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 1713.468994140625.\n",
      "The relative quantization error of layer 18 is 0.2919813394546509.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2615.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 363.8597412109375.\n",
      "The relative quantization error of layer 19 is 0.256161630153656.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 905.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 1208.1983642578125.\n",
      "The relative quantization error of layer 20 is 0.2969299852848053.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2028.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 1905.99609375.\n",
      "The relative quantization error of layer 21 is 0.3196929693222046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1664, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2600.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 429.2027587890625.\n",
      "The relative quantization error of layer 22 is 0.2712283134460449.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 128])\n",
      "shape of quantized_layer_input: torch.Size([12608, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 921.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 977.6982421875.\n",
      "The relative quantization error of layer 23 is 0.38422855734825134.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1459.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 3248.0361328125.\n",
      "The relative quantization error of layer 24 is 0.3606936037540436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1664, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1664, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2575.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 619.997802734375.\n",
      "The relative quantization error of layer 25 is 0.3163575828075409.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1345.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 1319.0592041015625.\n",
      "The relative quantization error of layer 26 is 0.3583400249481201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([12608, 512])\n",
      "shape of quantized_layer_input: torch.Size([12608, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 541.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 3374.556640625.\n",
      "The relative quantization error of layer 27 is 0.35040706396102905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2406.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 1342.687744140625.\n",
      "The relative quantization error of layer 28 is 0.337513267993927.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2415.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 247.05331420898438.\n",
      "The relative quantization error of layer 29 is 0.16834965348243713.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1445.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 949.7885131835938.\n",
      "The relative quantization error of layer 30 is 0.434911847114563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2362.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 1523.1324462890625.\n",
      "The relative quantization error of layer 31 is 0.3655969500541687.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2436.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 289.31231689453125.\n",
      "The relative quantization error of layer 32 is 0.21890535950660706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1479.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 938.6133422851562.\n",
      "The relative quantization error of layer 33 is 0.5046312212944031.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2446.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 1684.1639404296875.\n",
      "The relative quantization error of layer 34 is 0.4186879098415375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2452.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 235.95875549316406.\n",
      "The relative quantization error of layer 35 is 0.2012035846710205.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1186.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1026.514892578125.\n",
      "The relative quantization error of layer 36 is 0.534750759601593.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2405.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 1820.3856201171875.\n",
      "The relative quantization error of layer 37 is 0.4471769630908966.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2439.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 202.6934051513672.\n",
      "The relative quantization error of layer 38 is 0.20532554388046265.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1361.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1343.6810302734375.\n",
      "The relative quantization error of layer 39 is 0.5166215300559998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2361.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 1849.5025634765625.\n",
      "The relative quantization error of layer 40 is 0.44048064947128296.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 2304])\n",
      "shape of quantized_layer_input: torch.Size([448, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2458.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 174.12353515625.\n",
      "The relative quantization error of layer 41 is 0.2187597006559372.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 256])\n",
      "shape of quantized_layer_input: torch.Size([3200, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1460.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1411.29736328125.\n",
      "The relative quantization error of layer 42 is 0.5378676652908325.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2049.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 2558.227294921875.\n",
      "The relative quantization error of layer 43 is 0.4569900631904602.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([448, 4608])\n",
      "shape of quantized_layer_input: torch.Size([448, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2466.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 167.3463897705078.\n",
      "The relative quantization error of layer 44 is 0.2066369205713272.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1998.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 968.0928955078125.\n",
      "The relative quantization error of layer 45 is 0.4362531006336212.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([3200, 1024])\n",
      "shape of quantized_layer_input: torch.Size([3200, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:01<00:00, 941.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 2213.98486328125.\n",
      "The relative quantization error of layer 46 is 0.46896880865097046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2568.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 428.9402770996094.\n",
      "The relative quantization error of layer 47 is 0.39763808250427246.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2505.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 108.9693374633789.\n",
      "The relative quantization error of layer 48 is 0.09824569523334503.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2021.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 533.310302734375.\n",
      "The relative quantization error of layer 49 is 0.6608641743659973.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 2048])\n",
      "shape of quantized_layer_input: torch.Size([832, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2422.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 506.0731201171875.\n",
      "The relative quantization error of layer 50 is 0.22988712787628174.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([192, 4608])\n",
      "shape of quantized_layer_input: torch.Size([192, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2469.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 76.79258728027344.\n",
      "The relative quantization error of layer 51 is 0.12739428877830505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([832, 512])\n",
      "shape of quantized_layer_input: torch.Size([832, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2004.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 110.79776000976562.\n",
      "The relative quantization error of layer 52 is 0.775634765625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2499.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 34.0487060546875.\n",
      "The relative quantization error of layer 53 is 0.19760474562644958.\n",
      "\n",
      "\n",
      "Time used for quantization: 0:00:53.604830\n",
      "\n",
      "\n",
      "Evaluting the original model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.88it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of efficientnet_b1 is 0.88.\n",
      "Top-5 accuracy of efficientnet_b1 is 0.978.\n",
      "\n",
      " Evaluting the quantized model to get its accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of quantized efficientnet_b1 is 0.767.\n",
      "Top-5 accuracy of quantized efficientnet_b1 is 0.968.\n",
      "\n",
      "Time used for evaluation: 0:00:04.779567\n",
      "\n",
      "Sparsity: Org: 0.0, Quant: 0.4539\n"
     ]
    }
   ],
   "source": [
    "sc_options = ['True'] * 7\n",
    "\n",
    "for sc_choice in sc_options:\n",
    "    os.system(f\"python main.py -model 'efficientnet_b1' -b 4 -bs 64 -s 1.16 -ds 'CIFAR100' -sn {subset_size} -sc '{sc_choice}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f8272c-a56d-4a86-9af2-02398d0359d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 79, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'spider', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.114634</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 52, 53, 85, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.024764</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>74.096380</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.987</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 81, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'streetcar', 'mountain',...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>71.164072</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.997</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.987</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 52, 53, 55, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>67.448789</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.968</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[68, 37, 69, 12, 76, 81, 17, 85, 89, 90]</td>\n",
       "      <td>['road', 'house', 'rocket', 'bridge', 'skyscra...</td>\n",
       "      <td>6.134069</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.738200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.921</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 77, 45, 79, 50, 51, 18, 26, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'snail', 'lobster', 'spid...</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.091850</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.891</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 67, 4, 72, 74, 29, 50, 55, 27, 93]</td>\n",
       "      <td>['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...</td>\n",
       "      <td>3.130085</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 69, 12, 76, 13, 81, 17, 85, 89, 90]</td>\n",
       "      <td>['house', 'rocket', 'bridge', 'skyscraper', 'b...</td>\n",
       "      <td>7.993174</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.750203</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 54, 57, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>5.336673</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>2.010920</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 23, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.701965</td>\n",
       "      <td>72.534661</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>73.389381</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 65, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'rabbit', 'keyboard', 'sea', 'mounta...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.157864</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 43, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'lion', 'mountain...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>72.530807</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 9, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bottle', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.841404</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 19, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'cattle', 'oak_tr...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.162383</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 60, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.692264</td>\n",
       "      <td>73.196192</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 35, 98, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'girl', 'woman', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.945</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[99, 7, 44, 45, 78, 79, 24, 26, 91, 29]</td>\n",
       "      <td>['worm', 'beetle', 'lizard', 'lobster', 'snake...</td>\n",
       "      <td>2.639629</td>\n",
       "      <td>0.069233</td>\n",
       "      <td>0.764570</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.977</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[40, 9, 10, 8, 16, 84, 22, 24, 28, 61]</td>\n",
       "      <td>['lamp', 'bottle', 'bowl', 'bicycle', 'can', '...</td>\n",
       "      <td>23.634743</td>\n",
       "      <td>0.211024</td>\n",
       "      <td>3.970792</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.982</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 40, 8, 9, 10, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'lamp', 'bicycle', 'bottle', 'bowl', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.953</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 8, 40, 9, 10, 16, 84, 22, 25, 28]</td>\n",
       "      <td>['bed', 'bicycle', 'lamp', 'bottle', 'bowl', '...</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>1.931516</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 38, 39, 71, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'kangaroo', 'keyboard', 'sea', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.796192</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.998</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 54, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>70.702394</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.997</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 80, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'squirrel', 'moun...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.325452</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 57, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>68.148521</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 77, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'snail', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>66.780730</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.946</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 45, 78, 79, 77, 51, 26, 91, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'lobster', 'snake', 'spid...</td>\n",
       "      <td>0.839073</td>\n",
       "      <td>0.069233</td>\n",
       "      <td>0.345852</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.977</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 41, 12, 13, 76, 48, 81, 85, 89, 90]</td>\n",
       "      <td>['house', 'lawn_mower', 'bridge', 'bus', 'skys...</td>\n",
       "      <td>5.125528</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.808591</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 71, 49, 52, 23, 56, 59, 60]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'sea', 'moun...</td>\n",
       "      <td>6.134205</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>2.298235</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 44, 45, 78, 79, 77, 51, 26, 91, 29]</td>\n",
       "      <td>['beetle', 'lizard', 'lobster', 'snake', 'spid...</td>\n",
       "      <td>0.839073</td>\n",
       "      <td>0.069233</td>\n",
       "      <td>0.345852</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.897</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 65, 66, 4, 38, 74, 15, 80, 50, 63]</td>\n",
       "      <td>['possum', 'rabbit', 'raccoon', 'beaver', 'kan...</td>\n",
       "      <td>1.423381</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.528430</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.938</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[99, 7, 44, 45, 78, 79, 77, 26, 91, 29]</td>\n",
       "      <td>['worm', 'beetle', 'lizard', 'lobster', 'snake...</td>\n",
       "      <td>2.524519</td>\n",
       "      <td>0.069233</td>\n",
       "      <td>0.516658</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.968</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[37, 69, 12, 76, 13, 17, 81, 85, 89, 90]</td>\n",
       "      <td>['house', 'rocket', 'bridge', 'skyscraper', 'b...</td>\n",
       "      <td>7.993174</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.750203</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Name   Dataset  Quantization Batch Size  \\\n",
       "0   efficientnet_b1  CIFAR100                       64   \n",
       "1   efficientnet_b1  CIFAR100                       64   \n",
       "2   efficientnet_b1  CIFAR100                       64   \n",
       "3   efficientnet_b1  CIFAR100                       64   \n",
       "4   efficientnet_b1  CIFAR100                       64   \n",
       "5   efficientnet_b1  CIFAR100                       64   \n",
       "6   efficientnet_b1  CIFAR100                       64   \n",
       "7   efficientnet_b1  CIFAR100                       64   \n",
       "8   efficientnet_b1  CIFAR100                       64   \n",
       "9   efficientnet_b1  CIFAR100                       64   \n",
       "10  efficientnet_b1  CIFAR100                       64   \n",
       "11  efficientnet_b1  CIFAR100                       64   \n",
       "12  efficientnet_b1  CIFAR100                       64   \n",
       "13  efficientnet_b1  CIFAR100                       64   \n",
       "14  efficientnet_b1  CIFAR100                       64   \n",
       "15  efficientnet_b1  CIFAR100                       64   \n",
       "16  efficientnet_b1  CIFAR100                       64   \n",
       "17  efficientnet_b1  CIFAR100                       64   \n",
       "18  efficientnet_b1  CIFAR100                       64   \n",
       "19  efficientnet_b1  CIFAR100                       64   \n",
       "20  efficientnet_b1  CIFAR100                       64   \n",
       "21  efficientnet_b1  CIFAR100                       64   \n",
       "22  efficientnet_b1  CIFAR100                       64   \n",
       "23  efficientnet_b1  CIFAR100                       64   \n",
       "24  efficientnet_b1  CIFAR100                       64   \n",
       "25  efficientnet_b1  CIFAR100                       64   \n",
       "26  efficientnet_b1  CIFAR100                       64   \n",
       "27  efficientnet_b1  CIFAR100                       64   \n",
       "28  efficientnet_b1  CIFAR100                       64   \n",
       "29  efficientnet_b1  CIFAR100                       64   \n",
       "30  efficientnet_b1  CIFAR100                       64   \n",
       "31  efficientnet_b1  CIFAR100                       64   \n",
       "32  efficientnet_b1  CIFAR100                       64   \n",
       "33  efficientnet_b1  CIFAR100                       64   \n",
       "34  efficientnet_b1  CIFAR100                       64   \n",
       "35  efficientnet_b1  CIFAR100                       64   \n",
       "36  efficientnet_b1  CIFAR100                       64   \n",
       "37  efficientnet_b1  CIFAR100                       64   \n",
       "38  efficientnet_b1  CIFAR100                       64   \n",
       "39  efficientnet_b1  CIFAR100                       64   \n",
       "40  efficientnet_b1  CIFAR100                       64   \n",
       "41  efficientnet_b1  CIFAR100                       64   \n",
       "\n",
       "    Original Top1 Accuracy  Quantized Top1 Accuracy  Original Top5 Accuracy  \\\n",
       "0                    0.877                    0.921                   0.988   \n",
       "1                    0.855                    0.951                   0.984   \n",
       "2                    0.880                    0.963                   0.989   \n",
       "3                    0.876                    0.954                   0.989   \n",
       "4                    0.866                    0.944                   0.989   \n",
       "5                    0.875                    0.928                   0.989   \n",
       "6                    0.856                    0.922                   0.986   \n",
       "7                    0.808                    0.725                   0.986   \n",
       "8                    0.890                    0.768                   0.984   \n",
       "9                    0.767                    0.678                   0.961   \n",
       "10                   0.815                    0.646                   0.949   \n",
       "11                   0.746                    0.562                   0.939   \n",
       "12                   0.880                    0.799                   0.978   \n",
       "13                   0.870                    0.736                   0.975   \n",
       "14                   0.878                    0.940                   0.989   \n",
       "15                   0.873                    0.935                   0.986   \n",
       "16                   0.875                    0.940                   0.988   \n",
       "17                   0.878                    0.939                   0.990   \n",
       "18                   0.886                    0.942                   0.990   \n",
       "19                   0.871                    0.940                   0.987   \n",
       "20                   0.883                    0.953                   0.990   \n",
       "21                   0.748                    0.624                   0.963   \n",
       "22                   0.821                    0.682                   0.952   \n",
       "23                   0.828                    0.768                   0.965   \n",
       "24                   0.808                    0.736                   0.986   \n",
       "25                   0.823                    0.742                   0.963   \n",
       "26                   0.830                    0.639                   0.952   \n",
       "27                   0.823                    0.758                   0.963   \n",
       "28                   0.866                    0.935                   0.985   \n",
       "29                   0.861                    0.906                   0.987   \n",
       "30                   0.881                    0.958                   0.989   \n",
       "31                   0.869                    0.936                   0.988   \n",
       "32                   0.875                    0.943                   0.989   \n",
       "33                   0.876                    0.938                   0.989   \n",
       "34                   0.862                    0.939                   0.986   \n",
       "35                   0.821                    0.697                   0.950   \n",
       "36                   0.883                    0.797                   0.978   \n",
       "37                   0.808                    0.728                   0.986   \n",
       "38                   0.821                    0.700                   0.950   \n",
       "39                   0.781                    0.562                   0.945   \n",
       "40                   0.821                    0.666                   0.952   \n",
       "41                   0.880                    0.767                   0.978   \n",
       "\n",
       "    Quantized Top5 Accuracy  Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  \\\n",
       "0                     0.989     4                 1.16                 1.16   \n",
       "1                     0.995     4                 1.16                 1.16   \n",
       "2                     0.996     4                 1.16                 1.16   \n",
       "3                     0.998     4                 1.16                 1.16   \n",
       "4                     0.987     4                 1.16                 1.16   \n",
       "5                     0.997     4                 1.16                 1.16   \n",
       "6                     0.987     4                 1.16                 1.16   \n",
       "7                     0.983     4                 1.16                 1.16   \n",
       "8                     0.968     4                 1.16                 1.16   \n",
       "9                     0.973     4                 1.16                 1.16   \n",
       "10                    0.921     4                 1.16                 1.16   \n",
       "11                    0.891     4                 1.16                 1.16   \n",
       "12                    0.984     4                 1.16                 1.16   \n",
       "13                    0.975     4                 1.16                 1.16   \n",
       "14                    0.996     4                 1.16                 1.16   \n",
       "15                    0.990     4                 1.16                 1.16   \n",
       "16                    0.992     4                 1.16                 1.16   \n",
       "17                    0.989     4                 1.16                 1.16   \n",
       "18                    0.990     4                 1.16                 1.16   \n",
       "19                    0.993     4                 1.16                 1.16   \n",
       "20                    0.995     4                 1.16                 1.16   \n",
       "21                    0.960     4                 1.16                 1.16   \n",
       "22                    0.945     4                 1.16                 1.16   \n",
       "23                    0.977     4                 1.16                 1.16   \n",
       "24                    0.982     4                 1.16                 1.16   \n",
       "25                    0.963     4                 1.16                 1.16   \n",
       "26                    0.931     4                 1.16                 1.16   \n",
       "27                    0.953     4                 1.16                 1.16   \n",
       "28                    0.991     4                 1.16                 1.16   \n",
       "29                    0.988     4                 1.16                 1.16   \n",
       "30                    0.998     4                 1.16                 1.16   \n",
       "31                    0.997     4                 1.16                 1.16   \n",
       "32                    0.994     4                 1.16                 1.16   \n",
       "33                    0.992     4                 1.16                 1.16   \n",
       "34                    0.995     4                 1.16                 1.16   \n",
       "35                    0.946     4                 1.16                 1.16   \n",
       "36                    0.977     4                 1.16                 1.16   \n",
       "37                    0.984     4                 1.16                 1.16   \n",
       "38                    0.937     4                 1.16                 1.16   \n",
       "39                    0.897     4                 1.16                 1.16   \n",
       "40                    0.938     4                 1.16                 1.16   \n",
       "41                    0.968     4                 1.16                 1.16   \n",
       "\n",
       "    ...  Seed                               Subset_Inds  \\\n",
       "0   ...     0   [0, 39, 71, 79, 49, 52, 53, 58, 61, 94]   \n",
       "1   ...     0   [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2   ...     0   [0, 39, 71, 52, 53, 85, 62, 58, 61, 94]   \n",
       "3   ...     0   [0, 39, 71, 49, 52, 53, 62, 58, 61, 94]   \n",
       "4   ...     0   [0, 39, 81, 49, 52, 53, 62, 58, 61, 94]   \n",
       "5   ...     0   [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "6   ...     0   [0, 39, 71, 52, 53, 55, 62, 58, 61, 94]   \n",
       "7   ...     0  [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "8   ...     0  [68, 37, 69, 12, 76, 81, 17, 85, 89, 90]   \n",
       "9   ...     0  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "10  ...     0   [7, 44, 77, 45, 79, 50, 51, 18, 26, 29]   \n",
       "11  ...     0   [65, 67, 4, 72, 74, 29, 50, 55, 27, 93]   \n",
       "12  ...     0  [37, 69, 12, 76, 13, 81, 17, 85, 89, 90]   \n",
       "13  ...     0    [1, 70, 6, 14, 82, 83, 54, 57, 92, 62]   \n",
       "14  ...     0   [0, 39, 49, 52, 53, 23, 62, 58, 61, 94]   \n",
       "15  ...     0   [0, 39, 49, 52, 53, 20, 62, 58, 61, 94]   \n",
       "16  ...     0   [0, 65, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "17  ...     0   [0, 39, 71, 43, 49, 52, 53, 58, 61, 94]   \n",
       "18  ...     0    [0, 39, 9, 49, 52, 53, 20, 62, 58, 94]   \n",
       "19  ...     0   [0, 39, 71, 19, 52, 53, 62, 58, 61, 94]   \n",
       "20  ...     0   [0, 39, 49, 52, 53, 20, 62, 58, 60, 94]   \n",
       "21  ...     0    [32, 2, 35, 98, 8, 11, 46, 48, 84, 25]   \n",
       "22  ...     0   [99, 7, 44, 45, 78, 79, 24, 26, 91, 29]   \n",
       "23  ...     0    [40, 9, 10, 8, 16, 84, 22, 24, 28, 61]   \n",
       "24  ...     0  [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "25  ...     0     [5, 40, 8, 9, 10, 16, 84, 22, 25, 28]   \n",
       "26  ...     0    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "27  ...     0     [5, 8, 40, 9, 10, 16, 84, 22, 25, 28]   \n",
       "28  ...     0   [0, 38, 39, 71, 52, 53, 62, 58, 61, 94]   \n",
       "29  ...     0   [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "30  ...     0   [0, 39, 71, 49, 52, 53, 54, 58, 61, 94]   \n",
       "31  ...     0   [0, 39, 71, 80, 49, 52, 53, 58, 61, 94]   \n",
       "32  ...     0   [0, 39, 71, 49, 52, 53, 57, 58, 61, 94]   \n",
       "33  ...     0   [0, 71, 39, 77, 49, 52, 53, 58, 61, 94]   \n",
       "34  ...     0   [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "35  ...     0   [7, 44, 45, 78, 79, 77, 51, 26, 91, 29]   \n",
       "36  ...     0  [37, 41, 12, 13, 76, 48, 81, 85, 89, 90]   \n",
       "37  ...     0  [96, 33, 68, 71, 49, 52, 23, 56, 59, 60]   \n",
       "38  ...     0   [7, 44, 45, 78, 79, 77, 51, 26, 91, 29]   \n",
       "39  ...     0   [64, 65, 66, 4, 38, 74, 15, 80, 50, 63]   \n",
       "40  ...     0   [99, 7, 44, 45, 78, 79, 77, 26, 91, 29]   \n",
       "41  ...     0  [37, 69, 12, 76, 13, 17, 81, 85, 89, 90]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'sea', 'spider', 'mounta...  192.253176  0.544018   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'keyboard', 'sea', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'keyboard', 'streetcar', 'mountain',...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "7   ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "8   ['road', 'house', 'rocket', 'bridge', 'skyscra...    6.134069  0.151836   \n",
       "9   ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "10  ['beetle', 'lizard', 'snail', 'lobster', 'spid...    0.969446  0.091850   \n",
       "11  ['rabbit', 'ray', 'beaver', 'seal', 'shrew', '...    3.130085  0.074397   \n",
       "12  ['house', 'rocket', 'bridge', 'skyscraper', 'b...    7.993174  0.151836   \n",
       "13  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    5.336673  0.060302   \n",
       "14  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.701965   \n",
       "15  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "16  ['apple', 'rabbit', 'keyboard', 'sea', 'mounta...  192.253176  0.544018   \n",
       "17  ['apple', 'keyboard', 'sea', 'lion', 'mountain...  192.253176  0.544018   \n",
       "18  ['apple', 'keyboard', 'bottle', 'mountain', 'o...  192.253176  0.844140   \n",
       "19  ['apple', 'keyboard', 'sea', 'cattle', 'oak_tr...  192.253176  0.844140   \n",
       "20  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.692264   \n",
       "21  ['flatfish', 'baby', 'girl', 'woman', 'bicycle...    3.379163  0.038153   \n",
       "22  ['worm', 'beetle', 'lizard', 'lobster', 'snake...    2.639629  0.069233   \n",
       "23  ['lamp', 'bottle', 'bowl', 'bicycle', 'can', '...   23.634743  0.211024   \n",
       "24  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "25  ['bed', 'lamp', 'bicycle', 'bottle', 'bowl', '...    6.644043  0.207834   \n",
       "26  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "27  ['bed', 'bicycle', 'lamp', 'bottle', 'bowl', '...    6.644043  0.207834   \n",
       "28  ['apple', 'kangaroo', 'keyboard', 'sea', 'oak_...  192.253176  0.844140   \n",
       "29  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "30  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "31  ['apple', 'keyboard', 'sea', 'squirrel', 'moun...  192.253176  0.544018   \n",
       "32  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "33  ['apple', 'sea', 'keyboard', 'snail', 'mountai...  192.253176  0.544018   \n",
       "34  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "35  ['beetle', 'lizard', 'lobster', 'snake', 'spid...    0.839073  0.069233   \n",
       "36  ['house', 'lawn_mower', 'bridge', 'bus', 'skys...    5.125528  0.151836   \n",
       "37  ['willow_tree', 'forest', 'road', 'sea', 'moun...    6.134205  0.197318   \n",
       "38  ['beetle', 'lizard', 'lobster', 'snake', 'spid...    0.839073  0.069233   \n",
       "39  ['possum', 'rabbit', 'raccoon', 'beaver', 'kan...    1.423381  0.111503   \n",
       "40  ['worm', 'beetle', 'lizard', 'lobster', 'snake...    2.524519  0.069233   \n",
       "41  ['house', 'rocket', 'bridge', 'skyscraper', 'b...    7.993174  0.151836   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   66.114634             False                    NaN                    NaN   \n",
       "1   67.727136             False                    NaN                    NaN   \n",
       "2   68.024764             False                    NaN                    NaN   \n",
       "3   74.096380             False                    NaN                    NaN   \n",
       "4   71.164072             False                    NaN                    NaN   \n",
       "5   68.148521             False                    NaN                    NaN   \n",
       "6   67.448789             False                    NaN                    NaN   \n",
       "7    2.298235             False                    NaN                    NaN   \n",
       "8    1.738200             False                    NaN                    NaN   \n",
       "9    1.950773             False                    NaN                    NaN   \n",
       "10   0.369210             False                    NaN                    NaN   \n",
       "11   0.949666             False                    NaN                    NaN   \n",
       "12   1.750203             False                    NaN                    NaN   \n",
       "13   2.010920             False                    NaN                    NaN   \n",
       "14  72.534661             False                    NaN                    NaN   \n",
       "15  73.389381             False                    NaN                    NaN   \n",
       "16  67.157864             False                    NaN                    NaN   \n",
       "17  72.530807             False                    NaN                    NaN   \n",
       "18  68.841404             False                    NaN                    NaN   \n",
       "19  69.162383             False                    NaN                    NaN   \n",
       "20  73.196192             False                    NaN                    NaN   \n",
       "21   1.501770             False                    NaN                    NaN   \n",
       "22   0.764570             False                    NaN                    NaN   \n",
       "23   3.970792             False                    NaN                    NaN   \n",
       "24   2.298235             False                    NaN                    NaN   \n",
       "25   1.931516             False                    NaN                    NaN   \n",
       "26   0.424285             False                    NaN                    NaN   \n",
       "27   1.931516             False                    NaN                    NaN   \n",
       "28  68.796192             False                    NaN                    NaN   \n",
       "29  69.604010             False                    NaN                    NaN   \n",
       "30  70.702394             False                    NaN                    NaN   \n",
       "31  68.325452             False                    NaN                    NaN   \n",
       "32  68.148521             False                    NaN                    NaN   \n",
       "33  66.780730             False                    NaN                    NaN   \n",
       "34  71.118622             False                    NaN                    NaN   \n",
       "35   0.345852             False                    NaN                    NaN   \n",
       "36   1.808591             False                    NaN                    NaN   \n",
       "37   2.298235             False                    NaN                    NaN   \n",
       "38   0.345852             False                    NaN                    NaN   \n",
       "39   0.528430             False                    NaN                    NaN   \n",
       "40   0.516658             False                    NaN                    NaN   \n",
       "41   1.750203             False                    NaN                    NaN   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "14        NaN  \n",
       "15        NaN  \n",
       "16        NaN  \n",
       "17        NaN  \n",
       "18        NaN  \n",
       "19        NaN  \n",
       "20        NaN  \n",
       "21        NaN  \n",
       "22        NaN  \n",
       "23        NaN  \n",
       "24        NaN  \n",
       "25        NaN  \n",
       "26        NaN  \n",
       "27        NaN  \n",
       "28        NaN  \n",
       "29        NaN  \n",
       "30        NaN  \n",
       "31        NaN  \n",
       "32        NaN  \n",
       "33        NaN  \n",
       "34        NaN  \n",
       "35        NaN  \n",
       "36        NaN  \n",
       "37        NaN  \n",
       "38        NaN  \n",
       "39        NaN  \n",
       "40        NaN  \n",
       "41        NaN  \n",
       "\n",
       "[42 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df = df[df[\"Classes Repeated\"] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03bc03e-1a1c-43ae-bc01-15060dca5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016ac336-3c7c-48d5-bf4a-8b4e6205ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26582a93-487a-4ce3-aba2-79b9c0f99bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.975 0.998]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.989 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.984 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.985 1.   ]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.973 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.988 0.999]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 79/79 [00:28<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] - Loss: 0.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] - Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] - Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 79/79 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Loss: 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 and Top-5 Accuracy after fine-tuning: [0.854 0.996]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   9%|▉         | 7/79 [00:02<00:26,  2.71it/s]"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "# from data_loaders import data_loader\n",
    "# from utils import test_accuracy, eval_sparsity, fusion_layers_inplace, get_all_layers\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 64\n",
    "\n",
    "# topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "\n",
    "#     model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "#     model.to(device)  \n",
    "#     train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset = subset)\n",
    "\n",
    "# # ===========\n",
    "# #  CODE HERE\n",
    "# # ===========\n",
    "\n",
    "#     model.eval() \n",
    "#     original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "\n",
    "#     # maxk = max(topk)\n",
    "#     # topk_count = np.zeros((len(topk), len(test_loader)))\n",
    "#     # correct_mat = []\n",
    "#     # for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     #     with torch.no_grad():\n",
    "#     #         y_pred = model(x_test.to(device))\n",
    "#     #     topk_pred = torch.topk(y_pred, maxk, dim=1).indices\n",
    "#     #     target = target.to(device).view(-1, 1).expand_as(topk_pred)\n",
    "#     #     correct_mat += [(target == topk_pred)]\n",
    "\n",
    "\n",
    "# # break    \n",
    "# # acc_items += [original_topk_accuracy]\n",
    "\n",
    "# # df.iloc[i, 4] = original_topk_accuracy[0]\n",
    "# # df.iloc[i, 6] = original_topk_accuracy[1]\n",
    "# # df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)\n",
    "\n",
    "# # print(df.iloc[i][\"Subset_Classes\"], original_topk_accuracy)\n",
    "\n",
    "\n",
    "import timm\n",
    "from data_loaders import data_loader\n",
    "from utils import test_accuracy\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 5  # Set the number of fine-tuning epochs\n",
    "learning_rate = 1e-4  # Fine-tuning learning rate\n",
    "topk = (1, 5)   # top-1 and top-5 accuracy\n",
    "\n",
    "acc_items = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = [stage.item() if hasattr(stage, \"item\") else stage for stage in subset_stage]\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=True)\n",
    "    model.to(device)  \n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader = data_loader(\"CIFAR100\", batch_size, 1, subset=subset)\n",
    "\n",
    "    # Define optimizer & loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate after fine-tuning\n",
    "    model.eval()\n",
    "    original_topk_accuracy = test_accuracy(model, test_loader, device, topk)\n",
    "    print(f\"Top-1 and Top-5 Accuracy after fine-tuning: {original_topk_accuracy}\")\n",
    "\n",
    "    acc_items += [original_topk_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e564bcc8-8a12-4965-9e9c-79909c3b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the printed output as input for raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63c97c08-e8f2-4e8a-ba26-12b49693d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1726c059-fe07-4ee0-9236-bb67aba13d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# extracted = re.findall(r\"\\[[01]{1}.[0-9 ]{3} [01]{1}.[0-9 ]{3}\\]\", raw_text)\n",
    "extracted = re.findall(r\"Top-1 and Top-5 Accuracy after fine-tuning:\\s*(\\[[^\\]]+\\])\", raw_text)\n",
    "# data = list(map(lambda x: [float(x[1:6]), float(x[7:12])], extracted))\n",
    "data = [list(map(float, s.strip(\"[]\").split())) for s in extracted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "370887c8-4003-449d-93ff-700942aa2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[0.981 0.999]',\n",
       "  '[0.98  0.998]',\n",
       "  '[0.981 1.   ]',\n",
       "  '[0.979 0.999]',\n",
       "  '[0.983 0.997]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.979 1.   ]',\n",
       "  '[0.8   0.984]',\n",
       "  '[0.896 0.99 ]',\n",
       "  '[0.9   0.992]',\n",
       "  '[0.84  0.992]',\n",
       "  '[0.915 0.994]',\n",
       "  '[0.889 0.987]',\n",
       "  '[0.901 0.992]'],\n",
       " 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1879a6f-3f42-4c8f-bef8-b7a537282650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Trained Top1 Accuracy\", \"Trained Top5 Accuracy\"]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d20aacbe-ec3d-4a21-a92d-82bb75e69a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61737c13-e5ec-41b1-a0e0-b1d055afaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_mat_1 = torch.vstack(correct_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "699e2710-5b15-4307-aba1-144e15465bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes = []\n",
    "# for j, (x_test, target) in enumerate(tqdm(test_loader)):\n",
    "#     classes += [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92dbbe93-1086-43e6-9ef7-55be8644bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = torch.cat(classes).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed018779-776b-43df-8844-5447092a5dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_topk(correct_mat, classes, subset, topk = (1, 5)):\n",
    "#     topk_count = []\n",
    "#     filtered = correct_mat[np.isin(classes, subset)]\n",
    "#     for i, k in enumerate(topk):\n",
    "#         topk_count += [filtered[:, :k].reshape(-1).sum().item()]\n",
    "#     return np.array(topk_count) / filtered.shape[0]\n",
    "\n",
    "# acc_items = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "#     subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "#     if len(subset_stage) > 10:\n",
    "#         subset_stage = subset_stage[1:][::2]\n",
    "#     subset = []\n",
    "#     for j in range(len(subset_stage)):\n",
    "#         try:\n",
    "#             subset += [subset_stage[j].item()]\n",
    "#         except:\n",
    "#             subset += [subset_stage[j]]\n",
    "    \n",
    "#     acc_items += [get_topk(correct_mat_1.numpy(), classes, subset)]\n",
    "\n",
    "# acc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e68e1e22-86e9-4260-a7b3-70467e8d4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, [3, 5]] = np.vstack(acc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37482453-c670-4927-9380-0612eef4e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd0bad72-0960-4feb-a6bd-859b2d18b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import dist_matrix\n",
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "\n",
    "# G = nx.from_numpy_array(dist_matrix)\n",
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa2b9e10-57f2-462e-8f96-5df897ffd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import community \n",
    "# partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae727e7e-c5e5-4627-bb52-ca17fdbd41c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dfe0db6-01b1-4965-a589-ce94866dd132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from cifar100_subset_generation import class_names\n",
    "\n",
    "# grps = {}\n",
    "\n",
    "# for k,v in partition.items():\n",
    "#     if v not in grps:\n",
    "#         grps[v] = []\n",
    "#     grps[v] += [class_names[k].item()]\n",
    "\n",
    "# grps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e2b417d-386d-4233-80bd-e097adec7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100_subset_generation import dist_matrix, class_names\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "KL_data_all = []\n",
    "# new_col = []\n",
    "median = []\n",
    "for i in range(df.shape[0]):\n",
    "    subset_stage = df.iloc[i][\"Subset_Inds\"]\n",
    "    subset_stage = list(map(lambda x: int(x), re.findall(r\"[0-9]+\", subset_stage)))\n",
    "    if len(subset_stage) > 10:\n",
    "        subset_stage = subset_stage[1:][::2]\n",
    "    subset = []\n",
    "    for j in range(len(subset_stage)):\n",
    "        try:\n",
    "            subset += [subset_stage[j].item()]\n",
    "        except:\n",
    "            subset += [subset_stage[j]]\n",
    "    \n",
    "    # print(list(map(lambda x: class_names[x].item(), subset))))\n",
    "\n",
    "    # new_col += [len(subset) != len(set(subset))]\n",
    "    \n",
    "    KL_data = []\n",
    "    for j in combinations(set(subset), 2):\n",
    "        KL_data += [dist_matrix[j[0], j[1]].item()]\n",
    "\n",
    "    KL_data_all += [KL_data]\n",
    "\n",
    "    median += [np.median(KL_data).item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a011a4a-a284-4b40-b242-a757a73bfc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.995</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 74, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'shrew', 'mountai...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.727136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 34, 39, 71, 49, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'fox', 'keyboard', 'sea', 'mountain'...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.281856</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.999</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 71, 39, 52, 53, 20, 24, 62, 58, 94]</td>\n",
       "      <td>['apple', 'sea', 'keyboard', 'oak_tree', 'oran...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>66.670358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.997</td>\n",
       "      <td>46.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 18, 52, 53, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'cate...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>67.253203</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>49.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 58, 92, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>71.118622</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.747142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[32, 2, 98, 35, 8, 11, 46, 48, 84, 25]</td>\n",
       "      <td>['flatfish', 'baby', 'woman', 'girl', 'bicycle...</td>\n",
       "      <td>3.379163</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>1.501770</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.522912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[90, 37, 12, 13, 76, 81, 17, 85, 89, 58]</td>\n",
       "      <td>['train', 'house', 'bridge', 'bus', 'skyscrape...</td>\n",
       "      <td>6.824865</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>1.885359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.417347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[96, 33, 68, 27, 72, 75, 47, 55, 56, 59]</td>\n",
       "      <td>['willow_tree', 'forest', 'road', 'crocodile',...</td>\n",
       "      <td>7.107001</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>1.950773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 70, 6, 14, 82, 83, 18, 54, 92, 62]</td>\n",
       "      <td>['aquarium_fish', 'rose', 'bee', 'butterfly', ...</td>\n",
       "      <td>6.051048</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>1.929774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[64, 97, 34, 66, 38, 42, 43, 80, 88, 63]</td>\n",
       "      <td>['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...</td>\n",
       "      <td>2.287704</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.793771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 7, 44, 77, 14, 79, 45, 18, 51, 26]</td>\n",
       "      <td>['bee', 'beetle', 'lizard', 'snail', 'butterfl...</td>\n",
       "      <td>1.023288</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.378134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0       vgg16  CIFAR100                       64                   0.887   \n",
       "1       vgg16  CIFAR100                       64                   0.855   \n",
       "2       vgg16  CIFAR100                       64                   0.882   \n",
       "3       vgg16  CIFAR100                       64                   0.862   \n",
       "4       vgg16  CIFAR100                       64                   0.886   \n",
       "5       vgg16  CIFAR100                       64                   0.874   \n",
       "6       vgg16  CIFAR100                       64                   0.862   \n",
       "7       vgg16  CIFAR100                       64                   0.748   \n",
       "8       vgg16  CIFAR100                       64                   0.869   \n",
       "9       vgg16  CIFAR100                       64                   0.884   \n",
       "10      vgg16  CIFAR100                       64                   0.767   \n",
       "11      vgg16  CIFAR100                       64                   0.869   \n",
       "12      vgg16  CIFAR100                       64                   0.823   \n",
       "13      vgg16  CIFAR100                       64                   0.830   \n",
       "\n",
       "    Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                     0.944                   0.989                    0.991   \n",
       "1                     0.951                   0.984                    0.995   \n",
       "2                     0.946                   0.990                    0.996   \n",
       "3                     0.930                   0.986                    0.993   \n",
       "4                     0.947                   0.990                    0.993   \n",
       "5                     0.948                   0.987                    0.991   \n",
       "6                     0.953                   0.986                    0.996   \n",
       "7                     0.612                   0.963                    0.969   \n",
       "8                     0.703                   0.973                    0.972   \n",
       "9                     0.759                   0.981                    0.973   \n",
       "10                    0.685                   0.961                    0.973   \n",
       "11                    0.730                   0.973                    0.973   \n",
       "12                    0.645                   0.955                    0.931   \n",
       "13                    0.640                   0.952                    0.932   \n",
       "\n",
       "    Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0      4                 1.16                 1.16  ...     0   \n",
       "1      4                 1.16                 1.16  ...     0   \n",
       "2      4                 1.16                 1.16  ...     0   \n",
       "3      4                 1.16                 1.16  ...     0   \n",
       "4      4                 1.16                 1.16  ...     0   \n",
       "5      4                 1.16                 1.16  ...     0   \n",
       "6      4                 1.16                 1.16  ...     0   \n",
       "7      4                 1.16                 1.16  ...     0   \n",
       "8      4                 1.16                 1.16  ...     0   \n",
       "9      4                 1.16                 1.16  ...     0   \n",
       "10     4                 1.16                 1.16  ...     0   \n",
       "11     4                 1.16                 1.16  ...     0   \n",
       "12     4                 1.16                 1.16  ...     0   \n",
       "13     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                                 Subset_Inds  \\\n",
       "0    [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1    [0, 39, 71, 74, 49, 52, 53, 58, 61, 94]   \n",
       "2    [0, 34, 39, 71, 49, 52, 53, 58, 61, 94]   \n",
       "3    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "4    [0, 71, 39, 52, 53, 20, 24, 62, 58, 94]   \n",
       "5    [0, 39, 71, 49, 18, 52, 53, 58, 61, 94]   \n",
       "6    [0, 39, 71, 49, 52, 53, 58, 92, 61, 94]   \n",
       "7     [32, 2, 98, 35, 8, 11, 46, 48, 84, 25]   \n",
       "8     [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "9   [90, 37, 12, 13, 76, 81, 17, 85, 89, 58]   \n",
       "10  [96, 33, 68, 27, 72, 75, 47, 55, 56, 59]   \n",
       "11    [1, 70, 6, 14, 82, 83, 18, 54, 92, 62]   \n",
       "12  [64, 97, 34, 66, 38, 42, 43, 80, 88, 63]   \n",
       "13    [6, 7, 44, 77, 14, 79, 45, 18, 51, 26]   \n",
       "\n",
       "                                       Subset_Classes      Max_KL    Min_KL  \\\n",
       "0   ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1   ['apple', 'keyboard', 'sea', 'shrew', 'mountai...  192.253176  0.544018   \n",
       "2   ['apple', 'fox', 'keyboard', 'sea', 'mountain'...  192.253176  0.544018   \n",
       "3   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "4   ['apple', 'sea', 'keyboard', 'oak_tree', 'oran...  192.253176  0.844140   \n",
       "5   ['apple', 'keyboard', 'sea', 'mountain', 'cate...  192.253176  0.544018   \n",
       "6   ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "7   ['flatfish', 'baby', 'woman', 'girl', 'bicycle...    3.379163  0.038153   \n",
       "8   ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "9   ['train', 'house', 'bridge', 'bus', 'skyscrape...    6.824865  0.151836   \n",
       "10  ['willow_tree', 'forest', 'road', 'crocodile',...    7.107001  0.074397   \n",
       "11  ['aquarium_fish', 'rose', 'bee', 'butterfly', ...    6.051048  0.060302   \n",
       "12  ['possum', 'wolf', 'fox', 'raccoon', 'kangaroo...    2.287704  0.111503   \n",
       "13  ['bee', 'beetle', 'lizard', 'snail', 'butterfl...    1.023288  0.060302   \n",
       "\n",
       "       Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0   68.940139             False                  0.981                  0.999   \n",
       "1   67.727136             False                  0.980                  0.998   \n",
       "2   71.281856             False                  0.981                  1.000   \n",
       "3   71.118622             False                  0.979                  0.999   \n",
       "4   66.670358             False                  0.983                  0.997   \n",
       "5   67.253203             False                  0.979                  1.000   \n",
       "6   71.118622             False                  0.979                  1.000   \n",
       "7    1.501770             False                  0.800                  0.984   \n",
       "8    1.929774             False                  0.896                  0.990   \n",
       "9    1.885359             False                  0.900                  0.992   \n",
       "10   1.950773             False                  0.840                  0.992   \n",
       "11   1.929774             False                  0.915                  0.994   \n",
       "12   0.773437             False                  0.889                  0.987   \n",
       "13   0.424285             False                  0.901                  0.992   \n",
       "\n",
       "    Median_KL  \n",
       "0   66.980437  \n",
       "1   49.097501  \n",
       "2   60.747142  \n",
       "3   60.747142  \n",
       "4   46.604676  \n",
       "5   49.097501  \n",
       "6   60.747142  \n",
       "7    1.522912  \n",
       "8    1.549429  \n",
       "9    1.417347  \n",
       "10   1.666552  \n",
       "11   1.549429  \n",
       "12   0.793771  \n",
       "13   0.378134  \n",
       "\n",
       "[14 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Median_KL\"] = median\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dd02952-818a-4588-bfaa-bbfce9e4d30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAMtCAYAAAB6kCstAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2iElEQVR4nO3de3gU9d3+8TtnkkCCEAgBYohBCRIqkiCEMyrpQwtKlYJiqQfUhx/VioAtSH0UxKYiItgKBQtFUAutIrUUD1EhchQJUKNCMJwPgRAEciRsNvv7I2ZrzIHky2Z2k7xf15WLZHZm9jOfHTZ7Z2a+4+VwOBwCAAAAANSJt7sLAAAAAICGiDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABgwNfdBViptLRUJ0+eVIsWLeTl5eXucgAAAAC4icPhUF5entq3by9vb7NjTE0qTJ08eVKRkZHuLgMAAACAhzh27Jg6duxotGyTClMtWrSQVNawkJAQt9Zis9n04YcfKikpSX5+fm6tpbGj19ai39ai39ah19ai39ah19ai39aqqd+5ubmKjIx0ZgQTTSpMlZ/aFxIS4hFhKigoSCEhIfxHqmf02lr021r02zr02lr02zr02lr021q16feVXP7DABQAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYKBJ3WcK+KFDOQUqKC5xdxmNSklJiY7lS1+dzJWvL28x9Y1+W6cx9Do4wFfRYcHuLgMAGo2G+dsAcIFDOQUaMneju8topHw1N327u4uoxMs3V34tP5PtfG85Stx7427X8sx+N04Nv9cbpg4mUAGAixCm0GSVH5GaP6aHOrdt7uZqGo+SkhJt3rxZ/fv397i/3h/KzdCTO36vF386VtEhXdxdjkt4cr8bm4be68zsfE1avYej8QDgQg3vtwHgYp3bNldch1B3l9Fo2Gw2HWkudWsfIj8/P3eXU4F3s7LQHNO2ua5v3Thec0/ud2NDrwEAP0SYQpOQXVT5OofM7PwK/8I1PPm6kkO5Za/1gex8lV684OZqXMOT+93YNLRec30UANQ/z/9t0MgVFhbqwIEDio2NVVBQkLvLaZQOny3Qc3t8pT1VX+cwafUeawtqhCpfi+SZ15V4Nzuh4GjpsdV7VHrxjLvLcSHP7Hfj1LB6zfVRADxJYWGh9u3b16g+9xKm3CwjI0O9e/dWWlqaevbs6e5yGqWCYrskae6o7oqN+O+pXeXXD3DN1JX7/rVIkUExHntdSVmd0oIxPbhmCnXWkHrN9VEAPNG+ffsUHx/fqD73evZvA8CFOrcJrvLaKK6ZunLfvxbp2pAQj72uhGumcCXoNQDgh4xu2rtw4UJFR0erWbNmio+P16ZNm2qc/5VXXlHXrl0VGBioLl26aMWKFRUeX758uby8vCp9Xbx40TnPokWL9KMf/UghISEKCQlRYmKi3nvvPZPyAQAAAOCK1fnI1OrVqzVp0iQtXLhQ/fr10+LFizVs2DB9/fXXuvrqqyvNv2jRIk2fPl2vvvqqevXqpR07duihhx7SVVddpREjRjjnCwkJUUZGRoVlmzVr5vy+Y8eO+sMf/qDOnTtLkl577TXdfvvt2r17t7p161bXzQAAAACAK1LnMDVv3jyNHz9eDz74oCRp/vz5+uCDD7Ro0SIlJydXmn/lypX63//9X40ZM0aSdM0112j79u16/vnnK4QpLy8vtWvXrtrn/f68kvTcc89p0aJF2r59e4MOU0VFRRX+BQAAABqjxvi5t05h6tKlS0pLS9O0adMqTE9KStLWrVurXKa4uLjCESZJCgwM1I4dO2Sz2Zznnefn5ysqKkp2u109evTQs88+qxtvvLHKddrtdv3jH/9QQUGBEhMTq623uLhYxcXFzp9zc3MllZ33brPZLr/B9aj8+ffuz5Qkfbo7Q8EdY91ZUoNx8kKRii6V1nr+I2fzJEmf7DulA2cKnNOPnyv7j5x+7JxKSrhI+0oczisbZnx/1gUVnv9Wx/Kl/xz91uMu0v9+nZfyz7q5GtcoH67bE/vd2DSkXpe/15WUlDh/3xQUlf0+zMi60CDe8xpSvxs6em2tptzvT3eXnYW2d3+mbrrpJkues/w9sKrP/q7IA3V6BXNycmS327VlyxZNnjxZWVlZ6tatm+Lj43Xq1Kkql/nxj3+sl19+Wa+//rqysrIUHh6u8+fPy2azKScnRxERETpw4IDsdruOHj0qSTpx4oT+/e9/Kz09XXFxcZKkTz/9VE899ZQ2bdokh8OhoKAgvfPOO7r++uurrTc5OVkzZ86sNP3DDz/0mOEYt6d/I0l6eWeeFh9vOMPtNkQvbzhc5fTpa7+ytpBGyCd4v4Kulqa8s132gm8l+UrpO91dViXlQ6NPfitdpRe/dXc5LuSZ/W6cGlav//XxZh1pXfb9zjOS5Kspb6W7s6Q6alj9btjotbWaZr+LT5X9gXvz7r1q02q9pc+dkpJSaVphYeEVr9coDs+fP19//vOfnddMLVy4sMrrpSQpPDxchYWFKigo+ytZXl6e89Cej4+PJCkmJqbCNVOlpaVKSkrSkiVL9PLLL0uSCgoK1LdvX40ePVqPPPKI/ud//kf33nuvUlNTqw1U06dP1+TJk50/5+bmKjIyUklJSQoJCTHZdJex2WxKSUlRn+7X6jVJv05ooWEj+ri1pobgwJkCTXkrXZNu6azIqwJ1Jv+iim2OGpfJulCgVTuzdFdChCJC/3u/ldO5F/Xm58f1yOBruA/LFfrifI7WnJB+kdhK3Vp0VXp6urp37y4fH8/6i9vJokAtOSg9fktntQ/s7O5yXMJuL/HYfjc2VvU60N9b7UMDr2gdqftz9NLHmbr+RzfqJzdESJLaHTmnlZmf68VR3RXTxvPf80pKSrR9+3b16dOnyf313mr02lpNud/v/eu0nnxN6n9jV/3kJz+x5DnLP3MPHTq00kis5WetXYk6vYJhYWGSpFtvvbXCNVMrVqzQpUuXqlymfMCK3//+9zp9+rQiIiI0dOhQffrpp871SZWvmUpMTNQ333zj/HnYsGEaNmyYJOmRRx7RuHHjdOHCBS1YsECLFy+u8rkDAgIUEBBQabqfn5/HDGsbFFBWx9VXBahHVGs3V+P5yt90br2+nYIDfDVk7sZaL7tqZ1aV0/+08aArSmu0Kt+QtzLfkGMK7CC9seOYSnL3SvKVMvdaW2gtlB+ZeunjTJVebDzna3tqvxsna3p9pTfbPfxt2Wi4Pj4+zt93wYFlvw+7RIQ2iNtB2Gw2nfhSuuHqVh7zO7uxotfWasr9/uqqsvehQH9fy7e9qs//rqih3uNw+TVTfn5+6tixoyQpMzNTpaWlstvt8vYuG539+9dM3XDDDTp8+LB69+5d47odDkeFa6Kqem5Pv2aqsLgshB7JydOeI43jGo76VH4dQEbWBee0x2/prI5XVf9X3CNn8/TyhsOaPaKL4jpeVWFdU95KN/orbV2v22rIThZlasnBj/Vo79uqPZpTfmTqnpsiOTJlMY5MWceKXh8/V6SXPs7UrsNndaHg4uUXqEbm6bL3yCM5+c7fLd9//+SaKXwfvbZWU+73kZyy0/yKiq37LO5x10xJ0scff6xly5YpMTFRS5YsUUFBgVq2bCmp7NS6EydOOO8llZCQoD/+8Y/q2bOn2rdvr6eeekrHjx+Xw+FwXjNVfg3WoEGDdPr0ac2aNUtHjhypcL3Tk08+qWHDhikyMlKS9Prrr2vjxo16//33q623IVwztWnHfyRJL36wV0uyuGaqtr5/zv9LH2fWapmMvV+pRc5/f87KlyRfZWXslu+J2j93dpH03J6m8+ZXm6M5DeXIVPm1XfM3/kf2Ao5MwYQ1vXbVdU0vfZxZ6T2Sa6ZQNXptrabZ77wvyt4/N2xLU5vWV11mbtfyqGumHnvsMc2aNUtZWVmKi4vTuHHjtHnzZklSVlaWcyAJSZowYYLeeust3XHHHZLK7h31wAMPaOnSpc5rppo3b67Vq1drwYIFCg0NVY8ePeTn56dPP/1Uo0aNkiSdPn1a48aNU1ZW2ala33zzjd5//30NHTq02jobwjVTUeEtJUl3XR+sh/4f10xdzvePJkmq1ZGl/acu6Dfv7NX/DOilm65p45z+1clczU3frv79+6tb+9rvD1+dzJX2bNfcUd3VuQFcd3ClDuft11Np0rxR3dWpxXVVzrP1dJ4W7ZUm39pZN7VO8NhzwcvrnPLjCPUNbxz/35ryufdWs6LXV3LE/Pve3HFMf087obG9Omp0QkeXrtsq7NvWodfWasr9fvWPW7TwPema9q2b7jVTPj4+ys3NlZeXl7y8vCRJ58+fV3h4uCRp+fLlFZa58cYbNWvWLP3xj3/U4cOHdfXVV8tms6lFixbOa6ZeeuklvfTSS5KkVatW6e6771ZUVFSFa6YWL16sZ555Rm+88YYOHz6s06dPa9u2bbrlllucpwr+UEO4Zio6qmzgjtZBvrquTaDHHDHzVOVvOl0i/nu+f23P/w9uFlDhdS9fl69v3c7bLV8utoFcd3Cl/M+WbeN1EaG6vnXV1/UdtzeXJF0d1lw3RLby2HPBv19nY7lGsSmfe281K3r9/fe4K3l/2ZRZNlplRMsg577uqnVbhX3bOvTaWk2533ExZWeYtW8X3jSvmfL391enTp20dOlSLV682Dma38svv6wJEyZUucyiRYs0ffp0vfrqq+rVq5d27NihX/ziF+rXr1+lEHTkyBFNnTpVAwYMUHp6uiIiIpyPPf/88/rzn/+s1157TcOHD9cvf/lLvfDCCwoNDdVjjz1msOmeoTzsPfvssxo5cqR69uzp5ooahszs/Cq/r0r5dQIHzhRU+AtQ+XKXW766567rcg3Vodyy7TyQna/SixeqnOf4t0XOf7/yydWx/LIjeJ72F7fv1/llQNXb0tCUn3vvif1ubKzotaveX07nXnT+++WJCy5dd3CALyOgAjBy9uzZCv82Bsa/DcqDUPnRqXI/vGbq1Vdf1YABA9SzZ0/l5ORo7dq18vX1rXCO4syZM9WrVy/93//9n8aPH68333xTFy5cqBDQNm3apP79+6tDhw6SpIiICN10001KTU1t0GGqulEQUbUT58s+DE9avcc57fvf16S66wRqu7yrlmtoyq+Zemz1HpVePFPlPL4hGQrsIM39MEMluUGSfDU33fOuAfx+nX/Ide1R4NqMelh/PLPfjZM1vXbV+8vrnx3V658drTDNFeu+0tEGATRNNQ0G0VDVKUxdunRJhw8fVmJioh5++GHZ7XYFBgZq4MCB+uqrshuf/vCaqeLiYm3atEldunSRw+FQcHCwEhMTtWXLFtlsNvn5+en8+fO6++67lZeXp/379ysvL0+tW7eucGfkLVu2KD8/X//85z8lyXkt1PePXv1QQxjN79CRY5Ik31Ydtf9MkbwZ0a9G+06W/YX1V4Ov0TVhwXW6ZmrOz7rqunb/PbXl66xcPbn2a/1q0DW6pg7XD5SPtnW5UQQbi9qMgNdQRvP7fp0/atndpeuuzaiH9YHR/Kxj5Wh+V/r+8v6XWUrZl6PE6KvU55qy0/xO513UmzuOX9G6j50r0nwXjDZYG015xDOr0WtrNeV+Z5w6L0k6eSq76Y7mZ7fbtX379ko37S0fZe+H10xFRkZq7969eu655zR69GitWrVKTz31VIXR/EaNGqV//OMf2rhxo0aMGKHAwMBKpwAeOHBAzz77rF555RX5+PjIbrfL4XDozTffrLbehjCa35GzZadbhI2Yqmkbzksb+OtybRzK3K/As1JtRuPL/m7UvuzMdAWc+u/0L057SfLRK6lm95mq7SiCDV3jGs3vWwVdLb2+7VvZC1w7opl772Hlmf1unKzptaveX7YdOqdth865fN3WjQjYNEc8cw96ba2m2e/i4mskSSdyL2n9+vWWPrdHjebXrVs3Pffcc8rKylK3bt0UFBSk8+fPVznvuXPn1K5dOz355JN68skn5ePjo6ioKB0+fFg+Pj7Ky8vTL37xC/35z3/Wo48+qp/+9KdasmRJpYEjPvnkE7399tvq27ev0tPTlZdXNk79xo0bNXjw4Cqfe/Lkyc6bC0tSXl6err/+eg0ZMsTto/mVlJRow4YN6ntDrN6QlPOvuXru5b+oU+dr3VqXp9t17LxW7cxS1DXXqG3rYCl9r25M6KUbI1tWu8wXx89L6buV0KuXftTxv/MlFF7S9ftyFB0WpEA/n1rXcDCnwHmk65omcJrL4fxQzdwjzfnZ9erUvOr9c1v2BS3ZLz025Br1an2jdn7+uRJ69ZKvT+37aoWybVmm52/rVe22XNm6a+5TfSix2z22342NFb3edypPv/tXhn49pJM6tjQ/MvXB19n6OOOs+nRqqZuiWzqnB/j6qE1zf+P1Hj9fpJc3HL7i+mrDbi/V119/peuv7yYfn6oHmoJr0GtrNeV+r/3b5/qbpLhrOtQ4IrcrlX/mHjJkSKUjgZaP5lceQL788ssKA1Ds3r1bzZs3r3KZrKwsnT17Vq+//ro6deqkI0eOaNy4cZKk0NBQ7d27V4cPH9Ztt90mqex0PqnsFD1fX19lZGQoJiZGU6ZMUXFxsa699lo9//zzGjFihKKjo7Vy5Uo988wzVT73vHnzqjwytWHDBo85MpWZUfYXzpJvj+ullH0KSPf8Gyl6gkWf/vdU0vc3fa6cNtXPe+y7I1M7P/9cp3/wB+VQSd/W8czK6o50NVZnSk6W/ZuZLj/fqpt1rrjsL93njmXqdHawIptLp/d+blmNtVWbbfHEdV+Op/a7MarvXmeckSRfvbzhsEvWt/3weW0/fN4l6/o+V9V3eb5SZoZFz9XU0WtrNc1+5x8oOyPry/0HqzxSVJ82bNhQaZrlR6bK01tUVJTziM/8+fP1pz/9qdpzDktLS+Xn56fY2Fj17NmzwhGnb7/9VrGxsVqxYoWmTp2qtm3b6uc//7mef/55lZSUKC0tzXn64LfffqsOHTror3/9q/7+978rNzdXSUlJevvtt6uttyHcZyouLs457dcJLTRsROO49019Sd2fU+F6gilvpWv44ET1jKr+xm//OfqtlL5Tffr00Q1Xt7riGkzvT9VQ7f12rxa+v1D9+vdT11Zdq57pkPSPbf/QDT1u0NCOQ6u9n4O71WpbPHDdNanp/hlwLSt63e7IOa3M/PyK7wX1953H9ebnxyvcZ8oVrLxXVVO+F4/V6LW1mnK/k2f9W3+X1L5V86Z5n6nykeeOHj2qZcuWKTExUUuWLJHD4ZDD4ZBUeTS/Fi1ayMfHR71795bD4ZC/v7+8vb1VWlqq0tJS2Ww2/d///Z9uueUWFRUV6f/+7/80d+5c2e32CkEjICBAp0+fVv/+/fXZZ5/J399ff/rTnzRx4sQrboI7XbKXuruEBu/4+YsK8Kv+P8PeU2WnhH6074yOnCuudr5aP9+5suth9mblXfG6GoLDeWVDyx88U6DSi1X3uXyUxRPni/S1T56O5UtfZ+V53C+J2myLJ667JuUXMntivxsbK3p9/LxrBnUoKXW4ZD0A4FIl5WdgNZ73KC9HeQqqhcOHDys6Olrdu3fX119/7RzNLzw8XKdPn1ZhYaHuu+8+HT58WBs3bpQkPfzww1q6dKkzcAUGBsput+vSpUs6fvy4zpw5oxtvvFGS5OPjI4fDodLSUufP5af5BQQEOJ8vP7/sEKGXl5f+8pe/6IEHHqiy3meeeabK0/zefPNNjznNb80HqVqxqOyGxe3una+AdtaNAgbURtnACn9UwaFHVXqxQ5Xz+ATvV9DVy1R49AHZC66zuMLaq822eOK6AQBoDM5vXaULm17XgKHDNeVXD15+gXpWWFiosWPH6sKFC8ZnrdX5pr1S2TVTS5YscV4ztWDBArVs2VJS5dH8unXrJm9vb+eRq2bNmjkHq/Dz81OHDh3Uvn17/e53v1NMTIzGjRvnfPz7p/k5HA7ddNNN6tatm/7617/q+uuvl7e3t1599dVqw1RDOM0v8cbrteK7aZzmd3lVneZ3udNNvs0v0qpPdmlAz+sVFGB+4XW58qGLk0d2U9eIFle8Pk93OG+/nkqT5o3qrk4tqg5Kh/Na6am0ZXrxZ33UMfAajz19oTbb4onrrklTPl3Ealb02lWn0X20N1t/2nhQj9/SWYOuC/O4+mqDfds69NpaTbnfyVn/1N83SddFt2+ap/mFhf33DfmHN+0NDCwb1eeHp/ktX75cSUlJeuGFF3TgwAG9/vrrWrNmjUpLSxUWFqYvvvhCJ0+e1KOPPiq73e48BVCSevTo4TwyFRERoc6dO2v58uUaNWqUTp06JW9vb2VkVH/xXkBAQKVRAaWyEOcp1xZc3+W/H7quvipAPaJau7Eaz3f427JTYKLCmqtz27JBT7pEhCquQ2i1y9hsNuVlOvSTm6Jc8rp/eeKCXvo4U90jr6rxeRsL/7Nl23hdRKiub131/vn9ea4NaaUTX0o3XN3KY/6flavNtnjiumtis9k8tt+NjRW9Lv9gdbn3tcv5/nulK3+vuKq+2mDftg69tlZT7neXqHaSpPbh4ZZve1Wf/11Rg1Ecjo2N1axZs5SVlaW4uDg1b97c+QZb1U1709LSlJCQID8/Pw0ZMkRhYWE6ffq07Ha7YmNjlZ6erldeeUX79+/XggUL1Lt370oDUPTr10/vvvuuSkpKNGvWLD388MM6d+6coqKiqq2zIdy01+d7w+seycnTHm7aW6MjOWWneBYVX1LJd+fdlpSU1Ph6uvpu27V93saiNttb1Tye2Jv6fO3ctV94cr8bGyt67ar9yG63O/91Zb0FRWW/UzOyLjhrrS9N+camVqPX1mrK/T5bWPa+4fDybro37ZWkb775RosXL3YOQPHll186d4aIiAjnkSVJGjBggFavXq033nhD7du311NPPaXTp09XuGnvhQsX9K9//Ut79uxRWFiYIiIiVFBQUGEAim7duulvf/ubZs6cKW9vb50+fVqZmZmVTiv8voZw097PPvvM+f3Ln+dpSRY37a2NTTu/0NmrJMlXmzdv1pGqR+avwFVDcJYPtV7b523oTn435PeWzVt0yPdQreexesjT2qjNtnjiumvDE/vdWNVnr131/rLnuyHW9+zZLd8Tu11TnKSd362Xm/Y2RvTaWk2z33lffzdY08mzTfumvY899liFI1Pjxo3T5s2bJVU+MjVhwgS99dZbuuOOOySVXTP1wAMPaOnSpRVu2vvqq69WOI3w+44dO6aXX35ZL7/8spYsWaLf//738vHx0aBBg3TPPfdUW2dDuGaqd+/ezmkv3R2vrnE3uLEqz5eyN1uvbDyojp06K6JdCyk9XRFdblRUDefuu/rc5JIzBbV63sbCkbdfSpMiuvRQVDXXAn1/ng4efM1UbbbFE9ddk6Z87r3VrOi1q95fDu/PkTIz1aPHjfrJDREuq89VQ7fXBvu2dei1tZpyv9evPaYZ70lDEuOb7jVTPj4+6tevn+bOneuc/thjjyk8PFxS5QEobrzxRp09e1Y2m02nT59WRESElixZor///e/Oa6YOHz6sESNGOJcpP7JVftPe9PR0ZWdn6/HHH3fOU1xcrE8++US+vr4qLi6ucLpcuYZwzVRcXJxef/11/eIXv1CXiJZcM3UZH2eUHR1dsvmwc1rt/kLq+r8AWfeXWfcqG6VOmvxWukovflvlPF6+ufJreYseX3VYjpJv5al/cavNtnjiui/PM/vdOFnTa1e9vzQP9Hfp77vgwLLfqVwz1bjQa2s15X4XJHSXJHXtcm3TvGbK399f8fHxSklJ0c9+9jPn9JSUFN1+++01Luvn56eOHctuHLhq1SoNHz5c3t7ezmumvu93v/ud8vLytGDBAkVGRqpt27aV5rn//vsVGxur3/72t1UGqYYiKChIXbtad4PPhq7PNa31x08y9fydZf8Zf/t2uh4d0lkxbas/H8Zut2vPnt3q0eNGl+wrx74t1Isp+zVl6HWKbOUZp4vWp5OFwVqUKU0dep3aB11bw5wDJbm+365U+23xrHXXxJP73dhY0evy95f5Y3o4B9kxkZmdr0mr96hDy0AXVgcAV6Z8wLryfxuDOh9bnDx5ssaNG6eEhATnNVNHjx7VhAkTJFUezW///v3asWOHevfurXPnzmnevHn68ssv9dprr0kqO+3v+9dGSXIOs14+3d/fv9I8wcHBat26daXpaNxCA8v+gtCtfai+PHFBkvTHDZm1WNJXKzNdeyTpxZT9Ll2fpyo/6vTCN1lylBTUcinX99sVyo8ezU3Zr9KLtd0W96/78jyz342TNb2+IbKlosMa/2nEANDQ1TlMjRkzRmfPnq1wzdT69eudo+r98Jopu92uF198URkZGc7R/LZu3apOnTq5bCPQNCV1KxteM6ZtcwX6Vf9X4pKSEm3evFn9+/d3ybnJX528UKsjYo3LwFrP6clHSjgyhSthVa8D/X1UUFzi/IORiczsfBdWBACojtEny4kTJ2rixIlVPvbDa6a6du2q3bvrNpJQTSP0ldu4cWOd1unJYmNjlZaWptjYWHeX0qC0CvbXXTddfdn5bDabjjSXurUPcdl9pqTaHhFrqjzzSInZUbba4chUU9Gweh0c0LQubgfg2RrjZ17eZT1AUFCQevbs6e4yUEu1PSLWVLn6SKDr1c/oQYdyM/TkDmnBmB6KDulSL89RFc/vd+PR0HodHODLqYIAPEpj/Mzr+b8NAA9T2yNiTZWrjwQ2FN7Nyk75jGnbXNe3rt9Rzr6vqfbbHeg1AOCHCFNoUIpsdkmq07UE5Xca/+pkboP4a3JD11T7fSi37BqVA9n5Kr1ofq1LXTXVfrsDveZaLAD4oab52wAN1oHvfpFPW1PXaxZ8NTd9u+sLQjWaXr/Lr8f69RsH5Cg5Y/GzN71+uw+9lrgWCwDK8W6IBsXkeqWGdp1DQ9e0+23N3dy/r2n321r0ugzXYgHAfzXd3wZokEyuV+I6B2vRb2vRb+vQawDAD3m7uwAAAAAAaIgIUwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYYzQ9N2qGcAhUUl7i7jEaFG5tai35bpzH0mmHNAcC1GuZvA8AFDuUUaMjcje4uo5HyzBublt1Y9zPZzveWoyTE3eW4kGf2u3Fq+L3eMHUwgQoAXIQwhSar/IjU/DE91LltczdX03h48o1ND+Vm6Mkdv9eLPx2r6JAu7i7HJTy5341NQ+91Zna+Jq3ew9F4AHChhvfbAHCxzm2bK65DqLvLaDQ8+cam3s3KQnNM2+a6vnXjeM09ud+NDb0GAPwQA1AAAAAAgAHClJsVFhZq165dKiwsdHcpAAAAQL1pjJ97CVNulpGRofj4eO3bt8/dpQAAAAD1Zt++fY3ucy9hCgAAAAAM1FuYWrhwoaKjo9WsWTPFx8dr06ZNNc7/yiuvqGvXrgoMDFSXLl20YsWKCo+vWbNGCQkJatmypYKDg9WjRw+tXLmyvsoHAAAAgBrVy2h+q1ev1qRJk7Rw4UL169dPixcv1rBhw/T111/r6quvrjT/okWLNH36dL366qvq1auXduzYoYceekhXXXWVRowYIUlq1aqVZsyYodjYWPn7+2vdunW6//771bZtW/34xz+uj80AAAAAgGrVy5GpefPmafz48XrwwQfVtWtXzZ8/X5GRkVq0aFGV869cuVL/+7//qzFjxuiaa67RXXfdpfHjx+v55593zjN48GD97Gc/U9euXRUTE6PHHntMP/rRj7R58+b62AQAAAAAqJHLj0xdunRJaWlpmjZtWoXpSUlJ2rp1a5XLFBcXq1mzZhWmBQYGaseOHbLZbJXu5+FwOPTJJ58oIyOjQuCqar3FxcXOn3NzcyWV3SvEZrPVabtcrfz584vK6svIOi/vI2fdWVKjVVJSomP50n+OflvhRpsHzhRIkgqKit2+PzQm5b30xJ6WlJQ4//XE+kx4cr8bm4be6wLn75sLzv8Lnqy69264Hr22VlPud0bWeUlln3+tei+t6b3bFTW4/BXMycmR3W5XeHh4henh4eE6depUlcv8+Mc/1l/+8heNHDlSPXv2VFpampYtWyabzaacnBxFRERIki5cuKAOHTqouLhYPj4+WrhwoYYOHVptLcnJyZo5c2al6R9++KGCgoKuYCtd54NNn0uSJv8jXQGbitxcTWPmK6XvrPKRdRu36VQbi8tpAlJSUtxdQiUnS05KkrZs3qJDvofcXI1reWK/G6uG2uudZyTJV1PeSnd3KXVQ/Xs3XI1eW6tp9rv4VKYk6d8btulcTralz13Ve7crhmivtzjs5eVV4WeHw1FpWrmnnnpKp06dUp8+feRwOBQeHq777rtPc+bMkY+Pj3O+Fi1aaM+ePcrPz9fHH3+syZMn65prrtHgwYOrXO/06dM1efJk58+5ubmKjIxUUlKSQkJCrnwjr4DNZlNKSop+PKCX5kia9/Pu6hp3g1traqxKSkq0fft29enTp9KRqSlvpWv44ET1jLrKjRU2LuX79tChQysdVXa3vd/u1cL3F6pf/37q2qqru8txCU/ud2PT0Hvd7sg5rcz8XC+O6q6YNsHuLueyqnvvhuvRa2s15X7v/TJQY1+TfjokUYk3JVjynDW9d5eftXYlXP4KhoWFycfHp9JRqOzs7EpHq8oFBgZq2bJlWrx4sU6fPq2IiAgtWbJELVq0UFhYmHM+b29vde7cWZLUo0cP7d27V8nJydWGqYCAAAUEBFSa7ufn5zG/CJsHltXXJaKlekS1dnM1jZPNZtOJL6Ubrm5V4XUvfwMLDgzwmP2hMfGk/2flyl9zX19fj6vtSnlivxurhtrrYOfvm1DFdQh1czWXV917N1yPXlurKfe79GxLSWWff63e9qreu11Rg8sHoPD391d8fHylQ2kpKSnq27dvjcv6+fmpY8eO8vHx0apVqzR8+HB5e1dfosPhqHBNFAAAAABYpV6OLU6ePFnjxo1TQkKCEhMTtWTJEh09elQTJkyQVHb63YkTJ5z3ktq/f7927Nih3r1769y5c5o3b56+/PJLvfbaa851JicnKyEhQTExMbp06ZLWr1+vFStWVDtCIAAAAADUp3oJU2PGjNHZs2c1a9YsZWVlKS4uTuvXr1dUVJQkKSsrS0ePHnXOb7fb9eKLLyojI0N+fn4aMmSItm7dqk6dOjnnKSgo0MSJE3X8+HEFBgYqNjZWr7/+usaMGVMfmwAAAAAANaq3q94mTpyoiRMnVvnY8uXLK/zctWtX7d69u8b1zZ49W7Nnz3ZVeR6jS5cuSktLU2xsrLtLAQAAAOpNbGxso/vc27SGEPFAQUFB6tmzp7vLAAAAAOpVY/zc6/IBKAAAAACgKeDIFJqsIptdkvTliQturqRxKb+z+1cncz3u/hmHcvMlSQey81V6sXG87p7c78amofc6Mzvf3SUAQKPT8H4bAC5y4LsPFtPWpLu5ksbIV3PTt7u7iEq8fHPl1/IW/fqNA3KUnHF3OS7kmf1unBp+r4MD+NUPAK7COyqarKRu7SRJMW2bK9DPx83VNB4lJSXavHmz+vfv76F/vf+JuwtwKc/vd+PRGHodHOCr6LBgd5cBAI1Gw/xtALhAq2B/3XXT1e4uo9Gx2Ww60lzq1j6kyd3Z3R3ot3XoNQDghxiAAgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwABhCgAAAAAMEKYAAAAAwICvuwuAdCinQAXFJVU+Fhzgq+iwYIsrAgAAAHA5hCk3O3y2QEPnb5Ekefnmyq/lZ7Kd7y1HSYhzng1TBxOoAAAAAA9DmHKzgmK7JGn+mB7yaXZCT+74vV786VhFh3RRZna+Jq3eU+1RKwAAAADuQ5jyEJ3bNpd3s+aSpJi2zXV961A3VwQAAACgJgxAAQAAAAAGCFNuUlhYqAMHDqioqPCK17Nr1y4VFl7ZegAAAADUDaf5uUlGRoamTJmiN7v0uKL17Nu3T/Hx8UpLS1PPnj0lSXa7XRs3btTGjRslSYMHD9bgwYPl4+NzhVUDAAAAKEeYamTWrFmjCRMm6MyZM85ps2fPVtu2bbVo0SLdcccdbqwOAAAAaDyMTvNbuHChoqOj1axZM8XHx2vTpk3VznvffffJy8ur0le3bt2c8yxfvrzKeS5evOicJy8vT5MmTVJUVJQCAwPVt29fff755yblN1pr1qzRnXfeqTNnzqh///76+OOP9fHHH6t///7Kzs7WqFGjtGbNGneXCQAAADQKdQ5Tq1ev1qRJkzRjxgzt3r1bAwYM0LBhw3T06NEq51+wYIGysrKcX8eOHVOrVq3085//vMJ8ISEhFebLyspSs2bNnI8/+OCDSklJ0cqVK5Wenq6kpCTdeuutOnHiRF03oVGy2+2aPHmyAgMDNXz4cKWmpurmm2/WzTffrNTUVA0fPlyBgYGaOnWq7Ha7u8sFAAAAGrw6n+Y3b948jR8/Xg8++KAkaf78+frggw+0aNEiJScnV5o/NDRUoaH/HeZ77dq1OnfunO6///4K83l5ealdu3ZVPmdRUZHefvtt/fOf/9TAgQMlSc8884zWrl2rRYsWafbs2VUuV1xcrOLiYufPubm5kiSbzSabzVaHrXa9/KKyuo7k5EvyUUFRsQJ9y+4nVVJSIpvNpoLv5snIuqCSkqrvNZWRdV6StHX7Dh05ckSS9Nvf/lZ2u71CaPrNb36jdevW6dChQ9qwYYMGDRpUT1vmecpfa3e/5k0F/bYW/bYOvbYW/bYOvbYW/bZWTf12xWtQpzB16dIlpaWladq0aRWmJyUlaevWrbVax9KlS3XrrbcqKiqqwvT8/HxFRUXJbrerR48eevbZZ3XjjTdKKgsXdru9wpEqSQoMDNTmzZurfa7k5GTNnDmz0vQPP/xQQUFBtaq3vmxNPyBJWrDhkALadda6jdvU/qqTkqQtm7fokO8h7TwjSb6a8lZ6tespPpUpSfpo0zbntOPHj+vs2bMV5isqKnJ+/95776mgoMBFW9JwpKSkuLuEJoV+W4t+W4deW4t+W4deW4t+W6uqfrtiNOw6hamcnBzZ7XaFh4dXmB4eHq5Tp05ddvmsrCy99957evPNNytMj42N1fLly9W9e3fl5uZqwYIF6tevn/7zn//o2muvVYsWLZSYmKhnn31WXbt2VXh4uP72t7/ps88+07XXXlvt802fPl2TJ092/pybm6vIyEglJSUpJCSkLpvuci1abtccSY8Nidaf90rDBycqsMUpLXx/ofr176eurbqq3ZFzWpn5uV4c1V0xbYKrXM/eLwM19jXp1gGJWvePNyRJHTt2VO/evSvMt337duf3w4YNa3JHplJSUjR06FD5+fm5u5xGj35bi35bh15bi35bh15bi35bq6Z+l5+1diWMRvPz8vKq8LPD4ag0rSrLly9Xy5YtNXLkyArT+/Tpoz59+jh/7tevn3r27Kk//vGPevnllyVJK1eu1AMPPKAOHTrIx8dHPXv21NixY7Vr165qny8gIEABAQGVpvv5+bl9520eWFZXVFhzSUUKDgyQt2/Zy+Hr6ys/Pz8FfzdPl4hQxXUIrXI9pWdbSpL69rlJUVFRys7O1vPPP69//vOf8vYuuySutLRUc+bMUVBQkMLDwzVkyJAmOUy6J7zuTQn9thb9tg69thb9tg69thb9tlZV/XZF/+s0AEVYWJh8fHwqHYXKzs6udLTqhxwOh5YtW6Zx48bJ39+/5qK8vdWrVy998803zmkxMTFKTU1Vfn6+jh07ph07dshmsyk6Oroum9Bo+fj4aN68eSoqKtK6des0aNAgffTRR/roo480cOBArVu3TkVFRZo7d26TDFIAAACAq9UpTPn7+ys+Pr7SOYcpKSnq27dvjcumpqYqMzNT48ePv+zzOBwO7dmzRxEREZUeCw4OVkREhM6dO6cPPvhAt99+e102oVG744479Pbbb6tNmzbavHmzhg4dqqFDh2rLli1q27at3nrrLe4zBQAAALhInU/zmzx5ssaNG6eEhAQlJiZqyZIlOnr0qCZMmCCp7DqlEydOaMWKFRWWW7p0qXr37q24uLhK65w5c6b69Omja6+9Vrm5uXr55Ze1Z88evfLKK855PvjgAzkcDnXp0kWZmZl64okn1KVLl0qjAjZ1d9xxh26//XZt3LhRGzdulCQNHjxYgwcP5ogUAAAA4EJ1DlNjxozR2bNnNWvWLGVlZSkuLk7r1693js6XlZVV6Z5TFy5c0Ntvv60FCxZUuc7z58/r4Ycf1qlTpxQaGqobb7xRn376qW666aYK65g+fbqOHz+uVq1a6c4779Rzzz3HuaZV8PHx0S233KJbbrnF3aUAAAAAjZbRABQTJ07UxIkTq3xs+fLllaaFhobWOPTgSy+9pJdeeqnG5xw9erRGjx5dpzo9WZcuXfTiiy+qU8y10qYvjNcTGxurtLQ0xcbGurA6AAAAAJdjFKZw5YKCghQTE6PAwCu731VQUJB69uzpoqoAAAAA1FadBqAAAAAAAJThyJSbFdnskqQvT1xQcIt8SdKB7HyVXrygzOx8d5YGAAAAoAaEKTc7eKZAkjRtTbq8fHPl1/IW/fqNA3KUnHHOExzAywQAAAB4Gj6lu9mtXdvKx8dHMW2bK9DPR9JPKjweHOCr6LBg9xQHAAAAoFqEKTdrFeyvu2662t1lAAAAAKgjBqAAAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAOEKQAAAAAwQJgCAAAAAAO+7i4AZQ7lFKiguKTS9OAAX0WHBbuhIgAAAAA1IUx5gEM5BRoyd6O8fHPl1/Iz2c73lqMkxPn4hqmDCVQAAACAh+E0Pw9QfkTqiWERCmjzsV6+J0brHu2v+WN6VHgcAAAAgOfgyJQHiWwVJEmKadtc17cOdXM1AAAAAGrCkSkAAAAAMECYcpPCwkIdOHBAhYWFxsvv2rXLeHkAAAAAV4bT/NwkIyNDU6ZMUf/+/RXUoUudl9+3b5/i4+O1Y8cOFRQUKCsrS23btpUkZWdnKyIiQgMGDJCPj4+rSwcAAACgejwytXDhQkVHR6tZs2aKj4/Xpk2bqp33vvvuk5eXV6Wvbt26OedZs2aNEhIS1LJlSwUHB6tHjx5auXJlfZXfYIwcOVJDhgzR2LFjdeutt+rWW2/V2LFjNWTIEHXu3Flr1qxxd4kAAABAo1QvYWr16tWaNGmSZsyYod27d2vAgAEaNmyYjh49WuX8CxYsUFZWlvPr2LFjatWqlX7+858752nVqpVmzJihbdu26YsvvtD999+v+++/Xx988EF9bILH++STTyRJnTt3VnJysiSpf//+6t+/v7y8vJScnKzu3btr1KhRBCoAAACgHtRLmJo3b57Gjx+vBx98UF27dtX8+fMVGRmpRYsWVTl/aGio2rVr5/zauXOnzp07p/vvv985z+DBg/Wzn/1MXbt2VUxMjB577DH96Ec/0ubNm+tjEzya3W7XSy+9JEmaM2eOFi9erBEjRig1NVWpqakaPny4lixZorffflvDhw/X1KlTZbfb3Vw1AAAA0Li4/JqpS5cuKS0tTdOmTaswPSkpSVu3bq3VOpYuXapbb71VUVFRVT7ucDj0ySefKCMjQ88//3y16ykuLlZxcbHz59zcXEmSzWaTzWarVS31Jb+orK79WRcU6H1BklRUfEmSVFJSIpvNpoLv5snIuqCSkv/ea2rnts06efKkJGn7jp06fPiwVq5c6QxMTzzxhAYOHKjU1FTn9xs2bNCgQYMs2z5PUv5au/s1byrot7Xot3XotbXot3XotbXot7Vq6rcrXgOXh6mcnBzZ7XaFh4dXmB4eHq5Tp05ddvmsrCy99957evPNNys9duHCBXXo0EHFxcXy8fHRwoULNXTo0GrXlZycrJkzZ1aa/uGHHyooKKgWW1N/tqYfkCQ98c7XCmhXFqI27UyX/KQtm7fokO8h7TwjSb6a8lZ6hWULvt7i/P6jTdskScePH9fZs2clSUVFRZKk9957T7169XJ+X1BQUJ+b5PFSUlLcXUKTQr+tRb+tQ6+tRb+tQ6+tRb+tVVW/XTEqdr2N5ufl5VXhZ4fDUWlaVZYvX66WLVtq5MiRlR5r0aKF9uzZo/z8fH388ceaPHmyrrnmGg0ePLjKdU2fPl2TJ092/pybm6vIyEglJSUpJCSkTtvjai1abtccSS/87HoFduiiKW+la0BCd238j9Svfz91bdVV7Y6c08rMz/XiqO6KaRPsXHbnthI99K8XJEm3DkjUun+8oY4dO6p3796SpO3bt0uShg0bpoCAAOf3TfnIVEpKioYOHSo/Pz93l9Po0W9r0W/r0Gtr0W/r0Gtr0W9r1dTv8rPWroTLw1RYWJh8fHwqHYXKzs6udLTqhxwOh5YtW6Zx48bJ39+/0uPe3t7q3LmzJKlHjx7au3evkpOTqw1TAQEBzjDxfX5+fm7feZsHltV1XUSogiJCJUmBAWXb7OvrKz8/PwV/N0+XiFDFdQh1Ltu943A9PaW9Tp48qT43JahTp06aM2eO1q5dK0l64YUXFB0drUGDBunOO+9UdHS0hgwZ0uSHSfeE170pod/Wot/WodfWot/WodfWot/Wqqrfrui/yweg8Pf3V3x8fKVDaSkpKerbt2+Ny6ampiozM1Pjx4+v1XM5HI4K10Q1FT4+Pnr88cclSb/5zW/08MMP61//+pcGDhyoQYMGad26dXrooYd05513at26dZo7d26TD1IAAACAq9XLaX6TJ0/WuHHjlJCQoMTERC1ZskRHjx7VhAkTJJWdfnfixAmtWLGiwnJLly5V7969FRcXV2mdycnJSkhIUExMjC5duqT169drxYoV1Y4Q2NjdfPPNkqTMzEw9+eSTkqQtW/57LdWTTz6p6OhovfXWW7rjjjvcUiMAAADQmNVLmBozZozOnj2rWbNmKSsrS3FxcVq/fr1zdL6srKxK95y6cOGC3n77bS1YsKDKdRYUFGjixIk6fvy4AgMDFRsbq9dff11jxoypj01oMNauXauCggJlZWWpbdu2kspOqYyIiNCAAQM4IgUAAADUk3obgGLixImaOHFilY8tX7680rTQ0NAaR9SYPXu2Zs+e7aryGg0fH59qrxkDAAAAUH/q5aa9uLwuXbroxRdfVJcuXYyWj42NVVpammJjY11cGQAAAIDaqLcjU6hZUFCQYmJiyu53lV/3Me6DgoLUs2fPeqgMAAAAQG1wZAoAAAAADHBkygMU2eySpMzsfEnSgex8lV684PwZAAAAgOchTHmAA9+FppdTTsuv5S369RsH5Cg543w8OICXCQAAAPA0fEr3AEnd2kmSYto2V6DfTyo8Fhzgq+iwYHeUBQAAAKAGhCkP0CrYX3fddLW7ywAAAABQBwxAAQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYIAwBQAAAAAGCFMAAAAAYMDX3QWgzKGcAhUUl1SaHhzgq+iwYDdUBAAAAKAmhCkPcCinQEPmbpSXb678Wn4m2/necpSEOB/fMHUwgQoAAADwMJzm5wHKj0g9MSxCAW0+1sv3xGjdo/01f0yPCo8DAAAA8BwcmfIgka2CJEkxbZvr+tahbq4GAAAAQE04MgUAAAAABghTAAAAAGCAMOUmhYWFOnDggAoLC42X37Vrl/HyAAAAAK4M10y5SUZGhqZMmaL+/fsrqEOXOi+/b98+xcfHa8eOHSooKFBWVpbatm0rScrOzlZERIQGDBggHx8fV5cOAAAAQIZHphYuXKjo6Gg1a9ZM8fHx2rRpU7Xz3nffffLy8qr01a1btwrzvf3227r++usVEBCg66+/Xu+8806FxxctWqQf/ehHCgkJUUhIiBITE/Xee++ZlN+ojBw5UkOGDNHYsWN166236tZbb9XYsWM1ZMgQde7cWWvWrHF3iQAAAECjVOcwtXr1ak2aNEkzZszQ7t27NWDAAA0bNkxHjx6tcv4FCxYoKyvL+XXs2DG1atVKP//5z53zbNu2TWPGjNG4ceP0n//8R+PGjdPo0aP12WefOefp2LGj/vCHP2jnzp3auXOnbr75Zt1+++366quvDDa74fvkk08kSZ07d1ZycrIkqX///urfv7+8vLyUnJys7t27a9SoUQQqAAAAoB7UOUzNmzdP48eP14MPPqiuXbtq/vz5ioyM1KJFi6qcPzQ0VO3atXN+7dy5U+fOndP999/vnGf+/PkaOnSopk+frtjYWE2fPl233HKL5s+f75xnxIgR+slPfqLrrrtO1113nZ577jk1b95c27dvr/tWN3B2u10vvfSSJGnOnDlavHixRowYodTUVKWmpmr48OFasmSJ3n77bQ0fPlxTp06V3W53c9UAAABA41Kna6YuXbqktLQ0TZs2rcL0pKQkbd26tVbrWLp0qW699VZFRUU5p23btk2PP/54hfl+/OMfVwhT32e32/WPf/xDBQUFSkxMrPa5iouLVVxc7Pw5NzdXkmSz2WSz2WpVb33JLyqra3/WBQV6X5AkFRVfkiSVlJTIZrOp4Lt5MrIuqKTkvzfu3blts06ePClJ2r5jpw4fPqyVK1c6A9MTTzyhgQMHKjU11fn9hg0bNGjQIMu2z5OUv9bufs2bCvptLfptHXptLfptHXptLfptrZr67YrXoE5hKicnR3a7XeHh4RWmh4eH69SpU5ddPisrS++9957efPPNCtNPnTpVq3Wmp6crMTFRFy9eVPPmzfXOO+/o+uuvr/b5kpOTNXPmzErTP/zwQwUFBV223vq0Nf2AJOmJd75WQLuyELVpZ7rkJ23ZvEWHfA9p5xlJ8tWUt9IrLFvw9Rbn9x9t2iZJOn78uM6ePStJKioqkiS999576tWrl/P7goKC+twkj5eSkuLuEpoU+m0t+m0dem0t+m0dem0t+m2tqvrtilGxjUbz8/LyqvCzw+GoNK0qy5cvV8uWLTVy5EijdXbp0kV79uzR+fPn9fbbb+vee+9VampqtYFq+vTpmjx5svPn3NxcRUZGKikpSSEhIZettz61aLldcyS98LPrFdihi6a8la4BCd218T9Sv/791LVVV7U7ck4rMz/Xi6O6K6ZNsHPZndtK9NC/XpAk3TogUev+8YY6duyo3r17S5Lz1Mdhw4YpICDA+X1TPjKVkpKioUOHys/Pz93lNHr021r02zr02lr02zr02lr021o19bv8rLUrUacwFRYWJh8fn0pHjLKzsysdWfohh8OhZcuWady4cfL396/wWLt27Wq1Tn9/f3Xu3FmSlJCQoM8//1wLFizQ4sWLq3zOgIAAZ5j4Pj8/P7fvvM0Dy+q6LiJUQRGhkqTAgLK++Pr6ys/PT8HfzdMlIlRxHUKdy3bvOFxPT2mvkydPqs9NCerUqZPmzJmjtWvXSpJeeOEFRUdHa9CgQbrzzjsVHR2tIUOGNPlh0j3hdW9K6Le16Ld16LW16Ld16LW16Le1quq3K/pfpwEo/P39FR8fX+kwWUpKivr27VvjsqmpqcrMzNT48eMrPZaYmFhpnR9++OFl1+lwOCpcE9VU+Pj4OK8x+81vfqOHH35Y//rXvzRw4EANGjRI69at00MPPaQ777xT69at09y5c5t8kAIAAABcrc6n+U2ePFnjxo1TQkKCEhMTtWTJEh09elQTJkyQVHZq3YkTJ7RixYoKyy1dulS9e/dWXFxcpXU+9thjGjhwoJ5//nndfvvt+uc//6mPPvpImzdvds7z5JNPatiwYYqMjFReXp5WrVqljRs36v3336/rJjQKN998syQpMzNTTz75pCRpy5b/Xkv15JNPKjo6Wm+99ZbuuOMOt9QIAAAANGZ1DlNjxozR2bNnNWvWLGVlZSkuLk7r1693js6XlZVV6Z5TFy5c0Ntvv60FCxZUuc6+fftq1apV+t3vfqennnpKMTExWr16tfMaIEk6ffq0xo0bp6ysLIWGhupHP/qR3n//fQ0dOrSum9CorF27VgUFBcrKylLbtm0llZ0iGRERoQEDBnBECgAAAKgnRgNQTJw4URMnTqzyseXLl1eaFhoaetnRMkaNGqVRo0ZV+/jSpUvrVKOn69Kli1588UV16dJFx/LrvnxsbKzS0tIUGxvr9pEJAQAAgKbIKEzhygUFBSkmJqYsCOXXfVjGoKAg9ezZsx4qAwAAAFAbdRqAAgAAAABQhjAFAAAAAAY4zc8DFNnskqTM7LKLpw5k56v04gXnzwAAAAA8D2HKAxz4LjS9nHJafi1v0a/fOCBHyRnn48EBvEwAAACAp+FTugdI6tZOkhTTtrkC/X5S4bHgAF9FhwW7oywAAAAANSBMeYBWwf6666ar3V0GAAAAgDpgAAoAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMODr7gJQ5lBOgQqKSypNDw7wVXRYsBsqAgAAAFATwpQHOJRToCFzN0qSvHxz5dfyM9nO95ajJESStGHqYAIVAAAA4GE4zc8DlB+Rmj+mh16+J0YBbT7Wy/fEaP6YHhUeBwAAAOA5ODLlQTq3bS7vZs0lSTFtm6v0YnM3VwQAAACgOhyZAgAAAAADhCk3KSws1IEDB1RYWHhF69i1a9cVrQMAAACAGcKUm2RkZGjKlCnKyMgwXse+ffsUHx+vffv2yW63a+PGjfrb3/6mjRs3ym63VzkNAAAAgGsYhamFCxcqOjpazZo1U3x8vDZt2lTj/MXFxZoxY4aioqIUEBCgmJgYLVu2rMI88+fPV5cuXRQYGKjIyEg9/vjjunjxovPxZ555Rl5eXhW+2rVrZ1J+o/PJJ5+oc+fOGjJkiMaOHashQ4aoffv2ioiIqDCtc+fOWrNmjbvLBQAAABqFOoep1atXa9KkSZoxY4Z2796tAQMGaNiwYTp69Gi1y4wePVoff/yxli5dqoyMDP3tb39TbGys8/E33nhD06ZN09NPP629e/dq6dKlWr16taZPn15hPd26dVNWVpbzKz09va7lN0q/+c1v1L17d23btk15eXlKTk5Wdna2zpw5o+TkZOXl5Wnbtm3q3r27Ro0aRaACAAAAXKDOo/nNmzdP48eP14MPPiip7IjSBx98oEWLFik5ObnS/O+//75SU1N18OBBtWrVSpLUqVOnCvNs27ZN/fr109ixY52P33333dqxY0fFYn19ORr1PeWn7Q0YMEBr166Vt7e37Ha7Fi9erOHDh0uSlixZoieeeEJ9+vTR2rVrNXLkSE2dOlW33367fHx83Fk+AAAA0KDVKUxdunRJaWlpmjZtWoXpSUlJ2rp1a5XLvPvuu0pISNCcOXO0cuVKBQcH67bbbtOzzz6rwMBASVL//v31+uuva8eOHbrpppt08OBBrV+/Xvfee2+FdX3zzTdq3769AgIC1Lt3b/3+97/XNddcU229xcXFKi4udv6cm5srSbLZbLLZbHXZdJfLLyqra3/WBQV6X5AkFRQVK9C37J5SJSUlKvpunoysCyopqXyvqXc/Kju98q6xv3BeI5WamqrDhw9r5cqVcjgcGjhwoDZs2KBBgwZJkp544olK0xq78tfa3a95U0G/rUW/rUOvrUW/rUOvrUW/rVVTv13xGtQpTOXk5Mhutys8PLzC9PDwcJ06darKZQ4ePKjNmzerWbNmeuedd5STk6OJEyfq22+/dV43ddddd+nMmTPq37+/HA6HSkpK9P/+3/+rENp69+6tFStW6LrrrtPp06c1e/Zs9e3bV1999ZVat25d5XMnJydr5syZlaZ/+OGHCgoKqsumu9zW9AOSpCfe+VoB7S5JktZt3Kb2V52UJG3ZvEUnz7WX5Kspb1V9OuP5rXskSfuP52j9+vWSpE8//VSSdPz4ced87733ngoKCiRJRUVFlaY1FSkpKe4uoUmh39ai39ah19ai39ah19ai39aqqt+uGBHb6Ka9Xl5eFX52OByVppUrLS2Vl5eX3njjDYWGhkoqO1Vw1KhReuWVVxQYGKiNGzfqueee08KFC9W7d29lZmbqscceU0REhJ566ilJ0rBhw5zr7N69uxITExUTE6PXXntNkydPrvK5p0+fXuGx3NxcRUZGKikpSSEhISab7jItWm7XHEkv/Ox6BXbooilvpWv44EQFtjilhe8vVL/+/VSU104rMz/Xi6O6K6ZNcKV1vB2aodmbVuq6jmH6yU9+IkkKDg7WvHnz1LFjRzkcDkllvSs/CrV9+/ZK0xo7m82mlJQUDR06VH5+fu4up9Gj39ai39ah19ai39ah19ai39aqqd/lZ61diTqFqbCwMPn4+FQ6CpWdnV3paFW5iIgIdejQwRmkJKlr165yOBw6fvy4rr32Wj311FMaN26c8zqs7t27q6CgQA8//LBmzJghb+/K42QEBwere/fu+uabb6qtNyAgQAEBAZWm+/n5uX3nbR5YVtd1EaEKiijrTXBggLx9y14SX19fBX83T5eIUMV1CK20DtutAzT7SWnVm6/rfx8aL29vbw0ZMkSdOnXS888/L0mKjo7WkCFD5OPjo9LSUr3wwgsVpjUlnvC6NyX021r02zr02lr02zr02lr021pV9dsV/a/TaH7+/v6Kj4+vdJgsJSVFffv2rXKZfv366eTJk8rPz3dO279/v7y9vdWxY0dJZYfYfhiYfHx85HA4nEdXfqi4uFh79+5VREREXTahUSkPQ5s2bdLIkSO1bds2FRYW6uGHH9a6deu0bt06PfTQQyosLNS2bds0cuRIrVu3TnPnzm1yQQoAAABwtToPjT558mT95S9/0bJly7R37149/vjjOnr0qCZMmCCp7NS6X/7yl875x44dq9atW+v+++/X119/rU8//VRPPPGEHnjgAecAFCNGjNCiRYu0atUqHTp0SCkpKXrqqad02223OT/0T506VampqTp06JA+++wzjRo1Srm5uZUGqWiK5syZo/T0dPXt21chISF68skn1bZtW7Vp00ZPPvmkQkJC1LdvX3355Zd66623dMcdd7i7ZAAAAKDBq/M1U2PGjNHZs2c1a9YsZWVlKS4uTuvXr1dUVJQkKSsrq8I9p5o3b66UlBQ9+uijSkhIUOvWrTV69GjNnj3bOc/vfvc7eXl56Xe/+51OnDihNm3aaMSIEXruueec8xw/flx33323cnJy1KZNG/Xp00fbt293Pm9TdvPNN+vxxx/Xpk2blJWVpYiICA0YMECSKk3jiBQAAADgGkYDUEycOFETJ06s8rHly5dXmhYbG1vjiCW+vr56+umn9fTTT1c7z6pVq+pcZ1Pi4+OjwYMHV5pe1TQAAAAAV67Op/nBNbp06aIXX3xRXbp0MV5HbGys0tLSFBsb68LKAAAAANSG0ZEpXLmgoCDFxMSU3e8q32yM+6CgIPXs2dPFlQEAAACoDY5MAQAAAIABjkx5gCKbXZL05YkLCm5RNoT8gex82S/m17QYAAAAADciTHmAA9lloWnamnR5+ebKr+Ut+vUbB+QoOSNJCg7gZQIAAAA8DZ/SPUBSt3aSpJi2zRXo5yPpJ87HggN8FR0W7KbKAAAAAFSHMOUBWgX7666brnZ3GQAAAADqgAEoAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADBCmAAAAAMAAYQoAAAAADPi6u4Cm7vDZAhXbvSRJwQG+ig4LdnNFAAAAAGqDMOVG2UXSY/O3yMs3V34tP5PtfG99Muk2AhUAAADQAHCanxsV28v+fWJYhALafCwv3zwVFJe4tygAAAAAtUKY8gCRrYLcXQIAAACAOiJMAQAAAIABwpSbFBYW6tihAyq1XawwvaioULt27VJhYaGbKgMAAABQG4QpN8nIyNCcp6bIdvZ4hemHMvcrPj5e+/btc1NlAAAAAGqD0fw81M6dO5WRkaGIiAgNGDBAPj4+7i4JAAAAwPcYHZlauHChoqOj1axZM8XHx2vTpk01zl9cXKwZM2YoKipKAQEBiomJ0bJly6qcd9WqVfLy8tLIkSMrTH/mmWfk5eVV4atdu3Ym5Xu0z7Z8Kkn63//9X40dO1ZDhgxR586dtWbNGjdXBgAAAOD76hymVq9erUmTJmnGjBnavXu3BgwYoGHDhuno0aPVLjN69Gh9/PHHWrp0qTIyMvS3v/1NsbGxleY7cuSIpk6dqgEDBlS5nm7duikrK8v5lZ6eXtfyPdrFw//RS889LUlavny58vLytG3bNnXv3l2jRo0iUAEAAAAepM5hat68eRo/frwefPBBde3aVfPnz1dkZKQWLVpU5fzvv/++UlNTtX79et16663q1KmTbrrpJvXt27fCfHa7Xffcc49mzpypa665psp1+fr6ql27ds6vNm3a1LV8j5a785/qeVOiJKl79+5q3ry5+vTpo7Vr12r48OGaOnWq7Ha7m6sEAAAAINXxmqlLly4pLS1N06ZNqzA9KSlJW7durXKZd999VwkJCZozZ45Wrlyp4OBg3XbbbXr22WcVGBjonG/WrFlq06aNxo8fX+1pg998843at2+vgIAA9e7dW7///e+rDV5S2emFxcXFzp9zc3MlSTabTTabrdbbXR/yi4rle1V7efkG6NjZfEmSPf+s+ox6XGmfbVV+UXGFGp944gkNHDhQGzZs0KBBg9xVdoNU3kd3v+ZNBf22Fv22Dr22Fv22Dr22Fv22Vk39dsVrUKcwlZOTI7vdrvDw8ArTw8PDderUqSqXOXjwoDZv3qxmzZrpnXfeUU5OjiZOnKhvv/3Wed3Uli1btHTpUu3Zs6fa5+7du7dWrFih6667TqdPn9bs2bPVt29fffXVV2rdunWVyyQnJ2vmzJmVpn/44YcKCnLvjXI/+M9RdZw4V34tP9OLG4oUdHXZ9H98U3bk6d8btulcTrZz/qKiIknSe++9p4KCAsvrbQxSUlLcXUKTQr+tRb+tQ6+tRb+tQ6+tRb+tVVW/XXErIqPR/Ly8vCr87HA4Kk0rV1paKi8vL73xxhsKDQ2VVHaq4KhRo/TKK6+opKREv/jFL/Tqq68qLCys2uccNmyY8/vu3bsrMTFRMTExeu211zR58uQql5k+fXqFx3JzcxUZGamkpCSFhITUenvrw7deW/T+rv0KaPOxik6McU7/+bU+ekXST4ckKvGmBOf07du3SyrrA0em6sZmsyklJUVDhw6Vn5+fu8tp9Oi3tei3dei1tei3dei1tei3tWrqd/lZa1eiTmEqLCxMPj4+lY5CZWdnVzpaVS4iIkIdOnRwBilJ6tq1qxwOh44fP66CggIdPnxYI0aMcD5eWlpaVpyvrzIyMhQTE1NpvcHBwerevbu++eabausNCAhQQEBApel+fn5u33kDAyo/v0/z1tr+ftkgE80DA5w1lpaW6oUXXlB0dLSGDBnCMOmGPOF1b0rot7Xot3XotbXot3XotbXot7Wq6rcr+l+nASj8/f0VHx9f6TBZSkpKpQElyvXr108nT55Ufn6+c9r+/fvl7e2tjh07KjY2Vunp6dqzZ4/z67bbbtOQIUO0Z88eRUZGVrne4uJi7d27VxEREXXZBI8WknC7du3YJkn64osvnKP5jRw5UuvWrdPcuXMJUgAAAICHqPNofpMnT9Zf/vIXLVu2THv37tXjjz+uo0ePasKECZLKTq375S9/6Zx/7Nixat26te6//359/fXX+vTTT/XEE0/ogQceUGBgoJo1a6a4uLgKXy1btlSLFi0UFxcnf39/SdLUqVOVmpqqQ4cO6bPPPtOoUaOUm5ure++910WtsFbxxYu6lHNMklRqL7v4zb9jrB6fUXaN1/3336+QkBD17dtXX375pd566y3dcccdbqsXAAAAQEV1vmZqzJgxOnv2rGbNmqWsrCzFxcVp/fr1ioqKkiRlZWVVuOdU8+bNlZKSokcffVQJCQlq3bq1Ro8erdmzZ9fpeY8fP667775bOTk5atOmjfr06aPt27c7n7ehOXnsiM6um6urenWWPe9bSVLJ+Wz1Hn6rJGnx4sVq0aKFIiIiNGDAAI5IAQAAAB7GaACKiRMnauLEiVU+tnz5cknSwoUL9cILLygrK0vdunXT/Pnzq70Zr1R22t6sWbP0+uuv69SpU+rYsaOWLVumBx54QJK0atUq57yrVq3S3XffLbvdrrVr15psgtu1b9++yunRna9TWlqaYmNj3T7iIAAAAIDqGYWpy1m9erUmTZqkhQsXql+/flq8eLGGDRumr7/+WldffXWVy4wePVqnT5/W0qVL1blzZ2VnZ6ukpKTSfEeOHNHUqVNrDGYNgX+Af5XTAwODFNe5p8XVAAAAAKireglT8+bN0/jx4/Xggw9KkubPn68PPvhAixYtUnJycqX533//faWmpurgwYNq1aqVJKlTp06V5rPb7brnnns0c+ZMbdq0SefPn6+P8gEAAADgslwepi5duqS0tDRNmzatwvSkpCRt3bq1ymXeffddJSQkaM6cOVq5cqWCg4N122236dlnn1VgYKBzvlmzZqlNmzYaP368Nm3adNlaiouLVVxc7Py5fCx5m83m9rtO20vsVU4vKSlxe22NDXcatxb9thb9tg69thb9tg69thb9tlZN/XbFa+DyMJWTkyO73V7pvlPh4eGV7k9V7uDBg9q8ebOaNWumd955Rzk5OZo4caK+/fZbLVu2TJK0ZcsWLV26VHv27Kl1LcnJyZo5c2al6R9++KHbr0dKTz/g/L7U1kzZa7Pl0yZIn2/brCOBNSwIY9xp3Fr021r02zr02lr02zr02lr021pV9buwsPCK11svp/lJkpeXV4WfHQ5HpWnlSktL5eXlpTfeeMN5c9958+Zp1KhReuWVV1RSUqJf/OIXevXVVxUWFlbrGqZPn67Jkyc7f87NzVVkZKSSkpIUEhJisFWuk6eNzu8d34WpVf/urTuGNuxrwTwRdxq3Fv22Fv22Dr22Fv22Dr22Fv22Vk39Lj9r7Uq4PEyFhYXJx8en0lGo7OzsSkerykVERKhDhw7OICVJXbt2lcPh0PHjx1VQUKDDhw9rxIgRzsdLS0vLNsDXVxkZGYqJiam03oCAAAUEBFSa7gl3nPbxrTzU+bXtWrq9rsbME173poR+W4t+W4deW4t+W4deW4t+W6uqfrui/3W+ae/l+Pv7Kz4+vtKhtJSUFPXt27fKZfr166eTJ08qPz/fOW3//v3y9vZWx44dFRsbq/T0dO3Zs8f5ddttt2nIkCHas2ePIiMjXb0ZAAAAAFCjejnNb/LkyRo3bpwSEhKUmJioJUuW6OjRo5owYYKkstPvTpw4oRUrVkiSxo4dq2effVb333+/Zs6cqZycHD3xxBN64IEHnANQxMXFVXiOli1bVjkdAAAAAKxQL2FqzJgxOnv2rGbNmqWsrCzFxcVp/fr1ioqKkiRlZWXp6NGjzvmbN2+ulJQUPfroo0pISFDr1q01evRozZ49uz7KAwAAAIArVm8DUEycOFETJ06s8rHly5dXmhYbG1unUU2qWgcAAAAAWMXl10yhdjrFXKvWw6dKknxbttXq9zYqNjbWzVUBAAAAqC3ClJsEBgbJP6xs4Axv3wBd372H2+99BQAAAKD2CFMAAAAAYIAw5SZFNru7SwAAAABwBQhTbnLwTIEcJS1UfOYWOUpaKDig3sYCAQAAAFAP+ATvJrd2bav09GDdfvOTatcyWNFhwe4uCQAAAEAdEKbcpFWwvxLDHUqIukp+fn7uLgcAAABAHXGaHwAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAHCFAAAAAAYIEwBAAAAgAFfdxcA6VBOgQqKSypNDw7wVXRYsBsqAgAAAHA5hCk3O3y2QEPnb5Ekefnmyq/lZ7Kd7y1HSYgkacPUwQQqAAAAwANxmp+bFRTbJUnzx/TQy/fEKKDNx3r5nhjNH9Pju8crH7ECAAAA4H4cmfIQnds2l3ez5pKkmLbNVXqxuZsrAgAAAFATjkwBAAAAgAHCFAAAAAAYIEy5SWFhoQ4cOKCiosJaz79r1y4VFtZufgAAAAD1izDlJhkZGZoyZYoOH/imVvPv27dP8fHx2rdvXz1XBgAAAKA2jMLUwoULFR0drWbNmik+Pl6bNm2qcf7i4mLNmDFDUVFRCggIUExMjJYtW+Z8/KuvvtKdd96pTp06ycvLS/Pnz6+0juTkZPXq1UstWrRQ27ZtNXLkSGVkZJiUDwAAAABXrM5havXq1Zo0aZJmzJih3bt3a8CAARo2bJiOHj1a7TKjR4/Wxx9/rKVLlyojI0N/+9vfFBsb63y8sLBQ11xzjf7whz+oXbt2Va4jNTVVv/rVr7R9+3alpKSopKRESUlJKigoqOsmAAAAAMAVq/PQ6PPmzdP48eP14IMPSpLmz5+vDz74QIsWLVJycnKl+d9//32lpqbq4MGDatWqlSSpU6dOFebp1auXevXqJUmaNm1alc/7/vvvV/j5r3/9q9q2bau0tDQNHDiwrpsBAAAAAFekTmHq0qVLSktLqxR4kpKStHXr1iqXeffdd5WQkKA5c+Zo5cqVCg4O1m233aZnn31WgYGBxoVfuHBBkpwBrSrFxcUqLi52/pybmytJstlsstlsxs/tCvlFZXUdycmX5KOComIF+pbdoLekpERF3z2ekXVBJSUlysg671zO3bU3NOX9om/WoN/Wot/WodfWot/WodfWot/WqqnfrngN6hSmcnJyZLfbFR4eXmF6eHi4Tp06VeUyBw8e1ObNm9WsWTO98847ysnJ0cSJE/Xtt99WuG6qLhwOhyZPnqz+/fsrLi6u2vmSk5M1c+bMStM//PBDBQUFGT23q2xNPyBJWrDhkALadda6jdvU/qqTkqQtm7fo5Ln2knw15a10SVLxqUxJ0r83bNO5nGy31NzQpaSkuLuEJoV+W4t+W4deW4t+W4deW4t+W6uqfrtilOw6n+YnSV5eXhV+djgclaaVKy0tlZeXl9544w2FhoZKKjtVcNSoUXrllVeMjk498sgj+uKLL7R58+Ya55s+fbomT57s/Dk3N1eRkZFKSkpSSEhInZ/XlVq03K45kh4bEq0/75WGD05UYItTWvj+QvXr309Fee20MvNzvTiqu2LaBGvvl4Ea+5r00yGJSrwpwa21NzQ2m00pKSkaOnSo/Pz83F1Oo0e/rUW/rUOvrUW/rUOvrUW/rVVTv8vPWrsSdQpTYWFh8vHxqXQUKjs7u9LRqnIRERHq0KGDM0hJUteuXeVwOHT8+HFde+21dSr40Ucf1bvvvqtPP/1UHTt2rHHegIAABQQEVJru5+fn9p23eWBZXVFhzSUVKTgwQN6+ZS+Hr6+vgr97vEtEqOI6hKr0bEvncu6uvaHyhNe9KaHf1qLf1qHX1qLf1qHX1qLf1qqq367of51G8/P391d8fHylw2QpKSnq27dvlcv069dPJ0+eVH5+vnPa/v375e3tfdkw9H0Oh0OPPPKI1qxZo08++UTR0dF1KR0AAAAAXKrOQ6NPnjxZf/nLX7Rs2TLt3btXjz/+uI4ePaoJEyZIKju17pe//KVz/rFjx6p169a6//779fXXX+vTTz/VE088oQceeMB5it+lS5e0Z88e7dmzR5cuXdKJEye0Z88eZWZmOtfzq1/9Sq+//rrefPNNtWjRQqdOndKpU6dUVFR0pT0AAAAAgDqr8zVTY8aM0dmzZzVr1ixlZWUpLi5O69evV1RUlCQpKyurwj2nmjdvrpSUFD366KNKSEhQ69atNXr0aM2ePds5z8mTJ3XjjTc6f547d67mzp2rQYMGaePGjZKkRYsWSZIGDx5coZ6//vWvuu++++q6GQAAAABwRYwGoJg4caImTpxY5WPLly+vNC02NrbGEUs6deokh8NR43Ne7vGGpkuXLnrxxRfVKeZaadMXl50/NjZWaWlpFW52DAAAAMB9jMIUrlxQUJBiYmIUGFi7IdqDgoLUs2fPeq4KAAAAQG3V+ZopAAAAAABhCgAAAACMcJqfmxXZ7JKkL09cUHCLsuHjD2Tny34xv6bFAAAAALgZYcrNDp4pkCRNW5MuL99c+bW8Rb9+44AcJWckScEBvEQAAACAJ+KTupvd2rWtfHx8FNO2uQL9fCT9xPlYcICvosOC3VccAAAAgGoRptysVbC/7rrpaneXAQAAAKCOGIACAAAAAAwQpgAAAADAAGEKAAAAAAwQpgAAAADAAGEKAAAAAAwQpgAAAADAQJMaGt3hcEiScnNz3VyJZLPZVFhYqNzcXPn5+bm7nEaNXluLfluLfluHXluLfluHXluLflurpn6XZ4LyjGCiSYWpvLw8SVJkZKSbKwEAAADgCfLy8hQaGmq0rJfjSqJYA1NaWqqTJ0+qRYsW8vLycmstubm5ioyM1LFjxxQSEuLWWho7em0t+m0t+m0dem0t+m0dem0t+m2tmvrtcDiUl5en9u3by9vb7OqnJnVkytvbWx07dnR3GRWEhITwH8ki9Npa9Nta9Ns69Npa9Ns69Npa9Nta1fXb9IhUOQagAAAAAAADhCkAAAAAMECYcpOAgAA9/fTTCggIcHcpjR69thb9thb9tg69thb9tg69thb9tlZ997tJDUABAAAAAK7CkSkAAAAAMECYAgAAAAADhCkAAAAAMECYAgAAAAADhCkAAAAAMECYcoOFCxcqOjpazZo1U3x8vDZt2uTukhq85ORk9erVSy1atFDbtm01cuRIZWRkVJjnvvvuk5eXV4WvPn36uKnihu2ZZ56p1Mt27do5H3c4HHrmmWfUvn17BQYGavDgwfrqq6/cWHHD1qlTp0r99vLy0q9+9StJ7NtX4tNPP9WIESPUvn17eXl5ae3atRUer82+XFxcrEcffVRhYWEKDg7WbbfdpuPHj1u4FQ1HTf222Wz67W9/q+7duys4OFjt27fXL3/5S508ebLCOgYPHlxpf7/rrrss3pKG4XL7d23eO9i/a+dyva7qPdzLy0svvPCCcx727dqpzWc+K9+7CVMWW716tSZNmqQZM2Zo9+7dGjBggIYNG6ajR4+6u7QGLTU1Vb/61a+0fft2paSkqKSkRElJSSooKKgw3//8z/8oKyvL+bV+/Xo3VdzwdevWrUIv09PTnY/NmTNH8+bN05/+9Cd9/vnnateunYYOHaq8vDw3Vtxwff755xV6nZKSIkn6+c9/7pyHfdtMQUGBbrjhBv3pT3+q8vHa7MuTJk3SO++8o1WrVmnz5s3Kz8/X8OHDZbfbrdqMBqOmfhcWFmrXrl166qmntGvXLq1Zs0b79+/XbbfdVmnehx56qML+vnjxYivKb3Aut39Ll3/vYP+uncv1+vs9zsrK0rJly+Tl5aU777yzwnzs25dXm898lr53O2Cpm266yTFhwoQK02JjYx3Tpk1zU0WNU3Z2tkOSIzU11Tnt3nvvddx+++3uK6oRefrppx033HBDlY+VlpY62rVr5/jDH/7gnHbx4kVHaGio489//rNFFTZujz32mCMmJsZRWlrqcDjYt11FkuOdd95x/lybffn8+fMOPz8/x6pVq5zznDhxwuHt7e14//33Lau9Ifphv6uyY8cOhyTHkSNHnNMGDRrkeOyxx+q3uEaoqn5f7r2D/dtMbfbt22+/3XHzzTdXmMa+beaHn/msfu/myJSFLl26pLS0NCUlJVWYnpSUpK1bt7qpqsbpwoULkqRWrVpVmL5x40a1bdtW1113nR566CFlZ2e7o7xG4ZtvvlH79u0VHR2tu+66SwcPHpQkHTp0SKdOnaqwnwcEBGjQoEHs5y5w6dIlvf7663rggQfk5eXlnM6+7Xq12ZfT0tJks9kqzNO+fXvFxcWxv7vAhQsX5OXlpZYtW1aY/sYbbygsLEzdunXT1KlTOep9BWp672D/rh+nT5/Wv//9b40fP77SY+zbdffDz3xWv3f7XukGoPZycnJkt9sVHh5eYXp4eLhOnTrlpqoaH4fDocmTJ6t///6Ki4tzTh82bJh+/vOfKyoqSocOHdJTTz2lm2++WWlpaQoICHBjxQ1P7969tWLFCl133XU6ffq0Zs+erb59++qrr75y7stV7edHjhxxR7mNytq1a3X+/Hndd999zmns2/WjNvvyqVOn5O/vr6uuuqrSPLyvX5mLFy9q2rRpGjt2rEJCQpzT77nnHkVHR6tdu3b68ssvNX36dP3nP/9xnv6K2rvcewf7d/147bXX1KJFC91xxx0VprNv111Vn/msfu8mTLnB9/+aLJXtCD+cBnOPPPKIvvjiC23evLnC9DFjxji/j4uLU0JCgqKiovTvf/+70hsaajZs2DDn9927d1diYqJiYmL02muvOS9eZj+vH0uXLtWwYcPUvn175zT27fplsi+zv18Zm82mu+66S6WlpVq4cGGFxx566CHn93Fxcbr22muVkJCgXbt2qWfPnlaX2qCZvnewf1+ZZcuW6Z577lGzZs0qTGffrrvqPvNJ1r13c5qfhcLCwuTj41Mp8WZnZ1dKzzDz6KOP6t1339WGDRvUsWPHGueNiIhQVFSUvvnmG4uqa7yCg4PVvXt3ffPNN85R/djPXe/IkSP66KOP9OCDD9Y4H/u2a9RmX27Xrp0uXbqkc+fOVTsP6sZms2n06NE6dOiQUlJSKhyVqkrPnj3l5+fH/u4CP3zvYP92vU2bNikjI+Oy7+MS+/blVPeZz+r3bsKUhfz9/RUfH1/pcG1KSor69u3rpqoaB4fDoUceeURr1qzRJ598oujo6Msuc/bsWR07dkwREREWVNi4FRcXa+/evYqIiHCeovD9/fzSpUtKTU1lP79Cf/3rX9W2bVv99Kc/rXE+9m3XqM2+HB8fLz8/vwrzZGVl6csvv2R/N1AepL755ht99NFHat269WWX+eqrr2Sz2djfXeCH7x3s3663dOlSxcfH64YbbrjsvOzbVbvcZz7L37tNR86AmVWrVjn8/PwcS5cudXz99deOSZMmOYKDgx2HDx92d2kN2v/7f//PERoa6ti4caMjKyvL+VVYWOhwOByOvLw8x5QpUxxbt251HDp0yLFhwwZHYmKio0OHDo7c3Fw3V9/wTJkyxbFx40bHwYMHHdu3b3cMHz7c0aJFC+d+/Ic//MERGhrqWLNmjSM9Pd1x9913OyIiIuj1FbDb7Y6rr77a8dvf/rbCdPbtK5OXl+fYvXu3Y/fu3Q5Jjnnz5jl2797tHD2uNvvyhAkTHB07dnR89NFHjl27djluvvlmxw033OAoKSlx12Z5rJr6bbPZHLfddpujY8eOjj179lR4Ly8uLnY4HA5HZmamY+bMmY7PP//ccejQIce///1vR2xsrOPGG2+k31Woqd+1fe9g/66dy72XOBwOx4ULFxxBQUGORYsWVVqefbv2LveZz+Gw9r2bMOUGr7zyiiMqKsrh7+/v6NmzZ4Xhu2FGUpVff/3rXx0Oh8NRWFjoSEpKcrRp08bh5+fnuPrqqx333nuv4+jRo+4tvIEaM2aMIyIiwuHn5+do376944477nB89dVXzsdLS0sdTz/9tKNdu3aOgIAAx8CBAx3p6elurLjh++CDDxySHBkZGRWms29fmQ0bNlT53nHvvfc6HI7a7ctFRUWORx55xNGqVStHYGCgY/jw4fS/GjX1+9ChQ9W+l2/YsMHhcDgcR48edQwcONDRqlUrh7+/vyMmJsbx61//2nH27Fn3bpiHqqnftX3vYP+uncu9lzgcDsfixYsdgYGBjvPnz1dann279i73mc/hsPa92+u7ogAAAAAAdcA1UwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABggDAFAAAAAAYIUwAAAABg4P8DeTBtPGvUeAUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "pd.DataFrame(KL_data_all, index = df[\"Quantized Top1 Accuracy\"]).T.boxplot(vert = False, positions = df[\"Quantized Top1 Accuracy\"] * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0724d809-8a16-40f1-aad0-cd9252c5c0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[\"Classes Repeated\"] = new_col\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e9939a-6dcb-4678-8a83-9ad2ba3012bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../logs/Quantization_Log_Subsets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3593c-43f4-4388-9121-057b93a9b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00626567-9b3d-40c0-981e-484ed7d33fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3058420-34ee-470e-a70b-492d24039904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7102e16-7f17-4da8-b66c-ff7d8260d341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Quantization Batch Size</th>\n",
       "      <th>Original Top1 Accuracy</th>\n",
       "      <th>Quantized Top1 Accuracy</th>\n",
       "      <th>Original Top5 Accuracy</th>\n",
       "      <th>Quantized Top5 Accuracy</th>\n",
       "      <th>Bits</th>\n",
       "      <th>MLP_Alphabet_Scalar</th>\n",
       "      <th>CNN_Alphabet_Scalar</th>\n",
       "      <th>...</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Subset_Inds</th>\n",
       "      <th>Subset_Classes</th>\n",
       "      <th>Max_KL</th>\n",
       "      <th>Min_KL</th>\n",
       "      <th>Avg_KL</th>\n",
       "      <th>Classes Repeated</th>\n",
       "      <th>Trained Top1 Accuracy</th>\n",
       "      <th>Trained Top5 Accuracy</th>\n",
       "      <th>Median_KL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 12, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'bridge', 'mountain', 'o...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.940139</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 49, 52, 53, 20, 62, 58, 59, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'mountain', 'oak_tree', ...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>69.604010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.999</td>\n",
       "      <td>66.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 49, 52, 53, 20, 62, 58, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.544018</td>\n",
       "      <td>73.300755</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>66.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 39, 71, 15, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'keyboard', 'sea', 'camel', 'oak_tre...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.423650</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.000</td>\n",
       "      <td>50.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.994</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 39, 49, 52, 53, 62, 58, 61, 94]</td>\n",
       "      <td>['apple', 'bed', 'keyboard', 'mountain', 'oak_...</td>\n",
       "      <td>192.253176</td>\n",
       "      <td>0.844140</td>\n",
       "      <td>68.367547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>55.650079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name   Dataset  Quantization Batch Size  Original Top1 Accuracy  \\\n",
       "0      vgg16  CIFAR100                       64                   0.887   \n",
       "1      vgg16  CIFAR100                       64                   0.861   \n",
       "2      vgg16  CIFAR100                       64                   0.884   \n",
       "3      vgg16  CIFAR100                       64                   0.879   \n",
       "4      vgg16  CIFAR100                       64                   0.872   \n",
       "\n",
       "   Quantized Top1 Accuracy  Original Top5 Accuracy  Quantized Top5 Accuracy  \\\n",
       "0                    0.935                   0.989                    0.991   \n",
       "1                    0.902                   0.987                    0.989   \n",
       "2                    0.960                   0.991                    0.996   \n",
       "3                    0.953                   0.987                    0.994   \n",
       "4                    0.952                   0.986                    0.994   \n",
       "\n",
       "   Bits  MLP_Alphabet_Scalar  CNN_Alphabet_Scalar  ...  Seed  \\\n",
       "0     4                 1.16                 1.16  ...     0   \n",
       "1     4                 1.16                 1.16  ...     0   \n",
       "2     4                 1.16                 1.16  ...     0   \n",
       "3     4                 1.16                 1.16  ...     0   \n",
       "4     4                 1.16                 1.16  ...     0   \n",
       "\n",
       "                               Subset_Inds  \\\n",
       "0  [0, 39, 12, 49, 52, 53, 20, 62, 58, 94]   \n",
       "1  [0, 39, 49, 52, 53, 20, 62, 58, 59, 94]   \n",
       "2  [0, 39, 71, 49, 52, 53, 20, 62, 58, 94]   \n",
       "3  [0, 39, 71, 15, 52, 53, 62, 58, 61, 94]   \n",
       "4   [0, 5, 39, 49, 52, 53, 62, 58, 61, 94]   \n",
       "\n",
       "                                      Subset_Classes      Max_KL    Min_KL  \\\n",
       "0  ['apple', 'keyboard', 'bridge', 'mountain', 'o...  192.253176  0.844140   \n",
       "1  ['apple', 'keyboard', 'mountain', 'oak_tree', ...  192.253176  0.844140   \n",
       "2  ['apple', 'keyboard', 'sea', 'mountain', 'oak_...  192.253176  0.544018   \n",
       "3  ['apple', 'keyboard', 'sea', 'camel', 'oak_tre...  192.253176  0.844140   \n",
       "4  ['apple', 'bed', 'keyboard', 'mountain', 'oak_...  192.253176  0.844140   \n",
       "\n",
       "      Avg_KL  Classes Repeated  Trained Top1 Accuracy  Trained Top5 Accuracy  \\\n",
       "0  68.940139             False                  0.982                  0.999   \n",
       "1  69.604010             False                  0.955                  0.999   \n",
       "2  73.300755             False                  0.975                  1.000   \n",
       "3  68.423650             False                  0.988                  1.000   \n",
       "4  68.367547             False                  0.983                  1.000   \n",
       "\n",
       "   Median_KL  \n",
       "0  66.980437  \n",
       "1  66.877609  \n",
       "2  66.980437  \n",
       "3  50.328013  \n",
       "4  55.650079  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../logs/Quantization_Log_Subsets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "621a9e36-75ad-4db7-9d8e-305ecfec26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.2246467991473532e-16, 6.123233995736766e-17, 1.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "cmap = colormaps['rainbow']\n",
    "cmap(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76a2bb79-4fe0-4df9-9351-cb23d4b65bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f06af688250>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    plt.plot(df.iloc[i][[\"Min_KL\", \"Max_KL\"]], [df.iloc[i][\"Quantized Top1 Accuracy\"]] * 2, color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Min_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "    plt.plot([df.iloc[i][\"Max_KL\"]] * 2, [df.iloc[i][\"Quantized Top1 Accuracy\"] - 0.005, df.iloc[i][\"Quantized Top1 Accuracy\"] + 0.005], color = cmap(i / df.shape[0]))\n",
    "\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2893aa5-9b2c-4525-8c3c-bc28cfdedd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(100):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55237b84-05ed-4ff2-a023-3f101f4545a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(100):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "072a7807-ef35-47de-807e-713dcf873518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/3828107680.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(100):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "274ac53e-686d-4568-ba5d-350eea5bbe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Avg_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Average KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized EfficientNet On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e647349-11a1-48f2-bb7f-80b685680da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return (a * np.log(b * x)) + c\n",
    "\n",
    "X, y = df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_1 = []\n",
    "for i in range(80):\n",
    "    fitted_line_1 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fc909a7-7edb-48b6-a0ad-876549adac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Original Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_5 = []\n",
    "for i in range(80):\n",
    "    fitted_line_5 += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b67a379b-ea0d-41f1-8e05-11ab681a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213/1040412974.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return (a * np.log(b * x)) + c\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"]\n",
    "\n",
    "coefs, pcov = curve_fit(func, X, y)\n",
    "\n",
    "fitted_line_ = []\n",
    "for i in range(80):\n",
    "    fitted_line_ += [func(i, *coefs).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57a59db2-c5d9-448d-bd08-831468fc95f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Quantized Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_1)), fitted_line_1, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Original Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_5)), fitted_line_5, '--')\n",
    "plt.scatter(df[\"Median_KL\"], df[\"Trained Top1 Accuracy\"], s = 5)\n",
    "plt.plot(range(len(fitted_line_)), fitted_line_, '--')\n",
    "plt.xlabel(\"Median KL Divergence\")\n",
    "plt.ylabel(\"Quantized Accuracy\")\n",
    "plt.title(\"Performance Of GPFQ-Quantized EfficientNet On 10-Class CIFAR100 Subsets\", fontsize = 12)\n",
    "leg = plt.legend([\"Top-1\", \"-> fitted curve\", \"Top-1 (Original)\", \"-> fitted curve\",  \"Top-1 (Trained)\", \"-> fitted curve\"])\n",
    "plt.savefig(\"./imgs/vgg16_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973c463-7a01-4b31-81d8-98ff135a4621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
